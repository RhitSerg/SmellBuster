<classes>	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.QueryPlan$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>28</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.HadoopShimsSecure$InputSplitShim</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>15</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>0.3333333333333333</lcom3>
		<loc>65</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3142857142857143</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.mapred.lib.CombineFileSplit old)">0</method>
			<method name="public void shrinkSplit(long length)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void write(java.io.DataOutput out)">1</method>
			<method name="public long getShrinkedLength()">1</method>
			<method name="public boolean isShrinked()">1</method>
			<method name="public void readFields(java.io.DataInput in)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFContextNGrams$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>61</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>58.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.classification.InterfaceStability$Unstable</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyByte</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>11</cbo>
		<rfc>15</rfc>
		<lcom>4</lcom>
		<ca>5</ca>
		<ce>7</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>76</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.36666666666666664</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.2</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyByteObjectInspector oi)">0</method>
			<method name="public static byte parseByte(byte[] bytes, int start, int length)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.LazyByte copy)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
			<method name="public static byte parseByte(byte[] bytes, int start, int length, int radix)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryUtils$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>117</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>114.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyTimestampObjectInspector</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>9</rfc>
		<lcom>10</lcom>
		<ca>3</ca>
		<ce>7</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>37</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.9</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.4</amc>
		<cc>
			<method name="protected void _init_()">0</method>
			<method name="public volatile org.apache.hadoop.hive.serde2.io.TimestampWritable getPrimitiveWritableObject(Object x0)">1</method>
			<method name="public volatile Object getPrimitiveJavaObject(Object x0)">1</method>
			<method name="public Object copyObject(Object o)">2</method>
			<method name="public java.sql.Timestamp getPrimitiveJavaObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TFileTransport$truncableBufferedInputStream</name>
		<wmc>3</wmc>
		<dit>4</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>5</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>19</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.967741935483871</mfa>
		<cam>0.6666666666666666</cam>
		<ic>1</ic>
		<cbm>5</cbm>
		<amc>5.333333333333333</amc>
		<cc>
			<method name="public void _init_(java.io.InputStream in, int size)">0</method>
			<method name="public void trunc()">1</method>
			<method name="public void _init_(java.io.InputStream in)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ppr.ExprProcFactory$DefaultExprProcessor</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>8</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>37</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$uniqueJoinToken_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$selectExpressionList_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.Query$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>63</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>61.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Jetty20SShims$Server</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>15</rfc>
		<lcom>6</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>45</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.25</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public void addWar(String war, String contextPath)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.shims.Jetty20SShims$1 x0)">0</method>
			<method name="public void setupListenerHostPort(String listen, int port)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.AutoExpandingBuffer</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>3</npm>
		<lcom3>0.25</lcom3>
		<loc>53</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.0</amc>
		<cc>
			<method name="public byte[] array()">1</method>
			<method name="public void resizeIfNecessary(int size)">2</method>
			<method name="public void _init_(int initialCapacity, double growthCoefficient)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.JoinCondDesc</name>
		<wmc>13</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>25</rfc>
		<lcom>22</lcom>
		<ca>10</ca>
		<ce>3</ce>
		<npm>12</npm>
		<lcom3>0.8055555555555555</lcom3>
		<loc>179</loc>
		<dam>0.8333333333333334</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.307692307692308</amc>
		<cc>
			<method name="public void setType(int type)">1</method>
			<method name="public String getJoinCondString()">2</method>
			<method name="public void setLeft(int left)">1</method>
			<method name="public boolean getPreserved()">1</method>
			<method name="public void _init_(int left, int right, int type)">0</method>
			<method name="public void setRight(int right)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void setPreserved(boolean preserved)">1</method>
			<method name="public int getType()">1</method>
			<method name="public int getRight()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.parse.JoinCond condn)">0</method>
			<method name="public int getLeft()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.TableDesc</name>
		<wmc>20</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>61</cbo>
		<rfc>33</rfc>
		<lcom>98</lcom>
		<ca>59</ca>
		<ce>3</ce>
		<npm>20</npm>
		<lcom3>0.8345864661654135</lcom3>
		<loc>186</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.28</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.95</amc>
		<cc>
			<method name="public boolean isNonNative()">2</method>
			<method name="public Object clone()">3</method>
			<method name="public void _init_()">0</method>
			<method name="public String getOutputFileFormatClassName()">1</method>
			<method name="public Class getOutputFileFormatClass()">1</method>
			<method name="public void setOutputFileFormatClass(Class outputFileFormatClass)">1</method>
			<method name="public Class getInputFileFormatClass()">1</method>
			<method name="public void setProperties(java.util.Properties properties)">1</method>
			<method name="public Class getDeserializerClass()">1</method>
			<method name="public void setInputFileFormatClass(Class inputFileFormatClass)">1</method>
			<method name="public String getTableName()">1</method>
			<method name="public void setJobProperties(java.util.Map jobProperties)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.Deserializer getDeserializer()">1</method>
			<method name="public java.util.Properties getProperties()">1</method>
			<method name="public String getSerdeClassName()">1</method>
			<method name="public void setDeserializerClass(Class serdeClass)">1</method>
			<method name="public java.util.Map getJobProperties()">1</method>
			<method name="public void _init_(Class serdeClass, Class inputFileFormatClass, Class class1, java.util.Properties properties)">0</method>
			<method name="public String getInputFileFormatClassName()">1</method>
			<method name="public void setSerdeClassName(String serdeClassName)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.ByteStream$Output</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>6</rfc>
		<lcom>6</lcom>
		<ca>14</ca>
		<ce>1</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>17</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.25</amc>
		<cc>
			<method name="public byte[] getData()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(int size)">0</method>
			<method name="public int getCount()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$lockStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.ImportSemanticAnalyzer</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>44</cbo>
		<rfc>160</rfc>
		<lcom>20</lcom>
		<ca>2</ca>
		<ce>42</ce>
		<npm>3</npm>
		<lcom3>0.75</lcom3>
		<loc>1391</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.21296296296296297</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>153.44444444444446</amc>
		<cc>
			<method name="public void analyzeInternal(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Task loadTable(java.net.URI fromURI, org.apache.hadoop.hive.ql.metadata.Table table)">1</method>
			<method name="private void checkTargetLocationEmpty(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path targetPath)">1</method>
			<method name="public boolean existsTable()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.conf.HiveConf conf)">0</method>
			<method name="private static String checkParams(java.util.Map map1, java.util.Map map2, String[] keys)">8</method>
			<method name="private static void checkTable(org.apache.hadoop.hive.ql.metadata.Table table, org.apache.hadoop.hive.ql.plan.CreateTableDesc tableDesc)">1</method>
			<method name="private static String partSpecToString(java.util.Map partSpec)">3</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Task addSinglePartition(java.net.URI fromURI, org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.hive.ql.plan.CreateTableDesc tblDesc, org.apache.hadoop.hive.ql.metadata.Table table, org.apache.hadoop.hive.metastore.Warehouse wh, org.apache.hadoop.hive.ql.plan.AddPartitionDesc addPartitionDesc)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFDateSub</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>16</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>0.0</lcom3>
		<loc>93</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>29.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text dateString1, org.apache.hadoop.io.IntWritable days)">3</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable t, org.apache.hadoop.io.IntWritable days)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$columnNameComment_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDTFExplode$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>21</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>42</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>40.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.LimitOperator</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>14</rfc>
		<lcom>9</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>5</npm>
		<lcom3>0.8400000000000001</lcom3>
		<loc>80</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.5</amc>
		<cc>
			<method name="public void closeOp(boolean abort)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void processOp(Object row, int tag)">1</method>
			<method name="public String getName()">1</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.SelectDesc</name>
		<wmc>14</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>15</rfc>
		<lcom>51</lcom>
		<ca>8</ca>
		<ce>0</ce>
		<npm>14</npm>
		<lcom3>0.7846153846153846</lcom3>
		<loc>93</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5714285714285714</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.285714285714286</amc>
		<cc>
			<method name="public void setColList(java.util.ArrayList colList)">1</method>
			<method name="public void _init_(java.util.ArrayList colList, java.util.ArrayList outputColumnNames)">0</method>
			<method name="public void _init_(java.util.ArrayList colList, boolean selectStar, boolean selStarNoCompute)">0</method>
			<method name="public java.util.ArrayList getOutputColumnNames()">1</method>
			<method name="public void _init_(java.util.ArrayList colList, java.util.ArrayList outputColumnNames, boolean selectStar)">0</method>
			<method name="public void setSelStarNoCompute(boolean selStarNoCompute)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setSelectStar(boolean selectStar)">1</method>
			<method name="public boolean isSelStarNoCompute()">1</method>
			<method name="public void _init_(boolean selStarNoCompute)">0</method>
			<method name="public java.util.ArrayList getColList()">1</method>
			<method name="public void setOutputColumnNames(java.util.ArrayList outputColumnNames)">1</method>
			<method name="public boolean isSelectStar()">1</method>
			<method name="public String explainNoCompute()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.package-info</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.FileSinkOperator$TableIdEnum</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9791666666666666</lcom3>
		<loc>188</loc>
		<dam>0.0625</dam>
		<moa>16</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>42.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.FileSinkOperator$TableIdEnum[] values()">1</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.FileSinkOperator$TableIdEnum valueOf(String name)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>30</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>28</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.hadoop.io.Text getPrimitiveWritableObject(Object)">1</method>
			<method name="public abstract String getPrimitiveJavaObject(Object)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.AbstractSemanticAnalyzerHook</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>4</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.0</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.parse.ASTNode preAnalyze(org.apache.hadoop.hive.ql.parse.HiveSemanticAnalyzerHookContext context, org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void postAnalyze(org.apache.hadoop.hive.ql.parse.HiveSemanticAnalyzerHookContext context, java.util.List rootTasks)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFLike$PatternType</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9444444444444443</lcom3>
		<loc>78</loc>
		<dam>0.16666666666666666</dam>
		<moa>6</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>17.0</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.udf.UDFLike$PatternType valueOf(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.udf.UDFLike$PatternType[] values()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.unionproc.UnionProcFactory$NoUnion</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>7</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$ifExists_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarStruct</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>12</rfc>
		<lcom>6</lcom>
		<ca>1</ca>
		<ce>11</ce>
		<npm>1</npm>
		<lcom3>1.0</lcom3>
		<loc>52</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.75</amc>
		<cc>
			<method name="protected int getLength(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objectInspector, org.apache.hadoop.hive.serde2.lazy.ByteArrayRef cachedByteArrayRef, int start, int length)">6</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, java.util.ArrayList notSkippedColumnIDs)">0</method>
			<method name="protected org.apache.hadoop.hive.serde2.lazy.LazyObjectBase createLazyObjectBase(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objectInspector)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>52</cbo>
		<rfc>27</rfc>
		<lcom>1</lcom>
		<ca>17</ca>
		<ce>38</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>179</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>88.5</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters$Converter getConverter(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector inputOI, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector outputOI)">6</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPEqual$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>56</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>54.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.errors.TaskLogProcessor$HeuristicStats</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>8</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>0.5</lcom3>
		<loc>37</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.0</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="int getTriggerCount()">1</method>
			<method name="void addErrorAndSolution(org.apache.hadoop.hive.ql.exec.errors.ErrorAndSolution e)">1</method>
			<method name="java.util.List getErrorAndSolutions()">1</method>
			<method name="void incTriggerCount()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.history.HiveHistory$SessionInfo</name>
		<wmc>1</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyFloat</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>11</cbo>
		<rfc>18</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>9</ce>
		<npm>3</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>74</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>17.25</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyFloatObjectInspector oi)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.LazyFloat copy)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.UnlockTableDesc</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>7</rfc>
		<lcom>3</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>6</npm>
		<lcom3>0.8</lcom3>
		<loc>35</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.333333333333333</amc>
		<cc>
			<method name="public void _init_(String tableName, java.util.Map partSpec)">0</method>
			<method name="public String getTableName()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setTableName(String tableName)">1</method>
			<method name="public void setPartSpec(java.util.Map partSpec)">1</method>
			<method name="public java.util.Map getPartSpec()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.SamplePruner$SamplePrunerCtx</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>3</npm>
		<lcom3>0.0</lcom3>
		<loc>17</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.333333333333333</amc>
		<cc>
			<method name="public java.util.HashMap getOpToSamplePruner()">1</method>
			<method name="public void _init_(java.util.HashMap opToSamplePruner)">0</method>
			<method name="public void setOpToSamplePruner(java.util.HashMap opToSamplePruner)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.SortedMergeBucketMapJoinOptimizer$1</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>1</npm>
		<lcom3>1.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.ql.optimizer.SortedMergeBucketMapJoinOptimizer)">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNotNull</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>15</rfc>
		<lcom>6</lcom>
		<ca>0</ca>
		<ce>9</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>69</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.4</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFIf</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>22</rfc>
		<lcom>6</lcom>
		<ca>0</ca>
		<ce>12</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>213</loc>
		<dam>0.6666666666666666</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>41.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFIn</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>37</rfc>
		<lcom>3</lcom>
		<ca>0</ca>
		<ce>17</ce>
		<npm>4</npm>
		<lcom3>0.6904761904761904</lcom3>
		<loc>468</loc>
		<dam>0.42857142857142855</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.4166666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>64.85714285714286</amc>
		<cc>
			<method name="private void checkIfInSetConstant()">3</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">5</method>
			<method name="private void prepareInSet(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.HiveInterruptUtils</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>19</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>5</npm>
		<lcom3>0.4</lcom3>
		<loc>98</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.166666666666666</amc>
		<cc>
			<method name="public static void interrupt()">2</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.common.HiveInterruptCallback add(org.apache.hadoop.hive.common.HiveInterruptCallback command)">1</method>
			<method name="public static org.apache.hadoop.hive.common.HiveInterruptCallback remove(org.apache.hadoop.hive.common.HiveInterruptCallback command)">1</method>
			<method name="public static void checkInterrupted()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.MetadataOnlyOptimizer$FileSinkProcessor</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>14</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>53</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4444444444444444</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.666666666666668</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.optimizer.physical.MetadataOnlyOptimizer$1 x0)">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFLog2</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>8</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>37</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.666666666666666</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable a)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeFieldRequiredness</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>5</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>3</ce>
		<npm>3</npm>
		<lcom3>1.0</lcom3>
		<loc>16</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeFieldRequiredness$RequirednessTypes getRequiredness()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.TEnumHelper</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>6</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>36</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>17.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public static org.apache.thrift.TEnum getByValue(Class enumClass, int value)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.SelectOperator</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>21</cbo>
		<rfc>26</rfc>
		<lcom>11</lcom>
		<ca>10</ca>
		<ce>11</ce>
		<npm>4</npm>
		<lcom3>0.9</lcom3>
		<loc>174</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>27.333333333333332</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void processOp(Object row, int tag)">1</method>
			<method name="public String getName()">1</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.LocalMapJoinProcFactory$1</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>7</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.5</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.StandardConstantListObjectInspector</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>17</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.333333333333333</amc>
		<cc>
			<method name="public volatile Object getWritableConstantValue()">1</method>
			<method name="public java.util.List getWritableConstantValue()">1</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector listElementObjectInspector, java.util.List value)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ExprNodeEvaluatorFactory</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>21</cbo>
		<rfc>13</rfc>
		<lcom>1</lcom>
		<ca>11</ca>
		<ce>12</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>62</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>30.0</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator get(org.apache.hadoop.hive.ql.plan.ExprNodeDesc desc)">6</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TSocket</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>29</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>4</ce>
		<npm>8</npm>
		<lcom3>0.39999999999999997</lcom3>
		<loc>249</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4166666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>23.4</amc>
		<cc>
			<method name="public void _init_(String host, int port)">0</method>
			<method name="public boolean isOpen()">2</method>
			<method name="private void initSocket()">1</method>
			<method name="public void open()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void close()">2</method>
			<method name="public void setTimeout(int timeout)">1</method>
			<method name="public void _init_(String host, int port, int timeout)">0</method>
			<method name="public java.net.Socket getSocket()">2</method>
			<method name="public void _init_(java.net.Socket socket)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFSum$GenericUDAFSumLong$SumLongAgg</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>6</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeHeader</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.CodecPool</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>28</rfc>
		<lcom>14</lcom>
		<ca>3</ca>
		<ce>5</ce>
		<npm>4</npm>
		<lcom3>0.7142857142857143</lcom3>
		<loc>183</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.1836734693877551</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>21.5</amc>
		<cc>
			<method name="public static void returnCompressor(org.apache.hadoop.io.compress.Compressor compressor)">2</method>
			<method name="private void _init_()">0</method>
			<method name="private static void payback(java.util.Map pool, Object codec)">3</method>
			<method name="private static Object borrow(java.util.Map pool, Class codecClass)">4</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static void returnDecompressor(org.apache.hadoop.io.compress.Decompressor decompressor)">2</method>
			<method name="public static org.apache.hadoop.io.compress.Decompressor getDecompressor(org.apache.hadoop.io.compress.CompressionCodec codec)">2</method>
			<method name="public static org.apache.hadoop.io.compress.Compressor getCompressor(org.apache.hadoop.io.compress.CompressionCodec codec)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDTFJSONTuple</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>32</rfc>
		<lcom>7</lcom>
		<ca>0</ca>
		<ce>17</ce>
		<npm>5</npm>
		<lcom3>0.76</lcom3>
		<loc>338</loc>
		<dam>0.1</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>53.666666666666664</amc>
		<cc>
			<method name="public void process(Object[] o)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void close()">1</method>
			<method name="public String toString()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] args)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$principalName_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeUnflagArgs</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server$TUGIAssumingTransportFactory</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>9</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>53</loc>
		<dam>0.6666666666666666</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.5</amc>
		<cc>
			<method name="public void _init_(org.apache.thrift.transport.TTransportFactory wrapped, org.apache.hadoop.security.UserGroupInformation ugi)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="static org.apache.thrift.transport.TTransportFactory access$100(org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server$TUGIAssumingTransportFactory x0)">1</method>
			<method name="public org.apache.thrift.transport.TTransport getTransport(org.apache.thrift.transport.TTransport trans)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.ppd.OpProcFactory$LateralViewForwardPPD</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>13</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>43</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>20.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$kwUser_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.SkewJoinResolver$SkewJoinTaskDispatcher</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>20</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>18</ce>
		<npm>4</npm>
		<lcom3>0.5</lcom3>
		<loc>88</loc>
		<dam>0.5</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.4166666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>20.5</amc>
		<cc>
			<method name="public transient Object dispatch(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, Object[] nodeOutputs)">1</method>
			<method name="public org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext getPhysicalContext()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.optimizer.physical.SkewJoinResolver, org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext context)">0</method>
			<method name="public void setPhysicalContext(org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext physicalContext)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFOPPlus</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>20</rfc>
		<lcom>21</lcom>
		<ca>0</ca>
		<ce>7</ce>
		<npm>7</npm>
		<lcom3>2.0</lcom3>
		<loc>114</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2653061224489796</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.285714285714286</amc>
		<cc>
			<method name="public org.apache.hadoop.io.FloatWritable evaluate(org.apache.hadoop.io.FloatWritable a, org.apache.hadoop.io.FloatWritable b)">3</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.hive.serde2.io.ByteWritable a, org.apache.hadoop.hive.serde2.io.ByteWritable b)">3</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable a, org.apache.hadoop.hive.serde2.io.DoubleWritable b)">3</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.hive.serde2.io.ShortWritable a, org.apache.hadoop.hive.serde2.io.ShortWritable b)">3</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.LongWritable a, org.apache.hadoop.io.LongWritable b)">3</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.IntWritable a, org.apache.hadoop.io.IntWritable b)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.IOContext</name>
		<wmc>26</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>30</rfc>
		<lcom>231</lcom>
		<ca>7</ca>
		<ce>2</ce>
		<npm>25</npm>
		<lcom3>0.9033333333333333</lcom3>
		<loc>202</loc>
		<dam>0.08333333333333333</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.28</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.3076923076923075</amc>
		<cc>
			<method name="public void setComparison(Integer comparison)">6</method>
			<method name="public void setCurrentRow(long currentRow)">1</method>
			<method name="public long getNextBlockStart()">1</method>
			<method name="public boolean shouldEndBinarySearch()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public boolean getIOExceptions()">1</method>
			<method name="public void setUseSorted(boolean useSorted)">1</method>
			<method name="public long getCurrentBlockStart()">1</method>
			<method name="public void setCurrentBlockStart(long currentBlockStart)">1</method>
			<method name="public org.apache.hadoop.hive.ql.io.IOContext$Comparison getComparison()">1</method>
			<method name="public void setGenericUDFClassName(String genericUDFClassName)">1</method>
			<method name="public void resetSortingValues()">1</method>
			<method name="public void setBlockPointer(boolean isBlockPointer)">1</method>
			<method name="public void setIsBinarySearching(boolean isBinarySearching)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setNextBlockStart(long nextBlockStart)">1</method>
			<method name="public void setInputFile(String inputFile)">1</method>
			<method name="public void setIOExceptions(boolean ioe)">1</method>
			<method name="public boolean isBinarySearching()">1</method>
			<method name="public void setEndBinarySearch(boolean endBinarySearch)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.io.IOContext get()">1</method>
			<method name="public boolean useSorted()">1</method>
			<method name="public String getGenericUDFClassName()">1</method>
			<method name="public long getCurrentRow()">1</method>
			<method name="public String getInputFile()">1</method>
			<method name="public boolean isBlockPointer()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.GenMRProcContext$GenMapRedCtx</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>6</rfc>
		<lcom>4</lcom>
		<ca>12</ca>
		<ce>2</ce>
		<npm>5</npm>
		<lcom3>0.75</lcom3>
		<loc>32</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.8</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public String getCurrAliasId()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.Task currTask, org.apache.hadoop.hive.ql.exec.Operator currTopOp, String currAliasId)">0</method>
			<method name="public org.apache.hadoop.hive.ql.exec.Operator getCurrTopOp()">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.Task getCurrTask()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.AddPartitionDesc</name>
		<wmc>33</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>35</rfc>
		<lcom>404</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>33</npm>
		<lcom3>0.900390625</lcom3>
		<loc>241</loc>
		<dam>0.0625</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.22943722943722944</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.818181818181818</amc>
		<cc>
			<method name="public int getNumBuckets()">1</method>
			<method name="public void setSerdeParams(java.util.Map serdeParams)">1</method>
			<method name="public void setInputFormat(String inputFormat)">1</method>
			<method name="public java.util.List getSortCols()">1</method>
			<method name="public void setPartParams(java.util.Map partParams)">1</method>
			<method name="public java.util.List getCols()">1</method>
			<method name="public void _init_(String dbName, String tableName, java.util.Map partSpec, String location, boolean ifNotExists, boolean expectView)">0</method>
			<method name="public String getTableName()">1</method>
			<method name="public void setPartSpec(java.util.LinkedHashMap partSpec)">1</method>
			<method name="public void setLocation(String location)">1</method>
			<method name="public java.util.LinkedHashMap getPartSpec()">1</method>
			<method name="public void setTableName(String tableName)">1</method>
			<method name="public String getInputFormat()">1</method>
			<method name="public String getLocation()">1</method>
			<method name="public String getSerializationLib()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(String dbName, String tableName, java.util.Map partSpec, String location, java.util.Map params)">0</method>
			<method name="public java.util.List getBucketCols()">1</method>
			<method name="public boolean getExpectView()">1</method>
			<method name="public void setDbName(String dbName)">1</method>
			<method name="public void setIfNotExists(boolean ifNotExists)">1</method>
			<method name="public java.util.Map getPartParams()">1</method>
			<method name="public java.util.Map getSerdeParams()">1</method>
			<method name="public void setOutputFormat(String outputFormat)">1</method>
			<method name="public String getDbName()">1</method>
			<method name="public boolean getIfNotExists()">1</method>
			<method name="public void setSerializationLib(String serializationLib)">1</method>
			<method name="public void setCols(java.util.List cols)">1</method>
			<method name="public void setSortCols(java.util.List sortCols)">1</method>
			<method name="public String getOutputFormat()">1</method>
			<method name="public void setBucketCols(java.util.List bucketCols)">1</method>
			<method name="public void setNumBuckets(int numBuckets)">1</method>
			<method name="public void setExpectView(boolean expectView)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.formatting.MapBuilder</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>14</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>7</npm>
		<lcom3>0.0</lcom3>
		<loc>70</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.625</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.formatting.MapBuilder put(String name, boolean val)">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.formatting.MapBuilder put(String name, Object val, boolean use)">2</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.formatting.MapBuilder put(String name, int val)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.metadata.formatting.MapBuilder create()">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.formatting.MapBuilder put(String name, long val)">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.formatting.MapBuilder put(String name, Object val)">2</method>
			<method name="public java.util.Map build()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$trfmClause_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.Driver$1</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ShowDatabasesDesc</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>11</rfc>
		<lcom>14</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>9</npm>
		<lcom3>0.925</lcom3>
		<loc>55</loc>
		<dam>0.6</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5185185185185185</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.555555555555555</amc>
		<cc>
			<method name="public void setPattern(String pattern)">1</method>
			<method name="public void _init_(org.apache.hadoop.fs.Path resFile, String pattern)">0</method>
			<method name="public String getResFile()">1</method>
			<method name="public String getSchema()">1</method>
			<method name="public String getTable()">1</method>
			<method name="public void setResFile(String resFile)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(org.apache.hadoop.fs.Path resFile)">0</method>
			<method name="public String getPattern()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.xml.UDFXPathLong</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>18</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public long evaluate(String xml, String path)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TList</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>18</ca>
		<ce>0</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>18</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(byte t, int s)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TJSONProtocol$Factory</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>10</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.thrift.protocol.TProtocol getProtocol(org.apache.thrift.transport.TTransport trans)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar</name>
		<wmc>69</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>61</cbo>
		<rfc>164</rfc>
		<lcom>0</lcom>
		<ca>52</ca>
		<ce>57</ce>
		<npm>61</npm>
		<lcom3>0.6331269349845201</lcom3>
		<loc>6268</loc>
		<dam>0.7894736842105263</dam>
		<moa>5</moa>
		<mfa>0.0</mfa>
		<cam>0.1323529411764706</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>89.56521739130434</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.dynamic_type.ParseException generateParseException()">11</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode FlagArgs()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode ConstValue()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode Xception()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode EnumDefList()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode ConstMap()">1</method>
			<method name="private static void jj_la1_init_1()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode Definition()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeFieldRequiredness FieldRequiredness()">1</method>
			<method name="private static void jj_la1_init_0()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode ConstMapContents()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeFunction Function()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode Start()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode Namespace()">1</method>
			<method name="public final void Throws()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypedef Typedef()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeByte TypeByte()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypei64 Typei64()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.Token getToken(int index)">3</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode Const()">1</method>
			<method name="protected void _init_(java.io.InputStream is, java.util.List include_path, boolean junk)">0</method>
			<method name="public void ReInit(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammarTokenManager tm)">2</method>
			<method name="private static java.io.File findFile(String fname, java.util.List include_path)">2</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode DefinitionType()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypei32 Typei32()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeStruct Struct()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeMap TypeMap()">1</method>
			<method name="public void ReInit(java.io.InputStream stream, String encoding)">2</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode TypeDefinition()">1</method>
			<method name="public void _init_(java.io.InputStream stream, String encoding)">0</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode SenumDefList()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode HeaderList()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeFieldList FieldList()">1</method>
			<method name="public final void disable_tracing()">1</method>
			<method name="public void ReInit(java.io.Reader stream)">2</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypei16 Typei16()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode Include()">1</method>
			<method name="public final void Async()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeList TypeList()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeString TypeString()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode Enum()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode Header()">1</method>
			<method name="private int jj_ntk()">2</method>
			<method name="public void _init_(java.io.InputStream stream)">0</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode FieldValue()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeFieldType FieldType()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode Extends()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.Token getNextToken()">2</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode Service()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode Senum()">1</method>
			<method name="public final void FunctionType()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeField Field()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode ConstList()">1</method>
			<method name="private static void jj_la1_init_2()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeSet TypeSet()">1</method>
			<method name="public void _init_(java.io.Reader stream)">0</method>
			<method name="public final void enable_tracing()">1</method>
			<method name="public void ReInit(java.io.InputStream stream)">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode ConstListContents()">1</method>
			<method name="public final void CommaOrSemicolon()">1</method>
			<method name="public static void main(String[] args)">8</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammarTokenManager tm)">0</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode UnflagArgs()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeDouble TypeDouble()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeBool TypeBool()">1</method>
			<method name="private org.apache.hadoop.hive.serde2.dynamic_type.Token jj_consume_token(int kind)">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode EnumDef()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode SenumDef()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFResolver</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>6</ca>
		<ce>3</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[])">1</method>
		</cc>
	</class>
	<class>
		<name>javaewah.BufferedRunningLengthWord</name>
		<wmc>13</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>20</rfc>
		<lcom>20</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>13</npm>
		<lcom3>0.4583333333333333</lcom3>
		<loc>180</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3230769230769231</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.538461538461538</amc>
		<cc>
			<method name="public void setNumberOfLiteralWords(int number)">1</method>
			<method name="public void reset(javaewah.RunningLengthWord rlw)">1</method>
			<method name="public void setRunningBit(boolean b)">1</method>
			<method name="public boolean getRunningBit()">1</method>
			<method name="public long getRunningLength()">1</method>
			<method name="public void reset(long a)">2</method>
			<method name="public void _init_(javaewah.RunningLengthWord rlw)">0</method>
			<method name="public int getNumberOfLiteralWords()">1</method>
			<method name="public long size()">1</method>
			<method name="public void _init_(long a)">0</method>
			<method name="public void setRunningLength(long number)">1</method>
			<method name="public void discardFirstWords(long x)">2</method>
			<method name="public String toString()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.RCFile$1</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.ParseDriver$HiveLexerX</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>15</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>5</npm>
		<lcom3>0.5</lcom3>
		<loc>74</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.48</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.4</amc>
		<cc>
			<method name="public void displayRecognitionError(String[] tokenNames, org.antlr.runtime.RecognitionException e)">1</method>
			<method name="public String getErrorMessage(org.antlr.runtime.RecognitionException e, String[] tokenNames)">2</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.parse.ParseDriver, org.antlr.runtime.CharStream input)">0</method>
			<method name="public java.util.ArrayList getErrors()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.parse.ParseDriver)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$lateralView_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.typeinfo.UnionTypeInfo</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>19</rfc>
		<lcom>8</lcom>
		<ca>4</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>0.7142857142857143</lcom3>
		<loc>97</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4583333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.875</amc>
		<cc>
			<method name="public java.util.List getAllUnionObjectTypeInfos()">1</method>
			<method name="public int hashCode()">1</method>
			<method name="public void setAllUnionObjectTypeInfos(java.util.List allUnionObjectTypeInfos)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public String getTypeName()">3</method>
			<method name="public boolean equals(Object other)">3</method>
			<method name="void _init_(java.util.List typeInfos)">0</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tablePartitionPrefix_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.MapJoinOperator</name>
		<wmc>13</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>42</cbo>
		<rfc>93</rfc>
		<lcom>54</lcom>
		<ca>10</ca>
		<ce>32</ce>
		<npm>8</npm>
		<lcom3>0.8611111111111112</lcom3>
		<loc>666</loc>
		<dam>0.6666666666666666</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.18518518518518517</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>49.53846153846154</amc>
		<cc>
			<method name="public void closeOp(boolean abort)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void processOp(Object row, int tag)">1</method>
			<method name="public String getName()">1</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
			<method name="private void loadHashTable()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator mjop)">0</method>
			<method name="public void generateMapMetaData()">1</method>
			<method name="protected void fatalErrorMessage(StringBuilder errMsg, long counterCode)">1</method>
			<method name="public void cleanUpInputFileChangedOp()">1</method>
			<method name="private String getFileName(String path)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFOPBitNot</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>14</rfc>
		<lcom>10</lcom>
		<ca>0</ca>
		<ce>5</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>66</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.36</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.2</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.hive.serde2.io.ShortWritable a)">2</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.LongWritable a)">2</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.IntWritable a)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.hive.serde2.io.ByteWritable a)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.SerDeUtils</name>
		<wmc>12</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>39</cbo>
		<rfc>85</rfc>
		<lcom>58</lcom>
		<ca>10</ca>
		<ce>29</ce>
		<npm>8</npm>
		<lcom3>1.0247933884297522</lcom3>
		<loc>926</loc>
		<dam>0.2727272727272727</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.1717171717171717</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>75.25</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public static boolean shouldGetColsFromSerDe(String serde)">3</method>
			<method name="protected static boolean registerCoreSerDes()">1</method>
			<method name="static void buildJSONString(StringBuilder sb, Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">15</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static boolean hasAnyNullObject(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">17</method>
			<method name="public static String escapeString(String str)">12</method>
			<method name="public static void registerSerDe(String name, Class serde)">2</method>
			<method name="public static String lightEscapeString(String str)">3</method>
			<method name="public static org.apache.hadoop.hive.serde2.Deserializer lookupDeserializer(String name)">1</method>
			<method name="public static boolean hasAnyNullObject(java.util.List o, org.apache.hadoop.hive.serde2.objectinspector.StandardStructObjectInspector loi, boolean[] nullSafes)">5</method>
			<method name="public static String getJSONString(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TField</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>23</cbo>
		<rfc>9</rfc>
		<lcom>0</lcom>
		<ca>23</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>0.11111111111111116</lcom3>
		<loc>61</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.5</amc>
		<cc>
			<method name="public void _init_(String n, byte t, short i)">0</method>
			<method name="public void _init_()">0</method>
			<method name="public boolean equals(org.apache.thrift.protocol.TField otherField)">3</method>
			<method name="public String toString()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceEqualNegatableOperator_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ConditionalWork</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>22</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void setListWorks(java.util.List listWorks)">1</method>
			<method name="public void _init_(java.util.List listWorks)">0</method>
			<method name="public java.util.List getListWorks()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyProcFactory$CheckSelectProc</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>22</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>12</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>90</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4444444444444444</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>29.0</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyProcFactory$1 x0)">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFBin</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>63</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>29.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.LongWritable n)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.server.THsHaServer$Args</name>
		<wmc>13</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>14</rfc>
		<lcom>30</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>9</npm>
		<lcom3>0.75</lcom3>
		<loc>77</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.23076923076923078</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.615384615384615</amc>
		<cc>
			<method name="static int access$100(org.apache.thrift.server.THsHaServer$Args x0)">1</method>
			<method name="public java.util.concurrent.TimeUnit getStopTimeoutUnit()">1</method>
			<method name="static java.util.concurrent.ExecutorService access$000(org.apache.thrift.server.THsHaServer$Args x0)">1</method>
			<method name="public java.util.concurrent.ExecutorService getExecutorService()">1</method>
			<method name="public org.apache.thrift.server.THsHaServer$Args stopTimeoutUnit(java.util.concurrent.TimeUnit stopTimeoutUnit)">1</method>
			<method name="public int getStopTimeoutVal()">1</method>
			<method name="public org.apache.thrift.server.THsHaServer$Args executorService(java.util.concurrent.ExecutorService executorService)">1</method>
			<method name="public int getWorkerThreads()">1</method>
			<method name="public org.apache.thrift.server.THsHaServer$Args stopTimeoutVal(int stopTimeoutVal)">1</method>
			<method name="static java.util.concurrent.TimeUnit access$300(org.apache.thrift.server.THsHaServer$Args x0)">1</method>
			<method name="static int access$200(org.apache.thrift.server.THsHaServer$Args x0)">1</method>
			<method name="public void _init_(org.apache.thrift.transport.TNonblockingServerTransport transport)">0</method>
			<method name="public org.apache.thrift.server.THsHaServer$Args workerThreads(int i)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCorrelation$GenericUDAFCorrelationEvaluator</name>
		<wmc>11</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>20</cbo>
		<rfc>30</rfc>
		<lcom>43</lcom>
		<ca>1</ca>
		<ce>19</ce>
		<npm>10</npm>
		<lcom3>0.8833333333333334</lcom3>
		<loc>756</loc>
		<dam>0.9444444444444444</dam>
		<moa>16</moa>
		<mfa>0.0</mfa>
		<cam>0.2857142857142857</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>66.0909090909091</amc>
		<cc>
			<method name="public void iterate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object[] parameters)">1</method>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector init(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode m, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] parameters)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable getResult()">1</method>
			<method name="public void setResult(org.apache.hadoop.hive.serde2.io.DoubleWritable result)">1</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer getNewAggregationBuffer()">1</method>
			<method name="public void merge(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object partial)">1</method>
			<method name="public Object terminatePartial(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void reset(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.SubStructObjectInspector</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>20</rfc>
		<lcom>14</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>7</npm>
		<lcom3>0.7999999999999999</lcom3>
		<loc>101</loc>
		<dam>0.8</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.30952380952380953</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.0</amc>
		<cc>
			<method name="public Object getStructFieldData(Object data, org.apache.hadoop.hive.serde2.objectinspector.StructField fieldRef)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public java.util.List getStructFieldsDataAsList(Object data)">1</method>
			<method name="public java.util.List getAllStructFieldRefs()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector baseOI, int startCol, int numCols)">0</method>
			<method name="public String getTypeName()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.StructField getStructFieldRef(String fieldName)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterTblPartitionStatementSuffix_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileBlockMergeInputFormat</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>6</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>8</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>16</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit split, org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.mapred.Reporter reporter)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFSplit</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>21</rfc>
		<lcom>2</lcom>
		<ca>0</ca>
		<ce>13</ce>
		<npm>4</npm>
		<lcom3>0.625</lcom3>
		<loc>158</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>30.2</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.Collector</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void collect(Object)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLock</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>8</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>7</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>43</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.4642857142857143</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.714285714285714</amc>
		<cc>
			<method name="public String getPath()">1</method>
			<method name="public org.apache.hadoop.hive.ql.lockmgr.HiveLockObject getHiveLockObject()">1</method>
			<method name="public void _init_(String path, org.apache.hadoop.hive.ql.lockmgr.HiveLockObject obj, org.apache.hadoop.hive.ql.lockmgr.HiveLockMode mode)">0</method>
			<method name="public org.apache.hadoop.hive.ql.lockmgr.HiveLockMode getHiveLockMode()">1</method>
			<method name="public void setHiveLockMode(org.apache.hadoop.hive.ql.lockmgr.HiveLockMode mode)">1</method>
			<method name="public void setPath(String path)">1</method>
			<method name="public void setHiveLockObject(org.apache.hadoop.hive.ql.lockmgr.HiveLockObject obj)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tableLocation_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tableRowFormatLinesIdentifier_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.json.JSONWriter</name>
		<wmc>14</wmc>
		<dit>1</dit>
		<noc>1</noc>
		<cbo>4</cbo>
		<rfc>25</rfc>
		<lcom>35</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>10</npm>
		<lcom3>0.3974358974358974</lcom3>
		<loc>363</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.19047619047619047</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>24.5</amc>
		<cc>
			<method name="public org.json.JSONWriter value(Object arg0)">1</method>
			<method name="public void _init_(java.io.Writer arg0)">0</method>
			<method name="private org.json.JSONWriter append(String arg0)">1</method>
			<method name="public org.json.JSONWriter value(long arg0)">1</method>
			<method name="public org.json.JSONWriter endArray()">1</method>
			<method name="public org.json.JSONWriter object()">1</method>
			<method name="public org.json.JSONWriter key(String arg0)">1</method>
			<method name="private void push(org.json.JSONObject arg0)">1</method>
			<method name="public org.json.JSONWriter value(double arg0)">1</method>
			<method name="public org.json.JSONWriter endObject()">1</method>
			<method name="public org.json.JSONWriter value(boolean arg0)">1</method>
			<method name="private org.json.JSONWriter end(char arg0, char arg1)">1</method>
			<method name="private void pop(char arg0)">1</method>
			<method name="public org.json.JSONWriter array()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.server.TServlet</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>26</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>4</npm>
		<lcom3>0.3</lcom3>
		<loc>131</loc>
		<dam>1.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.38095238095238093</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>20.166666666666668</amc>
		<cc>
			<method name="public void _init_(org.apache.thrift.TProcessor processor, org.apache.thrift.protocol.TProtocolFactory protocolFactory)">0</method>
			<method name="public void setCustomHeaders(java.util.Collection headers)">1</method>
			<method name="protected void doGet(javax.servlet.http.HttpServletRequest request, javax.servlet.http.HttpServletResponse response)">1</method>
			<method name="protected void doPost(javax.servlet.http.HttpServletRequest request, javax.servlet.http.HttpServletResponse response)">1</method>
			<method name="public void _init_(org.apache.thrift.TProcessor processor, org.apache.thrift.protocol.TProtocolFactory inProtocolFactory, org.apache.thrift.protocol.TProtocolFactory outProtocolFactory)">0</method>
			<method name="public void addCustomHeader(String key, String value)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFFromUtcTimestamp</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>18</cbo>
		<rfc>29</rfc>
		<lcom>26</lcom>
		<ca>1</ca>
		<ce>17</ce>
		<npm>5</npm>
		<lcom3>0.9285714285714286</lcom3>
		<loc>224</loc>
		<dam>0.75</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.2857142857142857</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="protected boolean invert()">1</method>
			<method name="public String getDisplayString(String[] children)">2</method>
			<method name="public String getName()">1</method>
			<method name="protected java.sql.Timestamp applyOffset(long offset, java.sql.Timestamp t)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableTimestampObjectInspector</name>
		<wmc>11</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>11</cbo>
		<rfc>17</rfc>
		<lcom>55</lcom>
		<ca>6</ca>
		<ce>5</ce>
		<npm>11</npm>
		<lcom3>2.0</lcom3>
		<loc>78</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3939393939393939</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.090909090909091</amc>
		<cc>
			<method name="public Object set(Object o, java.sql.Timestamp t)">1</method>
			<method name="public Object set(Object o, org.apache.hadoop.hive.serde2.io.TimestampWritable t)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public Object create(java.sql.Timestamp t)">1</method>
			<method name="public Object set(Object o, byte[] bytes, int offset)">1</method>
			<method name="public volatile Object getPrimitiveJavaObject(Object x0)">1</method>
			<method name="public volatile Object getPrimitiveWritableObject(Object x0)">1</method>
			<method name="public Object create(byte[] bytes, int offset)">1</method>
			<method name="public Object copyObject(Object o)">2</method>
			<method name="public java.sql.Timestamp getPrimitiveJavaObject(Object o)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.TimestampWritable getPrimitiveWritableObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.ReworkMapredInputFormat</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void rework(org.apache.hadoop.hive.conf.HiveConf, org.apache.hadoop.hive.ql.plan.MapredWork)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.PartitionDesc</name>
		<wmc>28</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>37</cbo>
		<rfc>61</rfc>
		<lcom>156</lcom>
		<ca>27</ca>
		<ce>12</ce>
		<npm>27</npm>
		<lcom3>0.7366255144032922</lcom3>
		<loc>401</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.23979591836734693</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.0</amc>
		<cc>
			<method name="public Class getOutputFileFormatClass()">3</method>
			<method name="public volatile Object clone()">1</method>
			<method name="public Class getInputFileFormatClass()">3</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Partition part)">0</method>
			<method name="public void setProperties(java.util.Properties properties)">1</method>
			<method name="public String getTableName()">1</method>
			<method name="public void setPartSpec(java.util.LinkedHashMap partSpec)">1</method>
			<method name="public java.util.LinkedHashMap getPartSpec()">1</method>
			<method name="public java.util.Properties getProperties()">3</method>
			<method name="public void setTableDesc(org.apache.hadoop.hive.ql.plan.TableDesc tableDesc)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.TableDesc getTableDesc()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.TableDesc table, java.util.LinkedHashMap partSpec, Class serdeClass, Class inputFileFormatClass, Class outputFormat, java.util.Properties properties, String serdeClassName)">0</method>
			<method name="public void _init_()">0</method>
			<method name="public void setBaseFileName(String baseFileName)">1</method>
			<method name="public String getOutputFileFormatClassName()">1</method>
			<method name="public String getBaseFileName()">1</method>
			<method name="public void setOutputFileFormatClass(Class outputFileFormatClass)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.PartitionDesc clone()">4</method>
			<method name="public Class getDeserializerClass()">3</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.TableDesc table, java.util.LinkedHashMap partSpec)">0</method>
			<method name="public void setInputFileFormatClass(Class inputFileFormatClass)">1</method>
			<method name="void deriveBaseFileName(String path)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.Deserializer getDeserializer()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Partition part, org.apache.hadoop.hive.ql.plan.TableDesc tblDesc)">0</method>
			<method name="public String getSerdeClassName()">3</method>
			<method name="public void setDeserializerClass(Class serdeClass)">1</method>
			<method name="public String getInputFileFormatClassName()">1</method>
			<method name="public void setSerdeClassName(String serdeClassName)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazydio.LazyDioDouble</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>12</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>83</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyDoubleObjectInspector oi)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.lazydio.LazyDioDouble copy)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.AlterIndexDesc$AlterIndexTypes</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.888888888888889</lcom3>
		<loc>45</loc>
		<dam>0.3333333333333333</dam>
		<moa>3</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>9.5</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.plan.AlterIndexDesc$AlterIndexTypes valueOf(String name)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.AlterIndexDesc$AlterIndexTypes[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.xml.UDFXPathUtil</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>21</rfc>
		<lcom>19</lcom>
		<ca>8</ca>
		<ce>1</ce>
		<npm>7</npm>
		<lcom3>0.0</lcom3>
		<loc>139</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.142857142857142</amc>
		<cc>
			<method name="public Object eval(String xml, String path, javax.xml.namespace.QName qname)">8</method>
			<method name="public Boolean evalBoolean(String xml, String path)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public org.w3c.dom.NodeList evalNodeList(String xml, String path)">1</method>
			<method name="public org.w3c.dom.Node evalNode(String xml, String path)">1</method>
			<method name="public String evalString(String xml, String path)">1</method>
			<method name="public Double evalNumber(String xml, String path)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFToFloat</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>23</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>11</ce>
		<npm>10</npm>
		<lcom3>0.1111111111111111</lcom3>
		<loc>135</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.19</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.4</amc>
		<cc>
			<method name="public org.apache.hadoop.io.FloatWritable evaluate(org.apache.hadoop.io.LongWritable i)">2</method>
			<method name="public org.apache.hadoop.io.FloatWritable evaluate(org.apache.hadoop.io.IntWritable i)">2</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.FloatWritable evaluate(org.apache.hadoop.hive.serde2.io.ByteWritable i)">2</method>
			<method name="public org.apache.hadoop.io.FloatWritable evaluate(org.apache.hadoop.io.NullWritable i)">1</method>
			<method name="public org.apache.hadoop.io.FloatWritable evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable i)">2</method>
			<method name="public org.apache.hadoop.io.FloatWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable i)">2</method>
			<method name="public org.apache.hadoop.io.FloatWritable evaluate(org.apache.hadoop.hive.serde2.io.ShortWritable i)">2</method>
			<method name="public org.apache.hadoop.io.FloatWritable evaluate(org.apache.hadoop.io.Text i)">2</method>
			<method name="public org.apache.hadoop.io.FloatWritable evaluate(org.apache.hadoop.io.BooleanWritable i)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFSum$GenericUDAFSumDouble$SumDoubleAgg</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>6</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$SortBucketRSCtx</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>10</rfc>
		<lcom>12</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>9</npm>
		<lcom3>0.75</lcom3>
		<loc>56</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3611111111111111</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.777777777777778</amc>
		<cc>
			<method name="public void setMultiFileSpray(boolean multiFileSpray)">1</method>
			<method name="public int getNumFiles()">1</method>
			<method name="public java.util.ArrayList getPartnCols()">1</method>
			<method name="public void setNumFiles(int numFiles)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public int getTotalFiles()">1</method>
			<method name="public void setTotalFiles(int totalFiles)">1</method>
			<method name="public boolean isMultiFileSpray()">1</method>
			<method name="public void setPartnCols(java.util.ArrayList partnCols)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.AutoExpandingBufferReadTransport</name>
		<wmc>11</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>19</rfc>
		<lcom>19</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>11</npm>
		<lcom3>0.6333333333333333</lcom3>
		<loc>96</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.36363636363636365</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.454545454545454</amc>
		<cc>
			<method name="public final int getBytesRemainingInBuffer()">1</method>
			<method name="public boolean isOpen()">1</method>
			<method name="public final byte[] getBuffer()">1</method>
			<method name="public void open()">1</method>
			<method name="public void fill(org.apache.thrift.transport.TTransport inTrans, int length)">1</method>
			<method name="public void write(byte[] buf, int off, int len)">1</method>
			<method name="public void close()">1</method>
			<method name="public final int read(byte[] target, int off, int len)">1</method>
			<method name="public final void consumeBuffer(int len)">1</method>
			<method name="public void _init_(int initialCapacity, double overgrowthCoefficient)">0</method>
			<method name="public final int getBufferPosition()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFInFile</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>34</rfc>
		<lcom>11</lcom>
		<ca>0</ca>
		<ce>12</ce>
		<npm>6</npm>
		<lcom3>0.7916666666666666</lcom3>
		<loc>231</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>31.428571428571427</amc>
		<cc>
			<method name="public void load(java.io.InputStream is)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public String[] getRequiredFiles()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.FunctionInfo</name>
		<wmc>12</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>18</rfc>
		<lcom>12</lcom>
		<ca>5</ca>
		<ce>6</ce>
		<npm>12</npm>
		<lcom3>0.7272727272727273</lcom3>
		<loc>145</loc>
		<dam>1.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.2916666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.666666666666666</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDF getGenericUDF()">2</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFResolver getGenericUDAFResolver()">1</method>
			<method name="public boolean isGenericUDAF()">2</method>
			<method name="public String getDisplayName()">1</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDTF getGenericUDTF()">2</method>
			<method name="public void _init_(boolean isNative, String displayName, org.apache.hadoop.hive.ql.udf.generic.GenericUDAFResolver genericUDAFResolver)">0</method>
			<method name="public boolean isNative()">1</method>
			<method name="public boolean isGenericUDTF()">2</method>
			<method name="public void _init_(boolean isNative, String displayName, org.apache.hadoop.hive.ql.udf.generic.GenericUDF genericUDF)">0</method>
			<method name="public Class getFunctionClass()">6</method>
			<method name="public void _init_(boolean isNative, String displayName, org.apache.hadoop.hive.ql.udf.generic.GenericUDTF genericUDTF)">0</method>
			<method name="public boolean isGenericUDF()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Client</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>20</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>11</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>109</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>53.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.thrift.transport.TTransport createClientTransport(String principalConfig, String host, String methodStr, String tokenStrForm, org.apache.thrift.transport.TTransport underlyingTransport)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lockmgr.HiveLockObject</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>19</rfc>
		<lcom>11</lcom>
		<ca>8</ca>
		<ce>4</ce>
		<npm>10</npm>
		<lcom3>0.2222222222222222</lcom3>
		<loc>249</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.3</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>23.7</amc>
		<cc>
			<method name="public void _init_(String[] paths, org.apache.hadoop.hive.ql.lockmgr.HiveLockObject$HiveLockObjectData lockData)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Partition par, org.apache.hadoop.hive.ql.lockmgr.HiveLockObject$HiveLockObjectData lockData)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.DummyPartition par, org.apache.hadoop.hive.ql.lockmgr.HiveLockObject$HiveLockObjectData lockData)">0</method>
			<method name="public void _init_(String path, org.apache.hadoop.hive.ql.lockmgr.HiveLockObject$HiveLockObjectData lockData)">0</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.lockmgr.HiveLockObject$HiveLockObjectData getData()">1</method>
			<method name="public String getDisplayName()">6</method>
			<method name="public String getName()">4</method>
			<method name="public void setData(org.apache.hadoop.hive.ql.lockmgr.HiveLockObject$HiveLockObjectData data)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Table tbl, org.apache.hadoop.hive.ql.lockmgr.HiveLockObject$HiveLockObjectData lockData)">0</method>
		</cc>
	</class>
	<class>
		<name>javaewah.EWAHIterator</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>8</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>5</npm>
		<lcom3>0.41666666666666663</lcom3>
		<loc>62</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.8</amc>
		<cc>
			<method name="public javaewah.RunningLengthWord next()">1</method>
			<method name="public void _init_(long[] a, int sizeinwords)">0</method>
			<method name="public boolean hasNext()">2</method>
			<method name="public int dirtyWords()">1</method>
			<method name="public long[] buffer()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ExecDriver</name>
		<wmc>29</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>61</cbo>
		<rfc>257</rfc>
		<lcom>274</lcom>
		<ca>5</ca>
		<ce>59</ce>
		<npm>20</npm>
		<lcom3>0.869047619047619</lcom3>
		<loc>2322</loc>
		<dam>0.6666666666666666</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.10504201680672269</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>78.86206896551724</amc>
		<cc>
			<method name="private static void setupChildLog4j(org.apache.hadoop.conf.Configuration conf)">3</method>
			<method name="static void _clinit_()">0</method>
			<method name="public String getName()">1</method>
			<method name="public boolean mapStarted()">1</method>
			<method name="public static String generateCmdLine(org.apache.hadoop.hive.conf.HiveConf hconf)">6</method>
			<method name="public boolean requireLock()">1</method>
			<method name="public void initialize(org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.hive.ql.QueryPlan queryPlan, org.apache.hadoop.hive.ql.DriverContext driverContext)">4</method>
			<method name="private static void printUsage()">1</method>
			<method name="private static int addInputPath(String path, org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.hive.ql.plan.MapredWork work, String hiveScratchDir, int numEmptyPaths, boolean isEmptyPath, String alias)">1</method>
			<method name="public boolean hasReduce()">2</method>
			<method name="public void logPlanProgress(org.apache.hadoop.hive.ql.session.SessionState ss)">1</method>
			<method name="public boolean reduceDone()">1</method>
			<method name="public boolean checkFatalErrors(org.apache.hadoop.mapred.Counters ctrs, StringBuilder errMsg)">4</method>
			<method name="public int execute(org.apache.hadoop.hive.ql.DriverContext driverContext)">35</method>
			<method name="public boolean mapDone()">1</method>
			<method name="public void updateCounters(org.apache.hadoop.mapred.Counters ctrs, org.apache.hadoop.mapred.RunningJob rj)">1</method>
			<method name="public java.util.Collection getTopOperators()">1</method>
			<method name="public void _init_()">0</method>
			<method name="private static void setInputPaths(org.apache.hadoop.mapred.JobConf job, java.util.List pathsToAdd)">4</method>
			<method name="protected void localizeMRTmpFilesImpl(org.apache.hadoop.hive.ql.Context ctx)">9</method>
			<method name="public boolean isMapRedTask()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.StageType getType()">1</method>
			<method name="public static void main(String[] args)">1</method>
			<method name="protected void createTmpDirs()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.MapredWork plan, org.apache.hadoop.mapred.JobConf job, boolean isSilent)">0</method>
			<method name="private void initializeFiles(String prop, String files)">3</method>
			<method name="public boolean reduceStarted()">1</method>
			<method name="public static void addInputPaths(org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.hive.ql.plan.MapredWork work, String hiveScratchDir, org.apache.hadoop.hive.ql.Context ctx)">1</method>
			<method name="protected void setInputAttributes(org.apache.hadoop.conf.Configuration conf)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$mapType_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$dropDatabaseStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$indexPropertiesPrefixed_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.PlanUtils$1</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>6</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>19</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.333333333333333</amc>
		<cc>
			<method name="public volatile int compare(Object x0, Object x1)">1</method>
			<method name="void _init_()">0</method>
			<method name="public int compare(org.apache.hadoop.hive.metastore.api.FieldSchema o1, org.apache.hadoop.hive.metastore.api.FieldSchema o2)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.IndexWhereResolver</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>8</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>30</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext resolve(org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext physicalContext)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterTblPartitionStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceBitwiseOrOperator_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>8</rfc>
		<lcom>15</lcom>
		<ca>3</ca>
		<ce>9</ce>
		<npm>5</npm>
		<lcom3>1.0</lcom3>
		<loc>33</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.7</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.333333333333333</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Client createClient()">1</method>
			<method name="public volatile org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Client createClient()">1</method>
			<method name="public volatile org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server createServer(String x0, String x1)">1</method>
			<method name="public org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server createServer(String keytabFile, String principalConf)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.SchemaAwareCompressionOutputStream</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>6</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.0</amc>
		<cc>
			<method name="protected void _init_(java.io.OutputStream out)">0</method>
			<method name="public abstract void setColumnIndex(int)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.JoinCondDesc$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>49</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>47.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.typeinfo.MapTypeInfo</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>17</rfc>
		<lcom>11</lcom>
		<ca>7</ca>
		<ce>2</ce>
		<npm>9</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>97</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.4</amc>
		<cc>
			<method name="public int hashCode()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.typeinfo.TypeInfo getMapValueTypeInfo()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setMapKeyTypeInfo(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo mapKeyTypeInfo)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo keyTypeInfo, org.apache.hadoop.hive.serde2.typeinfo.TypeInfo valueTypeInfo)">0</method>
			<method name="public org.apache.hadoop.hive.serde2.typeinfo.TypeInfo getMapKeyTypeInfo()">1</method>
			<method name="public String getTypeName()">1</method>
			<method name="public boolean equals(Object other)">5</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
			<method name="public void setMapValueTypeInfo(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo mapValueTypeInfo)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Hadoop20SShims$1</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>1</npm>
		<lcom3>0.5</lcom3>
		<loc>19</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.5</amc>
		<cc>
			<method name="public void progress()">1</method>
			<method name="void _init_(org.apache.hadoop.hive.shims.Hadoop20SShims, org.apache.hadoop.conf.Configuration x0, org.apache.hadoop.mapreduce.TaskAttemptID x1, org.apache.hadoop.util.Progressable)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.QBMetaData</name>
		<wmc>17</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>25</rfc>
		<lcom>72</lcom>
		<ca>2</ca>
		<ce>5</ce>
		<npm>16</npm>
		<lcom3>0.9464285714285714</lcom3>
		<loc>199</loc>
		<dam>0.5714285714285714</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.32142857142857145</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.882352941176471</amc>
		<cc>
			<method name="public void setDestForAlias(String alias, org.apache.hadoop.hive.ql.metadata.Table tab)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.DynamicPartitionCtx getDPCtx(String alias)">1</method>
			<method name="public void setPartSpecForAlias(String alias, java.util.Map partSpec)">1</method>
			<method name="public java.util.Map getPartSpecForAlias(String alias)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void setDestForAlias(String alias, org.apache.hadoop.hive.ql.metadata.Partition part)">1</method>
			<method name="public Integer getDestTypeForAlias(String alias)">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Table getTableForAlias(String alias)">1</method>
			<method name="public void setSrcForAlias(String alias, org.apache.hadoop.hive.ql.metadata.Table tab)">1</method>
			<method name="public void setDPCtx(String alias, org.apache.hadoop.hive.ql.plan.DynamicPartitionCtx dpCtx)">1</method>
			<method name="public java.util.HashMap getAliasToTable()">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Partition getDestPartitionForAlias(String alias)">1</method>
			<method name="public void setDestForAlias(String alias, String fname, boolean isDfsFile)">2</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Table getSrcForAlias(String alias)">1</method>
			<method name="public String getDestFileForAlias(String alias)">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Table getDestTableForAlias(String alias)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Hadoop20SShims$2</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>21</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$fileFormat_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.MapJoinFactory$UnionMapJoin</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>19</cbo>
		<rfc>40</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>19</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>180</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>58.666666666666664</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFMax$GenericUDAFMaxEvaluator</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>17</rfc>
		<lcom>28</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>8</npm>
		<lcom3>0.8125</lcom3>
		<loc>123</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.3541666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.222222222222221</amc>
		<cc>
			<method name="public void iterate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object[] parameters)">1</method>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector init(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode m, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] parameters)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer getNewAggregationBuffer()">1</method>
			<method name="public void merge(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object partial)">1</method>
			<method name="public Object terminatePartial(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void reset(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFBaseCompare$CompareType</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>13</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9629629629629629</lcom3>
		<loc>111</loc>
		<dam>0.1111111111111111</dam>
		<moa>9</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>24.5</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.udf.generic.GenericUDFBaseCompare$CompareType valueOf(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.udf.generic.GenericUDFBaseCompare$CompareType[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ppr.OpProcFactory</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>6</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>14</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.6666666666666665</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getDefaultProc()">1</method>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getFilterProc()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.HadoopShimsSecure</name>
		<wmc>24</wmc>
		<dit>1</dit>
		<noc>2</noc>
		<cbo>34</cbo>
		<rfc>59</rfc>
		<lcom>274</lcom>
		<ca>4</ca>
		<ce>32</ce>
		<npm>24</npm>
		<lcom3>0.9565217391304348</lcom3>
		<loc>228</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.10912698412698413</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.458333333333334</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.shims.HadoopShims$CombineFileInputFormatShim getCombineFileInputFormat()">1</method>
			<method name="public boolean isSecureShimImpl()">1</method>
			<method name="public void prepareJobOutput(org.apache.hadoop.mapred.JobConf conf)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public String[] getTaskJobIDs(org.apache.hadoop.mapred.TaskCompletionEvent t)">1</method>
			<method name="public abstract org.apache.hadoop.mapreduce.TaskAttemptContext newTaskAttemptContext(org.apache.hadoop.conf.Configuration, org.apache.hadoop.util.Progressable)">1</method>
			<method name="public void inputFormatValidateInput(org.apache.hadoop.mapred.InputFormat fmt, org.apache.hadoop.mapred.JobConf conf)">1</method>
			<method name="public int compareText(org.apache.hadoop.io.Text a, org.apache.hadoop.io.Text b)">1</method>
			<method name="public abstract org.apache.hadoop.hive.shims.HadoopShims$JobTrackerState getJobTrackerState(org.apache.hadoop.mapred.ClusterStatus)">1</method>
			<method name="public int createHadoopArchive(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.fs.Path sourceDir, org.apache.hadoop.fs.Path destDir, String archiveName)">1</method>
			<method name="public org.apache.hadoop.hive.shims.HadoopShims$MiniDFSShim getMiniDfs(org.apache.hadoop.conf.Configuration conf, int numDataNodes, boolean format, String[] racks)">1</method>
			<method name="public void setFloatConf(org.apache.hadoop.conf.Configuration conf, String varName, float val)">1</method>
			<method name="public void doAs(org.apache.hadoop.security.UserGroupInformation ugi, java.security.PrivilegedExceptionAction pvea)">1</method>
			<method name="public String getTokenStrForm(String tokenSignature)">1</method>
			<method name="public abstract org.apache.hadoop.mapreduce.JobContext newJobContext(org.apache.hadoop.mapreduce.Job)">1</method>
			<method name="public boolean fileSystemDeleteOnExit(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path path)">1</method>
			<method name="public org.apache.hadoop.security.UserGroupInformation getUGIForConf(org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="public String getShortUserName(org.apache.hadoop.security.UserGroupInformation ugi)">1</method>
			<method name="public boolean usesJobShell()">1</method>
			<method name="public long getAccessTime(org.apache.hadoop.fs.FileStatus file)">1</method>
			<method name="public String getInputFormatClassName()">1</method>
			<method name="public boolean isJobPreparing(org.apache.hadoop.mapred.RunningJob job)">1</method>
			<method name="public org.apache.hadoop.security.UserGroupInformation createRemoteUser(String userName, java.util.List groupNames)">1</method>
			<method name="public void setTmpFiles(String prop, String files)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.SkewJoinResolver$SkewJoinProcCtx</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>3</ce>
		<npm>5</npm>
		<lcom3>0.5</lcom3>
		<loc>30</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.6</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext getParseCtx()">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.Task getCurrentTask()">1</method>
			<method name="public void setCurrentTask(org.apache.hadoop.hive.ql.exec.Task currentTask)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.Task task, org.apache.hadoop.hive.ql.parse.ParseContext parseCtx)">0</method>
			<method name="public void setParseCtx(org.apache.hadoop.hive.ql.parse.ParseContext parseCtx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.PrincipalDesc</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>7</rfc>
		<lcom>3</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>6</npm>
		<lcom3>0.8</lcom3>
		<loc>35</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.333333333333333</amc>
		<cc>
			<method name="public void setType(org.apache.hadoop.hive.metastore.api.PrincipalType type)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setName(String name)">1</method>
			<method name="public String getName()">1</method>
			<method name="public void _init_(String name, org.apache.hadoop.hive.metastore.api.PrincipalType type)">0</method>
			<method name="public org.apache.hadoop.hive.metastore.api.PrincipalType getType()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.UpdateInputAccessTimeHook$PreExec</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>22</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>11</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>99</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>48.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void run(org.apache.hadoop.hive.ql.session.SessionState sess, java.util.Set inputs, java.util.Set outputs, org.apache.hadoop.security.UserGroupInformation ugi)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lockmgr.HiveLockManagerCtx</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>4</npm>
		<lcom3>0.3333333333333333</lcom3>
		<loc>21</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.conf.HiveConf getConf()">1</method>
			<method name="public void setConf(org.apache.hadoop.hive.conf.HiveConf conf)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.conf.HiveConf conf)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.JavaShortObjectInspector</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>9</rfc>
		<lcom>10</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>30</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public short get(Object o)">1</method>
			<method name="public Object create(short value)">1</method>
			<method name="void _init_()">0</method>
			<method name="public Object getPrimitiveWritableObject(Object o)">2</method>
			<method name="public Object set(Object o, short value)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFEWAHBitmapAnd</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>10</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="protected javaewah.EWAHCompressedBitmap bitmapBop(javaewah.EWAHCompressedBitmap bitmap1, javaewah.EWAHCompressedBitmap bitmap2)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader</name>
		<wmc>21</wmc>
		<dit>1</dit>
		<noc>3</noc>
		<cbo>18</cbo>
		<rfc>71</rfc>
		<lcom>108</lcom>
		<ca>3</ca>
		<ce>15</ce>
		<npm>15</npm>
		<lcom3>0.7307692307692307</lcom3>
		<loc>637</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.23333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>28.714285714285715</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.mapred.RecordReader recordReader)">0</method>
			<method name="public float getProgress()">1</method>
			<method name="public org.apache.hadoop.hive.ql.io.IOContext getIOContext()">1</method>
			<method name="public void initIOContext(org.apache.hadoop.mapred.FileSplit split, org.apache.hadoop.mapred.JobConf job, Class inputFormatClass, org.apache.hadoop.mapred.RecordReader recordReader)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void close()">1</method>
			<method name="public void _init_(org.apache.hadoop.mapred.JobConf conf)">0</method>
			<method name="public void initIOContext(long startPos, boolean isBlockPointer, String inputFile)">1</method>
			<method name="public boolean doNext(Object key, Object value)">1</method>
			<method name="public abstract void doClose()">1</method>
			<method name="protected void updateIOContext()">1</method>
			<method name="public void initIOContext(org.apache.hadoop.mapred.FileSplit split, org.apache.hadoop.mapred.JobConf job, Class inputFormatClass)">1</method>
			<method name="public void _init_(org.apache.hadoop.mapred.RecordReader recordReader, org.apache.hadoop.mapred.JobConf conf)">0</method>
			<method name="public boolean foundAllTargets()">3</method>
			<method name="public void setRecordReader(org.apache.hadoop.mapred.RecordReader recordReader)">1</method>
			<method name="private void sync(long position)">1</method>
			<method name="private long getSyncedPosition()">1</method>
			<method name="private void beginLinearSearch()">1</method>
			<method name="private void setGenericUDFClassName(String genericUDFClassName)">1</method>
			<method name="public boolean next(Object key, Object value)">1</method>
			<method name="public void initIOContextSortedProps(org.apache.hadoop.mapred.FileSplit split, org.apache.hadoop.mapred.RecordReader recordReader, org.apache.hadoop.mapred.JobConf job)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ShowTableStatusDesc</name>
		<wmc>14</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>15</rfc>
		<lcom>53</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>14</npm>
		<lcom3>0.9010989010989012</lcom3>
		<loc>86</loc>
		<dam>0.42857142857142855</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.642857142857143</amc>
		<cc>
			<method name="public String getDbName()">1</method>
			<method name="public void setPattern(String pattern)">1</method>
			<method name="public java.util.HashMap getPartSpec()">1</method>
			<method name="public void _init_(String resFile, String dbName, String pattern, java.util.HashMap partSpec)">0</method>
			<method name="public String getResFile()">1</method>
			<method name="public String getSchema()">1</method>
			<method name="public String getTable()">1</method>
			<method name="public void setResFile(String resFile)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public String getPattern()">1</method>
			<method name="public String getResFileString()">1</method>
			<method name="public void setPartSpec(java.util.HashMap partSpec)">1</method>
			<method name="public void setDbName(String dbName)">1</method>
			<method name="public void _init_(String resFile, String dbName, String pattern)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Utilities$Tuple</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>20</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public void _init_(Object one, Object two)">0</method>
			<method name="public Object getTwo()">1</method>
			<method name="public Object getOne()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFSortArray</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>32</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>15</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>186</loc>
		<dam>0.75</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>35.4</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>30</cbo>
		<rfc>13</rfc>
		<lcom>3</lcom>
		<ca>25</ca>
		<ce>5</ce>
		<npm>9</npm>
		<lcom3>0.7222222222222222</lcom3>
		<loc>56</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.43333333333333335</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.4</amc>
		<cc>
			<method name="public void setTypeName(String typeName)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector$PrimitiveCategory getPrimitiveCategory()">1</method>
			<method name="public int hashCode()">1</method>
			<method name="void _init_(String typeName)">0</method>
			<method name="public void _init_()">0</method>
			<method name="public String getTypeName()">1</method>
			<method name="public boolean equals(Object other)">2</method>
			<method name="public Class getPrimitiveJavaClass()">1</method>
			<method name="public Class getPrimitiveWritableClass()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$clusterByClause_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ConditionalResolverSkewJoin</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>18</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>8</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>85</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>41.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public java.util.List getTasks(org.apache.hadoop.hive.conf.HiveConf conf, Object objCtx)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.proto.test.Complexpb$Complex</name>
		<wmc>16</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>21</rfc>
		<lcom>76</lcom>
		<ca>0</ca>
		<ce>1</ce>
		<npm>15</npm>
		<lcom3>0.9555555555555556</lcom3>
		<loc>122</loc>
		<dam>0.5833333333333334</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.34375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.875</amc>
		<cc>
			<method name="private void initFields()">1</method>
			<method name="public void _init_(int aint, String aString, java.util.List lint, java.util.List lString, java.util.List lintString)">0</method>
			<method name="public String getLString(int index)">1</method>
			<method name="public java.util.List getLintStringList()">1</method>
			<method name="public int getAint()">1</method>
			<method name="public java.util.List getLStringList()">1</method>
			<method name="public int getLint(int index)">1</method>
			<method name="public java.util.List getLintList()">1</method>
			<method name="public int getLintCount()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.proto.test.Complexpb$IntString getLintString(int index)">1</method>
			<method name="public int getLintStringCount()">1</method>
			<method name="public int getLStringCount()">1</method>
			<method name="public boolean hasAint()">1</method>
			<method name="public String getAString()">1</method>
			<method name="public boolean hasAString()">1</method>
			<method name="public final boolean isInitialized()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat$1</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>10</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>45</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.333333333333334</amc>
		<cc>
			<method name="public void close(boolean abort)">1</method>
			<method name="public void write(org.apache.hadoop.io.Writable r)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat, java.io.OutputStream)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.persistence.MapJoinRowContainer</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>16</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>9</npm>
		<lcom3>0.25</lcom3>
		<loc>124</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.555555555555555</amc>
		<cc>
			<method name="public void clear()">1</method>
			<method name="public int size()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public Object first()">1</method>
			<method name="public java.util.List getList()">1</method>
			<method name="public Object next()">1</method>
			<method name="public void reset(org.apache.hadoop.hive.ql.exec.persistence.MapJoinRowContainer other)">1</method>
			<method name="public void setList(java.util.List list)">1</method>
			<method name="public void add(Object t)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCovariance$GenericUDAFCovarianceEvaluator</name>
		<wmc>11</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>21</cbo>
		<rfc>29</rfc>
		<lcom>43</lcom>
		<ca>2</ca>
		<ce>19</ce>
		<npm>10</npm>
		<lcom3>0.8866666666666667</lcom3>
		<loc>573</loc>
		<dam>0.9333333333333333</dam>
		<moa>12</moa>
		<mfa>0.0</mfa>
		<cam>0.2857142857142857</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>49.72727272727273</amc>
		<cc>
			<method name="public void iterate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object[] parameters)">1</method>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector init(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode m, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] parameters)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable getResult()">1</method>
			<method name="public void setResult(org.apache.hadoop.hive.serde2.io.DoubleWritable result)">1</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer getNewAggregationBuffer()">1</method>
			<method name="public void merge(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object partial)">1</method>
			<method name="public Object terminatePartial(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void reset(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>6</rfc>
		<lcom>2</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>5</npm>
		<lcom3>0.9375</lcom3>
		<loc>46</loc>
		<dam>0.0</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.36</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.6</amc>
		<cc>
			<method name="public void _init_(boolean isPartitioned, org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector rowObjectInspector, org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector rawRowObjectInspector, org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector partObjectInspector, Object[] rowWithPart, org.apache.hadoop.hive.serde2.Deserializer deserializer)">0</method>
			<method name="public org.apache.hadoop.hive.serde2.Deserializer getDeserializer()">1</method>
			<method name="public Object[] getRowWithPart()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector getRowObjectInspector()">1</method>
			<method name="public boolean isPartitioned()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.NumericHistogram</name>
		<wmc>12</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>25</rfc>
		<lcom>0</lcom>
		<ca>6</ca>
		<ce>2</ce>
		<npm>10</npm>
		<lcom3>0.49090909090909096</lcom3>
		<loc>733</loc>
		<dam>0.8</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.36363636363636365</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>59.666666666666664</amc>
		<cc>
			<method name="public java.util.ArrayList serialize()">3</method>
			<method name="public boolean isReady()">2</method>
			<method name="private void trim()">7</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void reset()">1</method>
			<method name="public double quantile(double q)">9</method>
			<method name="public void add(double v)">8</method>
			<method name="public void allocate(int num_bins)">2</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.NumericHistogram$Coord getBin(int b)">1</method>
			<method name="public void merge(java.util.List other)">7</method>
			<method name="public int getUsedBins()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.OperatorType</name>
		<wmc>6</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>27</cbo>
		<rfc>9</rfc>
		<lcom>9</lcom>
		<ca>25</ca>
		<ce>2</ce>
		<npm>4</npm>
		<lcom3>0.79</lcom3>
		<loc>288</loc>
		<dam>0.1</dam>
		<moa>19</moa>
		<mfa>0.7647058823529411</mfa>
		<cam>0.4</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>43.666666666666664</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.OperatorType valueOf(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.OperatorType findByValue(int value)">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="public int getValue()">1</method>
			<method name="private void _init_(String, int, int value)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.OperatorType[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.KeyWrapperFactory</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>11</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>10</ce>
		<npm>2</npm>
		<lcom3>0.7777777777777778</lcom3>
		<loc>107</loc>
		<dam>0.0</dam>
		<moa>7</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>31.666666666666668</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.exec.KeyWrapper getKeyWrapper()">5</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator[] keyFields, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] keyObjectInspectors, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] currentKeyObjectInspectors)">0</method>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFStdSample$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>70</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>68.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.MetadataListStructObjectInspector</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>20</rfc>
		<lcom>22</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>5</npm>
		<lcom3>0.7142857142857143</lcom3>
		<loc>137</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.34285714285714286</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.0</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.MetadataListStructObjectInspector getInstance(java.util.List columnNames, java.util.List columnComments)">2</method>
			<method name="public Object getStructFieldData(Object data, org.apache.hadoop.hive.serde2.objectinspector.StructField fieldRef)">2</method>
			<method name="public void _init_(java.util.List columnNames, java.util.List columnComments)">0</method>
			<method name="void _init_(java.util.List columnNames)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public java.util.List getStructFieldsDataAsList(Object data)">2</method>
			<method name="static java.util.ArrayList getFieldObjectInspectors(int fields)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.MetadataListStructObjectInspector getInstance(java.util.List columnNames)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.FilterOperator</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>32</cbo>
		<rfc>33</rfc>
		<lcom>4</lcom>
		<ca>13</ca>
		<ce>19</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>224</loc>
		<dam>0.8888888888888888</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>42.0</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void processOp(Object row, int tag)">1</method>
			<method name="public String getName()">1</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.UDF</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>83</noc>
		<cbo>87</cbo>
		<rfc>9</rfc>
		<lcom>3</lcom>
		<ca>85</ca>
		<ce>2</ce>
		<npm>5</npm>
		<lcom3>0.4</lcom3>
		<loc>34</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public String[] getRequiredJars()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public String[] getRequiredFiles()">1</method>
			<method name="protected void _init_(org.apache.hadoop.hive.ql.exec.UDFMethodResolver rslv)">0</method>
			<method name="public void setResolver(org.apache.hadoop.hive.ql.exec.UDFMethodResolver rslv)">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.UDFMethodResolver getResolver()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.InputSignature</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>27</rfc>
		<lcom>11</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>9</npm>
		<lcom3>0.5925925925925926</lcom3>
		<loc>179</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2962962962962963</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>16.6</amc>
		<cc>
			<method name="public void add(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo paramType)">1</method>
			<method name="public java.util.ArrayList getTypeArray()">1</method>
			<method name="public int hashCode()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient void _init_(String name, org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] classList)">0</method>
			<method name="public boolean equals(Object obj)">4</method>
			<method name="public String getName()">1</method>
			<method name="public void _init_(String name)">0</method>
			<method name="public String toString()">3</method>
			<method name="public transient void _init_(String name, Class[] classList)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFStruct</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>15</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>7</ce>
		<npm>4</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>99</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>23.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$privilegeType_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.TaskFactory$1</name>
		<wmc>3</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>4</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>12</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.8461538461538461</mfa>
		<cam>1.0</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="protected volatile Object initialValue()">1</method>
			<method name="void _init_()">0</method>
			<method name="protected synchronized Integer initialValue()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFUtils$ReturnObjectInspectorResolver</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>21</cbo>
		<rfc>15</rfc>
		<lcom>2</lcom>
		<ca>11</ca>
		<ce>10</ce>
		<npm>5</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>125</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.45</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>23.4</amc>
		<cc>
			<method name="public Object convertIfNecessary(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">5</method>
			<method name="public boolean update(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector get()">1</method>
			<method name="public void _init_(boolean allowTypeConversion)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.UDFArgumentTypeException</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>47</cbo>
		<rfc>5</rfc>
		<lcom>1</lcom>
		<ca>46</ca>
		<ce>1</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>17</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.333333333333333</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public int getArgumentId()">1</method>
			<method name="public void _init_(int argumentId, String message)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.SMBMapJoinOperator</name>
		<wmc>24</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>30</cbo>
		<rfc>105</rfc>
		<lcom>128</lcom>
		<ca>2</ca>
		<ce>28</ce>
		<npm>9</npm>
		<lcom3>0.7907608695652174</lcom3>
		<loc>1510</loc>
		<dam>0.4375</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.1246376811594203</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>61.25</amc>
		<cc>
			<method name="public void initializeLocalWork(org.apache.hadoop.conf.Configuration hconf)">1</method>
			<method name="public void closeOp(boolean abort)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator mapJoinOp)">0</method>
			<method name="private java.util.List joinObject(int[] smallestPos)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="protected boolean allInitializedParentsAreClosed()">1</method>
			<method name="private void fetchOneRow(byte tag)">4</method>
			<method name="private void joinFinalLeftData()">1</method>
			<method name="public void processOp(Object row, int tag)">1</method>
			<method name="private boolean processKey(byte alias, java.util.ArrayList key)">1</method>
			<method name="public String getName()">1</method>
			<method name="private int compareKeys(java.util.ArrayList k1, java.util.ArrayList k2)">10</method>
			<method name="private void promoteNextGroupToCandidate(Byte t)">1</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
			<method name="private void fetchNextGroup(Byte t)">1</method>
			<method name="private int[] findSmallestKey()">6</method>
			<method name="private java.util.List joinOneGroup()">1</method>
			<method name="private void putDummyOrEmpty(Byte i)">2</method>
			<method name="public void cleanUpInputFileChangedOp()">1</method>
			<method name="public void initializeMapredLocalWork(org.apache.hadoop.hive.ql.plan.MapJoinDesc conf, org.apache.hadoop.conf.Configuration hconf, org.apache.hadoop.hive.ql.plan.MapredLocalWork localWork, org.apache.commons.logging.Log l4j)">1</method>
			<method name="private void setUpFetchOpContext(org.apache.hadoop.hive.ql.exec.FetchOperator fetchOp, String alias)">1</method>
			<method name="private boolean allFetchOpDone()">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableConstantStringObjectInspector</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>16</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public volatile Object getWritableConstantValue()">1</method>
			<method name="public org.apache.hadoop.io.Text getWritableConstantValue()">1</method>
			<method name="void _init_(org.apache.hadoop.io.Text value)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDTFExplode</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>26</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>12</ce>
		<npm>5</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>192</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>36.8</amc>
		<cc>
			<method name="public void process(Object[] o)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void close()">1</method>
			<method name="public String toString()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] args)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFUtils$ConversionHelper</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>21</rfc>
		<lcom>2</lcom>
		<ca>2</ca>
		<ce>11</ce>
		<npm>2</npm>
		<lcom3>0.7037037037037037</lcom3>
		<loc>442</loc>
		<dam>0.2222222222222222</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>107.25</amc>
		<cc>
			<method name="private static Class getClassFromType(java.lang.reflect.Type t)">3</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object[] convertIfNecessary(Object[] parameters)">8</method>
			<method name="public void _init_(java.lang.reflect.Method m, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] parameterOIs)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.LoadSemanticAnalyzer</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>32</cbo>
		<rfc>86</rfc>
		<lcom>4</lcom>
		<ca>2</ca>
		<ce>30</ce>
		<npm>3</npm>
		<lcom3>0.875</lcom3>
		<loc>664</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.26666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>131.4</amc>
		<cc>
			<method name="public void analyzeInternal(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="public static org.apache.hadoop.fs.FileStatus[] matchFilesOrDir(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path path)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.conf.HiveConf conf)">0</method>
			<method name="private void applyConstraints(java.net.URI fromURI, java.net.URI toURI, org.antlr.runtime.tree.Tree ast, boolean isLocal)">1</method>
			<method name="private java.net.URI initializeFromURI(String fromPath)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFBaseCompare</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>6</noc>
		<cbo>34</cbo>
		<rfc>28</rfc>
		<lcom>6</lcom>
		<ca>9</ca>
		<ce>25</ce>
		<npm>4</npm>
		<lcom3>0.925</lcom3>
		<loc>436</loc>
		<dam>0.95</dam>
		<moa>16</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>82.2</amc>
		<cc>
			<method name="public Integer compare(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.thrift.test.IntString$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>28</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$switchDatabaseStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.ParseContext</name>
		<wmc>54</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>80</cbo>
		<rfc>57</rfc>
		<lcom>1285</lcom>
		<ca>72</ca>
		<ce>8</ce>
		<npm>54</npm>
		<lcom3>0.9650593990216632</lcom3>
		<loc>351</loc>
		<dam>1.0</dam>
		<moa>7</moa>
		<mfa>0.0</mfa>
		<cam>0.1076388888888889</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public void setNameToSplitSample(java.util.HashMap nameToSplitSample)">1</method>
			<method name="public void setGroupOpToInputTables(java.util.Map groupOpToInputTables)">1</method>
			<method name="public void setListMapJoinOpsNoReducer(java.util.List listMapJoinOpsNoReducer)">1</method>
			<method name="public java.util.HashMap getNameToSplitSample()">1</method>
			<method name="public boolean getHasNonPartCols()">1</method>
			<method name="public void setContext(org.apache.hadoop.hive.ql.Context ctx)">1</method>
			<method name="public org.apache.hadoop.hive.ql.optimizer.unionproc.UnionProcContext getUCtx()">1</method>
			<method name="public java.util.HashMap getTopOps()">1</method>
			<method name="public java.util.HashMap getTopToTable()">1</method>
			<method name="public void setConf(org.apache.hadoop.hive.conf.HiveConf conf)">1</method>
			<method name="public java.util.Map getJoinContext()">1</method>
			<method name="public java.util.HashSet getSemanticInputs()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$GlobalLimitCtx getGlobalLimitCtx()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.Map getMapJoinContext()">1</method>
			<method name="public void setParseTree(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="public int getDestTableId()">1</method>
			<method name="public java.util.List getListMapJoinOpsNoReducer()">1</method>
			<method name="public void setUCtx(org.apache.hadoop.hive.ql.optimizer.unionproc.UnionProcContext uCtx)">1</method>
			<method name="public void setOpToSamplePruner(java.util.HashMap opToSamplePruner)">1</method>
			<method name="public void replaceRootTask(org.apache.hadoop.hive.ql.exec.Task rootTask, java.util.List tasks)">1</method>
			<method name="public void setOpToPartList(java.util.HashMap opToPartList)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.parse.ASTNode ast, java.util.HashMap opToPartPruner, java.util.HashMap opToPartList, java.util.HashMap topOps, java.util.HashMap topSelOps, java.util.LinkedHashMap opParseCtx, java.util.Map joinContext, java.util.HashMap topToTable, java.util.List loadTableWork, java.util.List loadFileWork, org.apache.hadoop.hive.ql.Context ctx, java.util.HashMap idToTableNameMap, int destTableId, org.apache.hadoop.hive.ql.optimizer.unionproc.UnionProcContext uCtx, java.util.List listMapJoinOpsNoReducer, java.util.Map groupOpToInputTables, java.util.Map prunedPartitions, java.util.HashMap opToSamplePruner, org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$GlobalLimitCtx globalLimitCtx, java.util.HashMap nameToSplitSample, java.util.HashSet semanticInputs, java.util.List rootTasks)">0</method>
			<method name="public java.util.HashMap getOpToPartPruner()">1</method>
			<method name="public void setTopOps(java.util.HashMap topOps)">1</method>
			<method name="public java.util.HashMap getOpToPartList()">1</method>
			<method name="public void setPrunedPartitions(java.util.Map prunedPartitions)">1</method>
			<method name="public java.util.LinkedHashMap getOpParseCtx()">1</method>
			<method name="public java.util.HashMap getTopSelOps()">1</method>
			<method name="public void setLoadTableWork(java.util.List loadTableWork)">1</method>
			<method name="public void setGlobalLimitCtx(org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$GlobalLimitCtx globalLimitCtx)">1</method>
			<method name="public void setHasNonPartCols(boolean val)">1</method>
			<method name="public void setJoinContext(java.util.Map joinContext)">1</method>
			<method name="public void setTopToTable(java.util.HashMap topToTable)">1</method>
			<method name="public void setOpToPartPruner(java.util.HashMap opToPartPruner)">1</method>
			<method name="public java.util.Map getPrunedPartitions()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ASTNode getParseTree()">1</method>
			<method name="public org.apache.hadoop.hive.conf.HiveConf getConf()">1</method>
			<method name="public java.util.List getLoadTableWork()">1</method>
			<method name="public void setOpParseCtx(java.util.LinkedHashMap opParseCtx)">1</method>
			<method name="public void setIdToTableNameMap(java.util.HashMap idToTableNameMap)">1</method>
			<method name="public void setQB(org.apache.hadoop.hive.ql.parse.QB qb)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.QB getQB()">1</method>
			<method name="public java.util.List getLoadFileWork()">1</method>
			<method name="public java.util.HashMap getOpToSamplePruner()">1</method>
			<method name="public org.apache.hadoop.hive.ql.hooks.LineageInfo getLineageInfo()">1</method>
			<method name="public java.util.Map getGroupOpToInputTables()">1</method>
			<method name="public void setMapJoinContext(java.util.Map mapJoinContext)">1</method>
			<method name="public org.apache.hadoop.hive.ql.Context getContext()">1</method>
			<method name="public void setLoadFileWork(java.util.List loadFileWork)">1</method>
			<method name="public void setDestTableId(int destTableId)">1</method>
			<method name="public void setLineageInfo(org.apache.hadoop.hive.ql.hooks.LineageInfo lInfo)">1</method>
			<method name="public void setTopSelOps(java.util.HashMap topSelOps)">1</method>
			<method name="public java.util.HashMap getIdToTableNameMap()">1</method>
		</cc>
	</class>
	<class>
		<name>org.json.JSONObject$1</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.server.TServer$AbstractServerArgs</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>3</noc>
		<cbo>13</cbo>
		<rfc>13</rfc>
		<lcom>14</lcom>
		<ca>7</ca>
		<ce>6</ce>
		<npm>9</npm>
		<lcom3>0.8125</lcom3>
		<loc>90</loc>
		<dam>0.0</dam>
		<moa>6</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.333333333333334</amc>
		<cc>
			<method name="public org.apache.thrift.server.TServer$AbstractServerArgs protocolFactory(org.apache.thrift.protocol.TProtocolFactory factory)">1</method>
			<method name="public void _init_(org.apache.thrift.transport.TServerTransport transport)">0</method>
			<method name="public org.apache.thrift.server.TServer$AbstractServerArgs processorFactory(org.apache.thrift.TProcessorFactory factory)">1</method>
			<method name="public org.apache.thrift.server.TServer$AbstractServerArgs inputProtocolFactory(org.apache.thrift.protocol.TProtocolFactory factory)">1</method>
			<method name="public org.apache.thrift.server.TServer$AbstractServerArgs processor(org.apache.thrift.TProcessor processor)">1</method>
			<method name="public org.apache.thrift.server.TServer$AbstractServerArgs outputTransportFactory(org.apache.thrift.transport.TTransportFactory factory)">1</method>
			<method name="public org.apache.thrift.server.TServer$AbstractServerArgs outputProtocolFactory(org.apache.thrift.protocol.TProtocolFactory factory)">1</method>
			<method name="public org.apache.thrift.server.TServer$AbstractServerArgs transportFactory(org.apache.thrift.transport.TTransportFactory factory)">1</method>
			<method name="public org.apache.thrift.server.TServer$AbstractServerArgs inputTransportFactory(org.apache.thrift.transport.TTransportFactory factory)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe$SerDeParameters</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>12</rfc>
		<lcom>53</lcom>
		<ca>5</ca>
		<ce>3</ce>
		<npm>11</npm>
		<lcom3>0.99</lcom3>
		<loc>57</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.272727272727273</amc>
		<cc>
			<method name="public String getNullString()">1</method>
			<method name="public boolean[] getNeedsEscape()">1</method>
			<method name="public java.util.List getColumnTypes()">1</method>
			<method name="public org.apache.hadoop.io.Text getNullSequence()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public boolean isLastColumnTakesRest()">1</method>
			<method name="public java.util.List getColumnNames()">1</method>
			<method name="public byte getEscapeChar()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.typeinfo.TypeInfo getRowTypeInfo()">1</method>
			<method name="public boolean isEscaped()">1</method>
			<method name="public byte[] getSeparators()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HiveRecordReader</name>
		<wmc>11</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>19</rfc>
		<lcom>35</lcom>
		<ca>2</ca>
		<ce>6</ce>
		<npm>11</npm>
		<lcom3>2.0</lcom3>
		<loc>70</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.25757575757575757</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.363636363636363</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.mapred.RecordReader recordReader)">0</method>
			<method name="public void _init_(org.apache.hadoop.mapred.RecordReader recordReader, org.apache.hadoop.mapred.JobConf conf)">0</method>
			<method name="public volatile Object createKey()">1</method>
			<method name="public org.apache.hadoop.io.Writable createValue()">1</method>
			<method name="public volatile boolean doNext(Object x0, Object x1)">1</method>
			<method name="public float getProgress()">1</method>
			<method name="public boolean doNext(org.apache.hadoop.io.WritableComparable key, org.apache.hadoop.io.Writable value)">1</method>
			<method name="public volatile Object createValue()">1</method>
			<method name="public long getPos()">1</method>
			<method name="public org.apache.hadoop.io.WritableComparable createKey()">1</method>
			<method name="public void doClose()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsUtils</name>
		<wmc>15</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>31</rfc>
		<lcom>45</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>14</npm>
		<lcom3>0.5714285714285714</lcom3>
		<loc>352</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.21428571428571427</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>22.333333333333332</amc>
		<cc>
			<method name="public static String getDeleteAggr(String rowID, String comment)">1</method>
			<method name="public static String getIdColumnName()">1</method>
			<method name="public static String getStatColumnName(String statType)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public static boolean isValidStatisticSet(java.util.Collection stats)">3</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static String getCreate(String comment)">2</method>
			<method name="public static boolean isValidStatistic(String statType)">1</method>
			<method name="public static String getSelectAggr(String statType, String comment)">1</method>
			<method name="public static String getTimestampColumnName()">1</method>
			<method name="public static java.util.List getSupportedStatistics()">1</method>
			<method name="public static String getUpdate(String comment)">2</method>
			<method name="public static String getInsert(String comment)">2</method>
			<method name="public static String getStatTableName()">1</method>
			<method name="public static String getBasicStat()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$lockMode_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Utilities$ReduceField</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>7</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9166666666666666</lcom3>
		<loc>56</loc>
		<dam>0.25</dam>
		<moa>4</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>12.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.Utilities$ReduceField valueOf(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.Utilities$ReduceField[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFCase</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>19</rfc>
		<lcom>2</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>355</loc>
		<dam>0.75</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>69.2</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeEnum</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ListObjectsEqualComparer$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>49</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>47.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.json.XML</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>46</rfc>
		<lcom>26</lcom>
		<ca>3</ca>
		<ce>4</ce>
		<npm>6</npm>
		<lcom3>0.8095238095238094</lcom3>
		<loc>756</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2857142857142857</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>92.375</amc>
		<cc>
			<method name="public static String toString(Object arg0, String arg1)">1</method>
			<method name="public static org.json.JSONObject toJSONObject(String arg0)">1</method>
			<method name="private static boolean parse(org.json.XMLTokener arg0, org.json.JSONObject arg1, String arg2)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static String escape(String arg0)">7</method>
			<method name="public static String toString(Object arg0)">1</method>
			<method name="public static void noSpace(String arg0)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.lineage.OpProcFactory</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>22</rfc>
		<lcom>55</lcom>
		<ca>9</ca>
		<ce>13</ce>
		<npm>10</npm>
		<lcom3>2.0</lcom3>
		<loc>55</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.09090909090909091</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getDefaultProc()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getGroupByProc()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getUnionProc()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getTransformProc()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getReduceSinkProc()">1</method>
			<method name="protected static org.apache.hadoop.hive.ql.exec.Operator getParent(java.util.Stack stack)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getLateralViewJoinProc()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getSelProc()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getJoinProc()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getTSProc()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.UDTFDesc</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>5</npm>
		<lcom3>0.75</lcom3>
		<loc>27</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.7</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDTF getGenericUDTF()">1</method>
			<method name="public void setGenericUDTF(org.apache.hadoop.hive.ql.udf.generic.GenericUDTF genericUDTF)">1</method>
			<method name="public String getUDTFName()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.udf.generic.GenericUDTF genericUDTF)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCovariance</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>14</cbo>
		<rfc>15</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>12</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>131</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>42.333333333333336</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] parameters)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFAscii</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>33</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.Text s)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFUnhex</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>12</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>66</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>32.0</amc>
		<cc>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text s)">4</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableConstantBooleanObjectInspector</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>16</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public volatile Object getWritableConstantValue()">1</method>
			<method name="public org.apache.hadoop.io.BooleanWritable getWritableConstantValue()">1</method>
			<method name="void _init_(org.apache.hadoop.io.BooleanWritable value)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ShowIndexesDesc</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>8</rfc>
		<lcom>9</lcom>
		<ca>4</ca>
		<ce>2</ce>
		<npm>6</npm>
		<lcom3>0.96</lcom3>
		<loc>36</loc>
		<dam>0.4</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.166666666666667</amc>
		<cc>
			<method name="public void setFormatted(boolean isFormatted)">1</method>
			<method name="public String getResFile()">1</method>
			<method name="public String getTableName()">1</method>
			<method name="public void _init_(String tableName, org.apache.hadoop.fs.Path resFile)">0</method>
			<method name="public boolean isFormatted()">1</method>
			<method name="public static String getSchema()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.SchemaDesc</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>22</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public String getSchema()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(String schema)">0</method>
			<method name="public void setSchema(String schema)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tableSource_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.TServiceClientFactory</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.thrift.TServiceClient getClient(org.apache.thrift.protocol.TProtocol)">1</method>
			<method name="public abstract org.apache.thrift.TServiceClient getClient(org.apache.thrift.protocol.TProtocol, org.apache.thrift.protocol.TProtocol)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveLexer$DFA23</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>38</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>17.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.parse.HiveLexer, org.antlr.runtime.BaseRecognizer recognizer)">0</method>
			<method name="public String getDescription()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TSaslTransport$SaslResponse</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>12</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.0</amc>
		<cc>
			<method name="public void _init_(org.apache.thrift.transport.TSaslTransport$NegotiationStatus status, byte[] payload)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.NodeType</name>
		<wmc>6</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>9</rfc>
		<lcom>9</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>64</loc>
		<dam>0.5</dam>
		<moa>3</moa>
		<mfa>0.7647058823529411</mfa>
		<cam>0.4</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>9.0</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.NodeType findByValue(int value)">4</method>
			<method name="static void _clinit_()">0</method>
			<method name="public int getValue()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.NodeType valueOf(String name)">1</method>
			<method name="private void _init_(String, int, int value)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.NodeType[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDAFWrongArgLengthForTestCase</name>
		<wmc>1</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.proto.test.Complexpb$IntString</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>9</rfc>
		<lcom>16</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>8</npm>
		<lcom3>0.9523809523809524</lcom3>
		<loc>67</loc>
		<dam>0.6666666666666666</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4166666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.25</amc>
		<cc>
			<method name="public String getMyString()">1</method>
			<method name="public boolean hasUnderscoreInt()">1</method>
			<method name="public int getUnderscoreInt()">1</method>
			<method name="public int getMyint()">1</method>
			<method name="public boolean hasMyString()">1</method>
			<method name="public boolean hasMyint()">1</method>
			<method name="public void _init_(int myInt, String myString, int underscoreInt)">0</method>
			<method name="public final boolean isInitialized()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.columnar.BytesRefWritable</name>
		<wmc>21</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>42</rfc>
		<lcom>0</lcom>
		<ca>11</ca>
		<ce>6</ce>
		<npm>19</npm>
		<lcom3>0.5642857142857143</lcom3>
		<loc>368</loc>
		<dam>0.14285714285714285</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.225</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>16.19047619047619</amc>
		<cc>
			<method name="public boolean equals(Object right_obj)">4</method>
			<method name="public byte[] getData()">1</method>
			<method name="private void lazyDecompress()">1</method>
			<method name="public byte[] getBytesCopy()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void writeDataTo(java.io.DataOutput out)">1</method>
			<method name="public void write(java.io.DataOutput out)">1</method>
			<method name="public void set(org.apache.hadoop.hive.serde2.columnar.LazyDecompressionCallback newData, int offset, int len)">1</method>
			<method name="public int getStart()">1</method>
			<method name="public void set(byte[] newData, int offset, int len)">1</method>
			<method name="public void readFields(java.io.DataInput in)">1</method>
			<method name="public volatile int compareTo(Object x0)">1</method>
			<method name="public int hashCode()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.columnar.LazyDecompressionCallback lazyDecompressData, int offset, int len)">0</method>
			<method name="public void _init_(int length)">0</method>
			<method name="public void _init_(byte[] bytes)">0</method>
			<method name="public int compareTo(org.apache.hadoop.hive.serde2.columnar.BytesRefWritable other)">3</method>
			<method name="public void _init_(byte[] data, int offset, int len)">0</method>
			<method name="public String toString()">4</method>
			<method name="public int getLength()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryArray</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>24</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>10</ce>
		<npm>4</npm>
		<lcom3>0.39999999999999997</lcom3>
		<loc>319</loc>
		<dam>0.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>37.625</amc>
		<cc>
			<method name="public int getListLength()">2</method>
			<method name="private Object uncheckedGetElement(int index)">4</method>
			<method name="private void adjustArraySize(int newSize)">3</method>
			<method name="public java.util.List getList()">4</method>
			<method name="private void parse()">5</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.lazybinary.objectinspector.LazyBinaryListObjectInspector oi)">0</method>
			<method name="public Object getListElementObject(int index)">4</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyUnion</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>22</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>9</ce>
		<npm>4</npm>
		<lcom3>0.4</lcom3>
		<loc>204</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>32.166666666666664</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.LazyUnionObjectInspector oi)">0</method>
			<method name="private Object uncheckedGetField()">5</method>
			<method name="private void parse()">8</method>
			<method name="public byte getTag()">2</method>
			<method name="public Object getField()">2</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.LoadDesc</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>2</noc>
		<cbo>2</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>22</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public String getSourceDir()">1</method>
			<method name="public void _init_(String sourceDir)">0</method>
			<method name="public void _init_()">0</method>
			<method name="public void setSourceDir(String source)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.IndexMetadataChangeTask</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>39</rfc>
		<lcom>10</lcom>
		<ca>1</ca>
		<ce>17</ce>
		<npm>3</npm>
		<lcom3>1.25</lcom3>
		<loc>183</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>35.4</amc>
		<cc>
			<method name="protected int execute(org.apache.hadoop.hive.ql.DriverContext driverContext)">7</method>
			<method name="public void _init_()">0</method>
			<method name="protected void localizeMRTmpFilesImpl(org.apache.hadoop.hive.ql.Context ctx)">1</method>
			<method name="public String getName()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.StageType getType()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFElt</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>21</rfc>
		<lcom>6</lcom>
		<ca>0</ca>
		<ce>15</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>195</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>37.6</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.CreateTableDesc</name>
		<wmc>48</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>51</rfc>
		<lcom>1000</lcom>
		<ca>7</ca>
		<ce>2</ce>
		<npm>48</npm>
		<lcom3>0.9398704902867715</lcom3>
		<loc>337</loc>
		<dam>0.043478260869565216</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.23511904761904762</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.541666666666667</amc>
		<cc>
			<method name="public int getNumBuckets()">1</method>
			<method name="public String getMapKeyDelim()">1</method>
			<method name="public void setPartCols(java.util.ArrayList partCols)">1</method>
			<method name="public String getStorageHandler()">1</method>
			<method name="public java.util.ArrayList getPartCols()">1</method>
			<method name="public void setSerdeProps(java.util.Map serdeProps)">1</method>
			<method name="public void setStorageHandler(String storageHandler)">1</method>
			<method name="public void setInputFormat(String inputFormat)">1</method>
			<method name="public void setCollItemDelim(String collItemDelim)">1</method>
			<method name="public java.util.List getPartColsString()">1</method>
			<method name="public java.util.List getColsString()">1</method>
			<method name="public void setFieldDelim(String fieldDelim)">1</method>
			<method name="public void setSortCols(java.util.ArrayList sortCols)">1</method>
			<method name="public void setCols(java.util.ArrayList cols)">1</method>
			<method name="public String getTableName()">1</method>
			<method name="public void setLocation(String location)">1</method>
			<method name="public void setTableName(String tableName)">1</method>
			<method name="public void setMapKeyDelim(String mapKeyDelim)">1</method>
			<method name="public String getCollItemDelim()">1</method>
			<method name="public java.util.Map getSerdeProps()">1</method>
			<method name="public String getLocation()">1</method>
			<method name="public String getInputFormat()">1</method>
			<method name="public java.util.ArrayList getCols()">1</method>
			<method name="public String getLineDelim()">1</method>
			<method name="public String getFieldEscape()">1</method>
			<method name="public void setExternal(boolean isExternal)">1</method>
			<method name="public void setComment(String comment)">1</method>
			<method name="public String getComment()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public String getDatabaseName()">1</method>
			<method name="public java.util.ArrayList getBucketCols()">1</method>
			<method name="public void setIfNotExists(boolean ifNotExists)">1</method>
			<method name="public void setOutputFormat(String outputFormat)">1</method>
			<method name="public void setFieldEscape(String fieldEscape)">1</method>
			<method name="public java.util.ArrayList getSortCols()">1</method>
			<method name="public boolean getIfNotExists()">1</method>
			<method name="public void _init_(String tableName, boolean isExternal, java.util.List cols, java.util.List partCols, java.util.List bucketCols, java.util.List sortCols, int numBuckets, String fieldDelim, String fieldEscape, String collItemDelim, String mapKeyDelim, String lineDelim, String comment, String inputFormat, String outputFormat, String location, String serName, String storageHandler, java.util.Map serdeProps, java.util.Map tblProps, boolean ifNotExists)">0</method>
			<method name="public void setTblProps(java.util.Map tblProps)">1</method>
			<method name="public java.util.Map getTblProps()">1</method>
			<method name="public String getOutputFormat()">1</method>
			<method name="public void setNumBuckets(int numBuckets)">1</method>
			<method name="public void setSerName(String serName)">1</method>
			<method name="public String getSerName()">1</method>
			<method name="public String getFieldDelim()">1</method>
			<method name="public void setLineDelim(String lineDelim)">1</method>
			<method name="public void _init_(String databaseName, String tableName, boolean isExternal, java.util.List cols, java.util.List partCols, java.util.List bucketCols, java.util.List sortCols, int numBuckets, String fieldDelim, String fieldEscape, String collItemDelim, String mapKeyDelim, String lineDelim, String comment, String inputFormat, String outputFormat, String location, String serName, String storageHandler, java.util.Map serdeProps, java.util.Map tblProps, boolean ifNotExists)">0</method>
			<method name="public void setBucketCols(java.util.ArrayList bucketCols)">1</method>
			<method name="public boolean isExternal()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.UnparseTranslator$1</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter$FloatConverter</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>36</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector inputOI, org.apache.hadoop.hive.serde2.objectinspector.primitive.SettableFloatObjectInspector outputOI)">0</method>
			<method name="public Object convert(Object input)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyPrimitiveObjectInspectorFactory</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>29</rfc>
		<lcom>2</lcom>
		<ca>1</ca>
		<ce>14</ce>
		<npm>2</npm>
		<lcom3>0.6363636363636364</lcom3>
		<loc>138</loc>
		<dam>0.0</dam>
		<moa>10</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>30.75</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.AbstractPrimitiveLazyObjectInspector getLazyObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector$PrimitiveCategory primitiveCategory, boolean escaped, byte escapeChar)">2</method>
			<method name="private void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector getLazyStringObjectInspector(boolean escaped, byte escapeChar)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.LoadMultiFilesDesc</name>
		<wmc>12</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>13</rfc>
		<lcom>36</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>12</npm>
		<lcom3>0.8636363636363636</lcom3>
		<loc>74</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4166666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.666666666666667</amc>
		<cc>
			<method name="public void setColumns(String columns)">1</method>
			<method name="public void setSourceDirs(java.util.List srcs)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setColumnTypes(String columnTypes)">1</method>
			<method name="public boolean getIsDfsDir()">1</method>
			<method name="public void setTargetDirs(java.util.List targetDir)">1</method>
			<method name="public String getColumns()">1</method>
			<method name="public void setIsDfsDir(boolean isDfsDir)">1</method>
			<method name="public java.util.List getTargetDirs()">1</method>
			<method name="public String getColumnTypes()">1</method>
			<method name="public java.util.List getSourceDirs()">1</method>
			<method name="public void _init_(java.util.List sourceDirs, java.util.List targetDir, boolean isDfsDir, String columns, String columnTypes)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TProtocolFactory</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>25</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>23</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.thrift.protocol.TProtocol getProtocol(org.apache.thrift.transport.TTransport)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFSize</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>23</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>13</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>162</loc>
		<dam>0.6666666666666666</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>30.8</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.history.HiveHistory$Info</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>3</noc>
		<cbo>3</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFDateAdd</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>16</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>0.0</lcom3>
		<loc>91</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>28.333333333333332</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text dateString1, org.apache.hadoop.io.IntWritable days)">3</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable t, org.apache.hadoop.io.IntWritable days)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixLocation_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFPercentileApprox$GenericUDAFSinglePercentileApproxEvaluator</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>16</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>15</ce>
		<npm>3</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>106</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>25.25</amc>
		<cc>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector init(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode m, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] parameters)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDAFPercentile$PercentileLongEvaluator</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>36</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>6</ce>
		<npm>6</npm>
		<lcom3>0.5</lcom3>
		<loc>211</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>33.833333333333336</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.udf.UDAFPercentile$State terminatePartial()">1</method>
			<method name="public boolean merge(org.apache.hadoop.hive.ql.udf.UDAFPercentile$State other)">6</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable terminate()">5</method>
			<method name="public boolean iterate(org.apache.hadoop.io.LongWritable o, Double percentile)">7</method>
			<method name="public void init()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterViewSuffixProperties_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.UnionObject</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract byte getTag()">1</method>
			<method name="public abstract Object getObject()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>40</cbo>
		<rfc>90</rfc>
		<lcom>21</lcom>
		<ca>2</ca>
		<ce>38</ce>
		<npm>8</npm>
		<lcom3>0.8518518518518517</lcom3>
		<loc>1092</loc>
		<dam>0.26666666666666666</dam>
		<moa>6</moa>
		<mfa>0.0</mfa>
		<cam>0.24691358024691357</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>106.7</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getObjectInspector()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static boolean serialize(org.apache.hadoop.hive.serde2.ByteStream$Output byteStream, Object obj, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objInspector, boolean skipLengthPrefix, boolean warnedOnceNullMapKey)">25</method>
			<method name="public Class getSerializedClass()">1</method>
			<method name="public org.apache.hadoop.io.Writable serialize(Object obj, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objInspector)">1</method>
			<method name="public void initialize(org.apache.hadoop.conf.Configuration conf, java.util.Properties tbl)">1</method>
			<method name="private static boolean serializeStruct(org.apache.hadoop.hive.serde2.ByteStream$Output byteStream, Object obj, org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector soi, boolean warnedOnceNullMapKey)">7</method>
			<method name="public Object deserialize(org.apache.hadoop.io.Writable field)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.SerDeStats getSerDeStats()">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils$PrimitiveTypeEntry</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>50</cbo>
		<rfc>11</rfc>
		<lcom>0</lcom>
		<ca>47</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>83</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4444444444444444</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>25.0</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector$PrimitiveCategory primitiveCategory, String typeName, Class primitiveType, Class javaClass, Class hiveClass)">0</method>
			<method name="public void write(java.io.DataOutput out)">1</method>
			<method name="public void readFields(java.io.DataInput in)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyFactory$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>117</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>114.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory$ColumnPrunerTableScanProc</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>27</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>12</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>131</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>64.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.DropFunctionDesc</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>22</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void setFunctionName(String functionName)">1</method>
			<method name="public void _init_(String functionName)">0</method>
			<method name="public String getFunctionName()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TSimpleJSONProtocol$StructContext</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>0</npm>
		<lcom3>0.0</lcom3>
		<loc>47</loc>
		<dam>0.6666666666666666</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>21.0</amc>
		<cc>
			<method name="protected void _init_(org.apache.thrift.protocol.TSimpleJSONProtocol)">0</method>
			<method name="protected void write()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFUtils</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>18</rfc>
		<lcom>6</lcom>
		<ca>8</ca>
		<ce>1</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>159</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3125</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>38.75</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public static boolean isUtfStartByte(byte b)">2</method>
			<method name="public static String getOrdinal(int i)">8</method>
			<method name="public static int findText(org.apache.hadoop.io.Text text, org.apache.hadoop.io.Text subtext, int start)">7</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ColumnarStructObjectInspector</name>
		<wmc>12</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>30</rfc>
		<lcom>42</lcom>
		<ca>3</ca>
		<ce>9</ce>
		<npm>8</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>205</loc>
		<dam>0.3333333333333333</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.36363636363636365</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.833333333333334</amc>
		<cc>
			<method name="protected void init(java.util.List structFieldNames, java.util.List structFieldObjectInspectors, java.util.List structFieldComments)">8</method>
			<method name="public Object getStructFieldData(Object data, org.apache.hadoop.hive.serde2.objectinspector.StructField fieldRef)">5</method>
			<method name="static void _clinit_()">0</method>
			<method name="public java.util.List getStructFieldsDataAsList(Object data)">2</method>
			<method name="public final org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
			<method name="protected void _init_(java.util.List fields)">0</method>
			<method name="public java.util.List getAllStructFieldRefs()">1</method>
			<method name="protected void init(java.util.List fields)">2</method>
			<method name="public String getTypeName()">1</method>
			<method name="public void _init_(java.util.List structFieldNames, java.util.List structFieldObjectInspectors)">0</method>
			<method name="public void _init_(java.util.List structFieldNames, java.util.List structFieldObjectInspectors, java.util.List structFieldComments)">0</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.StructField getStructFieldRef(String fieldName)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>6</noc>
		<cbo>57</cbo>
		<rfc>16</rfc>
		<lcom>15</lcom>
		<ca>55</ca>
		<ce>2</ce>
		<npm>6</npm>
		<lcom3>2.0</lcom3>
		<loc>56</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4166666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.333333333333334</amc>
		<cc>
			<method name="public abstract java.util.List getAllStructFieldRefs()">1</method>
			<method name="public abstract java.util.List getStructFieldsDataAsList(Object)">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.objectinspector.StructField getStructFieldRef(String)">1</method>
			<method name="public abstract Object getStructFieldData(Object, org.apache.hadoop.hive.serde2.objectinspector.StructField)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public String toString()">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.metrics.Metrics</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>33</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>9</npm>
		<lcom3>0.5277777777777778</lcom3>
		<loc>212</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.2777777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.8</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.common.metrics.Metrics$MetricsScope getScope(String name)">1</method>
			<method name="public static Long incrementCounter(String name, long increment)">1</method>
			<method name="public static void set(String name, Object value)">1</method>
			<method name="public static Long incrementCounter(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.common.metrics.Metrics$MetricsScope startScope(String name)">1</method>
			<method name="public static void endScope(String name)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static Object get(String name)">1</method>
			<method name="public static void init()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsPublisher</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>56</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>11</ce>
		<npm>5</npm>
		<lcom3>0.4545454545454546</lcom3>
		<loc>548</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2653061224489796</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>75.71428571428571</amc>
		<cc>
			<method name="private boolean handleSQLRecoverableException(Exception e, int failures)">3</method>
			<method name="public boolean init(org.apache.hadoop.conf.Configuration hconf)">2</method>
			<method name="public boolean closeConnection()">5</method>
			<method name="public void _init_()">0</method>
			<method name="public boolean publishStat(String fileID, java.util.Map stats)">5</method>
			<method name="static int access$000(org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsPublisher x0)">1</method>
			<method name="public boolean connect(org.apache.hadoop.conf.Configuration hiveconf)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.processors.DeleteResourceProcessor</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>23</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>3</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>92</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>21.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.processors.CommandProcessorResponse run(String command)">4</method>
			<method name="public void init()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFSpace</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>9</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>50</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>23.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.IntWritable n)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$GenericUDAFInfo</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>7</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.SettableMapObjectInspector</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>4</rfc>
		<lcom>6</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.875</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Object clear(Object)">1</method>
			<method name="public abstract Object remove(Object, Object)">1</method>
			<method name="public abstract Object create()">1</method>
			<method name="public abstract Object put(Object, Object, Object)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TSaslServerTransport$Factory</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>18</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>4</npm>
		<lcom3>0.5</lcom3>
		<loc>94</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.55</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>17.4</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void addServerDefinition(String mechanism, String protocol, String serverName, java.util.Map props, javax.security.auth.callback.CallbackHandler cbh)">1</method>
			<method name="public void _init_(String mechanism, String protocol, String serverName, java.util.Map props, javax.security.auth.callback.CallbackHandler cbh)">0</method>
			<method name="public org.apache.thrift.transport.TTransport getTransport(org.apache.thrift.transport.TTransport base)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Jetty20Shims$Server</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>15</rfc>
		<lcom>6</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>45</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.25</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public void addWar(String war, String contextPath)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.shims.Jetty20Shims$1 x0)">0</method>
			<method name="public void setupListenerHostPort(String listen, int port)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPGreaterThan</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>17</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>17</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>202</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>100.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HiveOutputFormatImpl$1</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>6</rfc>
		<lcom>6</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>3</npm>
		<lcom3>1.0</lcom3>
		<loc>24</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.75</amc>
		<cc>
			<method name="public void close(org.apache.hadoop.mapred.Reporter reporter)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.io.HiveOutputFormatImpl)">0</method>
			<method name="public volatile void write(Object x0, Object x1)">1</method>
			<method name="public void write(org.apache.hadoop.io.WritableComparable key, org.apache.hadoop.io.Writable value)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.processors.CommandProcessorFactory</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>22</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>10</ce>
		<npm>3</npm>
		<lcom3>0.25</lcom3>
		<loc>102</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4166666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.2</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.processors.CommandProcessor get(String cmd)">1</method>
			<method name="private void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static void clean(org.apache.hadoop.hive.conf.HiveConf conf)">2</method>
			<method name="public static org.apache.hadoop.hive.ql.processors.CommandProcessor get(String cmd, org.apache.hadoop.hive.conf.HiveConf conf)">8</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.SimpleGenericUDAFParameterInfo</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>5</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>53</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.0</amc>
		<cc>
			<method name="public boolean isDistinct()">1</method>
			<method name="public boolean isAllColumns()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] getParameterObjectInspectors()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] params, boolean distinct, boolean allColumns)">0</method>
			<method name="public org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] getParameters()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Operator$ProgressCounter</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9996673320026614</lcom3>
		<loc>11034</loc>
		<dam>9.98003992015968E-4</dam>
		<moa>1002</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>2507.0</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.exec.Operator$ProgressCounter valueOf(String name)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.Operator$ProgressCounter[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.HiveDriverRunHookContextImpl</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>3</npm>
		<lcom3>0.0</lcom3>
		<loc>17</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.333333333333333</amc>
		<cc>
			<method name="public org.apache.hadoop.conf.Configuration getConf()">1</method>
			<method name="public void setConf(org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="public void _init_(org.apache.hadoop.conf.Configuration conf)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.AutoExpandingBufferWriteTransport</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>15</rfc>
		<lcom>20</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>9</npm>
		<lcom3>0.6875</lcom3>
		<loc>65</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4166666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.0</amc>
		<cc>
			<method name="public boolean isOpen()">1</method>
			<method name="public void open()">1</method>
			<method name="public void reset()">1</method>
			<method name="public void close()">1</method>
			<method name="public void _init_(int initialCapacity, double growthCoefficient)">0</method>
			<method name="public void write(byte[] toWrite, int off, int len)">1</method>
			<method name="public int getPos()">1</method>
			<method name="public org.apache.thrift.transport.AutoExpandingBuffer getBuf()">1</method>
			<method name="public int read(byte[] buf, int off, int len)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>15</rfc>
		<lcom>8</lcom>
		<ca>9</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>0.7142857142857143</lcom3>
		<loc>62</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4583333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.5</amc>
		<cc>
			<method name="public int hashCode()">1</method>
			<method name="public void _init_()">0</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo elementTypeInfo)">0</method>
			<method name="public void setListElementTypeInfo(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo listElementTypeInfo)">1</method>
			<method name="public String getTypeName()">1</method>
			<method name="public boolean equals(Object other)">3</method>
			<method name="public org.apache.hadoop.hive.serde2.typeinfo.TypeInfo getListElementTypeInfo()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.QBJoinTree</name>
		<wmc>38</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>52</rfc>
		<lcom>633</lcom>
		<ca>10</ca>
		<ce>2</ce>
		<npm>38</npm>
		<lcom3>0.9669669669669669</lcom3>
		<loc>294</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.17543859649122806</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.2631578947368425</amc>
		<cc>
			<method name="public java.util.ArrayList getNullSafes()">1</method>
			<method name="public void addRHSSemijoinColumns(String alias, org.apache.hadoop.hive.ql.parse.ASTNode column)">2</method>
			<method name="public void setFilters(java.util.ArrayList filters)">1</method>
			<method name="public void setStreamAliases(java.util.List streamAliases)">1</method>
			<method name="public void setExpressions(java.util.ArrayList expressions)">1</method>
			<method name="public void setJoinCond(org.apache.hadoop.hive.ql.parse.JoinCond[] joinCond)">1</method>
			<method name="public void setNoSemiJoin(boolean semi)">1</method>
			<method name="public java.util.ArrayList getFilters()">1</method>
			<method name="public void setLeftAliases(String[] leftAliases)">1</method>
			<method name="public int getNextTag()">1</method>
			<method name="public void setNullSafes(java.util.ArrayList nullSafes)">1</method>
			<method name="public void setMapSideJoin(boolean mapSideJoin)">1</method>
			<method name="public java.util.ArrayList getRHSSemijoinColumns(String alias)">1</method>
			<method name="public String[] getBaseSrc()">1</method>
			<method name="public java.util.List getStreamAliases()">1</method>
			<method name="public boolean getNoOuterJoin()">1</method>
			<method name="public String getLeftAlias()">1</method>
			<method name="public void setMapAliases(java.util.List mapAliases)">1</method>
			<method name="public void setFiltersForPushing(java.util.ArrayList filters)">1</method>
			<method name="public void setLeftAlias(String leftAlias)">1</method>
			<method name="public boolean isMapSideJoin()">1</method>
			<method name="public java.util.List getMapAliases()">1</method>
			<method name="public String[] getLeftAliases()">1</method>
			<method name="public void setRightAliases(String[] rightAliases)">1</method>
			<method name="public void addRHSSemijoinColumns(String alias, java.util.ArrayList columns)">2</method>
			<method name="public void setBaseSrc(String[] baseSrc)">1</method>
			<method name="public void addRHSSemijoin(String alias)">2</method>
			<method name="public void _init_()">0</method>
			<method name="public String[] getRightAliases()">1</method>
			<method name="public void setNoOuterJoin(boolean noOuterJoin)">1</method>
			<method name="public void setJoinSrc(org.apache.hadoop.hive.ql.parse.QBJoinTree joinSrc)">1</method>
			<method name="public void mergeRHSSemijoin(org.apache.hadoop.hive.ql.parse.QBJoinTree src)">3</method>
			<method name="public java.util.ArrayList getExpressions()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.QBJoinTree getJoinSrc()">1</method>
			<method name="public java.util.ArrayList getFiltersForPushing()">1</method>
			<method name="public String getJoinStreamDesc()">1</method>
			<method name="public boolean getNoSemiJoin()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.JoinCond[] getJoinCond()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TFileTransport</name>
		<wmc>21</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>63</rfc>
		<lcom>76</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>16</npm>
		<lcom3>0.5625</lcom3>
		<loc>880</loc>
		<dam>0.5</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.19047619047619047</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>40.523809523809526</amc>
		<cc>
			<method name="public int getCurChunk()">1</method>
			<method name="public int getNumChunks()">1</method>
			<method name="public void write(byte[] buf, int off, int len)">1</method>
			<method name="public void seekToEnd()">1</method>
			<method name="private java.io.InputStream createInputStream()">1</method>
			<method name="public void close()">3</method>
			<method name="public org.apache.thrift.transport.TFileTransport$tailPolicy setTailPolicy(org.apache.thrift.transport.TFileTransport$tailPolicy policy)">1</method>
			<method name="private boolean readEvent()">1</method>
			<method name="public void _init_(org.apache.thrift.transport.TSeekableFile inputFile, boolean readOnly)">0</method>
			<method name="public int read(byte[] buf, int off, int len)">1</method>
			<method name="public boolean isOpen()">4</method>
			<method name="public void seekToChunk(int chunk)">1</method>
			<method name="public void open()">1</method>
			<method name="private int tailRead(java.io.InputStream is, byte[] buf, int off, int len, org.apache.thrift.transport.TFileTransport$tailPolicy tp)">1</method>
			<method name="public static void main(String[] args)">1</method>
			<method name="private boolean performRecovery()">1</method>
			<method name="public void flush()">1</method>
			<method name="private static void printUsage()">1</method>
			<method name="public org.apache.thrift.transport.TFileTransport$tailPolicy getTailPolicy()">1</method>
			<method name="public int readAll(byte[] buf, int off, int len)">1</method>
			<method name="public void _init_(String path, boolean readOnly)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.GenMRUnion1</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>30</cbo>
		<rfc>84</rfc>
		<lcom>16</lcom>
		<ca>1</ca>
		<ce>29</ce>
		<npm>2</npm>
		<lcom3>0.5714285714285714</lcom3>
		<loc>526</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.30952380952380953</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>64.625</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void processSubQueryUnionMapJoin(org.apache.hadoop.hive.ql.optimizer.GenMRProcContext ctx)">7</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx opProcCtx, Object[] nodeOutputs)">1</method>
			<method name="private void processSubQueryUnionMerge(org.apache.hadoop.hive.ql.optimizer.GenMRProcContext ctx, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext$GenMRUnionCtx uCtxTask, org.apache.hadoop.hive.ql.exec.UnionOperator union, java.util.Stack stack)">1</method>
			<method name="private void processSubQueryUnionCreateIntermediate(org.apache.hadoop.hive.ql.exec.Operator parent, org.apache.hadoop.hive.ql.exec.Operator child, org.apache.hadoop.hive.ql.exec.Task uTask, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext ctx, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext$GenMRUnionCtx uCtxTask)">5</method>
			<method name="private Object processMapOnlyUnion(org.apache.hadoop.hive.ql.exec.UnionOperator union, java.util.Stack stack, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext ctx, org.apache.hadoop.hive.ql.optimizer.unionproc.UnionProcContext uCtx)">1</method>
			<method name="private boolean shouldBeRootTask(org.apache.hadoop.hive.ql.exec.Task currTask, org.apache.hadoop.hive.ql.parse.ParseContext parseContext)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.index.IndexWhereProcessor</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>28</cbo>
		<rfc>69</rfc>
		<lcom>7</lcom>
		<ca>1</ca>
		<ce>27</ce>
		<npm>2</npm>
		<lcom3>0.7</lcom3>
		<loc>388</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3076923076923077</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>63.333333333333336</amc>
		<cc>
			<method name="private void findLeaves(java.util.List tasks, java.util.Set leaves)">3</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void insertIndexQuery(org.apache.hadoop.hive.ql.parse.ParseContext pctx, org.apache.hadoop.hive.ql.optimizer.physical.index.IndexWhereProcCtx context, java.util.List chosenRewrite)">2</method>
			<method name="private void rewriteForIndexes(org.apache.hadoop.hive.ql.plan.ExprNodeDesc predicate, java.util.List indexes, org.apache.hadoop.hive.ql.parse.ParseContext pctx, org.apache.hadoop.hive.ql.exec.Task task, org.apache.hadoop.hive.ql.index.HiveIndexQueryContext queryContext)">1</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
			<method name="public void _init_(java.util.Map indexes)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFnGrams</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>17</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>13</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>287</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>94.33333333333333</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] parameters)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.binarysortable.OutputByteBuffer</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>14</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>7</npm>
		<lcom3>0.3333333333333333</lcom3>
		<loc>116</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.47619047619047616</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.285714285714286</amc>
		<cc>
			<method name="public String dumpHex()">3</method>
			<method name="public final void write(byte b)">1</method>
			<method name="public final void write(byte b, boolean invert)">3</method>
			<method name="public final int getLength()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void reset()">1</method>
			<method name="public final byte[] getData()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>22</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>21</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9333333333333332</lcom3>
		<loc>67</loc>
		<dam>0.2</dam>
		<moa>5</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>14.5</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode valueOf(String name)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode[] values()">1</method>
			<method name="private void _init_(String, int)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.LateralViewJoinOperator</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>21</rfc>
		<lcom>6</lcom>
		<ca>3</ca>
		<ce>10</ce>
		<npm>4</npm>
		<lcom3>1.05</lcom3>
		<loc>146</loc>
		<dam>0.2</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>27.2</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void processOp(Object row, int tag)">1</method>
			<method name="public String getName()">1</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
		</cc>
	</class>
	<class>
		<name>javaewah.EWAHCompressedBitmap</name>
		<wmc>39</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>82</rfc>
		<lcom>0</lcom>
		<ca>8</ca>
		<ce>7</ce>
		<npm>28</npm>
		<lcom3>0.5043859649122807</lcom3>
		<loc>3361</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.14595660749506903</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>85.02564102564102</amc>
		<cc>
			<method name="public Object clone()">1</method>
			<method name="private int addLiteralWord(long newdata)">2</method>
			<method name="public int addStreamOfEmptyWords(boolean v, long number)">11</method>
			<method name="public boolean equals(Object o)">7</method>
			<method name="public java.util.Iterator iterator()">1</method>
			<method name="public void serialize(java.io.DataOutput out)">1</method>
			<method name="private int addEmptyWord(boolean v)">7</method>
			<method name="public boolean set(int i)">7</method>
			<method name="private boolean reserve(int size)">2</method>
			<method name="public void readExternal(java.io.ObjectInput in)">1</method>
			<method name="public int sizeInBytes()">1</method>
			<method name="private javaewah.EWAHIterator getEWAHIterator()">1</method>
			<method name="public void deserialize(java.io.DataInput in)">1</method>
			<method name="public java.util.List getPositions()">8</method>
			<method name="public void writeExternal(java.io.ObjectOutput out)">1</method>
			<method name="public int cardinality()">5</method>
			<method name="public String toString()">3</method>
			<method name="private static void dischargeAsEmpty(javaewah.BufferedRunningLengthWord initialWord, javaewah.EWAHIterator iterator, javaewah.EWAHCompressedBitmap container)">2</method>
			<method name="public javaewah.EWAHCompressedBitmap or(javaewah.EWAHCompressedBitmap a)">24</method>
			<method name="public boolean intersects(javaewah.EWAHCompressedBitmap a)">25</method>
			<method name="private static void discharge(javaewah.BufferedRunningLengthWord initialWord, javaewah.EWAHIterator iterator, javaewah.EWAHCompressedBitmap container)">2</method>
			<method name="public void _init_()">0</method>
			<method name="private long addStreamOfNegatedDirtyWords(long[] data, long start, long number)">4</method>
			<method name="public int add(long newdata, int bitsthatmatter)">3</method>
			<method name="private void push_back(long data)">2</method>
			<method name="public String toDebugString()">3</method>
			<method name="public int sizeInBits()">1</method>
			<method name="public void not()">6</method>
			<method name="public javaewah.EWAHCompressedBitmap xor(javaewah.EWAHCompressedBitmap a)">32</method>
			<method name="public int hashCode()">2</method>
			<method name="private long addStreamOfDirtyWords(long[] data, long start, long number)">4</method>
			<method name="public boolean setSizeInBits(int size, boolean defaultvalue)">7</method>
			<method name="public javaewah.IntIterator intIterator()">1</method>
			<method name="public void _init_(int buffersize)">0</method>
			<method name="public javaewah.EWAHCompressedBitmap andNot(javaewah.EWAHCompressedBitmap a)">27</method>
			<method name="private void push_back(long[] data, int start, int number)">2</method>
			<method name="public javaewah.EWAHCompressedBitmap and(javaewah.EWAHCompressedBitmap a)">25</method>
			<method name="private void negative_push_back(long[] data, int start, int number)">3</method>
			<method name="public int add(long newdata)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixUnArchive_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableConstantTimestampObjectInspector</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>16</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public volatile Object getWritableConstantValue()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.io.TimestampWritable getWritableConstantValue()">1</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.io.TimestampWritable value)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.AlterTableDesc$ProtectModeType</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9333333333333332</lcom3>
		<loc>67</loc>
		<dam>0.2</dam>
		<moa>5</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>14.5</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.plan.AlterTableDesc$ProtectModeType valueOf(String name)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.AlterTableDesc$ProtectModeType[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$analyzeStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.JoinType</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9523809523809524</lcom3>
		<loc>89</loc>
		<dam>0.14285714285714285</dam>
		<moa>7</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>19.5</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.parse.JoinType valueOf(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.parse.JoinType[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.ParseError</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>11</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>0.5</lcom3>
		<loc>50</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.4</amc>
		<cc>
			<method name="org.antlr.runtime.RecognitionException getRecognitionException()">1</method>
			<method name="String[] getTokenNames()">1</method>
			<method name="org.antlr.runtime.BaseRecognizer getBaseRecognizer()">1</method>
			<method name="String getMessage()">1</method>
			<method name="void _init_(org.antlr.runtime.BaseRecognizer br, org.antlr.runtime.RecognitionException re, String[] tokenNames)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.EximUtil</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>29</cbo>
		<rfc>90</rfc>
		<lcom>51</lcom>
		<ca>3</ca>
		<ce>26</ce>
		<npm>6</npm>
		<lcom3>0.9666666666666666</lcom3>
		<loc>707</loc>
		<dam>0.3333333333333333</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.22857142857142856</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>63.0</amc>
		<cc>
			<method name="private static void checkCompatibility(String version, String fcVersion)">1</method>
			<method name="static void validateTable(org.apache.hadoop.hive.ql.metadata.Table table)">1</method>
			<method name="private void _init_()">0</method>
			<method name="static java.net.URI getValidatedURI(org.apache.hadoop.hive.conf.HiveConf conf, String dcPath)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static java.util.Map$Entry readMetaData(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path metadataPath)">1</method>
			<method name="public static void createExportDump(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path metadataPath, org.apache.hadoop.hive.ql.metadata.Table tableHandle, java.util.List partitions)">1</method>
			<method name="public static String relativeToAbsolutePath(org.apache.hadoop.hive.conf.HiveConf conf, String location)">1</method>
			<method name="public static java.util.Map makePartSpec(java.util.List partCols, java.util.List partVals)">2</method>
			<method name="public static boolean schemaCompare(java.util.List newSchema, java.util.List oldSchema)">5</method>
			<method name="public static void doCheckCompatibility(String currVersion, String version, String fcVersion)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.MapRedTask</name>
		<wmc>14</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>34</cbo>
		<rfc>131</rfc>
		<lcom>25</lcom>
		<ca>6</ca>
		<ce>29</ce>
		<npm>9</npm>
		<lcom3>0.9120879120879122</lcom3>
		<loc>1425</loc>
		<dam>0.42857142857142855</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.1623931623931624</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>99.78571428571429</amc>
		<cc>
			<method name="public int execute(org.apache.hadoop.hive.ql.DriverContext driverContext)">28</method>
			<method name="public boolean mapDone()">2</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="static void configureDebugVariablesForChildJVM(java.util.Map environmentVariables)">17</method>
			<method name="private int estimateNumberOfReducers()">1</method>
			<method name="public boolean mapStarted()">2</method>
			<method name="public org.apache.hadoop.hive.ql.exec.Operator getReducer()">1</method>
			<method name="public static String isEligibleForLocalMode(org.apache.hadoop.hive.conf.HiveConf conf, int numReducers, long inputLength, long inputFileCount)">4</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.MapredWork plan, org.apache.hadoop.mapred.JobConf job, boolean isSilent)">0</method>
			<method name="private void estimateInputSize()">7</method>
			<method name="public boolean reduceStarted()">2</method>
			<method name="private void setNumberOfReducers()">1</method>
			<method name="public boolean reduceDone()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeSenumDef</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.io.CachingPrintStream</name>
		<wmc>5</wmc>
		<dit>4</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>11</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>5</npm>
		<lcom3>0.0</lcom3>
		<loc>46</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.9454545454545454</mfa>
		<cam>0.5</cam>
		<ic>2</ic>
		<cbm>3</cbm>
		<amc>8.0</amc>
		<cc>
			<method name="public void println(String out)">1</method>
			<method name="public void flush()">1</method>
			<method name="public void _init_(java.io.OutputStream out, boolean autoFlush, String encoding)">0</method>
			<method name="public java.util.List getOutput()">1</method>
			<method name="public void _init_(java.io.OutputStream out)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNotEqual</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>16</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>15</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>188</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>93.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.MapredWork</name>
		<wmc>63</wmc>
		<dit>1</dit>
		<noc>1</noc>
		<cbo>47</cbo>
		<rfc>99</rfc>
		<lcom>1777</lcom>
		<ca>40</ca>
		<ce>8</ce>
		<npm>61</npm>
		<lcom3>0.9665898617511521</lcom3>
		<loc>651</loc>
		<dam>0.9642857142857143</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.10483870967741936</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.88888888888889</amc>
		<cc>
			<method name="public void setNameToSplitSample(java.util.HashMap nameToSplitSample)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void setMapLocalWork(org.apache.hadoop.hive.ql.plan.MapredLocalWork mapLocalWork)">1</method>
			<method name="public java.util.HashMap getNameToSplitSample()">1</method>
			<method name="public void setJoinTree(org.apache.hadoop.hive.ql.parse.QBJoinTree joinTree)">1</method>
			<method name="public java.util.LinkedHashMap getPathToAliases()">1</method>
			<method name="public void setAliasToPartnInfo(java.util.LinkedHashMap aliasToPartnInfo)">1</method>
			<method name="public void setOpParseCtxMap(java.util.LinkedHashMap opParseCtxMap)">1</method>
			<method name="public String getIndexIntermediateFile()">1</method>
			<method name="public String toXML()">1</method>
			<method name="public void setInputformat(String inputformat)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(String command, java.util.LinkedHashMap pathToAliases, java.util.LinkedHashMap pathToPartitionInfo, java.util.LinkedHashMap aliasToWork, org.apache.hadoop.hive.ql.plan.TableDesc keyDesc, java.util.List tagToValueDesc, org.apache.hadoop.hive.ql.exec.Operator reducer, Integer numReduceTasks, org.apache.hadoop.hive.ql.plan.MapredLocalWork mapLocalWork, boolean hadoopSupportsSplittable)">0</method>
			<method name="public void setPathToPartitionInfo(java.util.LinkedHashMap pathToPartitionInfo)">1</method>
			<method name="public void setNeedsTagging(boolean needsTagging)">1</method>
			<method name="public Long getMinSplitSize()">1</method>
			<method name="public void setInputFormatSorted(boolean inputFormatSorted)">1</method>
			<method name="public void setAliasToWork(java.util.LinkedHashMap aliasToWork)">1</method>
			<method name="public void setMinSplitSize(Long minSplitSize)">1</method>
			<method name="public void setTmpHDFSFileURI(String tmpHDFSFileURI)">1</method>
			<method name="public void setHadoopSupportsSplittable(boolean hadoopSupportsSplittable)">1</method>
			<method name="public void addIndexIntermediateFile(String fileName)">2</method>
			<method name="public void setMinSplitSizePerRack(Long minSplitSizePerRack)">1</method>
			<method name="public java.util.LinkedHashMap getAliasToWork()">1</method>
			<method name="public void setKeyDesc(org.apache.hadoop.hive.ql.plan.TableDesc keyDesc)">1</method>
			<method name="public void deriveExplainAttributes()">4</method>
			<method name="public org.apache.hadoop.hive.ql.parse.QBJoinTree getJoinTree()">1</method>
			<method name="public boolean getNeedsTagging()">1</method>
			<method name="public Long getMinSplitSizePerRack()">1</method>
			<method name="public void setCommand(String command)">1</method>
			<method name="public Integer getNumReduceTasks()">1</method>
			<method name="public java.util.LinkedHashMap getOpParseCtxMap()">1</method>
			<method name="public void setMinSplitSizePerNode(Long minSplitSizePerNode)">1</method>
			<method name="public Integer getNumMapTasks()">1</method>
			<method name="public void setReducer(org.apache.hadoop.hive.ql.exec.Operator reducer)">1</method>
			<method name="public String getTmpHDFSFileURI()">1</method>
			<method name="public void initialize()">1</method>
			<method name="public java.util.LinkedHashMap getPathToPartitionInfo()">1</method>
			<method name="public boolean isInputFormatSorted()">1</method>
			<method name="public void resolveDynamicPartitionMerge(org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.fs.Path path, org.apache.hadoop.hive.ql.plan.TableDesc tblDesc, java.util.ArrayList aliases, org.apache.hadoop.hive.ql.plan.PartitionDesc partDesc)">1</method>
			<method name="public void setNumReduceTasks(Integer numReduceTasks)">1</method>
			<method name="public void setNumMapTasks(Integer numMapTasks)">1</method>
			<method name="public void setTagToValueDesc(java.util.List tagToValueDesc)">1</method>
			<method name="public Long getMinSplitSizePerNode()">1</method>
			<method name="public boolean isGatheringStats()">1</method>
			<method name="public boolean getHadoopSupportsSplittable()">1</method>
			<method name="public String getInputformat()">1</method>
			<method name="public java.util.LinkedHashMap getAliasToPartnInfo()">1</method>
			<method name="public String isInvalid()">5</method>
			<method name="public void setMapperCannotSpanPartns(boolean mapperCannotSpanPartns)">1</method>
			<method name="public java.util.List getAllOperators()">6</method>
			<method name="public void setMaxSplitSize(Long maxSplitSize)">1</method>
			<method name="public void setPathToAliases(java.util.LinkedHashMap pathToAliases)">1</method>
			<method name="private void setAliases()">3</method>
			<method name="public Long getMaxSplitSize()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.MapredLocalWork getMapLocalWork()">1</method>
			<method name="public void setGatheringStats(boolean gatherStats)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.TableDesc getKeyDesc()">1</method>
			<method name="public String getCommand()">1</method>
			<method name="public void addMapWork(String path, String alias, org.apache.hadoop.hive.ql.exec.Operator work, org.apache.hadoop.hive.ql.plan.PartitionDesc pd)">8</method>
			<method name="public org.apache.hadoop.hive.ql.exec.Operator getReducer()">1</method>
			<method name="public boolean isMapperCannotSpanPartns()">1</method>
			<method name="public java.util.List getTagToValueDesc()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyObjectBase</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>2</noc>
		<cbo>7</cbo>
		<rfc>4</rfc>
		<lcom>3</lcom>
		<ca>6</ca>
		<ce>1</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>6</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>1.0</amc>
		<cc>
			<method name="public abstract void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef, int, int)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public abstract Object getObject()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeConstMap</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$castExpression_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.QBExpr$Opcode</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9333333333333332</lcom3>
		<loc>67</loc>
		<dam>0.2</dam>
		<moa>5</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>14.5</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.parse.QBExpr$Opcode[] values()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.parse.QBExpr$Opcode valueOf(String name)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter$IntConverter</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>36</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector inputOI, org.apache.hadoop.hive.serde2.objectinspector.primitive.SettableIntObjectInspector outputOI)">0</method>
			<method name="public Object convert(Object input)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$kwRole_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazydio.LazyDioInteger</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>12</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>3</npm>
		<lcom3>1.0</lcom3>
		<loc>83</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazydio.LazyDioInteger copy)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyIntObjectInspector oi)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.async.TAsyncMethodCall$State</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9583333333333334</lcom3>
		<loc>100</loc>
		<dam>0.125</dam>
		<moa>8</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>22.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.thrift.async.TAsyncMethodCall$State[] values()">1</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.thrift.async.TAsyncMethodCall$State valueOf(String name)">1</method>
		</cc>
	</class>
	<class>
		<name>org.json.JSONTokener</name>
		<wmc>16</wmc>
		<dit>1</dit>
		<noc>2</noc>
		<cbo>9</cbo>
		<rfc>42</rfc>
		<lcom>90</lcom>
		<ca>8</ca>
		<ce>3</ce>
		<npm>16</npm>
		<lcom3>0.23333333333333334</lcom3>
		<loc>528</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3125</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>31.75</amc>
		<cc>
			<method name="public boolean more()">1</method>
			<method name="public char nextClean()">1</method>
			<method name="public String nextTo(char arg0)">1</method>
			<method name="public void _init_(String arg0)">0</method>
			<method name="public org.json.JSONException syntaxError(String arg0)">1</method>
			<method name="public char next()">1</method>
			<method name="public void _init_(java.io.Reader arg0)">0</method>
			<method name="public char skipTo(char arg0)">1</method>
			<method name="public static int dehexchar(char arg0)">7</method>
			<method name="public char next(char arg0)">1</method>
			<method name="public String next(int arg0)">1</method>
			<method name="public void back()">1</method>
			<method name="public String nextTo(String arg0)">1</method>
			<method name="public Object nextValue()">1</method>
			<method name="public String toString()">1</method>
			<method name="public String nextString(char arg0)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.HadoopShimsSecure$NullOutputCommitter</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>8</rfc>
		<lcom>21</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>7</npm>
		<lcom3>2.0</lcom3>
		<loc>17</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6190476190476191</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>1.4285714285714286</amc>
		<cc>
			<method name="public void setupJob(org.apache.hadoop.mapred.JobContext jobContext)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void commitTask(org.apache.hadoop.mapred.TaskAttemptContext taskContext)">1</method>
			<method name="public void setupTask(org.apache.hadoop.mapred.TaskAttemptContext taskContext)">1</method>
			<method name="public void cleanupJob(org.apache.hadoop.mapred.JobContext jobContext)">1</method>
			<method name="public void abortTask(org.apache.hadoop.mapred.TaskAttemptContext taskContext)">1</method>
			<method name="public boolean needsTaskCommit(org.apache.hadoop.mapred.TaskAttemptContext taskContext)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.OneNullRowInputFormat$OneNullRowRecordReader</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>10</rfc>
		<lcom>33</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>10</npm>
		<lcom3>0.5555555555555556</lcom3>
		<loc>61</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public volatile Object createKey()">1</method>
			<method name="public org.apache.hadoop.io.NullWritable createKey()">1</method>
			<method name="public boolean next(org.apache.hadoop.io.NullWritable arg0, org.apache.hadoop.io.NullWritable arg1)">1</method>
			<method name="public float getProgress()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public volatile boolean next(Object x0, Object x1)">1</method>
			<method name="public volatile Object createValue()">1</method>
			<method name="public long getPos()">1</method>
			<method name="public org.apache.hadoop.io.NullWritable createValue()">1</method>
			<method name="public void close()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDTFParseUrlTuple$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>77</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>75.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ColumnPruner</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>22</cbo>
		<rfc>24</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>21</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>130</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>63.0</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext transform(org.apache.hadoop.hive.ql.parse.ParseContext pactx)">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.lineage.OpProcFactory$TransformLineage</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>22</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>13</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>91</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>44.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.PartitionSpec</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>19</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>4</npm>
		<lcom3>0.0</lcom3>
		<loc>81</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public boolean existsKey(String key)">2</method>
			<method name="public void addPredicate(String key, String operator, String value)">1</method>
			<method name="public String toString()">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters$Converter</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>37</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>37</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Object convert(Object)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.formatting.JsonMetaDataFormatter</name>
		<wmc>22</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>22</cbo>
		<rfc>87</rfc>
		<lcom>219</lcom>
		<ca>1</ca>
		<ce>21</ce>
		<npm>13</npm>
		<lcom3>0.8095238095238095</lcom3>
		<loc>811</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.22408963585434175</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>35.81818181818182</amc>
		<cc>
			<method name="public void showDatabaseDescription(java.io.DataOutputStream out, String database, String comment, String location, java.util.Map params)">1</method>
			<method name="private void putFileSystemsStats(org.apache.hadoop.hive.ql.metadata.formatting.MapBuilder builder, java.util.List locations, org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.fs.Path tblPath)">1</method>
			<method name="public void showTables(java.io.DataOutputStream out, java.util.Set tables)">1</method>
			<method name="public void showDatabases(java.io.DataOutputStream out, java.util.List databases)">1</method>
			<method name="public void showTablePartitons(java.io.DataOutputStream out, java.util.List parts)">1</method>
			<method name="public void consoleError(org.apache.hadoop.hive.ql.session.SessionState$LogHelper console, String msg, String detail, int errorCode)">1</method>
			<method name="public void logWarn(java.io.OutputStream out, String msg, int errorCode)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void asJson(java.io.OutputStream out, java.util.Map data)">1</method>
			<method name="public void showTableStatus(java.io.DataOutputStream out, org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.conf.HiveConf conf, java.util.List tbls, java.util.Map part, org.apache.hadoop.hive.ql.metadata.Partition par)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private java.util.Map makeOneTablePartition(String partIdent)">1</method>
			<method name="public void consoleError(org.apache.hadoop.hive.ql.session.SessionState$LogHelper console, String msg, int errorCode)">1</method>
			<method name="public void error(java.io.OutputStream out, String msg, int errorCode)">1</method>
			<method name="private java.util.List makeTablePartions(java.util.List parts)">1</method>
			<method name="private java.util.Map makeOneTableStatus(org.apache.hadoop.hive.ql.metadata.Table tbl, org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.conf.HiveConf conf, java.util.Map part, org.apache.hadoop.hive.ql.metadata.Partition par)">1</method>
			<method name="private java.util.List makeAllTableStatus(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.conf.HiveConf conf, java.util.List tbls, java.util.Map part, org.apache.hadoop.hive.ql.metadata.Partition par)">1</method>
			<method name="private java.util.List makeTableStatusLocations(org.apache.hadoop.hive.ql.metadata.Table tbl, org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.metadata.Partition par)">1</method>
			<method name="public void logInfo(java.io.OutputStream out, String msg, int errorCode)">1</method>
			<method name="private java.util.List makeColsUnformatted(java.util.List cols)">2</method>
			<method name="private java.util.Map makeOneColUnformatted(org.apache.hadoop.hive.metastore.api.FieldSchema col)">1</method>
			<method name="public void describeTable(java.io.DataOutputStream out, String colPath, String tableName, org.apache.hadoop.hive.ql.metadata.Table tbl, org.apache.hadoop.hive.ql.metadata.Partition part, java.util.List cols, boolean isFormatted, boolean isExt)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.pcr.PcrOpProcFactory$DefaultPCR</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>7</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryInteger</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>15</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>1</npm>
		<lcom3>0.5</lcom3>
		<loc>71</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.25</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">3</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableIntObjectInspector oi)">0</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryInteger copy)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ExprNodeNullEvaluator</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>4</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>3</npm>
		<lcom3>1.0</lcom3>
		<loc>14</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.3333333333333335</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.ExprNodeNullDesc expr)">0</method>
			<method name="public Object evaluate(Object row)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector rowInspector)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazydio.LazyDioFloat</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>12</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>3</npm>
		<lcom3>1.0</lcom3>
		<loc>83</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazydio.LazyDioFloat copy)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyFloatObjectInspector oi)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFE</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>8</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.75</lcom3>
		<loc>25</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.666666666666667</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.DelegationTokenStore$TokenStoreException</name>
		<wmc>2</wmc>
		<dit>4</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>12</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>1.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(Throwable cause)">0</method>
			<method name="public void _init_(String message, Throwable cause)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ExprNodeColumnDesc</name>
		<wmc>15</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>31</cbo>
		<rfc>25</rfc>
		<lcom>21</lcom>
		<ca>28</ca>
		<ce>3</ce>
		<npm>15</npm>
		<lcom3>0.6785714285714286</lcom3>
		<loc>137</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2777777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.866666666666666</amc>
		<cc>
			<method name="public void _init_(Class c, String column, String tabAlias, boolean isPartitionColOrVirtualCol)">0</method>
			<method name="public void setColumn(String column)">1</method>
			<method name="public void setIsPartitionColOrVirtualCol(boolean isPartitionCol)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ExprNodeDesc clone()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public volatile Object clone()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo typeInfo, String column, String tabAlias, boolean isPartitionColOrVirtualCol)">0</method>
			<method name="public boolean isSame(Object o)">4</method>
			<method name="public String getExprString()">1</method>
			<method name="public String toString()">1</method>
			<method name="public boolean getIsPartitionColOrVirtualCol()">1</method>
			<method name="public String getColumn()">1</method>
			<method name="public void setTabAlias(String tabAlias)">1</method>
			<method name="public java.util.List getCols()">1</method>
			<method name="public String getTabAlias()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$privlegeDef_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryBinary</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>16</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>2</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>66</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.25</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryPrimitive copy)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableBinaryObjectInspector baoi)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFInstr</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>23</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>16</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>177</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>33.8</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.TaskFactory$taskTuple</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>12</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.0</amc>
		<cc>
			<method name="public void _init_(Class workClass, Class taskClass)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer</name>
		<wmc>35</wmc>
		<dit>1</dit>
		<noc>7</noc>
		<cbo>44</cbo>
		<rfc>99</rfc>
		<lcom>573</lcom>
		<ca>25</ca>
		<ce>20</ce>
		<npm>23</npm>
		<lcom3>0.9852941176470589</lcom3>
		<loc>1154</loc>
		<dam>0.8636363636363636</dam>
		<moa>7</moa>
		<mfa>0.0</mfa>
		<cam>0.125</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>31.34285714285714</amc>
		<cc>
			<method name="public final boolean isValidPrefixSpec(org.apache.hadoop.hive.ql.metadata.Table tTable, java.util.Map spec)">1</method>
			<method name="protected void reset()">1</method>
			<method name="public static void readProps(org.apache.hadoop.hive.ql.parse.ASTNode prop, java.util.Map mapProp)">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.exec.FetchTask getFetchTask()">1</method>
			<method name="public static String stripQuotes(String val)">1</method>
			<method name="protected java.util.List getColumnNames(org.apache.hadoop.hive.ql.parse.ASTNode ast)">2</method>
			<method name="public void _init_(org.apache.hadoop.hive.conf.HiveConf conf)">0</method>
			<method name="public static java.util.List getColumns(org.apache.hadoop.hive.ql.parse.ASTNode ast, boolean lowerCase)">1</method>
			<method name="public static String getUnescapedName(org.apache.hadoop.hive.ql.parse.ASTNode tableNameNode)">3</method>
			<method name="public static String unescapeIdentifier(String val)">4</method>
			<method name="public java.util.HashSet getOutputs()">1</method>
			<method name="private static String getUnionTypeStringFromAST(org.apache.hadoop.hive.ql.parse.ASTNode typeNode)">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Hive getDb()">1</method>
			<method name="public void analyze(org.apache.hadoop.hive.ql.parse.ASTNode ast, org.apache.hadoop.hive.ql.Context ctx)">1</method>
			<method name="public static String unescapeSQLString(String b)">28</method>
			<method name="protected static String getTypeStringFromAST(org.apache.hadoop.hive.ql.parse.ASTNode typeNode)">1</method>
			<method name="public static String charSetString(String charSetName, String charSetString)">1</method>
			<method name="public java.util.HashSet getInputs()">1</method>
			<method name="protected java.util.List getColumnNamesOrder(org.apache.hadoop.hive.ql.parse.ASTNode ast)">3</method>
			<method name="static void access$000(java.util.Map x0, java.util.List x1)">1</method>
			<method name="public java.util.List getResultSchema()">1</method>
			<method name="private static String getStructTypeStringFromAST(org.apache.hadoop.hive.ql.parse.ASTNode typeNode)">1</method>
			<method name="public void validate()">1</method>
			<method name="protected java.util.HashMap extractPartitionSpecs(org.antlr.runtime.tree.Tree partspec)">1</method>
			<method name="public void setFetchTask(org.apache.hadoop.hive.ql.exec.FetchTask fetchTask)">1</method>
			<method name="public void setLineageInfo(org.apache.hadoop.hive.ql.hooks.LineageInfo linfo)">1</method>
			<method name="public java.util.List getRootTasks()">1</method>
			<method name="public abstract void analyzeInternal(org.apache.hadoop.hive.ql.parse.ASTNode)">1</method>
			<method name="private static void ErrorPartSpec(java.util.Map partSpec, java.util.List parts)">1</method>
			<method name="public org.apache.hadoop.hive.ql.hooks.LineageInfo getLineageInfo()">1</method>
			<method name="protected java.util.List getColumns(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="protected void handleGenericFileFormat(org.apache.hadoop.hive.ql.parse.ASTNode node)">1</method>
			<method name="public org.apache.hadoop.hive.ql.QueryProperties getQueryProperties()">1</method>
			<method name="public java.util.HashMap getIdToTableNameMap()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.GrantDesc</name>
		<wmc>13</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>14</rfc>
		<lcom>42</lcom>
		<ca>3</ca>
		<ce>3</ce>
		<npm>13</npm>
		<lcom3>0.8690476190476191</lcom3>
		<loc>83</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.3076923076923077</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.846153846153846</amc>
		<cc>
			<method name="public void setGrantorType(org.apache.hadoop.hive.metastore.api.PrincipalType grantorType)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.PrivilegeObjectDesc privilegeSubject, java.util.List privilegeDesc, java.util.List principalDesc, String grantor, org.apache.hadoop.hive.metastore.api.PrincipalType grantorType, boolean grantOption)">0</method>
			<method name="public java.util.List getPrivileges()">1</method>
			<method name="public void setPrivilegeSubjectDesc(org.apache.hadoop.hive.ql.plan.PrivilegeObjectDesc privilegeSubjectDesc)">1</method>
			<method name="public java.util.List getPrincipals()">1</method>
			<method name="public void setGrantor(String grantor)">1</method>
			<method name="public void setGrantOption(boolean grantOption)">1</method>
			<method name="public String getGrantor()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.PrivilegeObjectDesc getPrivilegeSubjectDesc()">1</method>
			<method name="public boolean isGrantOption()">1</method>
			<method name="public org.apache.hadoop.hive.metastore.api.PrincipalType getGrantorType()">1</method>
			<method name="public void setPrincipals(java.util.List principals)">1</method>
			<method name="public void setPrivileges(java.util.List privileges)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ReduceSinkDeDuplication</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>16</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>12</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>59</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>28.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext transform(org.apache.hadoop.hive.ql.parse.ParseContext pctx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$selectList_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixRenamePart_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.HashTableSinkOperator$HashTableSinkObjectCtx</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>6</rfc>
		<lcom>2</lcom>
		<ca>7</ca>
		<ce>4</ce>
		<npm>5</npm>
		<lcom3>0.75</lcom3>
		<loc>36</loc>
		<dam>0.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.36</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.4</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getStandardOI()">1</method>
			<method name="public org.apache.hadoop.conf.Configuration getConf()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.SerDe getSerDe()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector standardOI, org.apache.hadoop.hive.serde2.SerDe serde, org.apache.hadoop.hive.ql.plan.TableDesc tblDesc, org.apache.hadoop.conf.Configuration conf)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.TableDesc getTblDesc()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Utilities$ListDelegate</name>
		<wmc>4</wmc>
		<dit>3</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>13</rfc>
		<lcom>6</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>66</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.8235294117647058</mfa>
		<cam>0.625</cam>
		<ic>2</ic>
		<cbm>4</cbm>
		<amc>15.5</amc>
		<cc>
			<method name="protected java.beans.Expression instantiate(Object oldInstance, java.beans.Encoder out)">1</method>
			<method name="protected boolean mutatesTo(Object oldInstance, Object newInstance)">1</method>
			<method name="public void _init_()">0</method>
			<method name="protected void initialize(Class type, Object oldInstance, Object newInstance, java.beans.Encoder out)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.security.authorization.HiveAuthorizationProviderBase</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>1</noc>
		<cbo>7</cbo>
		<rfc>10</rfc>
		<lcom>11</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>6</npm>
		<lcom3>0.8</lcom3>
		<loc>45</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.0</amc>
		<cc>
			<method name="public org.apache.hadoop.conf.Configuration getConf()">1</method>
			<method name="public void init(org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setConf(org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="public void setAuthenticator(org.apache.hadoop.hive.ql.security.HiveAuthenticationProvider authenticator)">1</method>
			<method name="public org.apache.hadoop.hive.ql.security.HiveAuthenticationProvider getAuthenticator()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFToShort</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>23</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>12</ce>
		<npm>10</npm>
		<lcom3>0.1111111111111111</lcom3>
		<loc>138</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.19</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.7</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.io.LongWritable i)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.io.NullWritable i)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable i)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.io.FloatWritable i)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.io.BooleanWritable i)">3</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.hive.serde2.io.ByteWritable i)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.io.IntWritable i)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable i)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.io.Text i)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.server.TSimpleServer</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>17</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>13</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>126</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>30.0</amc>
		<cc>
			<method name="public void stop()">1</method>
			<method name="public void _init_(org.apache.thrift.server.TServer$AbstractServerArgs args)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void serve()">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.CombineHiveInputFormat$CombineFilter</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>19</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>4</npm>
		<lcom3>0.0</lcom3>
		<loc>82</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.875</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.25</amc>
		<cc>
			<method name="public void addPath(org.apache.hadoop.fs.Path p)">1</method>
			<method name="public void _init_(org.apache.hadoop.fs.Path p)">0</method>
			<method name="public boolean accept(org.apache.hadoop.fs.Path path)">4</method>
			<method name="public String toString()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.history.HiveHistory$Listener</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void handle(org.apache.hadoop.hive.ql.history.HiveHistory$RecordTypes, java.util.Map)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDF</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>43</noc>
		<cbo>67</cbo>
		<rfc>16</rfc>
		<lcom>21</lcom>
		<ca>60</ca>
		<ce>8</ce>
		<npm>7</npm>
		<lcom3>2.0</lcom3>
		<loc>98</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.39285714285714285</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.0</amc>
		<cc>
			<method name="public String[] getRequiredJars()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initializeAndFoldConstants(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public abstract String getDisplayString(String[])">1</method>
			<method name="public void _init_()">0</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[])">1</method>
			<method name="public abstract Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[])">1</method>
			<method name="public String[] getRequiredFiles()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.RowResolver</name>
		<wmc>26</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>29</cbo>
		<rfc>64</rfc>
		<lcom>175</lcom>
		<ca>23</ca>
		<ce>6</ce>
		<npm>25</npm>
		<lcom3>0.84</lcom3>
		<loc>458</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.19111111111111112</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.346153846153847</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.exec.ColumnInfo getExpression(org.apache.hadoop.hive.ql.parse.ASTNode node)">1</method>
			<method name="public java.util.Map getExpressionMap()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void putExpression(org.apache.hadoop.hive.ql.parse.ASTNode node, org.apache.hadoop.hive.ql.exec.ColumnInfo colInfo)">1</method>
			<method name="public int getPosition(String internalName)">2</method>
			<method name="public java.util.List getNonHiddenColumnNames(int max)">4</method>
			<method name="public java.util.HashMap getFieldMap(String tabAlias)">2</method>
			<method name="public String[] reverseLookup(String internalName)">1</method>
			<method name="public boolean getIsExprResolver()">1</method>
			<method name="public java.util.HashMap getInvRslvMap()">1</method>
			<method name="public void setRslvMap(java.util.HashMap rslvMap)">1</method>
			<method name="public void setExpressionMap(java.util.Map expressionMap)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ASTNode getExpressionSource(org.apache.hadoop.hive.ql.parse.ASTNode node)">1</method>
			<method name="public String toString()">4</method>
			<method name="public java.util.HashMap getRslvMap()">1</method>
			<method name="public java.util.Set getTableNames()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setRowSchema(org.apache.hadoop.hive.ql.exec.RowSchema rowSchema)">1</method>
			<method name="public void setInvRslvMap(java.util.HashMap invRslvMap)">1</method>
			<method name="public void setIsExprResolver(boolean isExprResolver)">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.RowSchema getRowSchema()">1</method>
			<method name="public void put(String tab_alias, String col_alias, org.apache.hadoop.hive.ql.exec.ColumnInfo colInfo)">4</method>
			<method name="public void setExprResolver(boolean isExprResolver)">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.ColumnInfo get(String tab_alias, String col_alias)">1</method>
			<method name="public java.util.ArrayList getColumnInfos()">1</method>
			<method name="public boolean hasTableAlias(String tab_alias)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.FloatObjectInspector</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>10</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract float get(Object)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.binarysortable.BinarySortableSerDe$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>124</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>121.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFVariance$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>70</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>68.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeNamespace</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFPosMod</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>20</rfc>
		<lcom>21</lcom>
		<ca>0</ca>
		<ce>7</ce>
		<npm>7</npm>
		<lcom3>2.0</lcom3>
		<loc>150</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2653061224489796</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>20.428571428571427</amc>
		<cc>
			<method name="public org.apache.hadoop.io.FloatWritable evaluate(org.apache.hadoop.io.FloatWritable a, org.apache.hadoop.io.FloatWritable b)">3</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.hive.serde2.io.ByteWritable a, org.apache.hadoop.hive.serde2.io.ByteWritable b)">3</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable a, org.apache.hadoop.hive.serde2.io.DoubleWritable b)">3</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.hive.serde2.io.ShortWritable a, org.apache.hadoop.hive.serde2.io.ShortWritable b)">3</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.LongWritable a, org.apache.hadoop.io.LongWritable b)">3</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.IntWritable a, org.apache.hadoop.io.IntWritable b)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$rowFormat_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.bitmap.BitmapObjectOutput</name>
		<wmc>19</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>24</rfc>
		<lcom>159</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>19</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>110</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2046783625730994</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.7368421052631575</amc>
		<cc>
			<method name="public void writeLong(long v)">1</method>
			<method name="public java.util.List list()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void write(byte[] arg0, int arg1, int arg2)">1</method>
			<method name="public void write(int arg0)">1</method>
			<method name="public void writeBoolean(boolean arg0)">1</method>
			<method name="public void writeByte(int arg0)">1</method>
			<method name="public void close()">1</method>
			<method name="public void writeChars(String arg0)">1</method>
			<method name="public void writeDouble(double v)">1</method>
			<method name="public void writeUTF(String s)">1</method>
			<method name="public void writeChar(int arg0)">1</method>
			<method name="public void write(byte[] arg0)">1</method>
			<method name="public void writeFloat(float v)">1</method>
			<method name="public void flush()">1</method>
			<method name="public void writeShort(int v)">1</method>
			<method name="public void writeBytes(String arg0)">1</method>
			<method name="public void writeInt(int v)">1</method>
			<method name="public void writeObject(Object arg0)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.DropIndexDesc</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>5</npm>
		<lcom3>0.75</lcom3>
		<loc>31</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.6</amc>
		<cc>
			<method name="public void setIndexName(String indexName)">1</method>
			<method name="public String getTableName()">1</method>
			<method name="public void _init_(String indexName, String tableName)">0</method>
			<method name="public void setTableName(String tableName)">1</method>
			<method name="public String getIndexName()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.rcfile.merge.BlockMergeTask</name>
		<wmc>14</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>39</cbo>
		<rfc>130</rfc>
		<lcom>85</lcom>
		<ca>1</ca>
		<ce>38</ce>
		<npm>10</npm>
		<lcom3>0.9076923076923078</lcom3>
		<loc>891</loc>
		<dam>0.6</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.15384615384615385</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>62.285714285714285</amc>
		<cc>
			<method name="public int execute(org.apache.hadoop.hive.ql.DriverContext driverContext)">23</method>
			<method name="public void updateCounters(org.apache.hadoop.mapred.Counters ctrs, org.apache.hadoop.mapred.RunningJob rj)">1</method>
			<method name="public void _init_()">0</method>
			<method name="private void addInputPaths(org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.hive.ql.io.rcfile.merge.MergeWork work)">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="protected void localizeMRTmpFilesImpl(org.apache.hadoop.hive.ql.Context ctx)">1</method>
			<method name="public String getName()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.StageType getType()">1</method>
			<method name="public boolean requireLock()">1</method>
			<method name="public void initialize(org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.hive.ql.QueryPlan queryPlan, org.apache.hadoop.hive.ql.DriverContext driverContext)">1</method>
			<method name="public static void main(String[] args)">15</method>
			<method name="private static void printUsage()">1</method>
			<method name="public void logPlanProgress(org.apache.hadoop.hive.ql.session.SessionState ss)">1</method>
			<method name="public boolean checkFatalErrors(org.apache.hadoop.mapred.Counters ctrs, StringBuilder errMsg)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.Operator$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>49</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>47.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.AlterTableDesc$AlterTableTypes</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>6</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9824561403508772</lcom3>
		<loc>221</loc>
		<dam>0.05263157894736842</dam>
		<moa>19</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>49.5</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.plan.AlterTableDesc$AlterTableTypes[] values()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.AlterTableDesc$AlterTableTypes valueOf(String name)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$DefaultExprProcessor</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>39</cbo>
		<rfc>107</rfc>
		<lcom>10</lcom>
		<ca>5</ca>
		<ce>36</ce>
		<npm>5</npm>
		<lcom3>0.5</lcom3>
		<loc>1076</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.24675324675324675</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>133.0</amc>
		<cc>
			<method name="private boolean isDescendant(org.apache.hadoop.hive.ql.lib.Node ans, org.apache.hadoop.hive.ql.lib.Node des)">4</method>
			<method name="public static String getFunctionText(org.apache.hadoop.hive.ql.parse.ASTNode expr, boolean isFunction)">8</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="static org.apache.hadoop.hive.ql.plan.ExprNodeDesc getXpathOrFuncExprNodeDesc(org.apache.hadoop.hive.ql.parse.ASTNode expr, boolean isFunction, java.util.ArrayList children, org.apache.hadoop.hive.ql.parse.TypeCheckCtx ctx)">1</method>
			<method name="public static boolean isRedundantConversionFunction(org.apache.hadoop.hive.ql.parse.ASTNode expr, boolean isFunction, java.util.ArrayList children)">6</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
			<method name="public static transient org.apache.hadoop.hive.ql.plan.ExprNodeDesc getFuncExprNodeDesc(String udfName, org.apache.hadoop.hive.ql.plan.ExprNodeDesc[] children)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.metrics.Metrics$MetricsScope</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>18</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>3</npm>
		<lcom3>0.2142857142857142</lcom3>
		<loc>195</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>36.6</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.common.metrics.Metrics, String name)">0</method>
			<method name="public void open()">1</method>
			<method name="private void _init_(org.apache.hadoop.hive.common.metrics.Metrics)">0</method>
			<method name="public void reopen()">1</method>
			<method name="public void close()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFDate</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>11</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>3</npm>
		<lcom3>0.0</lcom3>
		<loc>57</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>17.333333333333332</amc>
		<cc>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text dateString)">2</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable i)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFnGrams$GenericUDAFnGramEvaluator</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>48</rfc>
		<lcom>39</lcom>
		<ca>1</ca>
		<ce>17</ce>
		<npm>8</npm>
		<lcom3>0.8888888888888888</lcom3>
		<loc>514</loc>
		<dam>0.875</dam>
		<moa>7</moa>
		<mfa>0.0</mfa>
		<cam>0.2777777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>49.6</amc>
		<cc>
			<method name="public void iterate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object[] parameters)">1</method>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector init(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode m, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] parameters)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer getNewAggregationBuffer()">1</method>
			<method name="public void reset(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="private void processNgrams(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFnGrams$GenericUDAFnGramEvaluator$NGramAggBuf agg, java.util.ArrayList seq)">1</method>
			<method name="public Object terminatePartial(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void merge(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object partial)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.CreateTableLikeDesc</name>
		<wmc>20</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>21</rfc>
		<lcom>136</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>20</npm>
		<lcom3>0.9105263157894737</lcom3>
		<loc>126</loc>
		<dam>0.1</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.8</amc>
		<cc>
			<method name="public String getDefaultSerName()">1</method>
			<method name="public String getDefaultOutputFormat()">1</method>
			<method name="public void _init_(String tableName, boolean isExternal, String defaultInputFormat, String defaultOutputFormat, String location, String defaultSerName, java.util.Map defaultSerdeProps, boolean ifNotExists, String likeTableName)">0</method>
			<method name="public void setExternal(boolean isExternal)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public String getLikeTableName()">1</method>
			<method name="public void setInputFormat(String inputFormat)">1</method>
			<method name="public void setDefaultSerdeProps(java.util.Map serdeProps)">1</method>
			<method name="public void setIfNotExists(boolean ifNotExists)">1</method>
			<method name="public void setOutputFormat(String outputFormat)">1</method>
			<method name="public boolean getIfNotExists()">1</method>
			<method name="public java.util.Map getDefaultSerdeProps()">1</method>
			<method name="public String getTableName()">1</method>
			<method name="public String getDefaultInputFormat()">1</method>
			<method name="public void setLocation(String location)">1</method>
			<method name="public void setLikeTableName(String likeTableName)">1</method>
			<method name="public void setTableName(String tableName)">1</method>
			<method name="public boolean isExternal()">1</method>
			<method name="public void setDefaultSerName(String serName)">1</method>
			<method name="public String getLocation()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lib.GraphWalker</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>33</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>32</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void startWalking(java.util.Collection, java.util.HashMap)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.MetadataOnlyOptimizer$MetadataOnlyTaskDispatcher</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>24</cbo>
		<rfc>65</rfc>
		<lcom>19</lcom>
		<ca>1</ca>
		<ce>24</ce>
		<npm>2</npm>
		<lcom3>0.9166666666666666</lcom3>
		<loc>319</loc>
		<dam>0.5</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.3</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>44.285714285714285</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.optimizer.physical.MetadataOnlyOptimizer, org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext context)">0</method>
			<method name="public transient Object dispatch(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, Object[] nodeOutputs)">1</method>
			<method name="private void convertToMetadataOnlyQuery(org.apache.hadoop.hive.ql.plan.MapredWork work, org.apache.hadoop.hive.ql.exec.TableScanOperator tso)">1</method>
			<method name="private String getAliasForTableScanOperator(org.apache.hadoop.hive.ql.plan.MapredWork work, org.apache.hadoop.hive.ql.exec.TableScanOperator tso)">2</method>
			<method name="private org.apache.hadoop.hive.ql.plan.PartitionDesc changePartitionToMetadataOnly(org.apache.hadoop.hive.ql.plan.PartitionDesc desc)">2</method>
			<method name="private void processAlias(org.apache.hadoop.hive.ql.plan.MapredWork work, String alias)">2</method>
			<method name="private java.util.List getPathsForAlias(org.apache.hadoop.hive.ql.plan.MapredWork work, String alias)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.bitmap.BitmapOuterQuery</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>10</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>150</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>35.5</amc>
		<cc>
			<method name="public String getAlias()">1</method>
			<method name="public void _init_(String alias, org.apache.hadoop.hive.ql.index.bitmap.BitmapQuery lhs, org.apache.hadoop.hive.ql.index.bitmap.BitmapQuery rhs)">0</method>
			<method name="private void constructQueryStr()">1</method>
			<method name="public String toString()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server$SaslDigestCallbackHandler</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>27</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>11</ce>
		<npm>2</npm>
		<lcom3>0.3333333333333333</lcom3>
		<loc>155</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>37.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.thrift.DelegationTokenSecretManager secretManager)">0</method>
			<method name="public void handle(javax.security.auth.callback.Callback[] callbacks)">1</method>
			<method name="private char[] getPassword(org.apache.hadoop.hive.thrift.DelegationTokenIdentifier tokenid)">1</method>
			<method name="private char[] encodePassword(byte[] password)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lib.DefaultGraphWalker</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>3</noc>
		<cbo>31</cbo>
		<rfc>30</rfc>
		<lcom>0</lcom>
		<ca>27</ca>
		<ce>4</ce>
		<npm>6</npm>
		<lcom3>0.45</lcom3>
		<loc>171</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.833333333333332</amc>
		<cc>
			<method name="public void dispatch(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack ndStack)">1</method>
			<method name="public java.util.List getToWalk()">1</method>
			<method name="public java.util.Set getDispatchedList()">1</method>
			<method name="public void startWalking(java.util.Collection startNodes, java.util.HashMap nodeOutput)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.lib.Dispatcher disp)">0</method>
			<method name="public void walk(org.apache.hadoop.hive.ql.lib.Node nd)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.JoinReorder</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>28</rfc>
		<lcom>10</lcom>
		<ca>1</ca>
		<ce>11</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>217</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.44</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>42.4</amc>
		<cc>
			<method name="private int getOutputSize(org.apache.hadoop.hive.ql.exec.Operator operator, java.util.Set bigTables)">7</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext transform(org.apache.hadoop.hive.ql.parse.ParseContext pactx)">1</method>
			<method name="public void _init_()">0</method>
			<method name="private java.util.Set getBigTables(org.apache.hadoop.hive.ql.parse.ParseContext joinCtx)">2</method>
			<method name="private void reorder(org.apache.hadoop.hive.ql.exec.JoinOperator joinOp, java.util.Set bigTables)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.ReadEntity</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>9</rfc>
		<lcom>6</lcom>
		<ca>7</ca>
		<ce>3</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>33</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.25</amc>
		<cc>
			<method name="public boolean equals(Object o)">3</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Partition p)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Table t)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.ppd.ExprWalkerProcFactory$GenericFuncExprProcessor</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>18</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>101</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>49.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.xml.UDFXPathString</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>34</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.Text evaluate(String xml, String path)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lockmgr.package-info</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$showStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFBridge$GenericUDAFBridgeEvaluator$UDAFAgg</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>8</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.0</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.ql.exec.UDAFEvaluator ueObject)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.QueryPlan</name>
		<wmc>53</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>43</cbo>
		<rfc>210</rfc>
		<lcom>1184</lcom>
		<ca>19</ca>
		<ce>28</ce>
		<npm>40</npm>
		<lcom3>0.9242788461538461</lcom3>
		<loc>1946</loc>
		<dam>1.0</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.08299595141700405</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>35.41509433962264</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="private void updateCountersInQueryPlan()">4</method>
			<method name="private void populateOperatorGraph(org.apache.hadoop.hive.ql.plan.api.Task task, java.util.Collection topOps)">3</method>
			<method name="public void setDone(java.util.HashSet done)">1</method>
			<method name="private String getJSONOperator(org.apache.hadoop.hive.ql.plan.api.Operator op)">1</method>
			<method name="public String toThriftJSONString()">1</method>
			<method name="private String getJSONAdjacency(org.apache.hadoop.hive.ql.plan.api.Adjacency adj)">2</method>
			<method name="private void populateQueryPlan()">1</method>
			<method name="public String getQueryStr()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.Query getQuery()">1</method>
			<method name="public void setQuery(org.apache.hadoop.hive.ql.plan.api.Query query)">1</method>
			<method name="private String getJSONTask(org.apache.hadoop.hive.ql.plan.api.Task task)">3</method>
			<method name="public java.util.ArrayList getRootTasks()">1</method>
			<method name="public void _init_(String queryString, org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer sem, Long startTime)">0</method>
			<method name="public void setInputs(java.util.HashSet inputs)">1</method>
			<method name="public String getJSONValue(Object value)">4</method>
			<method name="public String getJSONQuery(org.apache.hadoop.hive.ql.plan.api.Query query)">3</method>
			<method name="private String getJSONStage(org.apache.hadoop.hive.ql.plan.api.Stage stage)">3</method>
			<method name="public void setStarted(java.util.HashSet started)">1</method>
			<method name="public String getJSONMap(java.util.Map map)">3</method>
			<method name="public void setStarted()">1</method>
			<method name="public void setQueryId(String queryId)">1</method>
			<method name="public void setOutputs(java.util.HashSet outputs)">1</method>
			<method name="public Long getQueryStartTime()">1</method>
			<method name="public void setQueryStartTime(Long queryStartTime)">1</method>
			<method name="public java.util.HashSet getStarted()">1</method>
			<method name="private String getJSONList(java.util.List list)">3</method>
			<method name="public String getJSONKeyValue(Object key, Object value)">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.FetchTask getFetchTask()">1</method>
			<method name="public String getQueryString()">1</method>
			<method name="public void setDone()">1</method>
			<method name="public java.util.HashMap getCounters()">1</method>
			<method name="public java.util.HashSet getOutputs()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.Query getQueryPlan()">1</method>
			<method name="public void setRootTasks(java.util.ArrayList rootTasks)">1</method>
			<method name="private Object getJSONGraph(org.apache.hadoop.hive.ql.plan.api.Graph graph)">4</method>
			<method name="public String toString()">1</method>
			<method name="public java.util.HashSet getDone()">1</method>
			<method name="public java.util.HashSet getInputs()">1</method>
			<method name="public void setCounters(java.util.HashMap counters)">1</method>
			<method name="public void setQueryString(String queryString)">1</method>
			<method name="public void setFetchTask(org.apache.hadoop.hive.ql.exec.FetchTask fetchTask)">1</method>
			<method name="public void setLineageInfo(org.apache.hadoop.hive.ql.hooks.LineageInfo linfo)">1</method>
			<method name="private String makeQueryId()">1</method>
			<method name="public String getQueryId()">1</method>
			<method name="public void setIdToTableNameMap(java.util.HashMap idToTableNameMap)">1</method>
			<method name="private void extractOperatorCounters(java.util.Collection topOps, String taskId)">3</method>
			<method name="public org.apache.hadoop.hive.ql.hooks.LineageInfo getLineageInfo()">1</method>
			<method name="public org.apache.hadoop.hive.ql.QueryProperties getQueryProperties()">1</method>
			<method name="private void extractCounters()">1</method>
			<method name="public java.util.HashMap getIdToTableNameMap()">1</method>
			<method name="public String toBinaryString()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.Adjacency</name>
		<wmc>44</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>21</cbo>
		<rfc>104</rfc>
		<lcom>504</lcom>
		<ca>2</ca>
		<ce>19</ce>
		<npm>41</npm>
		<lcom3>0.7587209302325582</lcom3>
		<loc>887</loc>
		<dam>0.875</dam>
		<moa>5</moa>
		<mfa>0.0</mfa>
		<cam>0.12880143112701253</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>18.977272727272727</amc>
		<cc>
			<method name="public boolean isSetNode()">2</method>
			<method name="public void clear()">1</method>
			<method name="public void unsetAdjacencyType()">1</method>
			<method name="public boolean isSet(org.apache.hadoop.hive.ql.plan.api.Adjacency$_Fields field)">3</method>
			<method name="static void _clinit_()">0</method>
			<method name="public volatile org.apache.thrift.TBase deepCopy()">1</method>
			<method name="public java.util.List getChildren()">1</method>
			<method name="public volatile Object getFieldValue(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="private void writeObject(java.io.ObjectOutputStream out)">1</method>
			<method name="public void setAdjacencyTypeIsSet(boolean value)">2</method>
			<method name="public boolean equals(org.apache.hadoop.hive.ql.plan.api.Adjacency that)">17</method>
			<method name="public void read(org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public void write(org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public volatile boolean isSet(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="public void setChildrenIsSet(boolean value)">2</method>
			<method name="public void setFieldValue(org.apache.hadoop.hive.ql.plan.api.Adjacency$_Fields field, Object value)">5</method>
			<method name="public void _init_(String node, java.util.List children, org.apache.hadoop.hive.ql.plan.api.AdjacencyType adjacencyType)">0</method>
			<method name="public boolean isSetAdjacencyType()">2</method>
			<method name="public int getChildrenSize()">2</method>
			<method name="public String toString()">6</method>
			<method name="public void setChildren(java.util.List children)">1</method>
			<method name="public java.util.Iterator getChildrenIterator()">2</method>
			<method name="public void validate()">1</method>
			<method name="public int compareTo(org.apache.hadoop.hive.ql.plan.api.Adjacency other)">11</method>
			<method name="public void setNode(String node)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.AdjacencyType getAdjacencyType()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void unsetNode()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.Adjacency deepCopy()">1</method>
			<method name="public volatile void setFieldValue(org.apache.thrift.TFieldIdEnum x0, Object x1)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.api.Adjacency other)">0</method>
			<method name="public String getNode()">1</method>
			<method name="public volatile int compareTo(Object x0)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.Adjacency$_Fields fieldForId(int fieldId)">1</method>
			<method name="public void addToChildren(String elem)">2</method>
			<method name="public int hashCode()">1</method>
			<method name="private void readObject(java.io.ObjectInputStream in)">1</method>
			<method name="public Object getFieldValue(org.apache.hadoop.hive.ql.plan.api.Adjacency$_Fields field)">2</method>
			<method name="public void setAdjacencyType(org.apache.hadoop.hive.ql.plan.api.AdjacencyType adjacencyType)">1</method>
			<method name="public boolean isSetChildren()">2</method>
			<method name="public void unsetChildren()">1</method>
			<method name="public boolean equals(Object that)">3</method>
			<method name="public volatile org.apache.thrift.TFieldIdEnum fieldForId(int x0)">1</method>
			<method name="public void setNodeIsSet(boolean value)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.Entity$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>28</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.GenMRTableScan1</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>23</cbo>
		<rfc>42</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>22</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>189</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>61.666666666666664</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx opProcCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceAmpersandOperator_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters$MapConverter</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>24</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>140</loc>
		<dam>0.0</dam>
		<moa>6</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>64.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.MapObjectInspector inputOI, org.apache.hadoop.hive.serde2.objectinspector.SettableMapObjectInspector outputOI)">0</method>
			<method name="public Object convert(Object input)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.LogUtils$LogInitializationException</name>
		<wmc>1</wmc>
		<dit>3</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>1.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_(String msg)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.TableSample</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>13</rfc>
		<lcom>11</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>10</npm>
		<lcom3>0.7222222222222222</lcom3>
		<loc>70</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.34</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.6</amc>
		<cc>
			<method name="public boolean getInputPruning()">1</method>
			<method name="public void _init_(int num, int den)">0</method>
			<method name="public void setInputPruning(boolean inputPruning)">1</method>
			<method name="public void _init_(String num, String den, java.util.ArrayList exprs)">0</method>
			<method name="public void setNumerator(int num)">1</method>
			<method name="public int getNumerator()">1</method>
			<method name="public void setExprs(java.util.ArrayList exprs)">1</method>
			<method name="public java.util.ArrayList getExprs()">1</method>
			<method name="public int getDenominator()">1</method>
			<method name="public void setDenominator(int den)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCount</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>15</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>3</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>78</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFParameterInfo paramInfo)">1</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] parameters)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.JavaUtils</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>6</rfc>
		<lcom>1</lcom>
		<ca>10</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>15</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.5</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public static ClassLoader getClassLoader()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TSaslTransport$SaslRole</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.888888888888889</lcom3>
		<loc>45</loc>
		<dam>0.3333333333333333</dam>
		<moa>3</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>9.5</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.thrift.transport.TSaslTransport$SaslRole valueOf(String name)">1</method>
			<method name="public static org.apache.thrift.transport.TSaslTransport$SaslRole[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.Query</name>
		<wmc>73</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>25</cbo>
		<rfc>166</rfc>
		<lcom>1638</lcom>
		<ca>3</ca>
		<ce>22</ce>
		<npm>70</npm>
		<lcom3>0.8505291005291006</lcom3>
		<loc>2081</loc>
		<dam>0.9523809523809523</dam>
		<moa>10</moa>
		<mfa>0.0</mfa>
		<cam>0.10069444444444445</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>27.21917808219178</amc>
		<cc>
			<method name="public int getStageListSize()">2</method>
			<method name="public boolean isStarted()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.Query deepCopy()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void setDoneIsSet(boolean value)">1</method>
			<method name="public void unsetQueryAttributes()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.Query$_Fields fieldForId(int fieldId)">1</method>
			<method name="public volatile boolean isSet(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="public void setQueryCounters(java.util.Map queryCounters)">1</method>
			<method name="public java.util.List getStageList()">1</method>
			<method name="public void unsetStarted()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.api.Query other)">0</method>
			<method name="public boolean isSetStarted()">1</method>
			<method name="public boolean isSetQueryId()">2</method>
			<method name="public void validate()">1</method>
			<method name="public void unsetQueryId()">1</method>
			<method name="public boolean isDone()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setStartedIsSet(boolean value)">1</method>
			<method name="public void setQueryType(String queryType)">1</method>
			<method name="public volatile void setFieldValue(org.apache.thrift.TFieldIdEnum x0, Object x1)">1</method>
			<method name="public void _init_(String queryId, String queryType, java.util.Map queryAttributes, java.util.Map queryCounters, org.apache.hadoop.hive.ql.plan.api.Graph stageGraph, java.util.List stageList, boolean done, boolean started)">0</method>
			<method name="public volatile int compareTo(Object x0)">1</method>
			<method name="public java.util.Map getQueryAttributes()">1</method>
			<method name="public int getQueryAttributesSize()">2</method>
			<method name="public void setQueryAttributes(java.util.Map queryAttributes)">1</method>
			<method name="public void unsetStageGraph()">1</method>
			<method name="public boolean equals(Object that)">3</method>
			<method name="public void setQueryId(String queryId)">1</method>
			<method name="public void putToQueryAttributes(String key, String val)">2</method>
			<method name="public boolean isSetDone()">1</method>
			<method name="public int compareTo(org.apache.hadoop.hive.ql.plan.api.Query other)">26</method>
			<method name="public void clear()">1</method>
			<method name="public void setStageList(java.util.List stageList)">1</method>
			<method name="public boolean equals(org.apache.hadoop.hive.ql.plan.api.Query that)">42</method>
			<method name="public void setStarted(boolean started)">1</method>
			<method name="public boolean isSetQueryCounters()">2</method>
			<method name="public void setDone(boolean done)">1</method>
			<method name="public volatile org.apache.thrift.TBase deepCopy()">1</method>
			<method name="public volatile Object getFieldValue(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="private void writeObject(java.io.ObjectOutputStream out)">1</method>
			<method name="public void read(org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public java.util.Map getQueryCounters()">1</method>
			<method name="public void write(org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public void setStageListIsSet(boolean value)">2</method>
			<method name="public void addToStageList(org.apache.hadoop.hive.ql.plan.api.Stage elem)">2</method>
			<method name="public void unsetQueryCounters()">1</method>
			<method name="public boolean isSet(org.apache.hadoop.hive.ql.plan.api.Query$_Fields field)">3</method>
			<method name="public java.util.Iterator getStageListIterator()">2</method>
			<method name="public boolean isSetQueryType()">2</method>
			<method name="public Object getFieldValue(org.apache.hadoop.hive.ql.plan.api.Query$_Fields field)">2</method>
			<method name="public String toString()">14</method>
			<method name="public boolean isSetStageGraph()">2</method>
			<method name="public boolean isSetQueryAttributes()">2</method>
			<method name="public void setQueryIdIsSet(boolean value)">2</method>
			<method name="public void setQueryTypeIsSet(boolean value)">2</method>
			<method name="public void setStageGraph(org.apache.hadoop.hive.ql.plan.api.Graph stageGraph)">1</method>
			<method name="public void unsetQueryType()">1</method>
			<method name="public String getQueryType()">1</method>
			<method name="public boolean isSetStageList()">2</method>
			<method name="public String getQueryId()">1</method>
			<method name="public void setFieldValue(org.apache.hadoop.hive.ql.plan.api.Query$_Fields field, Object value)">10</method>
			<method name="public void setQueryCountersIsSet(boolean value)">2</method>
			<method name="public void unsetStageList()">1</method>
			<method name="public void unsetDone()">1</method>
			<method name="public void setStageGraphIsSet(boolean value)">2</method>
			<method name="public int hashCode()">1</method>
			<method name="private void readObject(java.io.ObjectInputStream in)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.Graph getStageGraph()">1</method>
			<method name="public void putToQueryCounters(String key, long val)">2</method>
			<method name="public volatile org.apache.thrift.TFieldIdEnum fieldForId(int x0)">1</method>
			<method name="public int getQueryCountersSize()">2</method>
			<method name="public void setQueryAttributesIsSet(boolean value)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ExprNodeConstantEvaluator</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>22</loc>
		<dam>0.5</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.666666666666667</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.ExprNodeConstantDesc expr)">0</method>
			<method name="public Object evaluate(Object row)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector rowInspector)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory</name>
		<wmc>19</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>31</cbo>
		<rfc>100</rfc>
		<lcom>171</lcom>
		<ca>6</ca>
		<ce>30</ce>
		<npm>9</npm>
		<lcom3>1.0</lcom3>
		<loc>792</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.13636363636363635</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>40.63157894736842</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory$ColumnPrunerSelectProc getSelectProc()">1</method>
			<method name="static boolean[] access$200(java.util.List x0, org.apache.hadoop.hive.ql.exec.ReduceSinkOperator x1)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory$ColumnPrunerDefaultProc getDefaultProc()">1</method>
			<method name="private static boolean[] getPruneReduceSinkOpRetainFlags(java.util.List retainedParentOpOutputCols, org.apache.hadoop.hive.ql.exec.ReduceSinkOperator reduce)">6</method>
			<method name="private static void pruneJoinOperator(org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, org.apache.hadoop.hive.ql.exec.CommonJoinOperator op, org.apache.hadoop.hive.ql.plan.JoinDesc conf, java.util.Map columnExprMap, java.util.Map retainMap, boolean mapJoin)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory$ColumnPrunerTableScanProc getTableScanProc()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory$ColumnPrunerJoinProc getJoinProc()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory$ColumnPrunerMapJoinProc getMapJoinProc()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory$ColumnPrunerLateralViewJoinProc getLateralViewJoinProc()">1</method>
			<method name="private void _init_()">0</method>
			<method name="static void access$300(org.apache.hadoop.hive.ql.lib.NodeProcessorCtx x0, org.apache.hadoop.hive.ql.exec.CommonJoinOperator x1, org.apache.hadoop.hive.ql.plan.JoinDesc x2, java.util.Map x3, java.util.Map x4, boolean x5)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory$ColumnPrunerReduceSinkProc getReduceSinkProc()">1</method>
			<method name="static void access$100(boolean[] x0, org.apache.hadoop.hive.ql.exec.ReduceSinkOperator x1, org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcCtx x2)">1</method>
			<method name="static void access$000(org.apache.hadoop.hive.ql.lib.NodeProcessorCtx x0, org.apache.hadoop.hive.ql.exec.Operator x1, java.util.List x2)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory$ColumnPrunerGroupByProc getGroupByProc()">1</method>
			<method name="private static void pruneOperator(org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, org.apache.hadoop.hive.ql.exec.Operator op, java.util.List cols)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory$ColumnPrunerFilterProc getFilterProc()">1</method>
			<method name="private static void pruneReduceSinkOperator(boolean[] retainFlags, org.apache.hadoop.hive.ql.exec.ReduceSinkOperator reduce, org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcCtx cppCtx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceEqualExpression_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.index.IndexWhereTaskDispatcher</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>19</cbo>
		<rfc>31</rfc>
		<lcom>4</lcom>
		<ca>2</ca>
		<ce>18</ce>
		<npm>2</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>143</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>34.5</amc>
		<cc>
			<method name="public transient Object dispatch(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, Object[] nodeOutputs)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext context)">0</method>
			<method name="private org.apache.hadoop.hive.ql.lib.NodeProcessor getDefaultProcessor()">1</method>
			<method name="private java.util.Map createOperatorRules(org.apache.hadoop.hive.ql.parse.ParseContext pctx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFHex</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>14</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>4</npm>
		<lcom3>0.0</lcom3>
		<loc>156</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.36</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>29.8</amc>
		<cc>
			<method name="private org.apache.hadoop.io.Text evaluate(long num)">2</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text s)">4</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.IntWritable n)">2</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.LongWritable n)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ScriptOperator$StreamThread</name>
		<wmc>2</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>18</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>1</npm>
		<lcom3>0.0</lcom3>
		<loc>241</loc>
		<dam>0.0</dam>
		<moa>3</moa>
		<mfa>0.9846153846153847</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>117.5</amc>
		<cc>
			<method name="public void run()">2</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.exec.ScriptOperator, org.apache.hadoop.hive.ql.exec.RecordReader in, org.apache.hadoop.hive.ql.exec.ScriptOperator$StreamProcessor proc, String name)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceAndExpression_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.thrift.ConfigurableTProtocol</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void initialize(org.apache.hadoop.conf.Configuration, java.util.Properties)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.NumericHistogram$Coord</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>1.5</lcom3>
		<loc>28</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.0</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public int compareTo(Object other)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.GroupByOptimizer$BucketGroupByProcessor</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>28</cbo>
		<rfc>56</rfc>
		<lcom>8</lcom>
		<ca>1</ca>
		<ce>28</ce>
		<npm>2</npm>
		<lcom3>0.75</lcom3>
		<loc>360</loc>
		<dam>0.5</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.3111111111111111</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>70.6</amc>
		<cc>
			<method name="private boolean matchBucketOrSortedColumns(java.util.List groupByCols, java.util.List bucketCols, java.util.List sortCols)">1</method>
			<method name="private void checkBucketGroupBy(org.apache.hadoop.hive.ql.exec.GroupByOperator curr)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.optimizer.GroupByOptimizer, org.apache.hadoop.hive.ql.parse.ParseContext pGraphContext)">0</method>
			<method name="private boolean matchBucketColumns(java.util.List grpCols, java.util.List tblBucketCols)">1</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.pcr.PcrExprProcFactory$NodeInfoWrapper</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>6</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>16</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.optimizer.pcr.PcrExprProcFactory$WalkState state, Boolean[] resultVector, org.apache.hadoop.hive.ql.plan.ExprNodeDesc outExpr)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFMin</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>10</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>11</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>46</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] parameters)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ArchiveDesc</name>
		<wmc>1</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.MapJoinDesc</name>
		<wmc>24</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>20</cbo>
		<rfc>41</rfc>
		<lcom>176</lcom>
		<ca>17</ca>
		<ce>3</ce>
		<npm>23</npm>
		<lcom3>0.8893280632411067</lcom3>
		<loc>233</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.175</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.25</amc>
		<cc>
			<method name="public void setDumpFilePrefix(String dumpFilePrefix)">1</method>
			<method name="public java.util.LinkedHashMap getAliasBucketFileNameMapping()">1</method>
			<method name="public String getDumpFilePrefix()">1</method>
			<method name="public int getPosBigTable()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setBucketFileNameMapping(java.util.LinkedHashMap bucketFileNameMapping)">1</method>
			<method name="public void setBigTableAlias(String bigTableAlias)">1</method>
			<method name="public void setAliasBucketFileNameMapping(java.util.LinkedHashMap aliasBucketFileNameMapping)">1</method>
			<method name="public java.util.LinkedHashMap getBucketFileNameMapping()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.MapJoinDesc clone)">0</method>
			<method name="public String getBigTableAlias()">1</method>
			<method name="public void setKeyTblDesc(org.apache.hadoop.hive.ql.plan.TableDesc keyTblDesc)">1</method>
			<method name="public void setPosBigTable(int posBigTable)">1</method>
			<method name="public java.util.List getValueFilteredTblDescs()">1</method>
			<method name="private void initRetainExprList()">3</method>
			<method name="public void setRetainList(java.util.Map retainList)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.TableDesc getKeyTblDesc()">1</method>
			<method name="public java.util.List getValueTblDescs()">1</method>
			<method name="public void setValueFilteredTblDescs(java.util.List valueFilteredTblDescs)">1</method>
			<method name="public void setValueTblDescs(java.util.List valueTblDescs)">1</method>
			<method name="public java.util.Map getRetainList()">1</method>
			<method name="public void setKeys(java.util.Map keys)">1</method>
			<method name="public void _init_(java.util.Map keys, org.apache.hadoop.hive.ql.plan.TableDesc keyTblDesc, java.util.Map values, java.util.List valueTblDescs, java.util.List valueFilteredTblDescs, java.util.List outputColumnNames, int posBigTable, org.apache.hadoop.hive.ql.plan.JoinCondDesc[] conds, java.util.Map filters, boolean noOuterJoin, String dumpFilePrefix)">0</method>
			<method name="public java.util.Map getKeys()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$functionName_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.HadoopJobExecHelper</name>
		<wmc>24</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>44</cbo>
		<rfc>172</rfc>
		<lcom>140</lcom>
		<ca>6</ca>
		<ce>39</ce>
		<npm>15</npm>
		<lcom3>0.8217391304347825</lcom3>
		<loc>1662</loc>
		<dam>0.7</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.14381270903010032</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>67.83333333333333</amc>
		<cc>
			<method name="public static String getJobEndMsg(String jobId)">1</method>
			<method name="public boolean mapDone()">2</method>
			<method name="private void showJobFailDebugInfo(org.apache.hadoop.mapred.JobConf conf, org.apache.hadoop.mapred.RunningJob rj)">1</method>
			<method name="public void setJobId(String jobId)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void updateCounters(org.apache.hadoop.mapred.Counters ctrs, org.apache.hadoop.mapred.RunningJob rj)">1</method>
			<method name="private org.apache.hadoop.hive.ql.MapRedStats progress(org.apache.hadoop.hive.ql.exec.HadoopJobExecHelper$ExecDriverTaskHandle th)">1</method>
			<method name="public void _init_(org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.hive.ql.session.SessionState$LogHelper console, org.apache.hadoop.hive.ql.exec.Task task, org.apache.hadoop.hive.ql.exec.HadoopJobExecHook hookCallBack)">0</method>
			<method name="private java.util.Map extractAllCounterValues(org.apache.hadoop.mapred.Counters counters)">2</method>
			<method name="public boolean mapStarted()">2</method>
			<method name="private static String getJobStartMsg(String jobId)">1</method>
			<method name="private String getId()">1</method>
			<method name="public String getJobId()">1</method>
			<method name="public int progress(org.apache.hadoop.mapred.RunningJob rj, org.apache.hadoop.mapred.JobClient jc)">1</method>
			<method name="public void jobInfo(org.apache.hadoop.mapred.RunningJob rj)">3</method>
			<method name="public boolean reduceStarted()">2</method>
			<method name="public int progressLocal(Process runningJob, String taskId)">3</method>
			<method name="public void localJobDebugger(int exitVal, String taskId)">2</method>
			<method name="public static void killRunningJobs()">2</method>
			<method name="private String getTaskAttemptLogUrl(String taskTrackerHttpAddress, String taskAttemptId)">1</method>
			<method name="public boolean reduceDone()">2</method>
			<method name="public boolean checkFatalErrors(org.apache.hadoop.mapred.Counters ctrs, StringBuilder errMsg)">3</method>
			<method name="private java.util.List getClientStatPublishers()">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.FileSinkDesc</name>
		<wmc>31</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>36</rfc>
		<lcom>367</lcom>
		<ca>10</ca>
		<ce>2</ce>
		<npm>31</npm>
		<lcom3>0.9333333333333333</lcom3>
		<loc>219</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.2488479262672811</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.580645161290323</amc>
		<cc>
			<method name="public String getStaticSpec()">1</method>
			<method name="public void setCompressType(String intermediateCompressType)">1</method>
			<method name="public void setStaticSpec(String staticSpec)">1</method>
			<method name="public void _init_(String dirName, org.apache.hadoop.hive.ql.plan.TableDesc tableInfo, boolean compressed)">0</method>
			<method name="public void setDirName(String dirName)">1</method>
			<method name="public void setPartitionCols(java.util.ArrayList partitionCols)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.DynamicPartitionCtx getDynPartCtx()">1</method>
			<method name="public void setMultiFileSpray(boolean multiFileSpray)">1</method>
			<method name="public String getStatsAggPrefix()">1</method>
			<method name="public String getCompressCodec()">1</method>
			<method name="public void setTableInfo(org.apache.hadoop.hive.ql.plan.TableDesc tableInfo)">1</method>
			<method name="public boolean isMultiFileSpray()">1</method>
			<method name="public int getNumFiles()">1</method>
			<method name="public String getDirName()">1</method>
			<method name="public String getCompressType()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setNumFiles(int numFiles)">1</method>
			<method name="public void setStatsAggPrefix(String k)">2</method>
			<method name="public org.apache.hadoop.hive.ql.plan.TableDesc getTableInfo()">1</method>
			<method name="public void setDynPartCtx(org.apache.hadoop.hive.ql.plan.DynamicPartitionCtx dpc)">1</method>
			<method name="public int getDestTableId()">1</method>
			<method name="public java.util.ArrayList getPartitionCols()">1</method>
			<method name="public void setCompressed(boolean compressed)">1</method>
			<method name="public void setGatherStats(boolean gatherStats)">1</method>
			<method name="public void _init_(String dirName, org.apache.hadoop.hive.ql.plan.TableDesc tableInfo, boolean compressed, int destTableId, boolean multiFileSpray, int numFiles, int totalFiles, java.util.ArrayList partitionCols, org.apache.hadoop.hive.ql.plan.DynamicPartitionCtx dpCtx)">0</method>
			<method name="public void setCompressCodec(String intermediateCompressorCodec)">1</method>
			<method name="public void setDestTableId(int destTableId)">1</method>
			<method name="public int getTotalFiles()">1</method>
			<method name="public void setTotalFiles(int totalFiles)">1</method>
			<method name="public boolean isGatherStats()">1</method>
			<method name="public boolean getCompressed()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.xml.UDFXPathUtil$ReusableStringReader</name>
		<wmc>11</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>21</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>10</npm>
		<lcom3>0.45</lcom3>
		<loc>201</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.5</mfa>
		<cam>0.2909090909090909</cam>
		<ic>1</ic>
		<cbm>2</cbm>
		<amc>16.90909090909091</amc>
		<cc>
			<method name="public long skip(long ns)">1</method>
			<method name="public void mark(int readAheadLimit)">1</method>
			<method name="public boolean markSupported()">1</method>
			<method name="public void set(String s)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public int read()">1</method>
			<method name="public void close()">1</method>
			<method name="public void reset()">1</method>
			<method name="public int read(char[] cbuf, int off, int len)">1</method>
			<method name="private void ensureOpen()">1</method>
			<method name="public boolean ready()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFVariance$GenericUDAFVarianceEvaluator$StdAgg</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>7</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.SchemaAwareCompressionInputStream</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>6</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.0</amc>
		<cc>
			<method name="protected void _init_(java.io.InputStream in)">0</method>
			<method name="public abstract void setColumnIndex(int)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ExplainTask</name>
		<wmc>17</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>20</cbo>
		<rfc>89</rfc>
		<lcom>136</lcom>
		<ca>0</ca>
		<ce>20</ce>
		<npm>9</npm>
		<lcom3>1.0625</lcom3>
		<loc>1381</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.18382352941176472</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>80.11764705882354</amc>
		<cc>
			<method name="public java.util.List getResultSchema()">1</method>
			<method name="public int execute(org.apache.hadoop.hive.ql.DriverContext driverContext)">2</method>
			<method name="private static org.json.JSONObject outputPlan(java.io.Serializable work, java.io.PrintStream out, boolean extended, boolean jsonOutput, int indent)">1</method>
			<method name="private static boolean isPrintable(Object val)">9</method>
			<method name="public void _init_()">0</method>
			<method name="public static org.json.JSONObject outputStagePlans(java.io.PrintStream out, org.apache.hadoop.hive.ql.plan.ExplainWork work, java.util.List rootTasks, int indent)">1</method>
			<method name="protected void localizeMRTmpFilesImpl(org.apache.hadoop.hive.ql.Context ctx)">1</method>
			<method name="private static String outputList(java.util.List l, String header, java.io.PrintStream out, boolean extended, boolean jsonOutput, int indent)">1</method>
			<method name="private static org.json.JSONObject outputPlan(org.apache.hadoop.hive.ql.exec.Task task, java.io.PrintStream out, org.json.JSONObject parentJSON, boolean extended, boolean jsonOutput, java.util.HashSet displayedSet, int indent)">1</method>
			<method name="public String getName()">1</method>
			<method name="public static org.json.JSONObject getJSONPlan(java.io.PrintStream out, org.apache.hadoop.hive.ql.plan.ExplainWork work)">1</method>
			<method name="public static org.json.JSONObject outputDependencies(java.io.PrintStream out, boolean jsonOutput, java.util.List rootTasks, int indent)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.StageType getType()">1</method>
			<method name="private static org.json.JSONObject outputDependencies(org.apache.hadoop.hive.ql.exec.Task task, java.util.Set dependeciesTaskSet, java.io.PrintStream out, org.json.JSONObject parentJson, boolean jsonOutput, int indent, boolean rootTskCandidate)">1</method>
			<method name="private static String indentString(int indent)">2</method>
			<method name="public static String outputAST(String treeString, java.io.PrintStream out, boolean jsonOutput, int indent)">1</method>
			<method name="private static org.json.JSONObject outputMap(java.util.Map mp, String header, java.io.PrintStream out, boolean extended, boolean jsonOutput, int indent)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFMax</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>10</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>11</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>46</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] parameters)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.errors.package-info</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableByteObjectInspector</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>11</cbo>
		<rfc>11</rfc>
		<lcom>15</lcom>
		<ca>6</ca>
		<ce>5</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>45</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.5</amc>
		<cc>
			<method name="public Object set(Object o, byte value)">1</method>
			<method name="void _init_()">0</method>
			<method name="public byte get(Object o)">1</method>
			<method name="public Object getPrimitiveJavaObject(Object o)">2</method>
			<method name="public Object create(byte value)">1</method>
			<method name="public Object copyObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceUnaryOperator_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcCtx</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>30</rfc>
		<lcom>10</lcom>
		<ca>9</ca>
		<ce>8</ce>
		<npm>8</npm>
		<lcom3>0.7142857142857143</lcom3>
		<loc>173</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.35</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>20.25</amc>
		<cc>
			<method name="public java.util.Map getPrunedColLists()">1</method>
			<method name="public java.util.List getColsFromSelectExpr(org.apache.hadoop.hive.ql.exec.SelectOperator op)">2</method>
			<method name="public java.util.List getPrunedColList(org.apache.hadoop.hive.ql.exec.Operator op)">1</method>
			<method name="public java.util.List getSelectColsFromChildren(org.apache.hadoop.hive.ql.exec.SelectOperator op, java.util.List colList)">4</method>
			<method name="public java.util.List genColLists(org.apache.hadoop.hive.ql.exec.Operator curOp)">1</method>
			<method name="public java.util.HashMap getOpToParseCtxMap()">1</method>
			<method name="public void _init_(java.util.HashMap opToParseContextMap)">0</method>
			<method name="public java.util.Map getJoinPrunedColLists()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.MapJoinProcessor$Default</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>7</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyProcFactory$CheckGroupByProc</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>46</rfc>
		<lcom>8</lcom>
		<ca>2</ca>
		<ce>15</ce>
		<npm>1</npm>
		<lcom3>0.75</lcom3>
		<loc>250</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.35714285714285715</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>48.8</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyProcFactory$1 x0)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, Object[] nodeOutputs)">1</method>
			<method name="private void checkExpression(org.apache.hadoop.hive.ql.plan.ExprNodeDesc expr)">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.ASTNodeOrigin</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>7</rfc>
		<lcom>5</lcom>
		<ca>5</ca>
		<ce>1</ce>
		<npm>6</npm>
		<lcom3>0.8</lcom3>
		<loc>44</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4444444444444444</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.5</amc>
		<cc>
			<method name="public String getObjectType()">1</method>
			<method name="public String getUsageAlias()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ASTNode getUsageNode()">1</method>
			<method name="public String getObjectName()">1</method>
			<method name="public String getObjectDefinition()">1</method>
			<method name="public void _init_(String objectType, String objectName, String objectDefinition, String usageAlias, org.apache.hadoop.hive.ql.parse.ASTNode usageNode)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeXception</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.fs.ProxyFileSystem</name>
		<wmc>36</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>89</rfc>
		<lcom>620</lcom>
		<ca>1</ca>
		<ce>12</ce>
		<npm>32</npm>
		<lcom3>0.6476190476190475</lcom3>
		<loc>400</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.18055555555555555</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.944444444444445</amc>
		<cc>
			<method name="public void completeLocalOutput(org.apache.hadoop.fs.Path fsOutputFile, org.apache.hadoop.fs.Path tmpLocalFile)">1</method>
			<method name="public void initialize(java.net.URI name, org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="public org.apache.hadoop.fs.FSDataInputStream open(org.apache.hadoop.fs.Path f, int bufferSize)">1</method>
			<method name="public org.apache.hadoop.fs.BlockLocation[] getFileBlockLocations(org.apache.hadoop.fs.FileStatus file, long start, long len)">1</method>
			<method name="private org.apache.hadoop.fs.Path swizzleParamPath(org.apache.hadoop.fs.Path p)">1</method>
			<method name="public boolean setReplication(org.apache.hadoop.fs.Path src, short replication)">1</method>
			<method name="public String getName()">1</method>
			<method name="public void setWorkingDirectory(org.apache.hadoop.fs.Path newDir)">1</method>
			<method name="public void copyToLocalFile(boolean delSrc, org.apache.hadoop.fs.Path src, org.apache.hadoop.fs.Path dst)">1</method>
			<method name="private org.apache.hadoop.fs.Path swizzleReturnPath(org.apache.hadoop.fs.Path p)">1</method>
			<method name="public org.apache.hadoop.fs.FSDataOutputStream create(org.apache.hadoop.fs.Path f, org.apache.hadoop.fs.permission.FsPermission permission, boolean overwrite, int bufferSize, short replication, long blockSize, org.apache.hadoop.util.Progressable progress)">1</method>
			<method name="public boolean deleteOnExit(org.apache.hadoop.fs.Path f)">1</method>
			<method name="public org.apache.hadoop.fs.ContentSummary getContentSummary(org.apache.hadoop.fs.Path f)">1</method>
			<method name="public org.apache.hadoop.fs.FileChecksum getFileChecksum(org.apache.hadoop.fs.Path f)">1</method>
			<method name="public org.apache.hadoop.fs.Path getWorkingDirectory()">1</method>
			<method name="public void _init_(org.apache.hadoop.fs.FileSystem fs, java.net.URI myUri)">0</method>
			<method name="public void setPermission(org.apache.hadoop.fs.Path p, org.apache.hadoop.fs.permission.FsPermission permission)">1</method>
			<method name="public org.apache.hadoop.fs.Path startLocalOutput(org.apache.hadoop.fs.Path fsOutputFile, org.apache.hadoop.fs.Path tmpLocalFile)">1</method>
			<method name="public void setTimes(org.apache.hadoop.fs.Path p, long mtime, long atime)">1</method>
			<method name="public void copyFromLocalFile(boolean delSrc, boolean overwrite, org.apache.hadoop.fs.Path src, org.apache.hadoop.fs.Path dst)">1</method>
			<method name="private org.apache.hadoop.fs.FileStatus swizzleFileStatus(org.apache.hadoop.fs.FileStatus orig, boolean isParam)">2</method>
			<method name="public boolean delete(org.apache.hadoop.fs.Path f, boolean recursive)">1</method>
			<method name="public org.apache.hadoop.fs.FSDataOutputStream append(org.apache.hadoop.fs.Path f, int bufferSize, org.apache.hadoop.util.Progressable progress)">1</method>
			<method name="public org.apache.hadoop.fs.Path makeQualified(org.apache.hadoop.fs.Path path)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.fs.Path getHomeDirectory()">1</method>
			<method name="public org.apache.hadoop.fs.FileStatus getFileStatus(org.apache.hadoop.fs.Path f)">1</method>
			<method name="public void setOwner(org.apache.hadoop.fs.Path p, String username, String groupname)">1</method>
			<method name="public boolean mkdirs(org.apache.hadoop.fs.Path f, org.apache.hadoop.fs.permission.FsPermission permission)">1</method>
			<method name="protected void checkPath(org.apache.hadoop.fs.Path path)">1</method>
			<method name="public void copyFromLocalFile(boolean delSrc, org.apache.hadoop.fs.Path src, org.apache.hadoop.fs.Path dst)">1</method>
			<method name="public void copyFromLocalFile(boolean delSrc, boolean overwrite, org.apache.hadoop.fs.Path[] srcs, org.apache.hadoop.fs.Path dst)">1</method>
			<method name="public java.net.URI getUri()">1</method>
			<method name="public org.apache.hadoop.fs.FileStatus[] listStatus(org.apache.hadoop.fs.Path f)">1</method>
			<method name="public boolean rename(org.apache.hadoop.fs.Path src, org.apache.hadoop.fs.Path dst)">1</method>
			<method name="public void _init_(org.apache.hadoop.fs.FileSystem fs)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HiveFileFormatUtils</name>
		<wmc>19</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>27</cbo>
		<rfc>66</rfc>
		<lcom>151</lcom>
		<ca>12</ca>
		<ce>18</ce>
		<npm>12</npm>
		<lcom3>0.8518518518518519</lcom3>
		<loc>562</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.1746031746031746</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>28.42105263157895</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.plan.PartitionDesc getPartitionDescFromPathRecursively(java.util.Map pathToPartitionInfo, org.apache.hadoop.fs.Path dir, java.util.Map cacheMap, boolean ignoreSchema)">1</method>
			<method name="private static void populateNewPartitionDesc(java.util.Map pathToPartitionInfo, java.util.Map newPathToPartitionInfo)">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static boolean checkInputFormat(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.hive.conf.HiveConf conf, Class inputFormatCls, java.util.ArrayList files)">1</method>
			<method name="public static java.util.List doGetAliasesFromPath(java.util.Map pathToAliases, org.apache.hadoop.fs.Path dir)">2</method>
			<method name="public static synchronized void registerOutputFormatSubstitute(Class origin, Class substitute)">1</method>
			<method name="private static String getMatchingPath(java.util.Map pathToAliases, org.apache.hadoop.fs.Path dir)">7</method>
			<method name="private static boolean checkTextInputFormat(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.hive.conf.HiveConf conf, java.util.ArrayList files)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf jc, org.apache.hadoop.hive.ql.plan.TableDesc tableInfo, Class outputClass, org.apache.hadoop.hive.ql.plan.FileSinkDesc conf, org.apache.hadoop.fs.Path outPath)">1</method>
			<method name="private void _init_()">0</method>
			<method name="public static synchronized void registerInputFormatChecker(Class format, Class checker)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getRecordWriter(org.apache.hadoop.mapred.JobConf jc, org.apache.hadoop.hive.ql.io.HiveOutputFormat hiveOutputFormat, Class valueClass, boolean isCompressed, java.util.Properties tableProp, org.apache.hadoop.fs.Path outPath)">1</method>
			<method name="private static boolean foundAlias(java.util.Map pathToAliases, String path)">3</method>
			<method name="public static synchronized Class getOutputFormatSubstitute(Class origin)">2</method>
			<method name="private static org.apache.hadoop.hive.ql.plan.PartitionDesc doGetPartitionDescFromPath(java.util.Map pathToPartitionInfo, org.apache.hadoop.fs.Path dir)">7</method>
			<method name="public static synchronized Class getInputFormatChecker(Class inputFormat)">1</method>
			<method name="public static java.util.List doGetWorksFromPath(java.util.Map pathToAliases, java.util.Map aliasToWork, org.apache.hadoop.fs.Path dir)">2</method>
			<method name="public static org.apache.hadoop.fs.Path getOutputFormatFinalPath(org.apache.hadoop.fs.Path parent, String taskId, org.apache.hadoop.mapred.JobConf jc, org.apache.hadoop.hive.ql.io.HiveOutputFormat hiveOutputFormat, boolean isCompressed, org.apache.hadoop.fs.Path defaultFinalPath)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.PartitionDesc getPartitionDescFromPathRecursively(java.util.Map pathToPartitionInfo, org.apache.hadoop.fs.Path dir, java.util.Map cacheMap)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.ParseDriver$1</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>10</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public Object create(org.antlr.runtime.Token payload)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.TUGIContainingTransport</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>6</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>4</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>27</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.5</amc>
		<cc>
			<method name="public org.apache.hadoop.security.UserGroupInformation getClientUGI()">1</method>
			<method name="public void setClientUGI(org.apache.hadoop.security.UserGroupInformation ugi)">1</method>
			<method name="public void _init_(org.apache.thrift.transport.TTransport wrapped, org.apache.hadoop.security.UserGroupInformation ugi)">0</method>
			<method name="public java.net.Socket getSocket()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFLog</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>8</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>3</npm>
		<lcom3>0.0</lcom3>
		<loc>59</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.333333333333332</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable a)">3</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable base, org.apache.hadoop.hive.serde2.io.DoubleWritable a)">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.InspectableObject</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>6</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>18</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFArrayContains</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>25</rfc>
		<lcom>6</lcom>
		<ca>0</ca>
		<ce>12</ce>
		<npm>4</npm>
		<lcom3>0.9722222222222222</lcom3>
		<loc>228</loc>
		<dam>0.8888888888888888</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>42.8</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter$BooleanConverter</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>36</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.5</amc>
		<cc>
			<method name="public Object convert(Object input)">2</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector inputOI, org.apache.hadoop.hive.serde2.objectinspector.primitive.SettableBooleanObjectInspector outputOI)">0</method>
		</cc>
	</class>
	<class>
		<name>org.json.CookieList</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>23</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>89</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>28.666666666666668</amc>
		<cc>
			<method name="public static org.json.JSONObject toJSONObject(String arg0)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public static String toString(org.json.JSONObject arg0)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.HashTableDummyDesc</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>14</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.3333333333333335</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void setTbl(org.apache.hadoop.hive.ql.plan.TableDesc tbl)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.TableDesc getTbl()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.BucketMapJoinOptimizer$BucketMapjoinOptProc</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>28</cbo>
		<rfc>84</rfc>
		<lcom>13</lcom>
		<ca>1</ca>
		<ce>28</ce>
		<npm>2</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>929</loc>
		<dam>0.3333333333333333</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.28205128205128205</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>131.28571428571428</amc>
		<cc>
			<method name="private boolean checkBucketNumberAgainstBigTable(java.util.LinkedHashMap aliasToBucketNumber, int bucketNumberInPart)">5</method>
			<method name="private void fillMapping(String baseBigAlias, java.util.LinkedHashMap aliasToBucketNumberMapping, java.util.LinkedHashMap aliasToBucketFileNamesMapping, String alias, java.util.LinkedHashMap mapping, int bigTblBucketNum, java.util.List bigTblBucketNameList, java.util.LinkedHashMap bucketFileNameMapping)">5</method>
			<method name="static void _clinit_()">0</method>
			<method name="private boolean checkBucketColumns(java.util.List bucketColumns, org.apache.hadoop.hive.ql.plan.MapJoinDesc mjDesc, int index)">10</method>
			<method name="private java.util.List getOnePartitionBucketFileNames(org.apache.hadoop.hive.ql.metadata.Partition part)">1</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.optimizer.BucketMapJoinOptimizer, org.apache.hadoop.hive.ql.parse.ParseContext pGraphContext)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.DelegationTokenSecretManager</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>13</cbo>
		<rfc>18</rfc>
		<lcom>15</lcom>
		<ca>5</ca>
		<ce>8</ce>
		<npm>6</npm>
		<lcom3>2.0</lcom3>
		<loc>90</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.0</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.thrift.DelegationTokenIdentifier createIdentifier()">1</method>
			<method name="public void _init_(long delegationKeyUpdateInterval, long delegationTokenMaxLifetime, long delegationTokenRenewInterval, long delegationTokenRemoverScanInterval)">0</method>
			<method name="public synchronized void cancelDelegationToken(String tokenStrForm)">1</method>
			<method name="public volatile org.apache.hadoop.security.token.TokenIdentifier createIdentifier()">1</method>
			<method name="public synchronized String getDelegationToken(String renewer)">1</method>
			<method name="public synchronized long renewDelegationToken(String tokenStrForm)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$fromClause_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tableAlias_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPEqualOrGreaterThan$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>56</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>54.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.SettableStructObjectInspector</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>2</noc>
		<cbo>6</cbo>
		<rfc>4</rfc>
		<lcom>3</lcom>
		<ca>4</ca>
		<ce>2</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>6</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>1.0</amc>
		<cc>
			<method name="public abstract Object create()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public abstract Object setStructFieldData(Object, org.apache.hadoop.hive.serde2.objectinspector.StructField, Object)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.SettableIntObjectInspector</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Object set(Object, int)">1</method>
			<method name="public abstract Object create(int)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>28</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.PrintOpTreeProcessor</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>25</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>5</ce>
		<npm>3</npm>
		<lcom3>0.33333333333333337</lcom3>
		<loc>192</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.34285714285714286</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>36.8</amc>
		<cc>
			<method name="private String getChildren(org.apache.hadoop.hive.ql.exec.Operator op)">4</method>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, Object[] nodeOutputs)">1</method>
			<method name="public void _init_(java.io.PrintStream o)">0</method>
			<method name="private String getParents(org.apache.hadoop.hive.ql.exec.Operator op)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFPI</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>8</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.75</lcom3>
		<loc>25</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.666666666666667</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.SkewJoinProcFactory$SkewJoinDefaultProcessor</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>7</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.security.authorization.Privilege</name>
		<wmc>12</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>18</rfc>
		<lcom>34</lcom>
		<ca>11</ca>
		<ce>3</ce>
		<npm>10</npm>
		<lcom3>0.9256198347107438</lcom3>
		<loc>247</loc>
		<dam>0.18181818181818182</dam>
		<moa>10</moa>
		<mfa>0.0</mfa>
		<cam>0.2727272727272727</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.666666666666668</amc>
		<cc>
			<method name="public boolean supportDBLevel()">3</method>
			<method name="public org.apache.hadoop.hive.ql.security.authorization.Privilege$PrivilegeType getPriv()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.security.authorization.Privilege$PrivilegeType priv)">0</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void setPriv(org.apache.hadoop.hive.ql.security.authorization.Privilege$PrivilegeType priv)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.security.authorization.Privilege$PrivilegeType getPrivTypeByToken(int token)">2</method>
			<method name="public static org.apache.hadoop.hive.ql.security.authorization.Privilege$PrivilegeType getPrivTypeByName(String privilegeName)">10</method>
			<method name="public String toString()">2</method>
			<method name="public boolean supportTableLevel()">3</method>
			<method name="public boolean supportColumnLevel()">3</method>
			<method name="private void _init_(org.apache.hadoop.hive.ql.security.authorization.Privilege$PrivilegeType priv, java.util.EnumSet scopeSet)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.RandomDimension</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>17</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public int hashCode(Object o)">1</method>
			<method name="public void _init_(Class t, String id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Jetty20Shims$1</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ArchiveWork$ArchiveActionType</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.888888888888889</lcom3>
		<loc>45</loc>
		<dam>0.3333333333333333</dam>
		<moa>3</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>9.5</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.plan.ArchiveWork$ArchiveActionType valueOf(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.ArchiveWork$ArchiveActionType[] values()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.GroupByOperator$varLenFields</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>24</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.0</amc>
		<cc>
			<method name="java.util.List getFields()">1</method>
			<method name="int getAggrPos()">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.exec.GroupByOperator, int aggrPos, java.util.List fields)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeSenumDefList</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.NumericOpMethodResolver</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>26</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>218</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>71.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="public java.lang.reflect.Method getEvalMethod(java.util.List argTypeInfos)">1</method>
			<method name="public void _init_(Class udfClass)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ScriptOperator$StreamProcessor</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>4</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void close()">1</method>
			<method name="public abstract void processLine(org.apache.hadoop.io.Writable)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.FlatFileInputFormat$SerializationContextFromConf</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>8</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>5</npm>
		<lcom3>0.75</lcom3>
		<loc>41</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.8</amc>
		<cc>
			<method name="public org.apache.hadoop.conf.Configuration getConf()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setConf(org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="public Class getRealClass()">1</method>
			<method name="public org.apache.hadoop.io.serializer.Serialization getSerialization()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.Explain</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract boolean normalExplain()">1</method>
			<method name="public abstract String displayName()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyDouble</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>11</cbo>
		<rfc>18</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>9</ce>
		<npm>3</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>74</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>17.25</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyDoubleObjectInspector oi)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.LazyDouble copy)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lib.RuleRegExp</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>28</cbo>
		<rfc>16</rfc>
		<lcom>0</lcom>
		<ca>25</ca>
		<ce>3</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>66</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>20.333333333333332</amc>
		<cc>
			<method name="public String getName()">1</method>
			<method name="public int cost(java.util.Stack stack)">1</method>
			<method name="public void _init_(String ruleName, String regExp)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.CombineHiveInputFormat$CombinePathInputFormat</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>3</npm>
		<lcom3>0.25</lcom3>
		<loc>51</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>15.333333333333334</amc>
		<cc>
			<method name="public boolean equals(Object o)">5</method>
			<method name="public int hashCode()">2</method>
			<method name="public void _init_(java.util.List opList, String inputFormatClassName)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.LineageInfo$DependencyType</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>8</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9166666666666666</lcom3>
		<loc>56</loc>
		<dam>0.25</dam>
		<moa>4</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>12.0</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.hooks.LineageInfo$DependencyType valueOf(String name)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.hooks.LineageInfo$DependencyType[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.SamplePruner</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>28</cbo>
		<rfc>56</rfc>
		<lcom>22</lcom>
		<ca>2</ca>
		<ce>26</ce>
		<npm>7</npm>
		<lcom3>0.5714285714285714</lcom3>
		<loc>414</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2222222222222222</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>50.625</amc>
		<cc>
			<method name="public static org.apache.hadoop.fs.Path[] prune(org.apache.hadoop.hive.ql.metadata.Partition part, org.apache.hadoop.hive.ql.plan.FilterDesc$sampleDesc sampleDescr)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getDefaultProc()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.SamplePruner$AddPathReturnStatus addPath(org.apache.hadoop.fs.FileSystem fs, String pathPattern, long sizeLeft, int fileLimit, java.util.Collection retPathList)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getFilterProc()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.SamplePruner$LimitPruneRetStatus limitPrune(org.apache.hadoop.hive.ql.metadata.Partition part, long sizeLimit, int fileLimit, java.util.Collection retPathList)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext transform(org.apache.hadoop.hive.ql.parse.ParseContext pctx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TJSONProtocol$JSONBaseContext</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>2</noc>
		<cbo>4</cbo>
		<rfc>5</rfc>
		<lcom>6</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>1.0</lcom3>
		<loc>15</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.5</amc>
		<cc>
			<method name="protected boolean escapeNum()">1</method>
			<method name="protected void write()">1</method>
			<method name="protected void read()">1</method>
			<method name="protected void _init_(org.apache.thrift.protocol.TJSONProtocol)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$tableSpec</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>25</cbo>
		<rfc>54</rfc>
		<lcom>5</lcom>
		<ca>8</ca>
		<ce>17</ce>
		<npm>5</npm>
		<lcom3>0.675</lcom3>
		<loc>394</loc>
		<dam>0.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.43333333333333335</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>63.333333333333336</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.hive.ql.parse.ASTNode ast, boolean allowDynamicPartitionsSpec, boolean allowPartialPartitionsSpec)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void setPartSpec(java.util.Map partSpec)">1</method>
			<method name="public String toString()">2</method>
			<method name="public java.util.Map getPartSpec()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.hive.ql.parse.ASTNode ast)">0</method>
		</cc>
	</class>
	<class>
		<name>org.json.JSONStringer</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>5</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>18</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public String toString()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCovariance$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>70</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>68.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ExprNodeDesc</name>
		<wmc>14</wmc>
		<dit>1</dit>
		<noc>5</noc>
		<cbo>99</cbo>
		<rfc>21</rfc>
		<lcom>69</lcom>
		<ca>95</ca>
		<ce>4</ce>
		<npm>13</npm>
		<lcom3>0.8974358974358974</lcom3>
		<loc>75</loc>
		<dam>0.3333333333333333</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.41025641025641024</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.142857142857143</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public java.util.List getChildren()">1</method>
			<method name="public volatile Object clone()">1</method>
			<method name="public abstract boolean isSame(Object)">1</method>
			<method name="public String getName()">1</method>
			<method name="public String getExprString()">2</method>
			<method name="public abstract org.apache.hadoop.hive.ql.plan.ExprNodeDesc clone()">1</method>
			<method name="public java.util.List getCols()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.typeinfo.TypeInfo getTypeInfo()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getWritableObjectInspector()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo typeInfo)">0</method>
			<method name="public String getTypeString()">1</method>
			<method name="public void setTypeInfo(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo typeInfo)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFConcatWS</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>27</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>14</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>288</loc>
		<dam>0.6666666666666666</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>56.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TStruct</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>23</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>23</ca>
		<ce>0</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>13</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public void _init_(String n)">0</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.BucketMatcher</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>4</rfc>
		<lcom>6</lcom>
		<ca>4</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void setBucketFileNameMapping(java.util.LinkedHashMap)">1</method>
			<method name="public abstract void setAliasBucketFileNameMapping(java.util.LinkedHashMap)">1</method>
			<method name="public abstract java.util.List getAliasBucketFiles(String, String, String)">1</method>
			<method name="public abstract java.util.LinkedHashMap getBucketFileNameMapping()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.async.TAsyncClientManager</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>20</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>5</ce>
		<npm>4</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>66</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.0</amc>
		<cc>
			<method name="static java.util.concurrent.ConcurrentLinkedQueue access$200(org.apache.thrift.async.TAsyncClientManager x0)">1</method>
			<method name="public void stop()">1</method>
			<method name="public boolean isRunning()">1</method>
			<method name="public void call(org.apache.thrift.async.TAsyncMethodCall method)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="static org.slf4j.Logger access$100()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$aliasList_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.SettableLongObjectInspector</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Object set(Object, long)">1</method>
			<method name="public abstract Object create(long)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.SymbolicInputFormat</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>1</noc>
		<cbo>10</cbo>
		<rfc>31</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>151</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>74.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void rework(org.apache.hadoop.hive.conf.HiveConf job, org.apache.hadoop.hive.ql.plan.MapredWork work)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFOPMinus</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>20</rfc>
		<lcom>21</lcom>
		<ca>0</ca>
		<ce>7</ce>
		<npm>7</npm>
		<lcom3>2.0</lcom3>
		<loc>114</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2653061224489796</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.285714285714286</amc>
		<cc>
			<method name="public org.apache.hadoop.io.FloatWritable evaluate(org.apache.hadoop.io.FloatWritable a, org.apache.hadoop.io.FloatWritable b)">3</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.hive.serde2.io.ByteWritable a, org.apache.hadoop.hive.serde2.io.ByteWritable b)">3</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable a, org.apache.hadoop.hive.serde2.io.DoubleWritable b)">3</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.hive.serde2.io.ShortWritable a, org.apache.hadoop.hive.serde2.io.ShortWritable b)">3</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.LongWritable a, org.apache.hadoop.io.LongWritable b)">3</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.IntWritable a, org.apache.hadoop.io.IntWritable b)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFVariance</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>3</noc>
		<cbo>16</cbo>
		<rfc>15</rfc>
		<lcom>3</lcom>
		<ca>5</ca>
		<ce>12</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>80</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>25.333333333333332</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] parameters)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredJavaObject</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>12</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(Object value)">0</method>
			<method name="public Object get()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.UDAFEvaluator</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>5</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void init()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.metrics.MetricsMBeanImpl</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>43</rfc>
		<lcom>13</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>11</npm>
		<lcom3>0.7166666666666666</lcom3>
		<loc>368</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2857142857142857</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>31.90909090909091</amc>
		<cc>
			<method name="public boolean hasKey(String name)">1</method>
			<method name="public javax.management.MBeanInfo getMBeanInfo()">3</method>
			<method name="public javax.management.AttributeList getAttributes(String[] arg0)">2</method>
			<method name="public void _init_()">0</method>
			<method name="public Object get(String name)">1</method>
			<method name="public void setAttribute(javax.management.Attribute attr)">1</method>
			<method name="public javax.management.AttributeList setAttributes(javax.management.AttributeList arg0)">2</method>
			<method name="public Object invoke(String name, Object[] args, String[] signature)">1</method>
			<method name="public void reset()">2</method>
			<method name="public Object getAttribute(String arg0)">1</method>
			<method name="public void put(String name, Object value)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.StandardMapObjectInspector</name>
		<wmc>12</wmc>
		<dit>1</dit>
		<noc>2</noc>
		<cbo>11</cbo>
		<rfc>23</rfc>
		<lcom>56</lcom>
		<ca>8</ca>
		<ce>3</ce>
		<npm>11</npm>
		<lcom3>0.8181818181818182</lcom3>
		<loc>114</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.5277777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.333333333333334</amc>
		<cc>
			<method name="public int getMapSize(Object data)">2</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector mapKeyObjectInspector, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector mapValueObjectInspector)">0</method>
			<method name="public Object create()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getMapKeyObjectInspector()">1</method>
			<method name="public Object remove(Object map, Object key)">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
			<method name="public java.util.Map getMap(Object data)">2</method>
			<method name="public String getTypeName()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getMapValueObjectInspector()">1</method>
			<method name="public Object put(Object map, Object key, Object value)">1</method>
			<method name="public Object clear(Object map)">1</method>
			<method name="public Object getMapValueElement(Object data, Object key)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.io.NonSyncByteArrayOutputStream</name>
		<wmc>10</wmc>
		<dit>3</dit>
		<noc>1</noc>
		<cbo>2</cbo>
		<rfc>16</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>9</npm>
		<lcom3>2.0</lcom3>
		<loc>156</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.68</mfa>
		<cam>0.36</cam>
		<ic>1</ic>
		<cbm>8</cbm>
		<amc>14.6</amc>
		<cc>
			<method name="public byte[] getData()">1</method>
			<method name="public void write(java.io.DataInput in, int length)">1</method>
			<method name="public void write(int b)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void writeTo(java.io.OutputStream out)">1</method>
			<method name="public void write(byte[] b, int off, int len)">7</method>
			<method name="public void _init_(int size)">0</method>
			<method name="public void reset()">1</method>
			<method name="private int enLargeBuffer(int increment)">3</method>
			<method name="public int getLength()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.thrift.test.Complex</name>
		<wmc>67</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>21</cbo>
		<rfc>151</rfc>
		<lcom>1283</lcom>
		<ca>0</ca>
		<ce>21</ce>
		<npm>64</npm>
		<lcom3>0.8295454545454546</lcom3>
		<loc>1795</loc>
		<dam>0.9375</dam>
		<moa>7</moa>
		<mfa>0.0</mfa>
		<cam>0.11363636363636363</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>25.55223880597015</amc>
		<cc>
			<method name="public boolean isSetAString()">2</method>
			<method name="public void setLStringIsSet(boolean value)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.thrift.test.Complex$_Fields fieldForId(int fieldId)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object getFieldValue(org.apache.hadoop.hive.serde2.thrift.test.Complex$_Fields field)">2</method>
			<method name="public void unsetLintString()">1</method>
			<method name="public volatile boolean isSet(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="public int getLintSize()">2</method>
			<method name="public java.util.List getLString()">1</method>
			<method name="public void setAintIsSet(boolean value)">1</method>
			<method name="public void validate()">1</method>
			<method name="public void unsetAint()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setLintIsSet(boolean value)">2</method>
			<method name="public volatile void setFieldValue(org.apache.thrift.TFieldIdEnum x0, Object x1)">1</method>
			<method name="public int getMStringStringSize()">2</method>
			<method name="public void setFieldValue(org.apache.hadoop.hive.serde2.thrift.test.Complex$_Fields field, Object value)">8</method>
			<method name="public volatile int compareTo(Object x0)">1</method>
			<method name="public int compareTo(org.apache.hadoop.hive.serde2.thrift.test.Complex other)">20</method>
			<method name="public boolean isSet(org.apache.hadoop.hive.serde2.thrift.test.Complex$_Fields field)">3</method>
			<method name="public java.util.Iterator getLintStringIterator()">2</method>
			<method name="public int getLStringSize()">2</method>
			<method name="public void addToLint(int elem)">2</method>
			<method name="public void setLintStringIsSet(boolean value)">2</method>
			<method name="public boolean equals(Object that)">3</method>
			<method name="public void unsetLint()">1</method>
			<method name="public void clear()">1</method>
			<method name="public boolean isSetAint()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.thrift.test.Complex deepCopy()">1</method>
			<method name="public volatile org.apache.thrift.TBase deepCopy()">1</method>
			<method name="public volatile Object getFieldValue(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="private void writeObject(java.io.ObjectOutputStream out)">1</method>
			<method name="public boolean equals(org.apache.hadoop.hive.serde2.thrift.test.Complex that)">32</method>
			<method name="public void _init_(int aint, String aString, java.util.List lint, java.util.List lString, java.util.List lintString, java.util.Map mStringString)">0</method>
			<method name="public java.util.List getLintString()">1</method>
			<method name="public void read(org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public void setMStringStringIsSet(boolean value)">2</method>
			<method name="public void write(org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.thrift.test.Complex other)">0</method>
			<method name="public void setMStringString(java.util.Map mStringString)">1</method>
			<method name="public void addToLintString(org.apache.hadoop.hive.serde2.thrift.test.IntString elem)">2</method>
			<method name="public void setLintString(java.util.List lintString)">1</method>
			<method name="public String getAString()">1</method>
			<method name="public String toString()">11</method>
			<method name="public java.util.Iterator getLStringIterator()">2</method>
			<method name="public void unsetLString()">1</method>
			<method name="public void setLString(java.util.List lString)">1</method>
			<method name="public int getLintStringSize()">2</method>
			<method name="public java.util.Iterator getLintIterator()">2</method>
			<method name="public int getAint()">1</method>
			<method name="public void setAint(int aint)">1</method>
			<method name="public void unsetMStringString()">1</method>
			<method name="public void setAString(String aString)">1</method>
			<method name="public void addToLString(String elem)">2</method>
			<method name="public void setLint(java.util.List lint)">1</method>
			<method name="public void setAStringIsSet(boolean value)">2</method>
			<method name="public int hashCode()">1</method>
			<method name="public boolean isSetLint()">2</method>
			<method name="public void unsetAString()">1</method>
			<method name="public boolean isSetLString()">2</method>
			<method name="public void putToMStringString(String key, String val)">2</method>
			<method name="private void readObject(java.io.ObjectInputStream in)">1</method>
			<method name="public boolean isSetLintString()">2</method>
			<method name="public java.util.List getLint()">1</method>
			<method name="public volatile org.apache.thrift.TFieldIdEnum fieldForId(int x0)">1</method>
			<method name="public boolean isSetMStringString()">2</method>
			<method name="public java.util.Map getMStringString()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$ddlStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeFieldValue</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$dropViewStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Client</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>1</noc>
		<cbo>4</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>1.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public abstract org.apache.thrift.transport.TTransport createClientTransport(String, String, String, String, org.apache.thrift.transport.TTransport)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.NullStructSerDe$1</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>9</rfc>
		<lcom>21</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>6</npm>
		<lcom3>1.0</lcom3>
		<loc>30</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.34285714285714286</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.142857142857143</amc>
		<cc>
			<method name="public Object getStructFieldData(Object data, org.apache.hadoop.hive.serde2.objectinspector.StructField fieldRef)">1</method>
			<method name="public java.util.List getStructFieldsDataAsList(Object data)">1</method>
			<method name="public java.util.List getAllStructFieldRefs()">1</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.NullStructSerDe)">0</method>
			<method name="public String getTypeName()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.StructField getStructFieldRef(String fieldName)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ListObjectsEqualComparer$CompareType</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9583333333333334</lcom3>
		<loc>100</loc>
		<dam>0.125</dam>
		<moa>8</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>22.0</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ListObjectsEqualComparer$CompareType valueOf(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ListObjectsEqualComparer$CompareType[] values()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.security.authorization.Privilege$PrivilegeType</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9696969696969697</lcom3>
		<loc>133</loc>
		<dam>0.09090909090909091</dam>
		<moa>11</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>29.5</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.security.authorization.Privilege$PrivilegeType[] values()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.security.authorization.Privilege$PrivilegeType valueOf(String name)">1</method>
			<method name="private void _init_(String, int)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyInteger</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>15</cbo>
		<rfc>25</rfc>
		<lcom>22</lcom>
		<ca>10</ca>
		<ce>7</ce>
		<npm>7</npm>
		<lcom3>2.0</lcom3>
		<loc>270</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.28125</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>32.75</amc>
		<cc>
			<method name="public static void writeUTF8(java.io.OutputStream out, int i)">1</method>
			<method name="public static void writeUTF8NoException(java.io.OutputStream out, int i)">1</method>
			<method name="public static int parseInt(byte[] bytes, int start, int length)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.LazyInteger copy)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyIntObjectInspector oi)">0</method>
			<method name="public static int parseInt(byte[] bytes, int start, int length, int radix)">9</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
			<method name="private static int parse(byte[] bytes, int start, int length, int offset, int radix, boolean negative)">7</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.thrift.test.Complex$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>49</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>47.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.TFieldRequirementType</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>7</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Jetty23Shims</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>5</rfc>
		<lcom>3</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>22</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.7777777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.333333333333333</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public volatile org.apache.hadoop.hive.shims.JettyShims$Server startServer(String x0, int x1)">1</method>
			<method name="public org.apache.hadoop.hive.shims.Jetty23Shims$Server startServer(String listen, int port)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.PrivilegeObjectDesc</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>9</rfc>
		<lcom>10</lcom>
		<ca>5</ca>
		<ce>0</ce>
		<npm>8</npm>
		<lcom3>0.7142857142857143</lcom3>
		<loc>47</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public java.util.HashMap getPartSpec()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(boolean isTable, String object, java.util.HashMap partSpec)">0</method>
			<method name="public void setObject(String object)">1</method>
			<method name="public void setPartSpec(java.util.HashMap partSpec)">1</method>
			<method name="public String getObject()">1</method>
			<method name="public void setTable(boolean isTable)">1</method>
			<method name="public boolean getTable()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$primitiveType_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFnGrams$GenericUDAFnGramEvaluator$NGramAggBuf</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>6</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>56</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>55</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Object get()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TFileTransport$Event</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>8</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>6</npm>
		<lcom3>0.4</lcom3>
		<loc>70</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.166666666666666</amc>
		<cc>
			<method name="public void setAvailable(int sz)">1</method>
			<method name="public int getRemaining()">1</method>
			<method name="public int getSize()">1</method>
			<method name="public void _init_(byte[] buf)">0</method>
			<method name="public byte[] getBuf()">1</method>
			<method name="public int emit(byte[] buf, int offset, int ndesired)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.IndexMetadataChangeWork</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>9</rfc>
		<lcom>10</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>8</npm>
		<lcom3>0.8214285714285714</lcom3>
		<loc>48</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5416666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public String getDbName()">1</method>
			<method name="public java.util.HashMap getPartSpec()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setIndexTbl(String indexTbl)">1</method>
			<method name="public String getIndexTbl()">1</method>
			<method name="public void _init_(java.util.HashMap partSpec, String indexTbl, String dbName)">0</method>
			<method name="public void setPartSpec(java.util.HashMap partSpec)">1</method>
			<method name="public void setDbName(String dbName)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.unionproc.UnionProcContext</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>9</rfc>
		<lcom>0</lcom>
		<ca>10</ca>
		<ce>3</ce>
		<npm>5</npm>
		<lcom3>0.5</lcom3>
		<loc>38</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.45</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.2</amc>
		<cc>
			<method name="public void setUnionParseContext(org.apache.hadoop.hive.ql.exec.UnionOperator u, org.apache.hadoop.hive.ql.optimizer.unionproc.UnionProcContext$UnionParseContext uCtx)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setMapOnlySubq(boolean mapOnlySubq)">1</method>
			<method name="public org.apache.hadoop.hive.ql.optimizer.unionproc.UnionProcContext$UnionParseContext getUnionParseContext(org.apache.hadoop.hive.ql.exec.UnionOperator u)">1</method>
			<method name="public boolean isMapOnlySubq()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.classification.InterfaceStability</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDAFPercentile</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>20</rfc>
		<lcom>10</lcom>
		<ca>2</ca>
		<ce>3</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>142</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.36666666666666664</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>27.4</amc>
		<cc>
			<method name="static void access$200(org.apache.hadoop.hive.ql.udf.UDAFPercentile$State x0, org.apache.hadoop.io.LongWritable x1, long x2)">1</method>
			<method name="private static double getPercentile(java.util.List entriesList, double position)">5</method>
			<method name="private static void increment(org.apache.hadoop.hive.ql.udf.UDAFPercentile$State s, org.apache.hadoop.io.LongWritable o, long i)">3</method>
			<method name="public void _init_()">0</method>
			<method name="static double access$300(java.util.List x0, double x1)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.ppd.OpProcFactory$JoinPPD</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>25</cbo>
		<rfc>82</rfc>
		<lcom>19</lcom>
		<ca>1</ca>
		<ce>25</ce>
		<npm>2</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>611</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.25</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>86.14285714285714</amc>
		<cc>
			<method name="private java.util.Set getQualifiedAliases(org.apache.hadoop.hive.ql.exec.JoinOperator op, org.apache.hadoop.hive.ql.parse.RowResolver rr)">7</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="private org.apache.hadoop.hive.ql.exec.ColumnInfo getColumnInfoFromAST(org.apache.hadoop.hive.ql.parse.ASTNode nd, java.util.Map aliastoRR)">1</method>
			<method name="private void replaceColumnReference(org.apache.hadoop.hive.ql.plan.ExprNodeDesc expr, String oldColumn, String newColumn)">5</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
			<method name="private void applyFilterTransitivity(org.apache.hadoop.hive.ql.exec.JoinOperator nd, org.apache.hadoop.hive.ql.ppd.OpWalkerInfo owi)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFCeil</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>25</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable i)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.unionproc.UnionProcessor</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>20</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>12</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>80</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>39.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext transform(org.apache.hadoop.hive.ql.parse.ParseContext pCtx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.ExplainSemanticAnalyzer</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>24</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>12</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>125</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>40.333333333333336</amc>
		<cc>
			<method name="public java.util.List getResultSchema()">1</method>
			<method name="public void analyzeInternal(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.conf.HiveConf conf)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ppr.ExprProcFactory$ColumnExprProcessor</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>11</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>38</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TMemoryInputTransport</name>
		<wmc>15</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>18</rfc>
		<lcom>75</lcom>
		<ca>4</ca>
		<ce>2</ce>
		<npm>15</npm>
		<lcom3>0.6428571428571429</lcom3>
		<loc>111</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5777777777777777</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.2</amc>
		<cc>
			<method name="public void clear()">1</method>
			<method name="public int getBufferPosition()">1</method>
			<method name="public void consumeBuffer(int len)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void write(byte[] buf, int off, int len)">1</method>
			<method name="public void close()">1</method>
			<method name="public int read(byte[] buf, int off, int len)">1</method>
			<method name="public byte[] getBuffer()">1</method>
			<method name="public boolean isOpen()">1</method>
			<method name="public void reset(byte[] buf, int offset, int length)">1</method>
			<method name="public void open()">1</method>
			<method name="public void reset(byte[] buf)">1</method>
			<method name="public void _init_(byte[] buf)">0</method>
			<method name="public int getBytesRemainingInBuffer()">1</method>
			<method name="public void _init_(byte[] buf, int offset, int length)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.LineageInfo</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>10</rfc>
		<lcom>0</lcom>
		<ca>8</ca>
		<ce>4</ce>
		<npm>4</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>39</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.25</amc>
		<cc>
			<method name="public void putDependency(org.apache.hadoop.hive.ql.hooks.LineageInfo$DataContainer dc, org.apache.hadoop.hive.metastore.api.FieldSchema col, org.apache.hadoop.hive.ql.hooks.LineageInfo$Dependency dep)">1</method>
			<method name="public org.apache.hadoop.hive.ql.hooks.LineageInfo$Dependency getDependency(org.apache.hadoop.hive.ql.hooks.LineageInfo$DataContainer dc, org.apache.hadoop.hive.metastore.api.FieldSchema col)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.Set entrySet()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.TaskResult</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>6</rfc>
		<lcom>2</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>5</npm>
		<lcom3>0.375</lcom3>
		<loc>33</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.2</amc>
		<cc>
			<method name="public int getExitVal()">1</method>
			<method name="public boolean isRunning()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setExitVal(int exitVal)">1</method>
			<method name="public void setRunning(boolean val)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFToBinary</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>17</rfc>
		<lcom>6</lcom>
		<ca>0</ca>
		<ce>14</ce>
		<npm>4</npm>
		<lcom3>0.8333333333333333</lcom3>
		<loc>121</loc>
		<dam>0.6666666666666666</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>22.6</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.BinaryRecordReader</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>13</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>5</npm>
		<lcom3>0.5833333333333334</lcom3>
		<loc>59</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.36</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.2</amc>
		<cc>
			<method name="public void initialize(java.io.InputStream in, org.apache.hadoop.conf.Configuration conf, java.util.Properties tbl)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void close()">1</method>
			<method name="public int next(org.apache.hadoop.io.Writable row)">1</method>
			<method name="public org.apache.hadoop.io.Writable createRow()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$exportStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFEWAHBitmapOr</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>10</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="protected javaewah.EWAHCompressedBitmap bitmapBop(javaewah.EWAHCompressedBitmap bitmap1, javaewah.EWAHCompressedBitmap bitmap2)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tablePropertiesPrefixed_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.TEnum</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>6</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract int getValue()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.RCFileOutputFormat</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>25</rfc>
		<lcom>13</lcom>
		<ca>2</ca>
		<ce>16</ce>
		<npm>5</npm>
		<lcom3>0.6</lcom3>
		<loc>117</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2909090909090909</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.333333333333332</amc>
		<cc>
			<method name="public static int getColumnNumber(org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf jc, org.apache.hadoop.fs.Path finalOutPath, Class valueClass, boolean isCompressed, java.util.Properties tableProperties, org.apache.hadoop.util.Progressable progress)">1</method>
			<method name="public static void setColumnNumber(org.apache.hadoop.conf.Configuration conf, int columnNum)">3</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.mapred.RecordWriter getRecordWriter(org.apache.hadoop.fs.FileSystem ignored, org.apache.hadoop.mapred.JobConf job, String name, org.apache.hadoop.util.Progressable progress)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFAtan</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>10</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.75</lcom3>
		<loc>31</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.666666666666666</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable x)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFLn</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>29</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable a)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFContextNGrams</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>17</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>13</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>294</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>96.66666666666667</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] parameters)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyProcFactory</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>11</rfc>
		<lcom>15</lcom>
		<ca>4</ca>
		<ce>5</ce>
		<npm>3</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>35</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.16666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.857142857142857</amc>
		<cc>
			<method name="static org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyCtx access$000()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyProcFactory$CheckSelectProc canApplyOnSelectOperator()">1</method>
			<method name="private void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyProcFactory$CheckGroupByProc canApplyOnGroupByOperator()">1</method>
			<method name="static org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyCtx access$002(org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyCtx x0)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyProcFactory$CheckFilterProc canApplyOnFilterOperator()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$dropPartitionOperator_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.Node</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>7</rfc>
		<lcom>21</lcom>
		<ca>12</ca>
		<ce>0</ce>
		<npm>7</npm>
		<lcom3>2.0</lcom3>
		<loc>7</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5238095238095238</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.hadoop.hive.serde2.dynamic_type.Node jjtGetChild(int)">1</method>
			<method name="public abstract void jjtSetParent(org.apache.hadoop.hive.serde2.dynamic_type.Node)">1</method>
			<method name="public abstract void jjtOpen()">1</method>
			<method name="public abstract void jjtClose()">1</method>
			<method name="public abstract void jjtAddChild(org.apache.hadoop.hive.serde2.dynamic_type.Node, int)">1</method>
			<method name="public abstract int jjtGetNumChildren()">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.dynamic_type.Node jjtGetParent()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyUtils</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>32</cbo>
		<rfc>63</rfc>
		<lcom>43</lcom>
		<ca>11</ca>
		<ce>23</ce>
		<npm>7</npm>
		<lcom3>0.8888888888888888</lcom3>
		<loc>553</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.24074074074074073</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>54.1</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="private static void writeEscaped(java.io.OutputStream out, byte[] bytes, int start, int len, boolean escaped, byte escapeChar, boolean[] needsEscape)">1</method>
			<method name="public static int compare(byte[] b1, int start1, int length1, byte[] b2, int start2, int length2)">6</method>
			<method name="public static void extractColumnInfo(java.util.Properties tbl, org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe$SerDeParameters serdeParams, String serdeName)">1</method>
			<method name="public static String convertToString(byte[] bytes, int start, int length)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static void writePrimitiveUTF8(java.io.OutputStream out, Object o, org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector oi, boolean escaped, byte escapeChar, boolean[] needsEscape)">1</method>
			<method name="public static int hashBytes(byte[] data, int start, int len)">2</method>
			<method name="public static void writePrimitive(java.io.OutputStream out, Object o, org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector oi)">1</method>
			<method name="public static int digit(int b, int radix)">8</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TSaslClientTransport</name>
		<wmc>14</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>35</rfc>
		<lcom>83</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>11</npm>
		<lcom3>0.8846153846153846</lcom3>
		<loc>125</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.22115384615384615</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.785714285714286</amc>
		<cc>
			<method name="public volatile boolean isOpen()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public volatile void flush()">1</method>
			<method name="public volatile javax.security.sasl.SaslServer getSaslServer()">1</method>
			<method name="public void _init_(String mechanism, String authorizationId, String protocol, String serverName, java.util.Map props, javax.security.auth.callback.CallbackHandler cbh, org.apache.thrift.transport.TTransport transport)">0</method>
			<method name="protected void handleSaslStartMessage()">1</method>
			<method name="public volatile int read(byte[] x0, int x1, int x2)">1</method>
			<method name="protected org.apache.thrift.transport.TSaslTransport$SaslRole getRole()">1</method>
			<method name="public volatile org.apache.thrift.transport.TTransport getUnderlyingTransport()">1</method>
			<method name="public volatile javax.security.sasl.SaslClient getSaslClient()">1</method>
			<method name="public volatile void open()">1</method>
			<method name="public volatile void write(byte[] x0, int x1, int x2)">1</method>
			<method name="public void _init_(javax.security.sasl.SaslClient saslClient, org.apache.thrift.transport.TTransport transport)">0</method>
			<method name="public volatile void close()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.stats.ClientStatsPublisher</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void run(java.util.Map, String)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>1</noc>
		<cbo>5</cbo>
		<rfc>5</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>3</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>16</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.333333333333333</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server createServer(String keytabFile, String principalConf)">1</method>
			<method name="public org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Client createClient()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.stats.StatsPublisher</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>4</rfc>
		<lcom>6</lcom>
		<ca>6</ca>
		<ce>1</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract boolean closeConnection()">1</method>
			<method name="public abstract boolean publishStat(String, java.util.Map)">1</method>
			<method name="public abstract boolean init(org.apache.hadoop.conf.Configuration)">1</method>
			<method name="public abstract boolean connect(org.apache.hadoop.conf.Configuration)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.LocalMapJoinProcFactory</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>8</rfc>
		<lcom>6</lcom>
		<ca>2</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>19</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.25</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.75</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getDefaultProc()">1</method>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getGroupByProc()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getJoinProc()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCollectSet$GenericUDAFMkSetEvaluator</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>29</rfc>
		<lcom>39</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>8</npm>
		<lcom3>0.8611111111111112</lcom3>
		<loc>197</loc>
		<dam>0.75</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.31746031746031744</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.3</amc>
		<cc>
			<method name="private void putIntoSet(Object p, org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCollectSet$GenericUDAFMkSetEvaluator$MkArrayAggregationBuffer myagg)">2</method>
			<method name="public void iterate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object[] parameters)">1</method>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector init(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode m, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] parameters)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer getNewAggregationBuffer()">1</method>
			<method name="public void merge(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object partial)">1</method>
			<method name="public Object terminatePartial(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void reset(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.GrantRevokeRoleDDL</name>
		<wmc>14</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>15</rfc>
		<lcom>55</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>14</npm>
		<lcom3>0.8461538461538461</lcom3>
		<loc>86</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.34285714285714286</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.714285714285714</amc>
		<cc>
			<method name="public java.util.List getRoles()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(boolean grant, java.util.List roles, java.util.List principalDesc, String grantor, org.apache.hadoop.hive.metastore.api.PrincipalType grantorType, boolean grantOption)">0</method>
			<method name="public void setPrincipalDesc(java.util.List principalDesc)">1</method>
			<method name="public void setGrantor(String grantor)">1</method>
			<method name="public boolean isGrantOption()">1</method>
			<method name="public org.apache.hadoop.hive.metastore.api.PrincipalType getGrantorType()">1</method>
			<method name="public void setRoles(java.util.List roles)">1</method>
			<method name="public void setGrantorType(org.apache.hadoop.hive.metastore.api.PrincipalType grantorType)">1</method>
			<method name="public java.util.List getPrincipalDesc()">1</method>
			<method name="public void setGrant(boolean grant)">1</method>
			<method name="public void setGrantOption(boolean grantOption)">1</method>
			<method name="public String getGrantor()">1</method>
			<method name="public boolean getGrant()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.MapObjectInspector</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>24</cbo>
		<rfc>5</rfc>
		<lcom>10</lcom>
		<ca>23</ca>
		<ce>1</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract int getMapSize(Object)">1</method>
			<method name="public abstract java.util.Map getMap(Object)">1</method>
			<method name="public abstract Object getMapValueElement(Object, Object)">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getMapKeyObjectInspector()">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getMapValueObjectInspector()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>112</cbo>
		<rfc>50</rfc>
		<lcom>11</lcom>
		<ca>64</ca>
		<ce>48</ce>
		<npm>4</npm>
		<lcom3>0.9666666666666666</lcom3>
		<loc>403</loc>
		<dam>0.08333333333333333</dam>
		<moa>22</moa>
		<mfa>0.0</mfa>
		<cam>0.3</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>62.166666666666664</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector getPrimitiveObjectInspectorFromClass(Class c)">4</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ConstantObjectInspector getPrimitiveWritableConstantObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector$PrimitiveCategory primitiveCategory, Object value)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.primitive.AbstractPrimitiveWritableObjectInspector getPrimitiveWritableObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector$PrimitiveCategory primitiveCategory)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.primitive.AbstractPrimitiveJavaObjectInspector getPrimitiveJavaObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector$PrimitiveCategory primitiveCategory)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$selectStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.io.HiveIOExceptionHandler</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void handleRecorReaderNextException(Exception, org.apache.hadoop.hive.io.HiveIOExceptionNextHandleResult)">1</method>
			<method name="public abstract org.apache.hadoop.mapred.RecordReader handleRecordReaderCreationException(Exception)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazydio.LazyDioByte</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>12</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>3</npm>
		<lcom3>1.0</lcom3>
		<loc>83</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazydio.LazyDioByte copy)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyByteObjectInspector oi)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.AbstractPrimitiveJavaObjectInspector</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>11</noc>
		<cbo>23</cbo>
		<rfc>5</rfc>
		<lcom>6</lcom>
		<ca>21</ca>
		<ce>2</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>14</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.5</amc>
		<cc>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils$PrimitiveTypeEntry typeEntry)">0</method>
			<method name="public boolean preferWritable()">1</method>
			<method name="public Object getPrimitiveJavaObject(Object o)">1</method>
			<method name="public Object copyObject(Object o)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>10</rfc>
		<lcom>32</lcom>
		<ca>3</ca>
		<ce>7</ce>
		<npm>8</npm>
		<lcom3>0.875</lcom3>
		<loc>68</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4722222222222222</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.333333333333333</amc>
		<cc>
			<method name="public volatile org.apache.hadoop.io.Writable getPrimitiveWritableObject(Object x0)">1</method>
			<method name="void _init_(boolean escaped, byte escapeChar)">0</method>
			<method name="public volatile Object getPrimitiveJavaObject(Object x0)">1</method>
			<method name="public volatile Object getPrimitiveWritableObject(Object x0)">1</method>
			<method name="public org.apache.hadoop.io.Text getPrimitiveWritableObject(Object o)">2</method>
			<method name="public byte getEscapeChar()">1</method>
			<method name="public boolean isEscaped()">1</method>
			<method name="public String getPrimitiveJavaObject(Object o)">2</method>
			<method name="public Object copyObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.DescDatabaseDesc</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>11</rfc>
		<lcom>18</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>9</npm>
		<lcom3>0.9</lcom3>
		<loc>53</loc>
		<dam>0.4</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3888888888888889</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.333333333333333</amc>
		<cc>
			<method name="public void setDatabaseName(String db)">1</method>
			<method name="public void _init_(org.apache.hadoop.fs.Path resFile, String dbName, boolean isExt)">0</method>
			<method name="public String getResFile()">1</method>
			<method name="public void setResFile(String resFile)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public String getDatabaseName()">1</method>
			<method name="public boolean isExt()">1</method>
			<method name="public void setExt(boolean isExt)">1</method>
			<method name="public static String getSchema()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tableRowFormatFieldIdentifier_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.processors.AddResourceProcessor</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>23</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>3</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>104</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>24.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.processors.CommandProcessorResponse run(String command)">5</method>
			<method name="public void init()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDAFPercentile$MyComparator</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>6</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>20</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.666666666666667</amc>
		<cc>
			<method name="public volatile int compare(Object x0, Object x1)">1</method>
			<method name="public int compare(java.util.Map$Entry o1, java.util.Map$Entry o2)">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFSign</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>9</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.75</lcom3>
		<loc>49</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.666666666666666</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable a)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.ByteArrayRef</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>51</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>51</ca>
		<ce>0</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>14</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.3333333333333335</amc>
		<cc>
			<method name="public byte[] getData()">1</method>
			<method name="public void setData(byte[] data)">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.DummyPartition</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>22</rfc>
		<lcom>18</lcom>
		<ca>6</ca>
		<ce>6</ce>
		<npm>8</npm>
		<lcom3>0.75</lcom3>
		<loc>83</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.888888888888889</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Table tbl, String name, java.util.Map partSpec)">0</method>
			<method name="public java.util.List getValues()">2</method>
			<method name="public java.util.LinkedHashMap getSpec()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public String getCompleteName()">1</method>
			<method name="public void setName(String name)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Table tbl, String name)">0</method>
			<method name="public String getName()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>37</cbo>
		<rfc>72</rfc>
		<lcom>18</lcom>
		<ca>0</ca>
		<ce>37</ce>
		<npm>8</npm>
		<lcom3>0.90625</lcom3>
		<loc>395</loc>
		<dam>0.5833333333333334</dam>
		<moa>7</moa>
		<mfa>0.0</mfa>
		<cam>0.23214285714285715</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>41.55555555555556</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getObjectInspector()">1</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector dynamicSerDeStructBaseToObjectInspector(org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeBase bt)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Class getSerializedClass()">1</method>
			<method name="public org.apache.hadoop.io.Writable serialize(Object obj, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objInspector)">1</method>
			<method name="public void initialize(org.apache.hadoop.conf.Configuration job, java.util.Properties tbl)">1</method>
			<method name="public Object deserialize(org.apache.hadoop.io.Writable field)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.SerDeStats getSerDeStats()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.Driver</name>
		<wmc>36</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>105</cbo>
		<rfc>339</rfc>
		<lcom>320</lcom>
		<ca>6</ca>
		<ce>99</ce>
		<npm>27</npm>
		<lcom3>0.8464285714285714</lcom3>
		<loc>3682</loc>
		<dam>0.875</dam>
		<moa>6</moa>
		<mfa>0.0</mfa>
		<cam>0.09841269841269841</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>100.83333333333333</amc>
		<cc>
			<method name="public int acquireReadWriteLocks()">11</method>
			<method name="private java.util.List getHooks(org.apache.hadoop.hive.conf.HiveConf$ConfVars hookConfVar)">1</method>
			<method name="private void releaseLocks(java.util.List hiveLocks)">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void taskCleanup()">1</method>
			<method name="public org.apache.hadoop.hive.metastore.api.Schema getThriftSchema()">1</method>
			<method name="public org.apache.hadoop.mapred.ClusterStatus getClusterStatus()">1</method>
			<method name="private java.util.List getLockObjects(org.apache.hadoop.hive.ql.metadata.Table t, org.apache.hadoop.hive.ql.metadata.Partition p, org.apache.hadoop.hive.ql.lockmgr.HiveLockMode mode)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.conf.HiveConf conf)">0</method>
			<method name="public boolean hasReduceTasks(java.util.List tasks)">6</method>
			<method name="public void saveSession(org.apache.hadoop.hive.ql.Driver$QueryState qs)">3</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.Query getQueryPlan()">1</method>
			<method name="public int getTryCount()">1</method>
			<method name="public boolean getResults(java.util.ArrayList res)">1</method>
			<method name="private void setLockManager()">1</method>
			<method name="public void restoreSession(org.apache.hadoop.hive.ql.Driver$QueryState qs)">4</method>
			<method name="private boolean checkLockManager()">4</method>
			<method name="public org.apache.hadoop.hive.ql.processors.CommandProcessorResponse run(String command)">1</method>
			<method name="public void _init_()">0</method>
			<method name="private java.util.List getHooks(org.apache.hadoop.hive.conf.HiveConf$ConfVars hookConfVar, Class clazz)">1</method>
			<method name="public org.apache.hadoop.hive.ql.QueryPlan getPlan()">1</method>
			<method name="public void launchTask(org.apache.hadoop.hive.ql.exec.Task tsk, String queryId, boolean noName, java.util.Map running, String jobname, int jobs, org.apache.hadoop.hive.ql.DriverContext cxt)">7</method>
			<method name="private void releaseLocks()">3</method>
			<method name="public void destroy()">1</method>
			<method name="private void doAuthorization(org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer sem)">1</method>
			<method name="public void init()">1</method>
			<method name="public int execute()">1</method>
			<method name="public int close()">4</method>
			<method name="public org.apache.hadoop.hive.metastore.api.Schema getSchema()">1</method>
			<method name="public static org.apache.hadoop.hive.metastore.api.Schema getSchema(org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer sem, org.apache.hadoop.hive.conf.HiveConf conf)">11</method>
			<method name="public int compile(String command)">1</method>
			<method name="public int getMaxRows()">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.TaskResult pollTasks(java.util.Set results)">2</method>
			<method name="public void setMaxRows(int maxRows)">1</method>
			<method name="public int compile(String command, boolean resetTaskIds)">9</method>
			<method name="public void setTryCount(int tryCount)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$indexPropertiesList_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.pcr.PcrOpProcFactory</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>9</rfc>
		<lcom>8</lcom>
		<ca>2</ca>
		<ce>5</ce>
		<npm>2</npm>
		<lcom3>0.75</lcom3>
		<loc>23</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.25</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.4</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getDefaultProc()">1</method>
			<method name="private void _init_()">0</method>
			<method name="static org.apache.commons.logging.Log access$000()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getFilterProc()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.FullMapEqualComparer</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>13</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>107</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>52.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public int compare(Object o1, org.apache.hadoop.hive.serde2.objectinspector.MapObjectInspector moi1, Object o2, org.apache.hadoop.hive.serde2.objectinspector.MapObjectInspector moi2)">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.ppd.OpProcFactory$FilterPPD</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>31</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>18</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>132</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>65.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.SequenceFileInputFormatChecker</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>9</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>8</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>52</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>25.0</amc>
		<cc>
			<method name="public boolean validateInput(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.hive.conf.HiveConf conf, java.util.ArrayList files)">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ColumnPruner$ColumnPrunerWalker</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>16</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>80</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>39.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.lib.Dispatcher disp)">0</method>
			<method name="public void walk(org.apache.hadoop.hive.ql.lib.Node nd)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lib.PreOrderWalker</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>10</rfc>
		<lcom>1</lcom>
		<ca>4</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>39</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.lib.Dispatcher disp)">0</method>
			<method name="public void walk(org.apache.hadoop.hive.ql.lib.Node nd)">1</method>
		</cc>
	</class>
	<class>
		<name>javaewah.RunningLengthWord</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>16</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>0</ce>
		<npm>8</npm>
		<lcom3>0.9</lcom3>
		<loc>156</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3111111111111111</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.222222222222221</amc>
		<cc>
			<method name="public int getNumberOfLiteralWords()">1</method>
			<method name="public long size()">1</method>
			<method name="public void setRunningLength(long number)">1</method>
			<method name="public boolean getRunningBit()">2</method>
			<method name="public void setRunningBit(boolean b)">2</method>
			<method name="void _init_(long[] a, int p)">0</method>
			<method name="public long getRunningLength()">1</method>
			<method name="public String toString()">1</method>
			<method name="public void setNumberOfLiteralWords(long number)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.DDLTask</name>
		<wmc>62</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>127</cbo>
		<rfc>672</rfc>
		<lcom>979</lcom>
		<ca>1</ca>
		<ce>127</ce>
		<npm>7</npm>
		<lcom3>0.8868852459016394</lcom3>
		<loc>8947</loc>
		<dam>0.8</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.05196412001237241</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>143.1451612903226</amc>
		<cc>
			<method name="private void setUnArchived(org.apache.hadoop.hive.ql.metadata.Partition p)">5</method>
			<method name="private int grantOrRevokePrivileges(java.util.List principals, java.util.List privileges, org.apache.hadoop.hive.ql.plan.PrivilegeObjectDesc privSubjectDesc, String grantor, org.apache.hadoop.hive.metastore.api.PrincipalType grantorType, boolean grantOption, boolean isGrant)">29</method>
			<method name="static void _clinit_()">0</method>
			<method name="private int createTable(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.CreateTableDesc crtTbl)">1</method>
			<method name="private int lockTable(org.apache.hadoop.hive.ql.plan.LockTableDesc lockTbl)">1</method>
			<method name="private int alterIndex(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.AlterIndexDesc alterIndex)">1</method>
			<method name="private int archive(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.AlterTableSimpleDesc simpleDesc, org.apache.hadoop.hive.ql.DriverContext driverContext)">1</method>
			<method name="private int mergeFiles(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.parse.AlterTablePartMergeFilesDesc mergeFilesDesc)">1</method>
			<method name="private int descDatabase(org.apache.hadoop.hive.ql.plan.DescDatabaseDesc descDatabase)">1</method>
			<method name="private int setGenericTableAttributes(org.apache.hadoop.hive.ql.metadata.Table tbl)">1</method>
			<method name="private void moveDir(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path from, org.apache.hadoop.fs.Path to)">1</method>
			<method name="private int showIndexes(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.ShowIndexesDesc showIndexes)">1</method>
			<method name="private int unlockTable(org.apache.hadoop.hive.ql.plan.UnlockTableDesc unlockTbl)">1</method>
			<method name="private int showDatabases(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.ShowDatabasesDesc showDatabasesDesc)">1</method>
			<method name="private int createIndex(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.CreateIndexDesc crtIndex)">1</method>
			<method name="boolean partitionInCustomLocation(org.apache.hadoop.hive.ql.metadata.Table tbl, org.apache.hadoop.hive.ql.metadata.Partition p)">1</method>
			<method name="public int execute(org.apache.hadoop.hive.ql.DriverContext driverContext)">38</method>
			<method name="public void _init_()">0</method>
			<method name="private int touch(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.AlterTableSimpleDesc touchDesc)">1</method>
			<method name="private int dropTable(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.DropTableDesc dropTbl)">1</method>
			<method name="private int showPartitions(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.ShowPartitionsDesc showParts)">1</method>
			<method name="private int describeTable(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.DescTableDesc descTbl)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.StageType getType()">1</method>
			<method name="private int showTables(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.ShowTablesDesc showTbls)">1</method>
			<method name="private int alterDatabase(org.apache.hadoop.hive.ql.plan.AlterDatabaseDesc alterDbDesc)">1</method>
			<method name="private boolean writeMsckResult(java.util.List result, String msg, java.io.Writer out, boolean wrote)">1</method>
			<method name="private int dropDatabase(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.DropDatabaseDesc dropDb)">1</method>
			<method name="private int showFunctions(org.apache.hadoop.hive.ql.plan.ShowFunctionsDesc showFuncs)">1</method>
			<method name="private int createView(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.CreateViewDesc crtView)">1</method>
			<method name="private boolean pathExists(org.apache.hadoop.fs.Path p)">1</method>
			<method name="private int describeFunction(org.apache.hadoop.hive.ql.plan.DescFunctionDesc descFunc)">1</method>
			<method name="private int alterTable(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.AlterTableDesc alterTbl)">1</method>
			<method name="private static void writeKeyValuePair(java.io.DataOutput outStream, String key, String value)">1</method>
			<method name="private int createDatabase(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.CreateDatabaseDesc crtDb)">1</method>
			<method name="private void setOriginalLocation(org.apache.hadoop.hive.ql.metadata.Partition p, String loc)">2</method>
			<method name="private void setIsArchived(org.apache.hadoop.hive.ql.metadata.Partition p, boolean state, int level)">2</method>
			<method name="private void setArchived(org.apache.hadoop.hive.ql.metadata.Partition p, org.apache.hadoop.fs.Path harPath, int level)">3</method>
			<method name="private int addPartition(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.AddPartitionDesc addPartitionDesc)">1</method>
			<method name="public String getName()">1</method>
			<method name="private int showGrants(org.apache.hadoop.hive.ql.plan.ShowGrantDesc showGrantDesc)">1</method>
			<method name="public void initialize(org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.hive.ql.QueryPlan queryPlan, org.apache.hadoop.hive.ql.DriverContext ctx)">2</method>
			<method name="public boolean requireLock()">3</method>
			<method name="private int msck(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.MsckDesc msckDesc)">22</method>
			<method name="private int unarchive(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.AlterTableSimpleDesc simpleDesc)">1</method>
			<method name="private int dropIndex(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.DropIndexDesc dropIdx)">1</method>
			<method name="private void validateAlterTableType(org.apache.hadoop.hive.ql.metadata.Table tbl, org.apache.hadoop.hive.ql.plan.AlterTableDesc$AlterTableTypes alterType)">1</method>
			<method name="private org.apache.hadoop.hive.ql.lockmgr.HiveLockObject getHiveObject(String tabName, java.util.Map partSpec)">1</method>
			<method name="private int showLocks(org.apache.hadoop.hive.ql.plan.ShowLocksDesc showLocks)">1</method>
			<method name="private void validateAlterTableType(org.apache.hadoop.hive.ql.metadata.Table tbl, org.apache.hadoop.hive.ql.plan.AlterTableDesc$AlterTableTypes alterType, boolean expectView)">1</method>
			<method name="private int switchDatabase(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.SwitchDatabaseDesc switchDb)">1</method>
			<method name="private int createTableLike(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.CreateTableLikeDesc crtTbl)">1</method>
			<method name="private void deleteDir(org.apache.hadoop.fs.Path dir)">1</method>
			<method name="private int grantOrRevokeRole(org.apache.hadoop.hive.ql.plan.GrantRevokeRoleDDL grantOrRevokeRoleDDL)">1</method>
			<method name="public static void writeGrantInfo(java.io.DataOutput outStream, org.apache.hadoop.hive.metastore.api.PrincipalType principalType, String principalName, String dbName, String tableName, String partName, String columnName, org.apache.hadoop.hive.metastore.api.PrivilegeGrantInfo grantInfo)">1</method>
			<method name="private String getOriginalLocation(org.apache.hadoop.hive.ql.metadata.Partition p)">1</method>
			<method name="private int showTableStatus(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.ShowTableStatusDesc showTblStatus)">1</method>
			<method name="protected void localizeMRTmpFilesImpl(org.apache.hadoop.hive.ql.Context ctx)">1</method>
			<method name="private int renamePartition(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.plan.RenamePartitionDesc renamePartitionDesc)">1</method>
			<method name="private void checkArchiveProperty(int partSpecLevel, boolean recovery, org.apache.hadoop.hive.ql.metadata.Partition p)">1</method>
			<method name="private int roleDDL(org.apache.hadoop.hive.ql.plan.RoleDDLDesc roleDDLDesc)">5</method>
			<method name="private void validateSerDe(String serdeName)">1</method>
			<method name="private boolean updateModifiedParameters(java.util.Map params, org.apache.hadoop.hive.conf.HiveConf conf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFAverage$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>70</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>68.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.unionproc.UnionProcFactory</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>21</rfc>
		<lcom>26</lcom>
		<ca>6</ca>
		<ce>8</ce>
		<npm>6</npm>
		<lcom3>0.8571428571428571</lcom3>
		<loc>87</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.14285714285714285</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.75</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getUnknownUnion()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getMapUnion()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getMapJoinUnion()">1</method>
			<method name="public static int getPositionParent(org.apache.hadoop.hive.ql.exec.UnionOperator union, java.util.Stack stack)">6</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getMapRedUnion()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getNoUnion()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles$ConditionalResolverMergeFilesCtx</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>9</rfc>
		<lcom>14</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>8</npm>
		<lcom3>0.8571428571428571</lcom3>
		<loc>45</loc>
		<dam>0.75</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.40625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.125</amc>
		<cc>
			<method name="public java.util.List getListTasks()">1</method>
			<method name="public void setDPCtx(org.apache.hadoop.hive.ql.plan.DynamicPartitionCtx dp)">1</method>
			<method name="public void setDir(String dir)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.DynamicPartitionCtx getDPCtx()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public String getDir()">1</method>
			<method name="public void setListTasks(java.util.List listTasks)">1</method>
			<method name="public void _init_(java.util.List listTasks, String dir)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.DropTableDesc</name>
		<wmc>11</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>16</rfc>
		<lcom>17</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>11</npm>
		<lcom3>0.8</lcom3>
		<loc>93</loc>
		<dam>0.2</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.36363636363636365</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public void setIfExists(boolean ifExists)">1</method>
			<method name="public java.util.ArrayList getPartSpecs()">1</method>
			<method name="public boolean getIfExists()">1</method>
			<method name="public String getTableName()">1</method>
			<method name="public void _init_(String tableName, boolean expectView, boolean ifExists)">0</method>
			<method name="public void _init_()">0</method>
			<method name="public void setPartSpecs(java.util.ArrayList partSpecs)">1</method>
			<method name="public void _init_(String tableName, java.util.List partSpecs, boolean expectView)">0</method>
			<method name="public void setExpectView(boolean expectView)">1</method>
			<method name="public void setTableName(String tableName)">1</method>
			<method name="public boolean getExpectView()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.FilterDesc$sampleDesc</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>6</rfc>
		<lcom>4</lcom>
		<ca>5</ca>
		<ce>0</ce>
		<npm>5</npm>
		<lcom3>0.75</lcom3>
		<loc>32</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.8</amc>
		<cc>
			<method name="public boolean getInputPruning()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public int getNumerator()">1</method>
			<method name="public int getDenominator()">1</method>
			<method name="public void _init_(int numerator, int denominator, java.util.List tabBucketCols, boolean inputPruning)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterProtectMode_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeConst</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TProtocolException</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>13</rfc>
		<lcom>0</lcom>
		<ca>5</ca>
		<ce>1</ce>
		<npm>9</npm>
		<lcom3>0.984375</lcom3>
		<loc>88</loc>
		<dam>0.25</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.888888888888889</amc>
		<cc>
			<method name="public void _init_(int type)">0</method>
			<method name="public void _init_(int type, String message)">0</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(Throwable cause)">0</method>
			<method name="public void _init_(int type, String message, Throwable cause)">0</method>
			<method name="public void _init_(int type, Throwable cause)">0</method>
			<method name="public int getType()">1</method>
			<method name="public void _init_(String message, Throwable cause)">0</method>
			<method name="public void _init_(String message)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.columnar.ColumnarSerDeBase</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>2</noc>
		<cbo>11</cbo>
		<rfc>24</rfc>
		<lcom>11</lcom>
		<ca>2</ca>
		<ce>9</ce>
		<npm>5</npm>
		<lcom3>0.85</lcom3>
		<loc>146</loc>
		<dam>0.5</dam>
		<moa>6</moa>
		<mfa>0.0</mfa>
		<cam>0.4444444444444444</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.428571428571427</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getObjectInspector()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object deserialize(org.apache.hadoop.io.Writable blob)">1</method>
			<method name="public Class getSerializedClass()">1</method>
			<method name="protected void initialize(int size)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.SerDeStats getSerDeStats()">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.DelegationTokenSelector</name>
		<wmc>1</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter$DoubleConverter</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>36</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector inputOI, org.apache.hadoop.hive.serde2.objectinspector.primitive.SettableDoubleObjectInspector outputOI)">0</method>
			<method name="public Object convert(Object input)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.ppd.OpProcFactory$UDTFPPD</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>9</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>26</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$principalSpecification_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.async.AsyncMethodCallback</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void onComplete(Object)">1</method>
			<method name="public abstract void onError(Exception)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFType</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>3</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract boolean deterministic()">1</method>
			<method name="public abstract boolean distinctLike()">1</method>
			<method name="public abstract boolean stateful()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.DDLDesc</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>30</noc>
		<cbo>30</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>30</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TTransportFactory</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>6</noc>
		<cbo>16</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>15</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>7</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.thrift.transport.TTransport getTransport(org.apache.thrift.transport.TTransport trans)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFLTrim</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>25</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.0</amc>
		<cc>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text s)">2</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.AbstractGenericUDAFResolver</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>12</noc>
		<cbo>17</cbo>
		<rfc>7</rfc>
		<lcom>3</lcom>
		<ca>12</ca>
		<ce>5</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>24</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] info)">1</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFParameterInfo info)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.processors.CommandProcessor</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>6</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.hadoop.hive.ql.processors.CommandProcessorResponse run(String)">1</method>
			<method name="public abstract void init()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.CheckResult$PartitionResult</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>13</rfc>
		<lcom>6</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>8</npm>
		<lcom3>0.42857142857142855</lcom3>
		<loc>61</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.375</amc>
		<cc>
			<method name="public volatile int compareTo(Object x0)">1</method>
			<method name="public String getPartitionName()">1</method>
			<method name="public String getTableName()">1</method>
			<method name="public int compareTo(org.apache.hadoop.hive.ql.metadata.CheckResult$PartitionResult o)">2</method>
			<method name="public void _init_()">0</method>
			<method name="public void setTableName(String tableName)">1</method>
			<method name="public String toString()">1</method>
			<method name="public void setPartitionName(String partitionName)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryUtils$RecordInfo</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>0</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>30</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public String toString()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableDoubleObjectInspector</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>19</cbo>
		<rfc>11</rfc>
		<lcom>15</lcom>
		<ca>14</ca>
		<ce>5</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>45</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.5</amc>
		<cc>
			<method name="public double get(Object o)">1</method>
			<method name="void _init_()">0</method>
			<method name="public Object set(Object o, double value)">1</method>
			<method name="public Object create(double value)">1</method>
			<method name="public Object getPrimitiveJavaObject(Object o)">2</method>
			<method name="public Object copyObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ConditionalTask</name>
		<wmc>17</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>19</cbo>
		<rfc>43</rfc>
		<lcom>98</lcom>
		<ca>10</ca>
		<ce>10</ce>
		<npm>16</npm>
		<lcom3>0.8541666666666666</lcom3>
		<loc>281</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.16993464052287582</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.176470588235293</amc>
		<cc>
			<method name="public int execute(org.apache.hadoop.hive.ql.DriverContext driverContext)">4</method>
			<method name="public void _init_()">0</method>
			<method name="protected void localizeMRTmpFilesImpl(org.apache.hadoop.hive.ql.Context ctx)">3</method>
			<method name="public Object getResolverCtx()">1</method>
			<method name="public java.util.List getDependentTasks()">1</method>
			<method name="public String getName()">1</method>
			<method name="public boolean isMapRedTask()">2</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.StageType getType()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ConditionalResolver getResolver()">1</method>
			<method name="public void initialize(org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.hive.ql.QueryPlan queryPlan, org.apache.hadoop.hive.ql.DriverContext driverContext)">1</method>
			<method name="public java.util.List getListTasks()">1</method>
			<method name="public boolean hasReduce()">2</method>
			<method name="public void setResolverCtx(Object resolverCtx)">1</method>
			<method name="public boolean addDependentTask(org.apache.hadoop.hive.ql.exec.Task dependent)">3</method>
			<method name="public void setListTasks(java.util.List listTasks)">1</method>
			<method name="public boolean done()">11</method>
			<method name="public void setResolver(org.apache.hadoop.hive.ql.plan.ConditionalResolver resolver)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ProtocolBuffersStructObjectInspector</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.5</amc>
		<cc>
			<method name="public boolean shouldIgnoreField(String name)">1</method>
			<method name="void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter$ByteConverter</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>36</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector inputOI, org.apache.hadoop.hive.serde2.objectinspector.primitive.SettableByteObjectInspector outputOI)">0</method>
			<method name="public Object convert(Object input)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Utilities$3</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>14</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>11</ce>
		<npm>1</npm>
		<lcom3>0.0</lcom3>
		<loc>84</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5714285714285714</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>38.0</amc>
		<cc>
			<method name="public void run()">2</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.plan.PartitionDesc, org.apache.hadoop.mapred.JobConf, org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, java.util.Map, String)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.StandardListObjectInspector</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>2</noc>
		<cbo>26</cbo>
		<rfc>22</rfc>
		<lcom>39</lcom>
		<ca>23</ca>
		<ce>3</ce>
		<npm>9</npm>
		<lcom3>0.7777777777777778</lcom3>
		<loc>176</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.5</amc>
		<cc>
			<method name="public Object getListElement(Object data, int index)">8</method>
			<method name="public Object set(Object list, int index, Object element)">1</method>
			<method name="public Object resize(Object list, int newSize)">3</method>
			<method name="public int getListLength(Object data)">4</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector listElementObjectInspector)">0</method>
			<method name="public final org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
			<method name="public java.util.List getList(Object data)">3</method>
			<method name="public String getTypeName()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getListElementObjectInspector()">1</method>
			<method name="public Object create(int size)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.lineage.OpProcFactory$JoinLineage</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>26</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>18</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>95</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>30.333333333333332</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Utilities$1</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>15</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.5</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public void exceptionThrown(Exception e)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>33</cbo>
		<rfc>10</rfc>
		<lcom>0</lcom>
		<ca>27</ca>
		<ce>6</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>71</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.5714285714285714</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>33.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.lib.NodeProcessor defaultProc, java.util.Map rules, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx)">0</method>
			<method name="public transient Object dispatch(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack ndStack, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Utilities$2</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>0.0</lcom3>
		<loc>17</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public void interrupt()">2</method>
			<method name="void _init_(java.util.concurrent.ThreadPoolExecutor)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.UnionDesc</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>5</ca>
		<ce>0</ce>
		<npm>3</npm>
		<lcom3>0.75</lcom3>
		<loc>18</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.333333333333333</amc>
		<cc>
			<method name="public int getNumInputs()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setNumInputs(int numInputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$AnalyzeCreateCommonVars</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>18</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.0</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.AlterTablePartMergeFilesDesc</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>11</rfc>
		<lcom>12</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>9</npm>
		<lcom3>0.75</lcom3>
		<loc>58</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4166666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public void setOutputDir(String outputDir)">1</method>
			<method name="public java.util.HashMap getPartSpec()">1</method>
			<method name="public String getTableName()">1</method>
			<method name="public java.util.List getInputDir()">1</method>
			<method name="public void setTableName(String tableName)">1</method>
			<method name="public void setInputDir(java.util.List inputDir)">1</method>
			<method name="public void setPartSpec(java.util.HashMap partSpec)">1</method>
			<method name="public String getOutputDir()">1</method>
			<method name="public void _init_(String tableName, java.util.HashMap partSpec)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ConditionalResolverSkewJoin$ConditionalResolverSkewJoinCtx</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>22</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void setDirToTaskMap(java.util.HashMap dirToTaskMap)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.HashMap getDirToTaskMap()">1</method>
			<method name="public void _init_(java.util.HashMap dirToTaskMap)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ScriptOperator$1</name>
		<wmc>2</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>0.5</lcom3>
		<loc>17</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.75</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.5</amc>
		<cc>
			<method name="public void run()">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.exec.ScriptOperator, Thread)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ListObjectsEqualComparer</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>10</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>149</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>47.666666666666664</amc>
		<cc>
			<method name="public boolean areEqual(Object[] ol0, Object[] ol1)">12</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] oi0, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] oi1)">0</method>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.TaskExecutionException</name>
		<wmc>3</wmc>
		<dit>4</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>6</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>3</npm>
		<lcom3>1.5</lcom3>
		<loc>17</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>1.0</mfa>
		<cam>0.7777777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.333333333333333</amc>
		<cc>
			<method name="public void _init_(String msg)">0</method>
			<method name="public void _init_(Throwable cause)">0</method>
			<method name="public void _init_(String msg, Throwable cause)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lib.TaskGraphWalker</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>41</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>7</ce>
		<npm>7</npm>
		<lcom3>0.5428571428571428</lcom3>
		<loc>315</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.265625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>37.75</amc>
		<cc>
			<method name="public void dispatch(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack ndStack)">1</method>
			<method name="public java.util.List getToWalk()">1</method>
			<method name="public java.util.Set getDispatchedList()">1</method>
			<method name="static java.util.HashMap access$000(org.apache.hadoop.hive.ql.lib.TaskGraphWalker x0)">1</method>
			<method name="public void startWalking(java.util.Collection startNodes, java.util.HashMap nodeOutput)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.lib.Dispatcher disp)">0</method>
			<method name="public void walk(org.apache.hadoop.hive.ql.lib.Node nd)">1</method>
			<method name="public void dispatch(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack ndStack, org.apache.hadoop.hive.ql.lib.TaskGraphWalker$TaskGraphWalkerContext walkerCtx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.classification.InterfaceAudience$Private</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.HookContext$HookType</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9166666666666666</lcom3>
		<loc>56</loc>
		<dam>0.25</dam>
		<moa>4</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>12.0</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.hooks.HookContext$HookType[] values()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.hooks.HookContext$HookType valueOf(String name)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.pcr.PcrExprProcFactory$GenericFuncExprProcessor</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>26</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>16</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>495</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>163.66666666666666</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.async.TAsyncMethodCall$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>42</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>40.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.typeinfo.package-info</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.json.JSONML</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>49</rfc>
		<lcom>28</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>7</npm>
		<lcom3>2.0</lcom3>
		<loc>702</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.20833333333333334</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>86.75</amc>
		<cc>
			<method name="public static org.json.JSONObject toJSONObject(String arg0)">1</method>
			<method name="public static String toString(org.json.JSONArray arg0)">1</method>
			<method name="public static org.json.JSONArray toJSONArray(org.json.XMLTokener arg0)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public static org.json.JSONObject toJSONObject(org.json.XMLTokener arg0)">1</method>
			<method name="public static org.json.JSONArray toJSONArray(String arg0)">1</method>
			<method name="private static Object parse(org.json.XMLTokener arg0, boolean arg1, org.json.JSONArray arg2)">1</method>
			<method name="public static String toString(org.json.JSONObject arg0)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.IOContext$1</name>
		<wmc>3</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>4</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>13</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.8461538461538461</mfa>
		<cam>1.0</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>3.3333333333333335</amc>
		<cc>
			<method name="protected volatile Object initialValue()">1</method>
			<method name="void _init_()">0</method>
			<method name="protected synchronized org.apache.hadoop.hive.ql.io.IOContext initialValue()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TServerTransport</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>2</noc>
		<cbo>12</cbo>
		<rfc>8</rfc>
		<lcom>15</lcom>
		<ca>10</ca>
		<ce>2</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>22</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.6666666666666665</amc>
		<cc>
			<method name="public abstract void listen()">1</method>
			<method name="public final org.apache.thrift.transport.TTransport accept()">1</method>
			<method name="public void interrupt()">1</method>
			<method name="public void _init_()">0</method>
			<method name="protected abstract org.apache.thrift.transport.TTransport acceptImpl()">1</method>
			<method name="public abstract void close()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>13</rfc>
		<lcom>3</lcom>
		<ca>3</ca>
		<ce>13</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>52</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.48148148148148145</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.333333333333332</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.mapred.RecordWriter getRecordWriter(org.apache.hadoop.fs.FileSystem ignored, org.apache.hadoop.mapred.JobConf job, String name, org.apache.hadoop.util.Progressable progress)">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf jc, org.apache.hadoop.fs.Path outPath, Class valueClass, boolean isCompressed, java.util.Properties tableProperties, org.apache.hadoop.util.Progressable progress)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.RCFileOutputFormat$2</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>23</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.0</amc>
		<cc>
			<method name="public void close(boolean abort)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.io.RCFileOutputFormat, org.apache.hadoop.hive.ql.io.RCFile$Writer)">0</method>
			<method name="public void write(org.apache.hadoop.io.Writable r)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.RCFileOutputFormat$1</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>31</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.35714285714285715</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.25</amc>
		<cc>
			<method name="public void close(org.apache.hadoop.mapred.Reporter reporter)">1</method>
			<method name="public void write(org.apache.hadoop.io.WritableComparable key, org.apache.hadoop.hive.serde2.columnar.BytesRefArrayWritable value)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.io.RCFileOutputFormat, org.apache.hadoop.hive.ql.io.RCFile$Writer)">0</method>
			<method name="public volatile void write(Object x0, Object x1)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.server.THsHaServer$Invocation</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>17</loc>
		<dam>0.5</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.5</amc>
		<cc>
			<method name="public void _init_(org.apache.thrift.server.THsHaServer, org.apache.thrift.server.TNonblockingServer$FrameBuffer frameBuffer)">0</method>
			<method name="public void run()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server$TUGIAssumingTransportFactory$1</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>24</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.333333333333333</amc>
		<cc>
			<method name="public org.apache.thrift.transport.TTransport run()">1</method>
			<method name="void _init_(org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server$TUGIAssumingTransportFactory, org.apache.thrift.transport.TTransport)">0</method>
			<method name="public volatile Object run()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.GroupByOperator</name>
		<wmc>23</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>53</cbo>
		<rfc>160</rfc>
		<lcom>137</lcom>
		<ca>13</ca>
		<ce>41</ce>
		<npm>8</npm>
		<lcom3>0.9163961038961038</lcom3>
		<loc>2417</loc>
		<dam>0.48214285714285715</dam>
		<moa>14</moa>
		<mfa>0.0</mfa>
		<cam>0.15454545454545454</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>101.65217391304348</amc>
		<cc>
			<method name="public java.util.List genColLists(java.util.HashMap opParseCtx)">3</method>
			<method name="public void closeOp(boolean abort)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="private int getSize(int pos, Class c, java.lang.reflect.Field f)">13</method>
			<method name="public void _init_()">0</method>
			<method name="private void computeMaxEntriesHashAggr(org.apache.hadoop.conf.Configuration hconf)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void processOp(Object row, int tag)">1</method>
			<method name="public void endGroup()">1</method>
			<method name="private int getSize(int pos, org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector$PrimitiveCategory category)">2</method>
			<method name="protected org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer[] newAggregations()">1</method>
			<method name="private boolean shouldBeFlushed(org.apache.hadoop.hive.ql.exec.KeyWrapper newKeys)">10</method>
			<method name="private void estimateRowSize()">1</method>
			<method name="public String getName()">1</method>
			<method name="private int getSize(int pos, org.apache.hadoop.hive.serde2.typeinfo.TypeInfo typeInfo)">2</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
			<method name="protected void resetAggregations(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer[] aggs)">1</method>
			<method name="protected void forward(Object[] keys, org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer[] aggs)">1</method>
			<method name="private void flush(boolean complete)">1</method>
			<method name="protected void updateAggregations(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer[] aggs, Object row, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector rowInspector, boolean hashAggr, boolean newEntryForHashAggr, Object[][] lastInvoke)">1</method>
			<method name="private void processHashAggr(Object row, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector rowInspector, org.apache.hadoop.hive.ql.exec.KeyWrapper newKeys)">1</method>
			<method name="private void processAggr(Object row, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector rowInspector, org.apache.hadoop.hive.ql.exec.KeyWrapper newKeys)">1</method>
			<method name="public void startGroup()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFSortArray$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>14</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.PhysicalOptimizer</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>16</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>2</npm>
		<lcom3>0.25</lcom3>
		<loc>92</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>29.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext pctx, org.apache.hadoop.hive.conf.HiveConf hiveConf)">0</method>
			<method name="public org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext optimize()">1</method>
			<method name="private void initialize(org.apache.hadoop.hive.conf.HiveConf hiveConf)">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.TaskHandle</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>1</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>7</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.mapred.Counters getCounters()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCollectSet$GenericUDAFMkSetEvaluator$MkArrayAggregationBuffer</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>42</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>40.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>66</rfc>
		<lcom>29</lcom>
		<ca>0</ca>
		<ce>18</ce>
		<npm>9</npm>
		<lcom3>0.8833333333333334</lcom3>
		<loc>472</loc>
		<dam>0.5</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.2</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>40.81818181818182</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getObjectInspector()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static Object deserialize(org.apache.hadoop.hive.serde2.ColumnSet c, String row, String sep, String nullString, int limit)">1</method>
			<method name="public Class getSerializedClass()">1</method>
			<method name="public org.apache.hadoop.io.Writable serialize(Object obj, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objInspector)">1</method>
			<method name="public void initialize(org.apache.hadoop.conf.Configuration job, java.util.Properties tbl)">1</method>
			<method name="private String getByteValue(String altValue, String defaultVal)">3</method>
			<method name="public String toString()">1</method>
			<method name="public Object deserialize(org.apache.hadoop.io.Writable field)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.SerDeStats getSerDeStats()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.TerminalOperator</name>
		<wmc>1</wmc>
		<dit>0</dit>
		<noc>3</noc>
		<cbo>4</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ScriptOperator</name>
		<wmc>14</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>32</cbo>
		<rfc>112</rfc>
		<lcom>63</lcom>
		<ca>9</ca>
		<ce>28</ce>
		<npm>6</npm>
		<lcom3>0.8956043956043955</lcom3>
		<loc>1024</loc>
		<dam>0.21428571428571427</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.15</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>71.14285714285714</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="protected String[] addWrapper(String[] inArgs)">4</method>
			<method name="static org.apache.hadoop.io.LongWritable access$000(org.apache.hadoop.hive.ql.exec.ScriptOperator x0)">1</method>
			<method name="public void _init_()">0</method>
			<method name="boolean allowPartialConsumption()">1</method>
			<method name="public void processOp(Object row, int tag)">1</method>
			<method name="public String getName()">1</method>
			<method name="static String safeEnvVarName(String var)">8</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
			<method name="void displayBrokenPipeInfo()">1</method>
			<method name="public void close(boolean abort)">1</method>
			<method name="static void addJobConfToEnvironment(org.apache.hadoop.conf.Configuration conf, java.util.Map env)">2</method>
			<method name="boolean isBrokenPipeException(java.io.IOException e)">2</method>
			<method name="public static String[] splitArgs(String args)">17</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.ShortObjectInspector</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>11</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract short get(Object)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableConstantLongObjectInspector</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>16</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public volatile Object getWritableConstantValue()">1</method>
			<method name="public org.apache.hadoop.io.LongWritable getWritableConstantValue()">1</method>
			<method name="void _init_(org.apache.hadoop.io.LongWritable value)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.UDFMethodResolver</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>7</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract java.lang.reflect.Method getEvalMethod(java.util.List)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tableRowFormatMapKeysIdentifier_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.UDAFEvaluatorResolver</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Class getEvaluatorClass(java.util.List)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyShort</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>10</cbo>
		<rfc>15</rfc>
		<lcom>4</lcom>
		<ca>4</ca>
		<ce>7</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>75</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.36666666666666664</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyShortObjectInspector oi)">0</method>
			<method name="public static short parseShort(byte[] bytes, int start, int length)">1</method>
			<method name="public static short parseShort(byte[] bytes, int start, int length, int radix)">2</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.LazyShort copy)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>84</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>82.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.CommonJoinOperator</name>
		<wmc>26</wmc>
		<dit>0</dit>
		<noc>2</noc>
		<cbo>32</cbo>
		<rfc>100</rfc>
		<lcom>171</lcom>
		<ca>7</ca>
		<ce>25</ce>
		<npm>8</npm>
		<lcom3>0.9</lcom3>
		<loc>2061</loc>
		<dam>0.6176470588235294</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.2</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>76.96153846153847</amc>
		<cc>
			<method name="public java.util.Map getPosToAliasMap()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void endGroup()">1</method>
			<method name="private void genUniqueJoinObject(int aliasNum, int forwardCachePos)">1</method>
			<method name="private java.util.ArrayList joinObjects(java.util.ArrayList inputNulls, java.util.ArrayList newObj, org.apache.hadoop.hive.ql.exec.CommonJoinOperator$IntermediateObject intObj, int joinPos, boolean firstRow)">17</method>
			<method name="public String getName()">1</method>
			<method name="private java.util.ArrayList joinObjectsLeftOuterJoin(java.util.ArrayList resNulls, java.util.ArrayList inputNulls, java.util.ArrayList newObj, org.apache.hadoop.hive.ql.exec.CommonJoinOperator$IntermediateObject intObj, int left, boolean newObjNull)">6</method>
			<method name="private java.util.ArrayList joinObjectsInnerJoin(java.util.ArrayList resNulls, java.util.ArrayList inputNulls, java.util.ArrayList newObj, org.apache.hadoop.hive.ql.exec.CommonJoinOperator$IntermediateObject intObj, int left, boolean newObjNull)">3</method>
			<method name="protected static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getJoinOutputObjectInspector(Byte[] order, java.util.Map aliasToObjectInspectors, org.apache.hadoop.hive.ql.plan.JoinDesc conf)">2</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.CommonJoinOperator clone)">0</method>
			<method name="private void createForwardJoinObject(org.apache.hadoop.hive.ql.exec.CommonJoinOperator$IntermediateObject intObj, boolean[] nullsArr)">1</method>
			<method name="protected void checkAndGenObject()">1</method>
			<method name="private java.util.ArrayList joinObjectsRightOuterJoin(java.util.ArrayList resNulls, java.util.ArrayList inputNulls, java.util.ArrayList newObj, org.apache.hadoop.hive.ql.exec.CommonJoinOperator$IntermediateObject intObj, int left, boolean newObjNull, boolean firstRow)">12</method>
			<method name="private java.util.ArrayList joinObjectsLeftSemiJoin(java.util.ArrayList resNulls, java.util.ArrayList inputNulls, java.util.ArrayList newObj, org.apache.hadoop.hive.ql.exec.CommonJoinOperator$IntermediateObject intObj, int left, boolean newObjNull)">3</method>
			<method name="public void startGroup()">1</method>
			<method name="public void closeOp(boolean abort)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setPosToAliasMap(java.util.Map posToAliasMap)">1</method>
			<method name="protected void reportProgress()">3</method>
			<method name="private void copyOldArray(boolean[] src, boolean[] dest)">2</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
			<method name="protected int getNextSize(int sz)">2</method>
			<method name="protected static Boolean isFiltered(Object row, java.util.List filters, java.util.List ois)">1</method>
			<method name="private void genAllOneUniqueJoinObject()">1</method>
			<method name="private void genObject(java.util.ArrayList inputNulls, int aliasNum, org.apache.hadoop.hive.ql.exec.CommonJoinOperator$IntermediateObject intObj, boolean firstRow)">1</method>
			<method name="private java.util.ArrayList joinObjectsFullOuterJoin(java.util.ArrayList resNulls, java.util.ArrayList inputNulls, java.util.ArrayList newObj, org.apache.hadoop.hive.ql.exec.CommonJoinOperator$IntermediateObject intObj, int left, boolean newObjNull, boolean firstRow)">14</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.SemanticException</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>203</cbo>
		<rfc>8</rfc>
		<lcom>6</lcom>
		<ca>202</ca>
		<ce>1</ce>
		<npm>4</npm>
		<lcom3>1.3333333333333333</lcom3>
		<loc>21</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(Throwable cause)">0</method>
			<method name="public void _init_(String message, Throwable cause)">0</method>
			<method name="public void _init_(String message)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ShowFunctionsDesc</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>11</rfc>
		<lcom>14</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>9</npm>
		<lcom3>0.925</lcom3>
		<loc>55</loc>
		<dam>0.6</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5185185185185185</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.555555555555555</amc>
		<cc>
			<method name="public void setPattern(String pattern)">1</method>
			<method name="public void _init_(org.apache.hadoop.fs.Path resFile, String pattern)">0</method>
			<method name="public String getResFile()">1</method>
			<method name="public String getSchema()">1</method>
			<method name="public String getTable()">1</method>
			<method name="public void setResFile(String resFile)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(org.apache.hadoop.fs.Path resFile)">0</method>
			<method name="public String getPattern()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFBridge$GenericUDAFBridgeEvaluator</name>
		<wmc>11</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>30</rfc>
		<lcom>25</lcom>
		<ca>1</ca>
		<ce>13</ce>
		<npm>11</npm>
		<lcom3>0.9111111111111111</lcom3>
		<loc>224</loc>
		<dam>0.1111111111111111</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.2857142857142857</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.545454545454547</amc>
		<cc>
			<method name="public void iterate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object[] parameters)">1</method>
			<method name="public Class getUdafEvaluator()">1</method>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void _init_(Class udafEvaluator)">0</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector init(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode m, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] parameters)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer getNewAggregationBuffer()">1</method>
			<method name="public void setUdafEvaluator(Class udafEvaluator)">1</method>
			<method name="public Object terminatePartial(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void merge(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object partial)">1</method>
			<method name="public void reset(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.THttpClient$Factory</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>5</ce>
		<npm>3</npm>
		<lcom3>0.0</lcom3>
		<loc>44</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.0</amc>
		<cc>
			<method name="public void _init_(String url)">0</method>
			<method name="public void _init_(String url, org.apache.http.client.HttpClient client)">0</method>
			<method name="public org.apache.thrift.transport.TTransport getTransport(org.apache.thrift.transport.TTransport trans)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFReflect</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>30</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>18</ce>
		<npm>4</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>424</loc>
		<dam>0.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>102.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde.test.InnerStruct</name>
		<wmc>31</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>77</rfc>
		<lcom>343</lcom>
		<ca>1</ca>
		<ce>15</ce>
		<npm>28</npm>
		<lcom3>0.7833333333333333</lcom3>
		<loc>444</loc>
		<dam>0.8333333333333334</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.17333333333333334</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>13.129032258064516</amc>
		<cc>
			<method name="public void clear()">1</method>
			<method name="public void unsetField0()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public volatile org.apache.thrift.TBase deepCopy()">1</method>
			<method name="public volatile Object getFieldValue(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="public void setField0IsSet(boolean value)">1</method>
			<method name="private void writeObject(java.io.ObjectOutputStream out)">1</method>
			<method name="public void read(org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public void write(org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public volatile boolean isSet(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde.test.InnerStruct other)">0</method>
			<method name="public int getField0()">1</method>
			<method name="public org.apache.hadoop.hive.serde.test.InnerStruct$_Fields fieldForId(int fieldId)">1</method>
			<method name="public String toString()">1</method>
			<method name="public boolean isSet(org.apache.hadoop.hive.serde.test.InnerStruct$_Fields field)">4</method>
			<method name="public void validate()">1</method>
			<method name="public boolean isSetField0()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setFieldValue(org.apache.hadoop.hive.serde.test.InnerStruct$_Fields field, Object value)">4</method>
			<method name="public void setField0(int field0)">1</method>
			<method name="public boolean equals(org.apache.hadoop.hive.serde.test.InnerStruct that)">7</method>
			<method name="public volatile void setFieldValue(org.apache.thrift.TFieldIdEnum x0, Object x1)">1</method>
			<method name="public org.apache.hadoop.hive.serde.test.InnerStruct deepCopy()">1</method>
			<method name="public volatile int compareTo(Object x0)">1</method>
			<method name="public Object getFieldValue(org.apache.hadoop.hive.serde.test.InnerStruct$_Fields field)">3</method>
			<method name="public int hashCode()">1</method>
			<method name="private void readObject(java.io.ObjectInputStream in)">1</method>
			<method name="public int compareTo(org.apache.hadoop.hive.serde.test.InnerStruct other)">5</method>
			<method name="public boolean equals(Object that)">3</method>
			<method name="public volatile org.apache.thrift.TFieldIdEnum fieldForId(int x0)">1</method>
			<method name="public void _init_(int field0)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.async.TAsyncClientManager$TAsyncMethodCallTimeoutComparator</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>6</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>37</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.25</amc>
		<cc>
			<method name="public volatile int compare(Object x0, Object x1)">1</method>
			<method name="private void _init_()">0</method>
			<method name="public int compare(org.apache.thrift.async.TAsyncMethodCall left, org.apache.thrift.async.TAsyncMethodCall right)">2</method>
			<method name="void _init_(org.apache.thrift.async.TAsyncClientManager$1 x0)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.objectinspector.LazyListObjectInspector</name>
		<wmc>12</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>22</rfc>
		<lcom>52</lcom>
		<ca>3</ca>
		<ce>7</ce>
		<npm>10</npm>
		<lcom3>0.9090909090909091</lcom3>
		<loc>102</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.24675324675324675</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public Object getListElement(Object data, int index)">2</method>
			<method name="public int getListLength(Object data)">2</method>
			<method name="public org.apache.hadoop.io.Text getNullSequence()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public byte getSeparator()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
			<method name="public java.util.List getList(Object data)">2</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector listElementObjectInspector, byte separator, org.apache.hadoop.io.Text nullSequence, boolean escaped, byte escapeChar)">0</method>
			<method name="public String getTypeName()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getListElementObjectInspector()">1</method>
			<method name="public byte getEscapeChar()">1</method>
			<method name="public boolean isEscaped()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TProtocol</name>
		<wmc>45</wmc>
		<dit>1</dit>
		<noc>6</noc>
		<cbo>69</cbo>
		<rfc>46</rfc>
		<lcom>988</lcom>
		<ca>61</ca>
		<ce>8</ce>
		<npm>43</npm>
		<lcom3>0.9772727272727273</lcom3>
		<loc>59</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.08333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.28888888888888886</amc>
		<cc>
			<method name="public abstract void readListEnd()">1</method>
			<method name="public abstract void writeI32(int)">1</method>
			<method name="public abstract org.apache.thrift.protocol.TField readFieldBegin()">1</method>
			<method name="public abstract void writeFieldStop()">1</method>
			<method name="public void reset()">1</method>
			<method name="public abstract void writeMapEnd()">1</method>
			<method name="public abstract boolean readBool()">1</method>
			<method name="public abstract short readI16()">1</method>
			<method name="public abstract byte readByte()">1</method>
			<method name="public abstract void writeSetEnd()">1</method>
			<method name="public abstract void writeMessageEnd()">1</method>
			<method name="public abstract void writeFieldBegin(org.apache.thrift.protocol.TField)">1</method>
			<method name="public abstract void writeSetBegin(org.apache.thrift.protocol.TSet)">1</method>
			<method name="public abstract void writeMapBegin(org.apache.thrift.protocol.TMap)">1</method>
			<method name="public abstract void readMessageEnd()">1</method>
			<method name="private void _init_()">0</method>
			<method name="public abstract org.apache.thrift.protocol.TMap readMapBegin()">1</method>
			<method name="public abstract void writeFieldEnd()">1</method>
			<method name="public abstract String readString()">1</method>
			<method name="public abstract void readSetEnd()">1</method>
			<method name="protected void _init_(org.apache.thrift.transport.TTransport trans)">0</method>
			<method name="public abstract void writeByte(byte)">1</method>
			<method name="public abstract void writeBool(boolean)">1</method>
			<method name="public abstract void writeStructEnd()">1</method>
			<method name="public abstract void readMapEnd()">1</method>
			<method name="public abstract void writeI16(short)">1</method>
			<method name="public abstract org.apache.thrift.protocol.TMessage readMessageBegin()">1</method>
			<method name="public abstract void writeListEnd()">1</method>
			<method name="public abstract double readDouble()">1</method>
			<method name="public abstract void writeMessageBegin(org.apache.thrift.protocol.TMessage)">1</method>
			<method name="public abstract void writeListBegin(org.apache.thrift.protocol.TList)">1</method>
			<method name="public abstract java.nio.ByteBuffer readBinary()">1</method>
			<method name="public abstract org.apache.thrift.protocol.TSet readSetBegin()">1</method>
			<method name="public abstract void readStructEnd()">1</method>
			<method name="public abstract long readI64()">1</method>
			<method name="public abstract org.apache.thrift.protocol.TStruct readStructBegin()">1</method>
			<method name="public abstract org.apache.thrift.protocol.TList readListBegin()">1</method>
			<method name="public abstract int readI32()">1</method>
			<method name="public abstract void writeStructBegin(org.apache.thrift.protocol.TStruct)">1</method>
			<method name="public abstract void writeDouble(double)">1</method>
			<method name="public org.apache.thrift.transport.TTransport getTransport()">1</method>
			<method name="public abstract void writeBinary(java.nio.ByteBuffer)">1</method>
			<method name="public abstract void readFieldEnd()">1</method>
			<method name="public abstract void writeI64(long)">1</method>
			<method name="public abstract void writeString(String)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.CombineHiveInputFormat$CombineHiveInputSplit</name>
		<wmc>20</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>50</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>12</ce>
		<npm>20</npm>
		<lcom3>0.42105263157894735</lcom3>
		<loc>192</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.1875</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.5</amc>
		<cc>
			<method name="public long[] getStartOffsets()">1</method>
			<method name="public org.apache.hadoop.hive.shims.HadoopShims$InputSplitShim getInputSplitShim()">1</method>
			<method name="public void shrinkSplit(long length)">1</method>
			<method name="public void setInputFormatClassName(String inputFormatClassName)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.mapred.JobConf getJob()">1</method>
			<method name="public void write(java.io.DataOutput out)">1</method>
			<method name="public long[] getLengths()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.shims.HadoopShims$InputSplitShim inputSplitShim)">0</method>
			<method name="public long getLength(int i)">1</method>
			<method name="public void readFields(java.io.DataInput in)">1</method>
			<method name="public org.apache.hadoop.fs.Path[] getPaths()">1</method>
			<method name="public long getLength()">1</method>
			<method name="public long getOffset(int i)">1</method>
			<method name="public org.apache.hadoop.fs.Path getPath(int i)">1</method>
			<method name="public void _init_(org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.hive.shims.HadoopShims$InputSplitShim inputSplitShim)">0</method>
			<method name="public String inputFormatClassName()">1</method>
			<method name="public String[] getLocations()">1</method>
			<method name="public int getNumPaths()">1</method>
			<method name="public String toString()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Utilities$MapDelegate</name>
		<wmc>4</wmc>
		<dit>3</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>13</rfc>
		<lcom>6</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>66</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.8235294117647058</mfa>
		<cam>0.625</cam>
		<ic>2</ic>
		<cbm>4</cbm>
		<amc>15.5</amc>
		<cc>
			<method name="protected java.beans.Expression instantiate(Object oldInstance, java.beans.Encoder out)">1</method>
			<method name="protected boolean mutatesTo(Object oldInstance, Object newInstance)">1</method>
			<method name="public void _init_()">0</method>
			<method name="protected void initialize(Class type, Object oldInstance, Object newInstance, java.beans.Encoder out)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.metrics.MetricsMBean</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>3</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>3</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.7777777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Object get(String)">1</method>
			<method name="public abstract boolean hasKey(String)">1</method>
			<method name="public abstract void put(String, Object)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$Phase1Ctx</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>10</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$1 x0)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPOr</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>16</rfc>
		<lcom>4</lcom>
		<ca>3</ca>
		<ce>10</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>142</loc>
		<dam>0.25</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.6</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ByteWritable$Comparator</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>8</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2)">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TSaslServerTransport$1</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.CopyTask</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>29</rfc>
		<lcom>13</lcom>
		<ca>0</ca>
		<ce>16</ce>
		<npm>4</npm>
		<lcom3>1.0</lcom3>
		<loc>222</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>35.666666666666664</amc>
		<cc>
			<method name="public int execute(org.apache.hadoop.hive.ql.DriverContext driverContext)">7</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="protected void localizeMRTmpFilesImpl(org.apache.hadoop.hive.ql.Context ctx)">1</method>
			<method name="public String getName()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.StageType getType()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.lineage.LineageCtx$Index</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>18</rfc>
		<lcom>0</lcom>
		<ca>13</ca>
		<ce>5</ce>
		<npm>4</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>95</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>22.25</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.hooks.LineageInfo$Dependency getDependency(org.apache.hadoop.hive.ql.exec.Operator op, org.apache.hadoop.hive.ql.exec.ColumnInfo col)">2</method>
			<method name="public void _init_()">0</method>
			<method name="public void putDependency(org.apache.hadoop.hive.ql.exec.Operator op, org.apache.hadoop.hive.ql.exec.ColumnInfo col, org.apache.hadoop.hive.ql.hooks.LineageInfo$Dependency dep)">2</method>
			<method name="public void mergeDependency(org.apache.hadoop.hive.ql.exec.Operator op, org.apache.hadoop.hive.ql.exec.ColumnInfo ci, org.apache.hadoop.hive.ql.hooks.LineageInfo$Dependency dep)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Hadoop20SShims</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>17</rfc>
		<lcom>6</lcom>
		<ca>1</ca>
		<ce>13</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>50</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.mapreduce.TaskAttemptContext newTaskAttemptContext(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.util.Progressable progressable)">1</method>
			<method name="public org.apache.hadoop.hive.shims.HadoopShims$JobTrackerState getJobTrackerState(org.apache.hadoop.mapred.ClusterStatus clusterStatus)">3</method>
			<method name="public org.apache.hadoop.mapreduce.JobContext newJobContext(org.apache.hadoop.mapreduce.Job job)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ReduceSinkDeDuplication$ReduceSinkDeduplicateProcFactory</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>6</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>14</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.6666666666666665</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getDefaultProc()">1</method>
			<method name="void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getReducerReducerProc()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCount$GenericUDAFCountEvaluator</name>
		<wmc>11</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>19</rfc>
		<lcom>43</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>8</npm>
		<lcom3>0.825</lcom3>
		<loc>161</loc>
		<dam>0.75</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.2625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.272727272727273</amc>
		<cc>
			<method name="public void iterate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object[] parameters)">1</method>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector init(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode m, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] parameters)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer getNewAggregationBuffer()">1</method>
			<method name="public Object terminatePartial(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void merge(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object partial)">1</method>
			<method name="public void reset(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="static org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCount$GenericUDAFCountEvaluator access$000(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCount$GenericUDAFCountEvaluator x0, boolean x1)">1</method>
			<method name="private org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCount$GenericUDAFCountEvaluator setCountAllColumns(boolean countAllCols)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.security.HiveAuthenticationProvider</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>3</rfc>
		<lcom>3</lcom>
		<ca>9</ca>
		<ce>2</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>3</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract java.util.List getGroupNames()">1</method>
			<method name="public abstract String getUserName()">1</method>
			<method name="public abstract void destroy()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.ProcessFunction</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>17</rfc>
		<lcom>8</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>75</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.36666666666666664</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.8</amc>
		<cc>
			<method name="protected abstract org.apache.thrift.TBase getEmptyArgsInstance()">1</method>
			<method name="public String getMethodName()">1</method>
			<method name="protected abstract org.apache.thrift.TBase getResult(Object, org.apache.thrift.TBase)">1</method>
			<method name="public final void process(int seqid, org.apache.thrift.protocol.TProtocol iprot, org.apache.thrift.protocol.TProtocol oprot, Object iface)">1</method>
			<method name="public void _init_(String methodName)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde.test.ThriftTestObj</name>
		<wmc>44</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>19</cbo>
		<rfc>114</rfc>
		<lcom>540</lcom>
		<ca>0</ca>
		<ce>19</ce>
		<npm>41</npm>
		<lcom3>0.7813953488372093</lcom3>
		<loc>916</loc>
		<dam>0.9</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.12880143112701253</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>19.59090909090909</amc>
		<cc>
			<method name="public void clear()">1</method>
			<method name="public String getField2()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde.test.ThriftTestObj other)">0</method>
			<method name="public boolean isSetField3()">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="public volatile org.apache.thrift.TBase deepCopy()">1</method>
			<method name="public volatile Object getFieldValue(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="private void writeObject(java.io.ObjectOutputStream out)">1</method>
			<method name="public void read(org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public Object getFieldValue(org.apache.hadoop.hive.serde.test.ThriftTestObj$_Fields field)">2</method>
			<method name="public void write(org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public volatile boolean isSet(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="public void _init_(int field1, String field2, java.util.List field3)">0</method>
			<method name="public void unsetField1()">1</method>
			<method name="public void addToField3(org.apache.hadoop.hive.serde.test.InnerStruct elem)">2</method>
			<method name="public void setField2(String field2)">1</method>
			<method name="public org.apache.hadoop.hive.serde.test.ThriftTestObj$_Fields fieldForId(int fieldId)">1</method>
			<method name="public void setField1(int field1)">1</method>
			<method name="public java.util.Iterator getField3Iterator()">2</method>
			<method name="public String toString()">5</method>
			<method name="public int getField3Size()">2</method>
			<method name="public void validate()">1</method>
			<method name="public void setField2IsSet(boolean value)">2</method>
			<method name="public void _init_()">0</method>
			<method name="public void setFieldValue(org.apache.hadoop.hive.serde.test.ThriftTestObj$_Fields field, Object value)">5</method>
			<method name="public void setField1IsSet(boolean value)">1</method>
			<method name="public boolean isSet(org.apache.hadoop.hive.serde.test.ThriftTestObj$_Fields field)">3</method>
			<method name="public volatile void setFieldValue(org.apache.thrift.TFieldIdEnum x0, Object x1)">1</method>
			<method name="public void setField3IsSet(boolean value)">2</method>
			<method name="public volatile int compareTo(Object x0)">1</method>
			<method name="public boolean isSetField1()">1</method>
			<method name="public java.util.List getField3()">1</method>
			<method name="public int hashCode()">1</method>
			<method name="public int getField1()">1</method>
			<method name="public int compareTo(org.apache.hadoop.hive.serde.test.ThriftTestObj other)">11</method>
			<method name="public void unsetField3()">1</method>
			<method name="private void readObject(java.io.ObjectInputStream in)">1</method>
			<method name="public void unsetField2()">1</method>
			<method name="public boolean equals(Object that)">3</method>
			<method name="public volatile org.apache.thrift.TFieldIdEnum fieldForId(int x0)">1</method>
			<method name="public boolean equals(org.apache.hadoop.hive.serde.test.ThriftTestObj that)">17</method>
			<method name="public org.apache.hadoop.hive.serde.test.ThriftTestObj deepCopy()">1</method>
			<method name="public boolean isSetField2()">2</method>
			<method name="public void setField3(java.util.List field3)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tableProperties_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.stats.StatsSetupConst</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Hadoop20Shims$CombineFileInputFormatShim</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>14</cbo>
		<rfc>18</rfc>
		<lcom>36</lcom>
		<ca>1</ca>
		<ce>13</ce>
		<npm>9</npm>
		<lcom3>2.0</lcom3>
		<loc>119</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3492063492063492</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.222222222222221</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.shims.Hadoop20Shims$InputSplitShim[] getSplits(org.apache.hadoop.mapred.JobConf job, int numSplits)">1</method>
			<method name="public volatile org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf x0, int x1)">1</method>
			<method name="public org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.hive.shims.HadoopShims$InputSplitShim split, org.apache.hadoop.mapred.Reporter reporter, Class rrClass)">1</method>
			<method name="public volatile org.apache.hadoop.hive.shims.HadoopShims$InputSplitShim getInputSplitShim()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public volatile org.apache.hadoop.hive.shims.HadoopShims$InputSplitShim[] getSplits(org.apache.hadoop.mapred.JobConf x0, int x1)">1</method>
			<method name="public transient void createPool(org.apache.hadoop.mapred.JobConf conf, org.apache.hadoop.fs.PathFilter[] filters)">1</method>
			<method name="public org.apache.hadoop.fs.Path[] getInputPathsShim(org.apache.hadoop.mapred.JobConf conf)">1</method>
			<method name="public org.apache.hadoop.hive.shims.Hadoop20Shims$InputSplitShim getInputSplitShim()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.LateralViewJoinDesc</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>22</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_(java.util.ArrayList outputInternalColNames)">0</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.ArrayList getOutputInternalColNames()">1</method>
			<method name="public void setOutputInternalColNames(java.util.ArrayList outputInternalColNames)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.ColumnProjectionUtils</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>23</rfc>
		<lcom>21</lcom>
		<ca>6</ca>
		<ce>2</ce>
		<npm>4</npm>
		<lcom3>1.1666666666666667</lcom3>
		<loc>159</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.35714285714285715</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>21.571428571428573</amc>
		<cc>
			<method name="public static void setFullyReadColumns(org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="private void _init_()">0</method>
			<method name="public static void appendReadColumnIDs(org.apache.hadoop.conf.Configuration conf, java.util.ArrayList ids)">3</method>
			<method name="private static String toReadColumnIDString(java.util.ArrayList ids)">4</method>
			<method name="public static java.util.ArrayList getReadColumnIDs(org.apache.hadoop.conf.Configuration conf)">4</method>
			<method name="public static void setReadColumnIDs(org.apache.hadoop.conf.Configuration conf, java.util.ArrayList ids)">1</method>
			<method name="private static void setReadColumnIDConf(org.apache.hadoop.conf.Configuration conf, String id)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.CreateDatabaseDesc</name>
		<wmc>13</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>14</rfc>
		<lcom>48</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>13</npm>
		<lcom3>0.8055555555555555</lcom3>
		<loc>82</loc>
		<dam>0.16666666666666666</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4230769230769231</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.846153846153846</amc>
		<cc>
			<method name="public void setDatabaseProperties(java.util.Map dbProps)">1</method>
			<method name="public void _init_(String databaseName, String comment, String locationUri, boolean ifNotExists)">0</method>
			<method name="public void setComment(String comment)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public String getComment()">1</method>
			<method name="public void setName(String databaseName)">1</method>
			<method name="public String getName()">1</method>
			<method name="public void _init_(String databaseName, boolean ifNotExists)">0</method>
			<method name="public void setIfNotExists(boolean ifNotExists)">1</method>
			<method name="public boolean getIfNotExists()">1</method>
			<method name="public java.util.Map getDatabaseProperties()">1</method>
			<method name="public String getLocationUri()">1</method>
			<method name="public void setLocationUri(String locationUri)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFAcos</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>24</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable a)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyTimestamp</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>21</rfc>
		<lcom>7</lcom>
		<ca>3</ca>
		<ce>8</ce>
		<npm>6</npm>
		<lcom3>1.0</lcom3>
		<loc>94</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2619047619047619</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.142857142857142</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyTimestampObjectInspector oi)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static void writeUTF8(java.io.OutputStream out, org.apache.hadoop.hive.serde2.io.TimestampWritable i)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.io.TimestampWritable getWritableObject()">1</method>
			<method name="public volatile org.apache.hadoop.io.Writable getWritableObject()">1</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">2</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.LazyTimestamp copy)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$descStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ConstantObjectInspector</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>23</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>22</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Object getWritableConstantValue()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFUpper</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>24</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.5</amc>
		<cc>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text s)">2</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableFloatObjectInspector</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>9</cbo>
		<rfc>11</rfc>
		<lcom>15</lcom>
		<ca>4</ca>
		<ce>5</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>45</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.5</amc>
		<cc>
			<method name="public Object create(float value)">1</method>
			<method name="void _init_()">0</method>
			<method name="public float get(Object o)">1</method>
			<method name="public Object set(Object o, float value)">1</method>
			<method name="public Object getPrimitiveJavaObject(Object o)">2</method>
			<method name="public Object copyObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.TBaseHelper$NestedStructureComparator</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>9</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>67</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>21.333333333333332</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="void _init_(org.apache.thrift.TBaseHelper$1 x0)">0</method>
			<method name="public int compare(Object oA, Object oB)">9</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPEqualNS</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>6</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>41</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.Task$_Fields</name>
		<wmc>9</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>24</rfc>
		<lcom>26</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>0.7708333333333333</lcom3>
		<loc>215</loc>
		<dam>0.3333333333333333</dam>
		<moa>9</moa>
		<mfa>0.65</mfa>
		<cam>0.3125</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>21.555555555555557</amc>
		<cc>
			<method name="private void _init_(String, int, short thriftId, String fieldName)">0</method>
			<method name="public String getFieldName()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Task$_Fields valueOf(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Task$_Fields[] values()">1</method>
			<method name="public short getThriftFieldId()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Task$_Fields findByThriftIdOrThrow(int fieldId)">2</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Task$_Fields findByThriftId(int fieldId)">2</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Task$_Fields findByName(String name)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.index.RewriteParseContextGenerator</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>19</cbo>
		<rfc>34</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>18</ce>
		<npm>1</npm>
		<lcom3>0.5</lcom3>
		<loc>199</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>48.25</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.parse.ParseContext generateOperatorTree(org.apache.hadoop.hive.conf.HiveConf conf, String command)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private static void doSemanticAnalysis(org.apache.hadoop.hive.ql.parse.SemanticAnalyzer sem, org.apache.hadoop.hive.ql.parse.ASTNode ast, org.apache.hadoop.hive.ql.Context ctx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HiveOutputFormat</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>10</ca>
		<ce>5</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf, org.apache.hadoop.fs.Path, Class, boolean, java.util.Properties, org.apache.hadoop.util.Progressable)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.persistence.AbstractMapJoinKey</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>3</noc>
		<cbo>7</cbo>
		<rfc>8</rfc>
		<lcom>21</lcom>
		<ca>7</ca>
		<ce>0</ce>
		<npm>6</npm>
		<lcom3>1.0</lcom3>
		<loc>14</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>0.8571428571428571</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public abstract void writeExternal(java.io.ObjectOutput)">1</method>
			<method name="public abstract boolean equals(Object)">1</method>
			<method name="public abstract boolean hasAnyNulls(boolean[])">1</method>
			<method name="public abstract void readExternal(java.io.ObjectInput)">1</method>
			<method name="public abstract int hashCode()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$privilegeIncludeColObject_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$sysFuncNames_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.SkewJoinProcFactory</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>6</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>14</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.6666666666666665</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getDefaultProc()">1</method>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getJoinProc()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.JavaIntObjectInspector</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>9</rfc>
		<lcom>10</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>30</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public Object create(int value)">1</method>
			<method name="public int get(Object o)">1</method>
			<method name="void _init_()">0</method>
			<method name="public Object set(Object o, int value)">1</method>
			<method name="public Object getPrimitiveWritableObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.SamplePruner$FilterPPR</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>13</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>65</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>20.333333333333332</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.thrift.SkippableTProtocol</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void skip(byte)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFAbs</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>17</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>4</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>64</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.25</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.LongWritable n)">2</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.IntWritable n)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable n)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lib.Node</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>132</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>132</ca>
		<ce>0</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract String getName()">1</method>
			<method name="public abstract java.util.List getChildren()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer$1</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>8</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>1</npm>
		<lcom3>0.0</lcom3>
		<loc>43</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5714285714285714</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.5</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer, java.util.List)">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tableBucketSample_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFSubstr</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>21</rfc>
		<lcom>5</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>5</npm>
		<lcom3>0.4</lcom3>
		<loc>179</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>28.333333333333332</amc>
		<cc>
			<method name="public org.apache.hadoop.io.BytesWritable evaluate(org.apache.hadoop.io.BytesWritable bw, org.apache.hadoop.io.IntWritable pos, org.apache.hadoop.io.IntWritable len)">6</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text s, org.apache.hadoop.io.IntWritable pos)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text t, org.apache.hadoop.io.IntWritable pos, org.apache.hadoop.io.IntWritable len)">6</method>
			<method name="public org.apache.hadoop.io.BytesWritable evaluate(org.apache.hadoop.io.BytesWritable bw, org.apache.hadoop.io.IntWritable pos)">1</method>
			<method name="private int[] makeIndex(int pos, int len, int inputLen)">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.NGramEstimator</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>54</rfc>
		<lcom>0</lcom>
		<ca>6</ca>
		<ce>5</ce>
		<npm>9</npm>
		<lcom3>0.4</lcom3>
		<loc>625</loc>
		<dam>0.8</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.28</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>55.36363636363637</amc>
		<cc>
			<method name="public java.util.ArrayList serialize()">1</method>
			<method name="public int size()">1</method>
			<method name="public void add(java.util.ArrayList ng)">1</method>
			<method name="public java.util.ArrayList getNGrams()">1</method>
			<method name="public void initialize(int pk, int ppf, int pn)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void reset()">1</method>
			<method name="private void trim(boolean finalTrim)">1</method>
			<method name="public void merge(java.util.List other)">1</method>
			<method name="public boolean isInitialized()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.persistence.MapJoinObjectValue</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>35</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>10</ce>
		<npm>10</npm>
		<lcom3>0.3888888888888889</lcom3>
		<loc>233</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.2833333333333333</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>22.1</amc>
		<cc>
			<method name="public void readExternal(java.io.ObjectInput in)">1</method>
			<method name="public void setMetadataTag(int metadataTag)">1</method>
			<method name="public boolean equals(Object o)">8</method>
			<method name="public int hashCode()">2</method>
			<method name="public void _init_()">0</method>
			<method name="public int getMetadataTag()">1</method>
			<method name="public void setObj(org.apache.hadoop.hive.ql.exec.persistence.MapJoinRowContainer obj)">1</method>
			<method name="public void writeExternal(java.io.ObjectOutput out)">1</method>
			<method name="public void _init_(int metadataTag, org.apache.hadoop.hive.ql.exec.persistence.MapJoinRowContainer obj)">0</method>
			<method name="public org.apache.hadoop.hive.ql.exec.persistence.MapJoinRowContainer getObj()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>49</cbo>
		<rfc>86</rfc>
		<lcom>30</lcom>
		<ca>8</ca>
		<ce>41</ce>
		<npm>5</npm>
		<lcom3>0.75</lcom3>
		<loc>676</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2638888888888889</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>74.0</amc>
		<cc>
			<method name="public static boolean hasColumnExpr(org.apache.hadoop.hive.ql.plan.ExprNodeDesc desc)">6</method>
			<method name="public static org.apache.hadoop.hive.ql.parse.PrunedPartitionList prune(org.apache.hadoop.hive.ql.metadata.Table tab, org.apache.hadoop.hive.ql.plan.ExprNodeDesc prunerExpr, org.apache.hadoop.hive.conf.HiveConf conf, String alias, java.util.Map prunedPartitionsMap)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="private static void pruneBySequentialScan(org.apache.hadoop.hive.ql.metadata.Table tab, java.util.Set true_parts, java.util.Set unkn_parts, java.util.Set denied_parts, org.apache.hadoop.hive.ql.plan.ExprNodeDesc prunerExpr, org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector rowObjectInspector)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext transform(org.apache.hadoop.hive.ql.parse.ParseContext pctx)">1</method>
			<method name="private static org.apache.hadoop.hive.ql.plan.ExprNodeDesc compactExpr(org.apache.hadoop.hive.ql.plan.ExprNodeDesc expr)">10</method>
			<method name="private static void pruneByPushDown(org.apache.hadoop.hive.ql.metadata.Table tab, java.util.Set true_parts, String filter)">1</method>
			<method name="public static boolean onlyContainsPartnCols(org.apache.hadoop.hive.ql.metadata.Table tab, org.apache.hadoop.hive.ql.plan.ExprNodeDesc expr)">9</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.TBase</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>21</cbo>
		<rfc>8</rfc>
		<lcom>28</lcom>
		<ca>18</ca>
		<ce>3</ce>
		<npm>8</npm>
		<lcom3>2.0</lcom3>
		<loc>8</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void setFieldValue(org.apache.thrift.TFieldIdEnum, Object)">1</method>
			<method name="public abstract org.apache.thrift.TFieldIdEnum fieldForId(int)">1</method>
			<method name="public abstract void write(org.apache.thrift.protocol.TProtocol)">1</method>
			<method name="public abstract boolean isSet(org.apache.thrift.TFieldIdEnum)">1</method>
			<method name="public abstract org.apache.thrift.TBase deepCopy()">1</method>
			<method name="public abstract void read(org.apache.thrift.protocol.TProtocol)">1</method>
			<method name="public abstract Object getFieldValue(org.apache.thrift.TFieldIdEnum)">1</method>
			<method name="public abstract void clear()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeCommaOrSemicolon</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterDatabaseStatementSuffix_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFPercentileApprox$GenericUDAFPercentileApproxEvaluator$PercentileAggBuf</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>6</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.FileUtils</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>52</rfc>
		<lcom>53</lcom>
		<ca>7</ca>
		<ce>5</ce>
		<npm>8</npm>
		<lcom3>0.8</lcom3>
		<loc>608</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.16666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>54.18181818181818</amc>
		<cc>
			<method name="public static void listStatusRecursively(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.FileStatus fileStatus, java.util.List results)">1</method>
			<method name="public static String makePartName(java.util.List partCols, java.util.List vals, String defaultStr)">3</method>
			<method name="private void _init_()">0</method>
			<method name="public static void tar(String parentDir, String[] inputFiles, String outputFile)">1</method>
			<method name="public static String escapePathName(String path, String defaultPath)">6</method>
			<method name="public static String escapePathName(String path)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static String unescapePathName(String path)">5</method>
			<method name="static boolean needsEscaping(char c)">4</method>
			<method name="public static String makePartName(java.util.List partCols, java.util.List vals)">1</method>
			<method name="public static org.apache.hadoop.fs.Path makeQualified(org.apache.hadoop.fs.Path path, org.apache.hadoop.conf.Configuration conf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsAggregator$3</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>19</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsAggregator)">0</method>
			<method name="public volatile Object run(java.sql.PreparedStatement x0)">1</method>
			<method name="public Void run(java.sql.PreparedStatement stmt)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFBridge</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>9</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>7</ce>
		<npm>3</npm>
		<lcom3>0.0</lcom3>
		<loc>26</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.333333333333333</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.UDAF udaf)">0</method>
			<method name="public Class getUDAFClass()">1</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] parameters)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.WriteEntity</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>16</rfc>
		<lcom>36</lcom>
		<ca>8</ca>
		<ce>4</ce>
		<npm>9</npm>
		<lcom3>2.0</lcom3>
		<loc>67</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3492063492063492</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.444444444444445</amc>
		<cc>
			<method name="public void _init_(String d, boolean islocal, boolean complete)">0</method>
			<method name="public boolean equals(Object o)">3</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.DummyPartition p, boolean complete)">0</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Partition p, boolean complete)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Partition p)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Table t, boolean complete)">0</method>
			<method name="public void _init_(String d, boolean islocal)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Table t)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.server.TNonblockingServer$FrameBuffer</name>
		<wmc>13</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>48</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>14</ce>
		<npm>8</npm>
		<lcom3>0.7948717948717948</lcom3>
		<loc>435</loc>
		<dam>0.8461538461538461</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.3076923076923077</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>31.46153846153846</amc>
		<cc>
			<method name="private void requestSelectInterestChange()">2</method>
			<method name="public void responseReady()">2</method>
			<method name="public void changeSelectInterests()">4</method>
			<method name="public void close()">3</method>
			<method name="public boolean isFrameFullyRead()">2</method>
			<method name="public boolean read()">10</method>
			<method name="public void _init_(org.apache.thrift.server.TNonblockingServer, org.apache.thrift.transport.TNonblockingTransport trans, java.nio.channels.SelectionKey selectionKey)">0</method>
			<method name="private boolean internalRead()">2</method>
			<method name="private org.apache.thrift.transport.TTransport getOutputTransport()">1</method>
			<method name="public boolean write()">3</method>
			<method name="private void prepareRead()">1</method>
			<method name="private org.apache.thrift.transport.TTransport getInputTransport()">1</method>
			<method name="public void invoke()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.thrift.test.IntString$_Fields</name>
		<wmc>9</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>24</rfc>
		<lcom>26</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>0.7857142857142857</lcom3>
		<loc>140</loc>
		<dam>0.5714285714285714</dam>
		<moa>4</moa>
		<mfa>0.65</mfa>
		<cam>0.3125</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>13.777777777777779</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.serde2.thrift.test.IntString$_Fields[] values()">1</method>
			<method name="private void _init_(String, int, short thriftId, String fieldName)">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.thrift.test.IntString$_Fields findByThriftIdOrThrow(int fieldId)">2</method>
			<method name="public String getFieldName()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.thrift.test.IntString$_Fields findByThriftId(int fieldId)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.thrift.test.IntString$_Fields findByName(String name)">1</method>
			<method name="public short getThriftFieldId()">1</method>
			<method name="public static org.apache.hadoop.hive.serde2.thrift.test.IntString$_Fields valueOf(String name)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ExprNodeColumnEvaluator</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>13</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>216</loc>
		<dam>0.14285714285714285</dam>
		<moa>5</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>68.66666666666667</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.ExprNodeColumnDesc expr)">0</method>
			<method name="public Object evaluate(Object row)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector rowInspector)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>150</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>146.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.BinaryObjectInspector</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>10</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.hadoop.hive.serde2.lazy.ByteArrayRef getPrimitiveJavaObject(Object)">1</method>
			<method name="public abstract org.apache.hadoop.io.BytesWritable getPrimitiveWritableObject(Object)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCount$GenericUDAFCountEvaluator$CountAgg</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$partTypeExpr_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryUtils$VInt</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>6</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>12</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.FlatFileInputFormat$RowContainer</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Utilities$CollectionPersistenceDelegate</name>
		<wmc>3</wmc>
		<dit>3</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>11</rfc>
		<lcom>3</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>38</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.875</mfa>
		<cam>0.6666666666666666</cam>
		<ic>2</ic>
		<cbm>2</cbm>
		<amc>11.666666666666666</amc>
		<cc>
			<method name="protected java.beans.Expression instantiate(Object oldInstance, java.beans.Encoder out)">1</method>
			<method name="public void _init_()">0</method>
			<method name="protected void initialize(Class type, Object oldInstance, Object newInstance, java.beans.Encoder out)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.SortedMergeBucketMapJoinOptimizer</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>21</rfc>
		<lcom>13</lcom>
		<ca>3</ca>
		<ce>14</ce>
		<npm>2</npm>
		<lcom3>0.8</lcom3>
		<loc>72</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.833333333333334</amc>
		<cc>
			<method name="static org.apache.commons.logging.Log access$000()">1</method>
			<method name="private org.apache.hadoop.hive.ql.lib.NodeProcessor getDefaultProc()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext transform(org.apache.hadoop.hive.ql.parse.ParseContext pctx)">1</method>
			<method name="private org.apache.hadoop.hive.ql.lib.NodeProcessor getSortedMergeBucketMapjoinProc(org.apache.hadoop.hive.ql.parse.ParseContext pctx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCorrelation</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>15</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>12</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>131</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>42.333333333333336</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] parameters)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.persistence.AbstractRowContainer</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>2</noc>
		<cbo>6</cbo>
		<rfc>7</rfc>
		<lcom>15</lcom>
		<ca>5</ca>
		<ce>1</ce>
		<npm>6</npm>
		<lcom3>2.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.5</amc>
		<cc>
			<method name="public abstract int size()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public abstract Object first()">1</method>
			<method name="public abstract void add(Object)">1</method>
			<method name="public abstract Object next()">1</method>
			<method name="public abstract void clear()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$columnNameType_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.AggregateIndexHandler</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>37</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>14</ce>
		<npm>2</npm>
		<lcom3>0.625</lcom3>
		<loc>392</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.40625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>77.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void createAggregationFunction(java.util.List indexTblCols, String property)">2</method>
			<method name="public void analyzeIndexDefinition(org.apache.hadoop.hive.metastore.api.Table baseTable, org.apache.hadoop.hive.metastore.api.Index idx, org.apache.hadoop.hive.metastore.api.Table indexTable)">1</method>
			<method name="protected org.apache.hadoop.hive.ql.exec.Task getIndexBuilderMapRedTask(java.util.Set inputs, java.util.Set outputs, java.util.List indexField, boolean partitioned, org.apache.hadoop.hive.ql.plan.PartitionDesc indexTblPartDesc, String indexTableName, org.apache.hadoop.hive.ql.plan.PartitionDesc baseTablePartDesc, String baseTableName, String dbName)">12</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TSimpleJSONProtocol$ListContext</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>0</npm>
		<lcom3>0.0</lcom3>
		<loc>27</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.5</amc>
		<cc>
			<method name="protected void _init_(org.apache.thrift.protocol.TSimpleJSONProtocol)">0</method>
			<method name="protected void write()">1</method>
		</cc>
	</class>
	<class>
		<name>org.json.XMLTokener</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>33</rfc>
		<lcom>26</lcom>
		<ca>2</ca>
		<ce>3</ce>
		<npm>7</npm>
		<lcom3>0.5714285714285714</lcom3>
		<loc>426</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.47619047619047616</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>52.125</amc>
		<cc>
			<method name="public boolean skipPast(String arg0)">1</method>
			<method name="public String nextCDATA()">1</method>
			<method name="public Object nextToken()">12</method>
			<method name="public Object nextContent()">1</method>
			<method name="public Object nextMeta()">10</method>
			<method name="public Object nextEntity(char arg0)">1</method>
			<method name="public void _init_(String arg0)">0</method>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyVoidObjectInspector</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>5</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>14</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.6666666666666665</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public Object getPrimitiveJavaObject(Object o)">1</method>
			<method name="public Object copyObject(Object o)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$loadStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TJSONProtocol$JSONListContext</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>0</npm>
		<lcom3>0.0</lcom3>
		<loc>40</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.666666666666666</amc>
		<cc>
			<method name="protected void write()">1</method>
			<method name="protected void read()">1</method>
			<method name="protected void _init_(org.apache.thrift.protocol.TJSONProtocol)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.UnionStructObjectInspector</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>27</rfc>
		<lcom>16</lcom>
		<ca>5</ca>
		<ce>5</ce>
		<npm>6</npm>
		<lcom3>0.625</lcom3>
		<loc>222</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.35</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>23.333333333333332</amc>
		<cc>
			<method name="protected void _init_(java.util.List unionObjectInspectors)">0</method>
			<method name="public Object getStructFieldData(Object data, org.apache.hadoop.hive.serde2.objectinspector.StructField fieldRef)">7</method>
			<method name="static void _clinit_()">0</method>
			<method name="public java.util.List getStructFieldsDataAsList(Object data)">6</method>
			<method name="public final org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
			<method name="public java.util.List getAllStructFieldRefs()">1</method>
			<method name="public String getTypeName()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.StructField getStructFieldRef(String fieldName)">1</method>
			<method name="void init(java.util.List unionObjectInspectors)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.StatsWork</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>12</rfc>
		<lcom>17</lcom>
		<ca>4</ca>
		<ce>3</ce>
		<npm>11</npm>
		<lcom3>0.8666666666666666</lcom3>
		<loc>73</loc>
		<dam>1.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.24242424242424243</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.090909090909091</amc>
		<cc>
			<method name="public void setNoStatsAggregator(boolean noStatsAggregator)">1</method>
			<method name="public void setAggKey(String aggK)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$tableSpec getTableSpecs()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.LoadFileDesc getLoadFileDesc()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.LoadTableDesc getLoadTableDesc()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.LoadFileDesc loadFileDesc)">0</method>
			<method name="public String getAggKey()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.LoadTableDesc loadTableDesc)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$tableSpec tableSpecs)">0</method>
			<method name="public boolean getNoStatsAggregator()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryBoolean</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>13</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>3</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>66</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.25</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">5</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableBooleanObjectInspector oi)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryBoolean copy)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsAggregator$2</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>17</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.333333333333333</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsAggregator)">0</method>
			<method name="public java.sql.ResultSet run(java.sql.PreparedStatement stmt)">1</method>
			<method name="public volatile Object run(java.sql.PreparedStatement x0)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.NumericUDAF</name>
		<wmc>1</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.PreExecute</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>3</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void run(org.apache.hadoop.hive.ql.session.SessionState, java.util.Set, java.util.Set, org.apache.hadoop.security.UserGroupInformation)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsAggregator$1</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>5</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>21</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.666666666666667</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsAggregator)">0</method>
			<method name="public volatile Object run(java.sql.PreparedStatement x0)">1</method>
			<method name="public Void run(java.sql.PreparedStatement stmt)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Jetty23Shims$1</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.TProcessorFactory</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>5</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>12</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.thrift.TProcessor processor)">0</method>
			<method name="public org.apache.thrift.TProcessor getProcessor(org.apache.thrift.transport.TTransport trans)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.SettableStringObjectInspector</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>4</rfc>
		<lcom>6</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Object create(String)">1</method>
			<method name="public abstract Object set(Object, org.apache.hadoop.io.Text)">1</method>
			<method name="public abstract Object create(org.apache.hadoop.io.Text)">1</method>
			<method name="public abstract Object set(Object, String)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFIn$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>28</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.AutoProgressor$StopReporterTimerTask</name>
		<wmc>2</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>8</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>35</loc>
		<dam>0.5</dam>
		<moa>2</moa>
		<mfa>0.75</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.5</amc>
		<cc>
			<method name="public void run()">2</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.AutoProgressor, org.apache.hadoop.hive.ql.exec.AutoProgressor$ReporterTask rp)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.Query$_Fields</name>
		<wmc>9</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>24</rfc>
		<lcom>26</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>0.7708333333333333</lcom3>
		<loc>215</loc>
		<dam>0.3333333333333333</dam>
		<moa>9</moa>
		<mfa>0.65</mfa>
		<cam>0.3125</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>21.555555555555557</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Query$_Fields findByThriftIdOrThrow(int fieldId)">2</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Query$_Fields[] values()">1</method>
			<method name="private void _init_(String, int, short thriftId, String fieldName)">0</method>
			<method name="public String getFieldName()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Query$_Fields findByName(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Query$_Fields valueOf(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Query$_Fields findByThriftId(int fieldId)">2</method>
			<method name="public short getThriftFieldId()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$keyValueProperty_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDTF</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>4</noc>
		<cbo>15</cbo>
		<rfc>8</rfc>
		<lcom>9</lcom>
		<ca>10</ca>
		<ce>5</ce>
		<npm>5</npm>
		<lcom3>0.6</lcom3>
		<loc>22</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.5</amc>
		<cc>
			<method name="public final void setCollector(org.apache.hadoop.hive.ql.udf.generic.Collector collector)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public abstract void close()">1</method>
			<method name="public abstract void process(Object[])">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[])">1</method>
			<method name="protected final void forward(Object o)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>7</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>12</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>29</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5714285714285714</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.0</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf jc, org.apache.hadoop.fs.Path finalOutPath, Class valueClass, boolean isCompressed, java.util.Properties tableProperties, org.apache.hadoop.util.Progressable progress)">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.thrift.TReflectionUtils</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>10</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>1.3333333333333333</lcom3>
		<loc>39</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.0</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.thrift.protocol.TProtocolFactory getProtocolFactoryByName(String protocolName)">1</method>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceNotOperator_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFToBoolean</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>22</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>11</ce>
		<npm>10</npm>
		<lcom3>0.1111111111111111</lcom3>
		<loc>158</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.19</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.7</amc>
		<cc>
			<method name="public org.apache.hadoop.io.BooleanWritable evaluate(org.apache.hadoop.io.NullWritable i)">1</method>
			<method name="public org.apache.hadoop.io.BooleanWritable evaluate(org.apache.hadoop.io.Text i)">3</method>
			<method name="public org.apache.hadoop.io.BooleanWritable evaluate(org.apache.hadoop.io.FloatWritable i)">3</method>
			<method name="public org.apache.hadoop.io.BooleanWritable evaluate(org.apache.hadoop.io.LongWritable i)">3</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.BooleanWritable evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable i)">4</method>
			<method name="public org.apache.hadoop.io.BooleanWritable evaluate(org.apache.hadoop.io.IntWritable i)">3</method>
			<method name="public org.apache.hadoop.io.BooleanWritable evaluate(org.apache.hadoop.hive.serde2.io.ShortWritable i)">3</method>
			<method name="public org.apache.hadoop.io.BooleanWritable evaluate(org.apache.hadoop.hive.serde2.io.ByteWritable i)">3</method>
			<method name="public org.apache.hadoop.io.BooleanWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable i)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.io.DoubleWritable$Comparator</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>28</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.0</amc>
		<cc>
			<method name="public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2)">3</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFAssertTrue</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>16</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>14</ce>
		<npm>4</npm>
		<lcom3>0.3333333333333333</lcom3>
		<loc>101</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>24.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.LongObjectInspector</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>26</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>25</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract long get(Object)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ScriptDesc</name>
		<wmc>16</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>17</rfc>
		<lcom>78</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>16</npm>
		<lcom3>0.8916666666666667</lcom3>
		<loc>100</loc>
		<dam>1.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.40625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.75</amc>
		<cc>
			<method name="public void setScriptOutputInfo(org.apache.hadoop.hive.ql.plan.TableDesc scriptOutputInfo)">1</method>
			<method name="public void setScriptInputInfo(org.apache.hadoop.hive.ql.plan.TableDesc scriptInputInfo)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.TableDesc getScriptOutputInfo()">1</method>
			<method name="public Class getErrRecordReaderClass()">1</method>
			<method name="public void setScriptCmd(String scriptCmd)">1</method>
			<method name="public String getScriptCmd()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.TableDesc getScriptErrInfo()">1</method>
			<method name="public Class getOutRecordReaderClass()">1</method>
			<method name="public void setOutRecordReaderClass(Class outRecordReaderClass)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.TableDesc getScriptInputInfo()">1</method>
			<method name="public void setInRecordWriterClass(Class inRecordWriterClass)">1</method>
			<method name="public Class getInRecordWriterClass()">1</method>
			<method name="public void _init_(String scriptCmd, org.apache.hadoop.hive.ql.plan.TableDesc scriptInputInfo, Class inRecordWriterClass, org.apache.hadoop.hive.ql.plan.TableDesc scriptOutputInfo, Class outRecordReaderClass, Class errRecordReaderClass, org.apache.hadoop.hive.ql.plan.TableDesc scriptErrInfo)">0</method>
			<method name="public void setErrRecordReaderClass(Class errRecordReaderClass)">1</method>
			<method name="public void setScriptErrInfo(org.apache.hadoop.hive.ql.plan.TableDesc scriptErrInfo)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.LockTableDesc</name>
		<wmc>12</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>13</rfc>
		<lcom>40</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>12</npm>
		<lcom3>0.8787878787878788</lcom3>
		<loc>71</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5277777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.416666666666667</amc>
		<cc>
			<method name="public String getQueryStr()">1</method>
			<method name="public void setQueryStr(String queryStr)">1</method>
			<method name="public String getMode()">1</method>
			<method name="public String getTableName()">1</method>
			<method name="public void _init_(String tableName, String mode, java.util.Map partSpec, String queryId)">0</method>
			<method name="public void _init_()">0</method>
			<method name="public void setMode(String mode)">1</method>
			<method name="public void setTableName(String tableName)">1</method>
			<method name="public String getQueryId()">1</method>
			<method name="public void setPartSpec(java.util.Map partSpec)">1</method>
			<method name="public void setQueryId(String queryId)">1</method>
			<method name="public java.util.Map getPartSpec()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.LateralViewForwardDesc</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.FetchTask</name>
		<wmc>12</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>30</cbo>
		<rfc>47</rfc>
		<lcom>34</lcom>
		<ca>6</ca>
		<ce>25</ce>
		<npm>10</npm>
		<lcom3>0.9090909090909091</lcom3>
		<loc>316</loc>
		<dam>0.8571428571428571</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.23376623376623376</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>24.75</amc>
		<cc>
			<method name="public int execute(org.apache.hadoop.hive.ql.DriverContext driverContext)">2</method>
			<method name="public boolean fetch(java.util.ArrayList res)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="protected void localizeMRTmpFilesImpl(org.apache.hadoop.hive.ql.Context ctx)">4</method>
			<method name="public int getMaxRows()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.TableDesc getTblDesc()">1</method>
			<method name="public void clearFetch()">1</method>
			<method name="public String getName()">1</method>
			<method name="public void setMaxRows(int maxRows)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.StageType getType()">1</method>
			<method name="public void initialize(org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.hive.ql.QueryPlan queryPlan, org.apache.hadoop.hive.ql.DriverContext ctx)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.ppd.OpProcFactory</name>
		<wmc>13</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>42</cbo>
		<rfc>82</rfc>
		<lcom>74</lcom>
		<ca>9</ca>
		<ce>41</ce>
		<npm>9</npm>
		<lcom3>0.875</lcom3>
		<loc>435</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.09523809523809523</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>32.30769230769231</amc>
		<cc>
			<method name="private static org.apache.hadoop.hive.ql.plan.ExprNodeDesc pushFilterToStorageHandler(org.apache.hadoop.hive.ql.exec.TableScanOperator tableScanOp, org.apache.hadoop.hive.ql.plan.ExprNodeDesc originalPredicate, org.apache.hadoop.hive.ql.ppd.OpWalkerInfo owi, org.apache.hadoop.hive.conf.HiveConf hiveConf)">9</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getTSProc()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getLIMProc()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getDefaultProc()">1</method>
			<method name="private void _init_()">0</method>
			<method name="protected static Object createFilter(org.apache.hadoop.hive.ql.exec.Operator op, org.apache.hadoop.hive.ql.ppd.ExprWalkerInfo pushDownPreds, org.apache.hadoop.hive.ql.ppd.OpWalkerInfo owi)">16</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getSCRProc()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getUDTFProc()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getFilterProc()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getRSProc()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getLVFProc()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getJoinProc()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEWAHBitmap$GenericUDAFEWAHBitmapEvaluator$BitmapAgg</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.BooleanObjectInspector</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>26</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>25</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract boolean get(Object)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.AlterTableDesc$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>28</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory$ColumnPrunerSelectProc</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>23</cbo>
		<rfc>42</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>22</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>270</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4166666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>89.0</amc>
		<cc>
			<method name="private void handleChildren(org.apache.hadoop.hive.ql.exec.SelectOperator op, java.util.List retainedSelOutputCols, org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcCtx cppCtx)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.AbstractPrimitiveLazyObjectInspector</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>11</noc>
		<cbo>17</cbo>
		<rfc>5</rfc>
		<lcom>6</lcom>
		<ca>13</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>22</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public org.apache.hadoop.io.Writable getPrimitiveWritableObject(Object o)">2</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils$PrimitiveTypeEntry typeEntry)">0</method>
			<method name="public boolean preferWritable()">1</method>
			<method name="public volatile Object getPrimitiveWritableObject(Object x0)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFBaseNumericOp</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>5</noc>
		<cbo>14</cbo>
		<rfc>17</rfc>
		<lcom>21</lcom>
		<ca>5</ca>
		<ce>9</ce>
		<npm>7</npm>
		<lcom3>1.0</lcom3>
		<loc>54</loc>
		<dam>1.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.2653061224489796</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.857142857142857</amc>
		<cc>
			<method name="public abstract org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable, org.apache.hadoop.hive.serde2.io.DoubleWritable)">1</method>
			<method name="public abstract org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.LongWritable, org.apache.hadoop.io.LongWritable)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public abstract org.apache.hadoop.io.FloatWritable evaluate(org.apache.hadoop.io.FloatWritable, org.apache.hadoop.io.FloatWritable)">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.hive.serde2.io.ShortWritable, org.apache.hadoop.hive.serde2.io.ShortWritable)">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.hive.serde2.io.ByteWritable, org.apache.hadoop.hive.serde2.io.ByteWritable)">1</method>
			<method name="public abstract org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.IntWritable, org.apache.hadoop.io.IntWritable)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFUnion</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>15</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>11</ce>
		<npm>4</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>100</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>23.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.JettyShims$Server</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>4</rfc>
		<lcom>6</lcom>
		<ca>7</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void join()">1</method>
			<method name="public abstract void addWar(String, String)">1</method>
			<method name="public abstract void start()">1</method>
			<method name="public abstract void stop()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.RCFile$Writer</name>
		<wmc>20</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>28</cbo>
		<rfc>90</rfc>
		<lcom>50</lcom>
		<ca>6</ca>
		<ce>23</ce>
		<npm>10</npm>
		<lcom3>0.7692307692307692</lcom3>
		<loc>1001</loc>
		<dam>0.34615384615384615</dam>
		<moa>5</moa>
		<mfa>0.0</mfa>
		<cam>0.19172932330827067</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>47.75</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.fs.Path name)">0</method>
			<method name="public void sync()">1</method>
			<method name="void writeFileHeader()">1</method>
			<method name="public org.apache.hadoop.io.compress.CompressionCodec getCompressionCodec()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void _init_(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.fs.Path name, int bufferSize, short replication, long blockSize, org.apache.hadoop.util.Progressable progress, org.apache.hadoop.io.SequenceFile$Metadata metadata, org.apache.hadoop.io.compress.CompressionCodec codec)">0</method>
			<method name="void init(org.apache.hadoop.fs.Path name, org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.fs.FSDataOutputStream out, org.apache.hadoop.io.compress.CompressionCodec codec, org.apache.hadoop.io.SequenceFile$Metadata metadata)">1</method>
			<method name="private void flushRecords()">1</method>
			<method name="public void append(org.apache.hadoop.io.Writable val)">1</method>
			<method name="org.apache.hadoop.conf.Configuration getConf()">1</method>
			<method name="public long getLength()">1</method>
			<method name="boolean isCompressed()">2</method>
			<method name="public synchronized void close()">1</method>
			<method name="public void _init_(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.fs.Path name, org.apache.hadoop.util.Progressable progress, org.apache.hadoop.io.SequenceFile$Metadata metadata, org.apache.hadoop.io.compress.CompressionCodec codec)">0</method>
			<method name="private void checkAndWriteSync()">1</method>
			<method name="public void _init_(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.fs.Path name, org.apache.hadoop.util.Progressable progress, org.apache.hadoop.io.compress.CompressionCodec codec)">0</method>
			<method name="private void clearColumnBuffers()">1</method>
			<method name="void finalizeFileHeader()">1</method>
			<method name="public void flushBlock(org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer keyBuffer, org.apache.hadoop.hive.ql.io.RCFile$ValueBuffer valueBuffer, int recordLen, int keyLength, int compressedKeyLen)">1</method>
			<method name="void initializeFileHeader()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFHistogramNumeric$GenericUDAFHistogramNumericEvaluator$StdAgg</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$queryStatementExpression_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lib.NodeProcessor</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>142</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>139</ca>
		<ce>3</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public transient abstract Object process(org.apache.hadoop.hive.ql.lib.Node, java.util.Stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx, Object[])">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.UnionObjectInspector</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>3</rfc>
		<lcom>3</lcom>
		<ca>8</ca>
		<ce>1</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>3</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Object getField(Object)">1</method>
			<method name="public abstract java.util.List getObjectInspectors()">1</method>
			<method name="public abstract byte getTag(Object)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyObject</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>2</noc>
		<cbo>11</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>9</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>0.3333333333333333</lcom3>
		<loc>18</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.25</amc>
		<cc>
			<method name="protected org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getInspector()">1</method>
			<method name="public abstract int hashCode()">1</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">0</method>
			<method name="protected void setInspector(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.TaskType</name>
		<wmc>6</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>9</rfc>
		<lcom>9</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>4</npm>
		<lcom3>0.76</lcom3>
		<loc>78</loc>
		<dam>0.4</dam>
		<moa>4</moa>
		<mfa>0.7647058823529411</mfa>
		<cam>0.4</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>11.166666666666666</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.TaskType findByValue(int value)">2</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.TaskType valueOf(String name)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public int getValue()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.TaskType[] values()">1</method>
			<method name="private void _init_(String, int, int value)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$columnName_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.DropDatabaseDesc</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>9</rfc>
		<lcom>10</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>8</npm>
		<lcom3>0.7142857142857143</lcom3>
		<loc>51</loc>
		<dam>0.25</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.875</amc>
		<cc>
			<method name="public void setIfExists(boolean ifExists)">1</method>
			<method name="public void setDatabaseName(String databaseName)">1</method>
			<method name="public void _init_(String databaseName, boolean ifExists)">0</method>
			<method name="public boolean getIfExists()">1</method>
			<method name="public void _init_(String databaseName, boolean ifExists, boolean cascade)">0</method>
			<method name="public void setIsCascade(boolean cascade)">1</method>
			<method name="public String getDatabaseName()">1</method>
			<method name="public boolean isCasdade()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$rowFormatSerde_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndex$ReplaceTableScanOpProc</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>25</cbo>
		<rfc>50</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>25</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>229</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4444444444444444</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>75.33333333333333</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, Object[] nodeOutputs)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndex$1 x0)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.errors.DataCorruptErrorHeuristic</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>23</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.1666666666666667</lcom3>
		<loc>104</loc>
		<dam>0.6666666666666666</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>32.666666666666664</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.exec.errors.ErrorAndSolution getErrorAndSolution()">6</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory$ColumnPrunerFilterProc</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>12</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>11</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>39</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.JavaFloatObjectInspector</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>9</rfc>
		<lcom>10</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>30</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public Object create(float value)">1</method>
			<method name="void _init_()">0</method>
			<method name="public Object getPrimitiveWritableObject(Object o)">2</method>
			<method name="public float get(Object o)">1</method>
			<method name="public Object set(Object o, float value)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>54</cbo>
		<rfc>77</rfc>
		<lcom>41</lcom>
		<ca>26</ca>
		<ce>29</ce>
		<npm>7</npm>
		<lcom3>0.8888888888888888</lcom3>
		<loc>693</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.1746031746031746</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>68.1</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public static java.util.ArrayList getTypeInfosFromTypeString(String typeString)">1</method>
			<method name="public static org.apache.hadoop.hive.serde2.typeinfo.TypeInfo getTypeInfoFromTypeString(String typeString)">1</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getStandardJavaObjectInspectorFromTypeInfo(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo typeInfo)">5</method>
			<method name="public static java.util.List getParameterTypeInfos(java.lang.reflect.Method m, int size)">8</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.typeinfo.TypeInfo getTypeInfoFromObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">5</method>
			<method name="private static org.apache.hadoop.hive.serde2.typeinfo.TypeInfo getExtendedTypeInfoFromJavaType(java.lang.reflect.Type t, java.lang.reflect.Method m)">12</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getStandardWritableObjectInspectorFromTypeInfo(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo typeInfo)">5</method>
			<method name="public static java.lang.reflect.Type getArrayElementType(java.lang.reflect.Type t)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$showRoleGrants_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.HiveIndexResult</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>51</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>17</ce>
		<npm>2</npm>
		<lcom3>0.7999999999999999</lcom3>
		<loc>407</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>99.5</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="public boolean contains(org.apache.hadoop.mapred.FileSplit split)">1</method>
			<method name="private void add(org.apache.hadoop.io.Text line)">1</method>
			<method name="public void _init_(java.util.List indexFiles, org.apache.hadoop.mapred.JobConf conf)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.THttpClient</name>
		<wmc>13</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>68</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>11</ce>
		<npm>12</npm>
		<lcom3>0.6770833333333334</lcom3>
		<loc>517</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3076923076923077</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>38.15384615384615</amc>
		<cc>
			<method name="public boolean isOpen()">1</method>
			<method name="public void open()">1</method>
			<method name="public void setCustomHeader(String key, String value)">2</method>
			<method name="public void setCustomHeaders(java.util.Map headers)">1</method>
			<method name="public void write(byte[] buf, int off, int len)">1</method>
			<method name="public void flush()">1</method>
			<method name="private void flushUsingHttpClient()">1</method>
			<method name="public void close()">2</method>
			<method name="public void setConnectTimeout(int timeout)">2</method>
			<method name="public void _init_(String url)">0</method>
			<method name="public void _init_(String url, org.apache.http.client.HttpClient client)">0</method>
			<method name="public void setReadTimeout(int timeout)">2</method>
			<method name="public int read(byte[] buf, int off, int len)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>26</cbo>
		<rfc>53</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>26</ce>
		<npm>4</npm>
		<lcom3>0.5</lcom3>
		<loc>370</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>72.6</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.io.Writable serialize(Object obj, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objInspector)">1</method>
			<method name="public void initialize(org.apache.hadoop.conf.Configuration job, java.util.Properties tbl)">1</method>
			<method name="public String toString()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ColumnInfo</name>
		<wmc>20</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>36</cbo>
		<rfc>28</rfc>
		<lcom>130</lcom>
		<ca>32</ca>
		<ce>4</ce>
		<npm>20</npm>
		<lcom3>0.7969924812030075</lcom3>
		<loc>149</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.3416666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.1</amc>
		<cc>
			<method name="public boolean isHiddenVirtualCol()">1</method>
			<method name="public boolean getIsVirtualCol()">1</method>
			<method name="public void setVirtualCol(boolean isVirtualCol)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.typeinfo.TypeInfo getType()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getObjectInspector()">1</method>
			<method name="public void _init_(String internalName, Class type, String tabAlias, boolean isVirtualCol)">0</method>
			<method name="public void _init_(String internalName, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objectInspector, String tabAlias, boolean isVirtualCol, boolean isHiddenVirtualCol)">0</method>
			<method name="public void _init_()">0</method>
			<method name="public void setType(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo type)">1</method>
			<method name="public String getInternalName()">1</method>
			<method name="public String getTabAlias()">1</method>
			<method name="public String getAlias()">1</method>
			<method name="public void _init_(String internalName, org.apache.hadoop.hive.serde2.typeinfo.TypeInfo type, String tabAlias, boolean isVirtualCol, boolean isHiddenVirtualCol)">0</method>
			<method name="public void _init_(String internalName, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objectInspector, String tabAlias, boolean isVirtualCol)">0</method>
			<method name="public void _init_(String internalName, org.apache.hadoop.hive.serde2.typeinfo.TypeInfo type, String tabAlias, boolean isVirtualCol)">0</method>
			<method name="public void setHiddenVirtualCol(boolean isHiddenVirtualCol)">1</method>
			<method name="public String toString()">1</method>
			<method name="public void setInternalName(String internalName)">1</method>
			<method name="public void setTabAlias(String tabAlias)">1</method>
			<method name="public void setAlias(String col_alias)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.lineage.OpProcFactory$GroupByLineage</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>21</cbo>
		<rfc>38</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>21</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>206</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>102.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TNonblockingSocket</name>
		<wmc>18</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>43</rfc>
		<lcom>17</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>16</npm>
		<lcom3>0.627450980392157</lcom3>
		<loc>209</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.25</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.444444444444445</amc>
		<cc>
			<method name="public void _init_(String host, int port)">0</method>
			<method name="public void _init_(java.nio.channels.SocketChannel socketChannel)">0</method>
			<method name="public java.nio.channels.SocketChannel getSocketChannel()">1</method>
			<method name="public void write(byte[] buf, int off, int len)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public boolean startConnect()">1</method>
			<method name="public void close()">1</method>
			<method name="public void _init_(String host, int port, int timeout)">0</method>
			<method name="public int write(java.nio.ByteBuffer buffer)">1</method>
			<method name="public int read(byte[] buf, int off, int len)">1</method>
			<method name="public boolean isOpen()">3</method>
			<method name="private void _init_(java.nio.channels.SocketChannel socketChannel, int timeout, java.net.SocketAddress socketAddress)">0</method>
			<method name="public void open()">1</method>
			<method name="public void flush()">1</method>
			<method name="public void setTimeout(int timeout)">1</method>
			<method name="public java.nio.channels.SelectionKey registerSelector(java.nio.channels.Selector selector, int interests)">1</method>
			<method name="public boolean finishConnect()">1</method>
			<method name="public int read(java.nio.ByteBuffer buffer)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TFileProcessor</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>18</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>7</ce>
		<npm>5</npm>
		<lcom3>0.0</lcom3>
		<loc>143</loc>
		<dam>1.0</dam>
		<moa>5</moa>
		<mfa>0.0</mfa>
		<cam>0.4722222222222222</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>22.0</amc>
		<cc>
			<method name="public void _init_(org.apache.thrift.TProcessor processor, org.apache.thrift.protocol.TProtocolFactory inputProtocolFactory, org.apache.thrift.protocol.TProtocolFactory outputProtocolFactory, org.apache.thrift.transport.TFileTransport inputTransport, org.apache.thrift.transport.TTransport outputTransport)">0</method>
			<method name="public void processChunk()">1</method>
			<method name="public void processChunk(int startChunkNum, int endChunkNum)">1</method>
			<method name="private void processUntil(int lastChunk)">1</method>
			<method name="public void processChunk(int chunkNum)">1</method>
			<method name="public void _init_(org.apache.thrift.TProcessor processor, org.apache.thrift.protocol.TProtocolFactory protocolFactory, org.apache.thrift.transport.TFileTransport inputTransport, org.apache.thrift.transport.TTransport outputTransport)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFVarianceSample$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>70</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>68.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.MapOperator$MapInputPath</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>10</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>5</npm>
		<lcom3>0.33333333333333337</lcom3>
		<loc>94</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.45</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>17.2</amc>
		<cc>
			<method name="public void setOp(org.apache.hadoop.hive.ql.exec.Operator op)">1</method>
			<method name="public boolean equals(Object o)">6</method>
			<method name="public int hashCode()">4</method>
			<method name="public org.apache.hadoop.hive.ql.exec.Operator getOp()">1</method>
			<method name="public void _init_(String path, String alias, org.apache.hadoop.hive.ql.exec.Operator op)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.server.TServer</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>3</noc>
		<cbo>8</cbo>
		<rfc>6</rfc>
		<lcom>8</lcom>
		<ca>3</ca>
		<ce>5</ce>
		<npm>3</npm>
		<lcom3>0.9642857142857143</lcom3>
		<loc>47</loc>
		<dam>1.0</dam>
		<moa>6</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public void stop()">1</method>
			<method name="protected void _init_(org.apache.thrift.server.TServer$AbstractServerArgs args)">0</method>
			<method name="protected void setServing(boolean serving)">1</method>
			<method name="public boolean isServing()">1</method>
			<method name="public abstract void serve()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Hadoop23Shims$1</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>1</npm>
		<lcom3>0.5</lcom3>
		<loc>19</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.5</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.shims.Hadoop23Shims, org.apache.hadoop.conf.Configuration x0, org.apache.hadoop.mapreduce.TaskAttemptID x1, org.apache.hadoop.util.Progressable)">0</method>
			<method name="public void progress()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Hadoop23Shims$2</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>21</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.errors.ErrorAndSolution</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>9</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>0.25</lcom3>
		<loc>60</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>10.6</amc>
		<cc>
			<method name="public String getSolution()">1</method>
			<method name="public boolean equals(Object o)">4</method>
			<method name="public int hashCode()">1</method>
			<method name="public String getError()">1</method>
			<method name="void _init_(String error, String solution)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.SettableBinaryObjectInspector</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>4</rfc>
		<lcom>6</lcom>
		<ca>5</ca>
		<ce>3</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Object create(org.apache.hadoop.io.BytesWritable)">1</method>
			<method name="public abstract Object set(Object, org.apache.hadoop.io.BytesWritable)">1</method>
			<method name="public abstract Object create(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef)">1</method>
			<method name="public abstract Object set(Object, org.apache.hadoop.hive.serde2.lazy.ByteArrayRef)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$recordReader_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.TableBasedIndexHandler</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>2</noc>
		<cbo>15</cbo>
		<rfc>37</rfc>
		<lcom>19</lcom>
		<ca>2</ca>
		<ce>13</ce>
		<npm>5</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>206</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2571428571428571</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>28.285714285714285</amc>
		<cc>
			<method name="public org.apache.hadoop.conf.Configuration getConf()">1</method>
			<method name="public java.util.List generateIndexBuildTaskList(org.apache.hadoop.hive.ql.metadata.Table baseTbl, org.apache.hadoop.hive.metastore.api.Index index, java.util.List indexTblPartitions, java.util.List baseTblPartitions, org.apache.hadoop.hive.ql.metadata.Table indexTbl, java.util.Set inputs, java.util.Set outputs)">1</method>
			<method name="public boolean usesIndexTable()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setConf(org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="protected java.util.List getPartKVPairStringArray(java.util.LinkedHashMap partSpec)">2</method>
			<method name="protected abstract org.apache.hadoop.hive.ql.exec.Task getIndexBuilderMapRedTask(java.util.Set, java.util.Set, java.util.List, boolean, org.apache.hadoop.hive.ql.plan.PartitionDesc, String, org.apache.hadoop.hive.ql.plan.PartitionDesc, String, String)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableConstantByteObjectInspector</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>16</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public volatile Object getWritableConstantValue()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable getWritableConstantValue()">1</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.io.ByteWritable value)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat$IgnoreKeyWriter</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>4</npm>
		<lcom3>0.0</lcom3>
		<loc>29</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.0</amc>
		<cc>
			<method name="public void close(org.apache.hadoop.mapred.Reporter reporter)">1</method>
			<method name="public synchronized void write(org.apache.hadoop.io.WritableComparable key, org.apache.hadoop.io.Writable value)">1</method>
			<method name="public volatile void write(Object x0, Object x1)">1</method>
			<method name="public void _init_(org.apache.hadoop.mapred.RecordWriter writer)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.objectinspector.LazyObjectInspectorFactory</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>21</rfc>
		<lcom>13</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>5</npm>
		<lcom3>0.7916666666666666</lcom3>
		<loc>274</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>37.57142857142857</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.lazy.objectinspector.LazyMapObjectInspector getLazySimpleMapObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector mapKeyObjectInspector, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector mapValueObjectInspector, byte itemSeparator, byte keyValueSeparator, org.apache.hadoop.io.Text nullSequence, boolean escaped, byte escapeChar)">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector getLazySimpleStructObjectInspector(java.util.List structFieldNames, java.util.List structFieldObjectInspectors, java.util.List structFieldComments, byte separator, org.apache.hadoop.io.Text nullSequence, boolean lastColumnTakesRest, boolean escaped, byte escapeChar)">3</method>
			<method name="public static org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector getLazySimpleStructObjectInspector(java.util.List structFieldNames, java.util.List structFieldObjectInspectors, byte separator, org.apache.hadoop.io.Text nullSequence, boolean lastColumnTakesRest, boolean escaped, byte escapeChar)">1</method>
			<method name="public static org.apache.hadoop.hive.serde2.lazy.objectinspector.LazyListObjectInspector getLazySimpleListObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector listElementObjectInspector, byte separator, org.apache.hadoop.io.Text nullSequence, boolean escaped, byte escapeChar)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.lazy.objectinspector.LazyUnionObjectInspector getLazyUnionObjectInspector(java.util.List ois, byte separator, org.apache.hadoop.io.Text nullSequence, boolean escaped, byte escapeChar)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.StandardStructObjectInspector$MyField</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>13</rfc>
		<lcom>7</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>0.625</lcom3>
		<loc>60</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4642857142857143</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public int getFieldID()">1</method>
			<method name="public void _init_(int fieldID, String fieldName, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector fieldObjectInspector, String fieldComment)">0</method>
			<method name="public String getFieldComment()">1</method>
			<method name="public String getFieldName()">1</method>
			<method name="public void _init_(int fieldID, String fieldName, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector fieldObjectInspector)">0</method>
			<method name="public String toString()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getFieldObjectInspector()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Utilities$EnumDelegate</name>
		<wmc>3</wmc>
		<dit>3</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>7</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>32</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.875</mfa>
		<cam>0.6666666666666666</cam>
		<ic>2</ic>
		<cbm>3</cbm>
		<amc>9.666666666666666</amc>
		<cc>
			<method name="protected java.beans.Expression instantiate(Object oldInstance, java.beans.Encoder out)">1</method>
			<method name="protected boolean mutatesTo(Object oldInstance, Object newInstance)">2</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$importStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tableOrPartition_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$body_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.session.SessionState$ResourceType$3</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>12</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.7777777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public boolean postHook(java.util.Set cur, String s)">1</method>
			<method name="public String preHook(java.util.Set cur, String s)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyCtx$1</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>1</npm>
		<lcom3>1.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyCtx)">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndex</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>14</rfc>
		<lcom>20</lcom>
		<ca>4</ca>
		<ce>7</ce>
		<npm>3</npm>
		<lcom3>0.7857142857142857</lcom3>
		<loc>43</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.14285714285714285</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.125</amc>
		<cc>
			<method name="static org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndexCtx access$002(org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndexCtx x0)">1</method>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndex$ReplaceTableScanOpProc getReplaceTableScanProc()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndex$NewQuerySelectSchemaProc getNewQuerySelectSchemaProc()">1</method>
			<method name="static org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndexCtx access$000()">1</method>
			<method name="static org.apache.commons.logging.Log access$200()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndex$NewQueryGroupbySchemaProc getNewQueryGroupbySchemaProc()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.QueryProperties</name>
		<wmc>17</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>18</rfc>
		<lcom>88</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>17</npm>
		<lcom3>0.875</lcom3>
		<loc>108</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.7352941176470589</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.882352941176471</amc>
		<cc>
			<method name="public void setHasClusterBy(boolean hasClusterBy)">1</method>
			<method name="public void setHasJoinFollowedByGroupBy(boolean hasJoinFollowedByGroupBy)">1</method>
			<method name="public boolean hasDistributeBy()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public boolean hasJoinFollowedByGroupBy()">1</method>
			<method name="public void setHasJoin(boolean hasJoin)">1</method>
			<method name="public void setUsesScript(boolean usesScript)">1</method>
			<method name="public void setHasOrderBy(boolean hasOrderBy)">1</method>
			<method name="public boolean hasClusterBy()">1</method>
			<method name="public boolean hasGroupBy()">1</method>
			<method name="public boolean hasOrderBy()">1</method>
			<method name="public boolean hasSortBy()">1</method>
			<method name="public void setHasDistributeBy(boolean hasDistributeBy)">1</method>
			<method name="public void setHasGroupBy(boolean hasGroupBy)">1</method>
			<method name="public boolean hasJoin()">1</method>
			<method name="public boolean usesScript()">1</method>
			<method name="public void setHasSortBy(boolean hasSortBy)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ScriptOperator$PathFinder</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>18</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>3</npm>
		<lcom3>0.375</lcom3>
		<loc>123</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.7777777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>38.666666666666664</amc>
		<cc>
			<method name="public void prependPathComponent(String str)">1</method>
			<method name="public java.io.File getAbsolutePath(String filename)">7</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.ScriptOperator, String envpath)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.AutoProgressor$ReporterTask</name>
		<wmc>2</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>8</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>36</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.75</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.0</amc>
		<cc>
			<method name="public void run()">2</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.AutoProgressor, org.apache.hadoop.mapred.Reporter rp)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixAddPartitions_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeConstValue</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.lineage.ExprProcFactory$GenericExprProcessor</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>15</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>80</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>25.333333333333332</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.columnar.ColumnarStruct</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>12</rfc>
		<lcom>8</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>2</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>57</loc>
		<dam>0.3333333333333333</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.8</amc>
		<cc>
			<method name="protected int getLength(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objectInspector, org.apache.hadoop.hive.serde2.lazy.ByteArrayRef cachedByteArrayRef, int start, int fieldLen)">3</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, java.util.ArrayList notSkippedColumnIDs, org.apache.hadoop.io.Text nullSequence)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">0</method>
			<method name="protected org.apache.hadoop.hive.serde2.lazy.LazyObjectBase createLazyObjectBase(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objectInspector)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.formatting.MetaDataFormatUtils</name>
		<wmc>21</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>98</rfc>
		<lcom>210</lcom>
		<ca>2</ca>
		<ce>15</ce>
		<npm>8</npm>
		<lcom3>1.05</lcom3>
		<loc>733</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.11507936507936507</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>33.714285714285715</amc>
		<cc>
			<method name="public static String getAllColumnsInformation(org.apache.hadoop.hive.metastore.api.Index index)">3</method>
			<method name="private static void formatOutput(String col1, String col2, String col3, StringBuilder tableInfo)">1</method>
			<method name="private static void formatColumnsHeader(StringBuilder columnInformation)">1</method>
			<method name="private static void formatAllFields(StringBuilder tableInfo, java.util.List cols)">2</method>
			<method name="public static String getTableInformation(org.apache.hadoop.hive.ql.metadata.Table table)">2</method>
			<method name="private static void formatOutput(String name, String value, StringBuilder tableInfo)">1</method>
			<method name="public static String getAllColumnsInformation(java.util.List cols)">1</method>
			<method name="public static String getIndexColumnsHeader()">1</method>
			<method name="public static String getAllColumnsInformation(java.util.List cols, java.util.List partCols)">3</method>
			<method name="public static String getPartitionInformation(org.apache.hadoop.hive.ql.metadata.Partition part)">2</method>
			<method name="private static void getPartitionMetaDataInformation(StringBuilder tableInfo, org.apache.hadoop.hive.ql.metadata.Partition part)">3</method>
			<method name="private void _init_()">0</method>
			<method name="public static String[] getColumnsHeader()">1</method>
			<method name="private static void getViewInfo(StringBuilder tableInfo, org.apache.hadoop.hive.ql.metadata.Table tbl)">1</method>
			<method name="private static void formatOutput(String[] fields, StringBuilder tableInfo)">3</method>
			<method name="private static String formatDate(long timeInSeconds)">2</method>
			<method name="private static void formatFieldSchemas(StringBuilder tableInfo, org.apache.hadoop.hive.metastore.api.FieldSchema col)">2</method>
			<method name="private static void displayAllParameters(java.util.Map params, StringBuilder tableInfo)">2</method>
			<method name="public static String displayColsUnformatted(java.util.List cols)">3</method>
			<method name="private static void getStorageDescriptorInfo(StringBuilder tableInfo, org.apache.hadoop.hive.metastore.api.StorageDescriptor storageDesc)">3</method>
			<method name="private static void getTableMetaDataInformation(StringBuilder tableInfo, org.apache.hadoop.hive.ql.metadata.Table tbl)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.lineage.OpProcFactory$TableScanLineage</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>25</cbo>
		<rfc>42</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>24</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>144</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>71.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$hintList_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.TFieldIdEnum</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>25</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>25</ca>
		<ce>0</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract String getFieldName()">1</method>
			<method name="public abstract short getThriftFieldId()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileBlockMergeOutputFormat</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>10</rfc>
		<lcom>6</lcom>
		<ca>2</ca>
		<ce>6</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>31</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.75</amc>
		<cc>
			<method name="public static org.apache.hadoop.fs.Path getMergeOutputPath(org.apache.hadoop.mapred.JobConf conf)">2</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.mapred.RecordWriter getRecordWriter(org.apache.hadoop.fs.FileSystem ignored, org.apache.hadoop.mapred.JobConf job, String name, org.apache.hadoop.util.Progressable progress)">1</method>
			<method name="public static void setMergeOutputPath(org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.fs.Path path)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.Driver$QueryState</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>5</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>4</npm>
		<lcom3>0.6666666666666667</lcom3>
		<loc>37</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.666666666666667</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public void init(org.apache.hadoop.hive.ql.plan.HiveOperation op, String cmd)">1</method>
			<method name="public String getCmd()">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.Driver$1 x0)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.HiveOperation getOp()">1</method>
			<method name="public boolean isInitialized()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TProtocolUtil</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>26</cbo>
		<rfc>28</rfc>
		<lcom>9</lcom>
		<ca>15</ca>
		<ce>11</ce>
		<npm>5</npm>
		<lcom3>0.6</lcom3>
		<loc>218</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>35.166666666666664</amc>
		<cc>
			<method name="public static void skip(org.apache.thrift.protocol.TProtocol prot, byte type)">1</method>
			<method name="public static void skip(org.apache.thrift.protocol.TProtocol prot, byte type, int maxDepth)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.thrift.protocol.TProtocolFactory guessProtocolFactory(byte[] data, org.apache.thrift.protocol.TProtocolFactory fallback)">9</method>
			<method name="public static void setMaxSkipDepth(int depth)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.thrift.TBinarySortableProtocol</name>
		<wmc>53</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>89</rfc>
		<lcom>832</lcom>
		<ca>1</ca>
		<ce>16</ce>
		<npm>49</npm>
		<lcom3>0.8962912087912087</lcom3>
		<loc>1876</loc>
		<dam>0.6071428571428571</dam>
		<moa>5</moa>
		<mfa>0.0</mfa>
		<cam>0.07596153846153846</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>33.867924528301884</amc>
		<cc>
			<method name="public void writeI16(short i16)">1</method>
			<method name="public void readFieldEnd()">1</method>
			<method name="public void writeString(String str)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void writeStructEnd()">1</method>
			<method name="public boolean readBool()">1</method>
			<method name="public void writeFieldBegin(org.apache.thrift.protocol.TField field)">1</method>
			<method name="public void writeBinary(java.nio.ByteBuffer bin)">1</method>
			<method name="private void writeRawBytes(byte[] bytes, int begin, int length)">1</method>
			<method name="public void writeListEnd()">1</method>
			<method name="public String readString()">1</method>
			<method name="public void writeMessageBegin(org.apache.thrift.protocol.TMessage message)">1</method>
			<method name="void writeTextBytes(byte[] bytes, int start, int length)">1</method>
			<method name="public org.apache.thrift.protocol.TField readFieldBegin()">1</method>
			<method name="public int readI32()">1</method>
			<method name="public void writeBool(boolean b)">1</method>
			<method name="public void readMapEnd()">1</method>
			<method name="public void writeBinary(byte[] bin, int offset, int length)">1</method>
			<method name="public void readSetEnd()">1</method>
			<method name="public void writeSetBegin(org.apache.thrift.protocol.TSet set)">1</method>
			<method name="public byte readByte()">1</method>
			<method name="public java.nio.ByteBuffer readBinary()">1</method>
			<method name="public void writeSetEnd()">1</method>
			<method name="private int readRawAll(byte[] buf, int off, int len)">1</method>
			<method name="public void writeDouble(double dub)">1</method>
			<method name="public void writeNull()">1</method>
			<method name="public void writeStructBegin(org.apache.thrift.protocol.TStruct struct)">1</method>
			<method name="public org.apache.thrift.protocol.TMap readMapBegin()">1</method>
			<method name="public final boolean readIsNull()">1</method>
			<method name="public void readStructEnd()">1</method>
			<method name="public org.apache.thrift.protocol.TStruct readStructBegin()">1</method>
			<method name="public void writeFieldStop()">1</method>
			<method name="public void writeMapBegin(org.apache.thrift.protocol.TMap map)">1</method>
			<method name="public org.apache.thrift.protocol.TSet readSetBegin()">1</method>
			<method name="public void writeText(org.apache.hadoop.io.Text text)">1</method>
			<method name="public org.apache.thrift.protocol.TMessage readMessageBegin()">1</method>
			<method name="public void writeBinary(byte[] bin)">1</method>
			<method name="public void _init_(org.apache.thrift.transport.TTransport trans)">0</method>
			<method name="public void readListEnd()">1</method>
			<method name="public void writeMapEnd()">1</method>
			<method name="public void writeFieldEnd()">1</method>
			<method name="public void writeListBegin(org.apache.thrift.protocol.TList list)">1</method>
			<method name="public void readMessageEnd()">1</method>
			<method name="public long readI64()">1</method>
			<method name="public short readI16()">1</method>
			<method name="public void writeI64(long i64)">1</method>
			<method name="public org.apache.thrift.protocol.TList readListBegin()">1</method>
			<method name="public double readDouble()">1</method>
			<method name="public void writeMessageEnd()">1</method>
			<method name="public void writeByte(byte b)">1</method>
			<method name="public void writeI32(int i32)">1</method>
			<method name="public boolean lastPrimitiveWasNull()">1</method>
			<method name="public void initialize(org.apache.hadoop.conf.Configuration conf, java.util.Properties tbl)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFStringToMap</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>22</rfc>
		<lcom>2</lcom>
		<ca>0</ca>
		<ce>13</ce>
		<npm>4</npm>
		<lcom3>0.8214285714285714</lcom3>
		<loc>240</loc>
		<dam>0.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>45.6</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$unionType_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFVarianceSample</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>12</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>73</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>35.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] parameters)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HivePartitioner</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract int getBucket(Object, Object, int)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Client$SaslClientCallbackHandler</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>20</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>138</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>33.0</amc>
		<cc>
			<method name="static String encodeIdentifier(byte[] identifier)">1</method>
			<method name="public void handle(javax.security.auth.callback.Callback[] callbacks)">1</method>
			<method name="public void _init_(org.apache.hadoop.security.token.Token token)">0</method>
			<method name="static char[] encodePassword(byte[] password)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.DefaultUDFMethodResolver</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>16</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.5</amc>
		<cc>
			<method name="public java.lang.reflect.Method getEvalMethod(java.util.List argClasses)">1</method>
			<method name="public void _init_(Class udfClass)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ExprNodeNullDesc</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>9</rfc>
		<lcom>15</lcom>
		<ca>8</ca>
		<ce>3</ce>
		<npm>6</npm>
		<lcom3>1.2</lcom3>
		<loc>39</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.333333333333333</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.plan.ExprNodeDesc clone()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public volatile Object clone()">1</method>
			<method name="public boolean isSame(Object o)">3</method>
			<method name="public String getExprString()">1</method>
			<method name="public Object getValue()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.unionproc.UnionProcFactory$UnknownUnion</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>15</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>82</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>40.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.HiveIndexedInputFormat</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>21</cbo>
		<rfc>62</rfc>
		<lcom>7</lcom>
		<ca>1</ca>
		<ce>20</ce>
		<npm>5</npm>
		<lcom3>0.7</lcom3>
		<loc>422</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>69.0</amc>
		<cc>
			<method name="public org.apache.hadoop.mapred.InputSplit[] doGetSplits(org.apache.hadoop.mapred.JobConf job, int numSplits)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void _init_(String indexFileName)">0</method>
			<method name="public static java.util.List getIndexFiles(String indexFileStr)">2</method>
			<method name="public org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf job, int numSplits)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Hadoop20Shims</name>
		<wmc>24</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>36</cbo>
		<rfc>69</rfc>
		<lcom>274</lcom>
		<ca>3</ca>
		<ce>36</ce>
		<npm>24</npm>
		<lcom3>0.9565217391304348</lcom3>
		<loc>272</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.10912698412698413</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.291666666666666</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.shims.HadoopShims$CombineFileInputFormatShim getCombineFileInputFormat()">1</method>
			<method name="public boolean isSecureShimImpl()">1</method>
			<method name="public void prepareJobOutput(org.apache.hadoop.mapred.JobConf conf)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public String[] getTaskJobIDs(org.apache.hadoop.mapred.TaskCompletionEvent t)">1</method>
			<method name="public org.apache.hadoop.hive.shims.HadoopShims$JobTrackerState getJobTrackerState(org.apache.hadoop.mapred.ClusterStatus clusterStatus)">3</method>
			<method name="public void inputFormatValidateInput(org.apache.hadoop.mapred.InputFormat fmt, org.apache.hadoop.mapred.JobConf conf)">1</method>
			<method name="public int compareText(org.apache.hadoop.io.Text a, org.apache.hadoop.io.Text b)">1</method>
			<method name="public int createHadoopArchive(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.fs.Path sourceDir, org.apache.hadoop.fs.Path destDir, String archiveName)">1</method>
			<method name="public org.apache.hadoop.hive.shims.HadoopShims$MiniDFSShim getMiniDfs(org.apache.hadoop.conf.Configuration conf, int numDataNodes, boolean format, String[] racks)">1</method>
			<method name="public void setFloatConf(org.apache.hadoop.conf.Configuration conf, String varName, float val)">1</method>
			<method name="public void doAs(org.apache.hadoop.security.UserGroupInformation ugi, java.security.PrivilegedExceptionAction pvea)">1</method>
			<method name="public String getTokenStrForm(String tokenSignature)">1</method>
			<method name="public boolean fileSystemDeleteOnExit(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path path)">1</method>
			<method name="public org.apache.hadoop.mapreduce.TaskAttemptContext newTaskAttemptContext(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.util.Progressable progressable)">1</method>
			<method name="public org.apache.hadoop.security.UserGroupInformation getUGIForConf(org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="public String getShortUserName(org.apache.hadoop.security.UserGroupInformation ugi)">1</method>
			<method name="public org.apache.hadoop.mapreduce.JobContext newJobContext(org.apache.hadoop.mapreduce.Job job)">1</method>
			<method name="public boolean usesJobShell()">1</method>
			<method name="public long getAccessTime(org.apache.hadoop.fs.FileStatus file)">1</method>
			<method name="public String getInputFormatClassName()">1</method>
			<method name="public boolean isJobPreparing(org.apache.hadoop.mapred.RunningJob job)">1</method>
			<method name="public org.apache.hadoop.security.UserGroupInformation createRemoteUser(String userName, java.util.List groupNames)">1</method>
			<method name="public void setTmpFiles(String prop, String files)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFnGrams$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>61</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>58.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.thrift.WriteTextProtocol</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void writeText(org.apache.hadoop.io.Text)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFMapKeys</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>24</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>11</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>120</loc>
		<dam>0.6666666666666666</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>22.4</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.errors.RegexErrorHeuristic</name>
		<wmc>12</wmc>
		<dit>1</dit>
		<noc>3</noc>
		<cbo>6</cbo>
		<rfc>33</rfc>
		<lcom>20</lcom>
		<ca>3</ca>
		<ce>3</ce>
		<npm>4</npm>
		<lcom3>0.7954545454545454</lcom3>
		<loc>191</loc>
		<dam>0.875</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.45454545454545453</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.25</amc>
		<cc>
			<method name="protected void reset()">2</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public abstract org.apache.hadoop.hive.ql.exec.errors.ErrorAndSolution getErrorAndSolution()">1</method>
			<method name="protected java.util.Map getRegexToLogLines()">1</method>
			<method name="protected boolean getQueryMatches()">1</method>
			<method name="protected org.apache.hadoop.mapred.JobConf getConf()">1</method>
			<method name="protected java.util.Set getLogRegexes()">1</method>
			<method name="public void init(String query, org.apache.hadoop.mapred.JobConf conf)">5</method>
			<method name="public void processLogLine(String line)">3</method>
			<method name="protected void setQueryRegex(String queryRegex)">1</method>
			<method name="protected String getQueryRegex()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.async.TAsyncClientManager$SelectThread</name>
		<wmc>7</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>53</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>4</npm>
		<lcom3>0.4583333333333333</lcom3>
		<loc>241</loc>
		<dam>0.75</dam>
		<moa>1</moa>
		<mfa>0.9142857142857143</mfa>
		<cam>0.5714285714285714</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>32.857142857142854</amc>
		<cc>
			<method name="private void transitionMethods()">3</method>
			<method name="private void timeoutMethods()">3</method>
			<method name="public void _init_(org.apache.thrift.async.TAsyncClientManager)">0</method>
			<method name="public void run()">4</method>
			<method name="private void startPendingMethods()">2</method>
			<method name="public java.nio.channels.Selector getSelector()">1</method>
			<method name="public void finish()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$privilegeObject_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixSerdeProperties_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$statement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$grantPrivileges_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.JobCloseFeedBack</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>9</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>3</npm>
		<lcom3>0.0</lcom3>
		<loc>41</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.333333333333334</amc>
		<cc>
			<method name="public java.util.List get(org.apache.hadoop.hive.ql.exec.JobCloseFeedBack$FeedBackType t)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void append(org.apache.hadoop.hive.ql.exec.JobCloseFeedBack$FeedBackType t, Object v)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.PlanUtils</name>
		<wmc>33</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>37</cbo>
		<rfc>107</rfc>
		<lcom>522</lcom>
		<ca>13</ca>
		<ce>26</ce>
		<npm>30</npm>
		<lcom3>0.9166666666666666</lcom3>
		<loc>1108</loc>
		<dam>0.6666666666666666</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.203125</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>32.484848484848484</amc>
		<cc>
			<method name="public static void configureOutputJobPropertiesForStorageHandler(org.apache.hadoop.hive.ql.plan.TableDesc tableDesc)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.ReduceSinkDesc getReduceSinkDesc(java.util.ArrayList keyCols, int numKeys, java.util.ArrayList valueCols, java.util.List distinctColIndices, java.util.List outputKeyColumnNames, java.util.List outputValueColumnNames, boolean includeKeyCols, int tag, java.util.ArrayList partitionCols, String order, int numReducers)">3</method>
			<method name="public static java.util.List sortFieldSchemas(java.util.List schema)">1</method>
			<method name="public static java.util.List getFieldSchemasFromColumnListWithLength(java.util.List cols, java.util.List distinctColIndices, java.util.List outputColumnNames, int length, String fieldPrefix)">5</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.TableDesc getMapJoinValueTableDesc(java.util.List fieldSchemas)">1</method>
			<method name="public static void configureInputJobPropertiesForStorageHandler(org.apache.hadoop.hive.ql.plan.TableDesc tableDesc)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.ReduceSinkDesc getReduceSinkDesc(java.util.ArrayList keyCols, java.util.ArrayList valueCols, java.util.List outputColumnNames, boolean includeKey, int tag, int numPartitionFields, int numReducers)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.TableDesc getReduceKeyTableDesc(java.util.List fieldSchemas, String order)">1</method>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.ReduceSinkDesc getReduceSinkDesc(java.util.ArrayList keyCols, int numKeys, java.util.ArrayList valueCols, java.util.List distinctColIndices, java.util.List outputKeyColumnNames, java.util.List outputValueColumnNames, boolean includeKey, int tag, int numPartitionFields, int numReducers)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.TableDesc getIntermediateFileTableDesc(java.util.List fieldSchemas)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.TableDesc getTableDesc(Class serdeClass, String separatorCode, String columns, String columnTypes, boolean lastColumnTakesRestOfTheLine)">1</method>
			<method name="public static long getCountForMapJoinDumpFilePrefix()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.TableDesc getDefaultTableDesc(String separatorCode)">1</method>
			<method name="public static java.util.List getFieldSchemasFromColumnInfo(java.util.ArrayList cols, String fieldPrefix)">5</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.TableDesc getTableDesc(org.apache.hadoop.hive.ql.plan.CreateTableDesc crtTblDesc, String cols, String colTypes)">9</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.TableDesc getDefaultTableDesc(String separatorCode, String columns)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.TableDesc getTableDesc(Class serdeClass, String separatorCode, String columns, boolean lastColumnTakesRestOfTheLine)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.TableDesc getTableDesc(Class serdeClass, String separatorCode, String columns)">1</method>
			<method name="private static void configureJobPropertiesForStorageHandler(boolean input, org.apache.hadoop.hive.ql.plan.TableDesc tableDesc)">3</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.TableDesc getReduceValueTableDesc(java.util.List fieldSchemas)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.TableDesc getDefaultTableDesc(String separatorCode, String columns, boolean lastColumnTakesRestOfTheLine)">1</method>
			<method name="public static java.util.List getFieldSchemasFromColumnList(java.util.List cols, java.util.List outputColumnNames, int start, String fieldPrefix)">2</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.ReduceSinkDesc getReduceSinkDesc(java.util.ArrayList keyCols, java.util.ArrayList valueCols, java.util.List outputColumnNames, boolean includeKeyCols, int tag, java.util.ArrayList partitionCols, String order, int numReducers)">3</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.TableDesc getMapJoinKeyTableDesc(java.util.List fieldSchemas)">1</method>
			<method name="public static java.util.List getFieldSchemasFromColumnList(java.util.List cols, String fieldPrefix)">2</method>
			<method name="public static java.util.List getFieldSchemasFromRowSchema(org.apache.hadoop.hive.ql.exec.RowSchema row, String fieldPrefix)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.TableDesc getDefaultQueryOutputTableDesc(String cols, String colTypes, String fileFormat)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.TableDesc getTableDesc(Class serdeClass, String separatorCode, String columns, String columnTypes, boolean lastColumnTakesRestOfTheLine, boolean useDelimitedJSON)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.TableDesc getDefaultTableDesc(String separatorCode, String columns, String columnTypes, boolean lastColumnTakesRestOfTheLine)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.MapredWork getMapRedWork()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.TableDesc getTableDesc(Class serdeClass, String separatorCode, String columns, String columnTypes, boolean lastColumnTakesRestOfTheLine, boolean useDelimitedJSON, String fileFormat)">9</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.Sample</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>18</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>8</npm>
		<lcom3>0.4642857142857143</lcom3>
		<loc>166</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>19.25</amc>
		<cc>
			<method name="public boolean inSample(Object o)">2</method>
			<method name="public boolean equals(Object o)">7</method>
			<method name="public int hashCode()">2</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Dimension getSampleDimension()">1</method>
			<method name="public void _init_(int num, int fraction, org.apache.hadoop.hive.ql.metadata.Dimension d)">0</method>
			<method name="public int getSampleNum()">1</method>
			<method name="public String toString()">1</method>
			<method name="public int getSampleFraction()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.GroupByOptimizer$GroupByOptProcCtx</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>8</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.optimizer.GroupByOptimizer)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.FetchOperator</name>
		<wmc>25</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>37</cbo>
		<rfc>99</rfc>
		<lcom>150</lcom>
		<ca>4</ca>
		<ce>33</ce>
		<npm>19</npm>
		<lcom3>0.8617424242424242</lcom3>
		<loc>856</loc>
		<dam>0.9090909090909091</dam>
		<moa>6</moa>
		<mfa>0.0</mfa>
		<cam>0.1284722222222222</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>32.36</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.InspectableObject getNextRow()">1</method>
			<method name="public boolean isEmptyTable()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getOutputObjectInspector()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.PartitionDesc getCurrPart()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.FetchWork getWork()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void setEmptyTable(boolean isEmptyTable)">1</method>
			<method name="public int getSplitNum()">1</method>
			<method name="public void initialize(org.apache.hadoop.mapred.JobConf job)">3</method>
			<method name="public org.apache.hadoop.hive.ql.plan.TableDesc getCurrTbl()">1</method>
			<method name="public void setSplitNum(int splitNum)">1</method>
			<method name="public void setWork(org.apache.hadoop.hive.ql.plan.FetchWork work)">1</method>
			<method name="public void setCurrTbl(org.apache.hadoop.hive.ql.plan.TableDesc currTbl)">1</method>
			<method name="static org.apache.hadoop.mapred.InputFormat getInputFormatFromCache(Class inputFormatClass, org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.FetchWork work, org.apache.hadoop.mapred.JobConf job)">0</method>
			<method name="private org.apache.hadoop.fs.FileStatus[] listStatusUnderPath(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path p)">1</method>
			<method name="public void setupContext(java.util.Iterator iterPath, java.util.Iterator iterPartDesc)">3</method>
			<method name="private void getNextPath()">1</method>
			<method name="private org.apache.hadoop.mapred.RecordReader getRecordReader()">1</method>
			<method name="public void setCurrPart(org.apache.hadoop.hive.ql.plan.PartitionDesc currPart)">1</method>
			<method name="private void setPrtnDesc()">1</method>
			<method name="public void clearFetchContext()">1</method>
			<method name="public void setTblDataDone(boolean tblDataDone)">1</method>
			<method name="public boolean isTblDataDone()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.unionproc.UnionProcFactory$MapRedUnion</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>12</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>46</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>22.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.NonSyncDataInputBuffer</name>
		<wmc>28</wmc>
		<dit>3</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>52</rfc>
		<lcom>244</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>24</npm>
		<lcom3>0.7222222222222222</lcom3>
		<loc>695</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.4090909090909091</mfa>
		<cam>0.26785714285714285</cam>
		<ic>1</ic>
		<cbm>7</cbm>
		<amc>23.75</amc>
		<cc>
			<method name="public final void readFully(byte[] buffer, int offset, int length)">1</method>
			<method name="private static String decodeUTF(int utfSize, java.io.DataInput in)">1</method>
			<method name="public void reset(byte[] input, int length)">1</method>
			<method name="private int readToBuff(int count)">1</method>
			<method name="public final short readShort()">1</method>
			<method name="public final char readChar()">1</method>
			<method name="public final long readLong()">1</method>
			<method name="public final int readUnsignedByte()">1</method>
			<method name="public int getLength()">1</method>
			<method name="public final float readFloat()">1</method>
			<method name="public final int readUnsignedShort()">1</method>
			<method name="public final byte readByte()">1</method>
			<method name="public void _init_()">0</method>
			<method name="String decodeUTF(int utfSize)">1</method>
			<method name="public final int read(byte[] buffer, int offset, int length)">1</method>
			<method name="public final void readFully(byte[] buffer)">1</method>
			<method name="public int getPosition()">1</method>
			<method name="public static String convertUTF8WithBuf(byte[] buf, char[] out, int offset, int utfSize)">1</method>
			<method name="private void _init_(org.apache.hadoop.hive.common.io.NonSyncByteArrayInputStream buffer)">0</method>
			<method name="public final double readDouble()">1</method>
			<method name="public final int readInt()">1</method>
			<method name="public static final String readUTF(java.io.DataInput in)">1</method>
			<method name="public final String readUTF()">1</method>
			<method name="public final boolean readBoolean()">1</method>
			<method name="public final String readLine()">1</method>
			<method name="public void reset(byte[] input, int start, int length)">1</method>
			<method name="public final int skipBytes(int count)">1</method>
			<method name="public final int read(byte[] buffer)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.HadoopShimsSecure$MiniDFSShim</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>22</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.666666666666667</amc>
		<cc>
			<method name="public void shutdown()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.shims.HadoopShimsSecure, org.apache.hadoop.hdfs.MiniDFSCluster cluster)">0</method>
			<method name="public org.apache.hadoop.fs.FileSystem getFileSystem()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.GroupByOptimizer$1</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>1</npm>
		<lcom3>1.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.ql.optimizer.GroupByOptimizer)">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFEWAHBitmapEmpty</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>33</rfc>
		<lcom>6</lcom>
		<ca>0</ca>
		<ce>18</ce>
		<npm>4</npm>
		<lcom3>0.8333333333333333</lcom3>
		<loc>191</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>36.6</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Hadoop20Shims$NullOutputCommitter</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>8</rfc>
		<lcom>21</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>7</npm>
		<lcom3>2.0</lcom3>
		<loc>17</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6190476190476191</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>1.4285714285714286</amc>
		<cc>
			<method name="public void setupJob(org.apache.hadoop.mapred.JobContext jobContext)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void commitTask(org.apache.hadoop.mapred.TaskAttemptContext taskContext)">1</method>
			<method name="public void setupTask(org.apache.hadoop.mapred.TaskAttemptContext taskContext)">1</method>
			<method name="public void cleanupJob(org.apache.hadoop.mapred.JobContext jobContext)">1</method>
			<method name="public void abortTask(org.apache.hadoop.mapred.TaskAttemptContext taskContext)">1</method>
			<method name="public boolean needsTaskCommit(org.apache.hadoop.mapred.TaskAttemptContext taskContext)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.session.CreateTableAutomaticGrant</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>26</rfc>
		<lcom>22</lcom>
		<ca>2</ca>
		<ce>10</ce>
		<npm>5</npm>
		<lcom3>0.8571428571428571</lcom3>
		<loc>280</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>33.625</amc>
		<cc>
			<method name="private static java.util.Map getGrantMap(String grantMapStr)">1</method>
			<method name="public java.util.Map getUserGrants()">1</method>
			<method name="private static void checkPrivilege(String ownerGrantsInConfig)">1</method>
			<method name="private static java.util.List getGrantorInfoList(String privList)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.Map getGroupGrants()">1</method>
			<method name="public java.util.Map getRoleGrants()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.session.CreateTableAutomaticGrant create(org.apache.hadoop.hive.conf.HiveConf conf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.security.authorization.PrivilegeScope</name>
		<wmc>6</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>11</rfc>
		<lcom>7</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>4</npm>
		<lcom3>0.9</lcom3>
		<loc>97</loc>
		<dam>0.25</dam>
		<moa>5</moa>
		<mfa>0.7647058823529411</mfa>
		<cam>0.4</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>13.833333333333334</amc>
		<cc>
			<method name="public void setMode(short mode)">1</method>
			<method name="public short getMode()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.security.authorization.PrivilegeScope valueOf(String name)">1</method>
			<method name="private void _init_(String, int, short mode)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.security.authorization.PrivilegeScope[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.proto.test.Complexpb</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="private void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.TypeCheckCtx</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>11</rfc>
		<lcom>27</lcom>
		<ca>8</ca>
		<ce>4</ce>
		<npm>10</npm>
		<lcom3>0.8222222222222223</lcom3>
		<loc>61</loc>
		<dam>1.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.26666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.6</amc>
		<cc>
			<method name="public boolean getAllowStatefulFunctions()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.UnparseTranslator getUnparseTranslator()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.parse.RowResolver inputRR)">0</method>
			<method name="public String getError()">1</method>
			<method name="public void setInputRR(org.apache.hadoop.hive.ql.parse.RowResolver inputRR)">1</method>
			<method name="public void setUnparseTranslator(org.apache.hadoop.hive.ql.parse.UnparseTranslator unparseTranslator)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ASTNode getErrorSrcNode()">1</method>
			<method name="public void setAllowStatefulFunctions(boolean allowStatefulFunctions)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.RowResolver getInputRR()">1</method>
			<method name="public void setError(String error, org.apache.hadoop.hive.ql.parse.ASTNode errorSrcNode)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.session.SessionState$ResourceType$1</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>12</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.7777777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public boolean postHook(java.util.Set cur, String s)">1</method>
			<method name="public String preHook(java.util.Set cur, String s)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.session.SessionState$ResourceType$2</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>24</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.7777777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public boolean postHook(java.util.Set cur, String s)">1</method>
			<method name="public String preHook(java.util.Set cur, String s)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.util.DosToUnix</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>27</rfc>
		<lcom>6</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>189</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>46.25</amc>
		<cc>
			<method name="public static boolean isWindowsScript(java.io.File file)">4</method>
			<method name="public void _init_()">0</method>
			<method name="public static String getUnixScriptNameFor(String windowsScriptFilename)">2</method>
			<method name="public static String convertWindowsScriptToUnix(java.io.File windowsScriptFile)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.columnar.BytesRefArrayWritable</name>
		<wmc>16</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>32</rfc>
		<lcom>0</lcom>
		<ca>9</ca>
		<ce>5</ce>
		<npm>14</npm>
		<lcom3>0.2</lcom3>
		<loc>281</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.26666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.4375</amc>
		<cc>
			<method name="public void clear()">1</method>
			<method name="protected void ensureCapacity(int newCapacity)">3</method>
			<method name="public boolean equals(Object o)">4</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void _init_(int capacity)">0</method>
			<method name="public void write(java.io.DataOutput out)">1</method>
			<method name="public void set(int index, org.apache.hadoop.hive.serde2.columnar.BytesRefWritable bytesRefWritable)">3</method>
			<method name="public void readFields(java.io.DataInput in)">1</method>
			<method name="public volatile int compareTo(Object x0)">1</method>
			<method name="public int size()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.columnar.BytesRefWritable get(int index)">2</method>
			<method name="public int compareTo(org.apache.hadoop.hive.serde2.columnar.BytesRefArrayWritable other)">6</method>
			<method name="public void resetValid(int newValidCapacity)">1</method>
			<method name="public boolean contains(org.apache.hadoop.hive.serde2.columnar.BytesRefWritable bytesRefWritable)">4</method>
			<method name="public org.apache.hadoop.hive.serde2.columnar.BytesRefWritable unCheckedGet(int index)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.SMBJoinDesc</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>8</rfc>
		<lcom>11</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>6</npm>
		<lcom3>0.9333333333333333</lcom3>
		<loc>30</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.5</amc>
		<cc>
			<method name="public java.util.HashMap getTagToAlias()">1</method>
			<method name="public void setTagToAlias(java.util.HashMap tagToAlias)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.MapredLocalWork getLocalWork()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.MapJoinDesc conf)">0</method>
			<method name="public void setLocalWork(org.apache.hadoop.hive.ql.plan.MapredLocalWork localWork)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.SettableFloatObjectInspector</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Object set(Object, float)">1</method>
			<method name="public abstract Object create(float)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFToString</name>
		<wmc>12</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>35</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>15</ce>
		<npm>12</npm>
		<lcom3>0.6590909090909091</lcom3>
		<loc>258</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.1597222222222222</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>20.166666666666668</amc>
		<cc>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.hive.serde2.io.ByteWritable i)">2</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable i)">2</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.hive.serde2.io.ShortWritable i)">2</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text i)">2</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.IntWritable i)">2</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.LongWritable i)">2</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.BytesWritable bw)">2</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable i)">2</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.NullWritable i)">1</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.BooleanWritable i)">3</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.FloatWritable i)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyString</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>15</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>6</ce>
		<npm>3</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>141</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>34.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.LazyString copy)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">7</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyStringObjectInspector oi)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.persistence.RowContainer</name>
		<wmc>22</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>34</cbo>
		<rfc>80</rfc>
		<lcom>95</lcom>
		<ca>7</ca>
		<ce>27</ce>
		<npm>14</npm>
		<lcom3>0.631336405529954</lcom3>
		<loc>1075</loc>
		<dam>0.6129032258064516</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.1391941391941392</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>46.45454545454545</amc>
		<cc>
			<method name="public void clear()">1</method>
			<method name="public volatile void add(Object x0)">1</method>
			<method name="private void closeReader()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void setTableDesc(org.apache.hadoop.hive.ql.plan.TableDesc tblDesc)">1</method>
			<method name="public java.util.List next()">1</method>
			<method name="public java.util.List first()">1</method>
			<method name="public volatile Object next()">1</method>
			<method name="private void spillBlock(java.util.List[] block, int length)">1</method>
			<method name="private boolean nextBlock()">1</method>
			<method name="private void closeWriter()">1</method>
			<method name="public void add(java.util.List t)">1</method>
			<method name="public int size()">1</method>
			<method name="public void setKeyObject(java.util.List dummyKey)">1</method>
			<method name="public void copyToDFSDirecory(org.apache.hadoop.fs.FileSystem destFs, org.apache.hadoop.fs.Path destPath)">1</method>
			<method name="public volatile Object first()">1</method>
			<method name="private void removeKeys(java.util.List ret)">4</method>
			<method name="private void deleteLocalFile(java.io.File file, boolean recursive)">5</method>
			<method name="private org.apache.hadoop.mapred.JobConf getLocalFSJobConfClone(org.apache.hadoop.conf.Configuration jc)">2</method>
			<method name="public void _init_(org.apache.hadoop.conf.Configuration jc)">0</method>
			<method name="public void setSerDe(org.apache.hadoop.hive.serde2.SerDe sd, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">1</method>
			<method name="public void _init_(int bs, org.apache.hadoop.conf.Configuration jc)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryStruct</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>33</rfc>
		<lcom>14</lcom>
		<ca>3</ca>
		<ce>13</ce>
		<npm>5</npm>
		<lcom3>0.6770833333333333</lcom3>
		<loc>359</loc>
		<dam>0.08333333333333333</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.40625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>37.55555555555556</amc>
		<cc>
			<method name="public long getRawDataSerializedSize()">1</method>
			<method name="public java.util.ArrayList getFieldsAsList()">4</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object getField(int fieldID)">2</method>
			<method name="private void parse()">13</method>
			<method name="private Object uncheckedGetField(int fieldID)">3</method>
			<method name="public Object getObject()">1</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.lazybinary.objectinspector.LazyBinaryStructObjectInspector oi)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.FlatFileInputFormat$SerializationContext</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Class getRealClass()">1</method>
			<method name="public abstract org.apache.hadoop.io.serializer.Serialization getSerialization()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryFloat</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>15</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>1</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>54</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.25</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableFloatObjectInspector oi)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryFloat copy)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.Stage</name>
		<wmc>68</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>25</cbo>
		<rfc>162</rfc>
		<lcom>1388</lcom>
		<ca>2</ca>
		<ce>23</ce>
		<npm>65</npm>
		<lcom3>0.842890809112333</lcom3>
		<loc>1895</loc>
		<dam>0.9473684210526315</dam>
		<moa>9</moa>
		<mfa>0.0</mfa>
		<cam>0.10167910447761194</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>26.58823529411765</amc>
		<cc>
			<method name="public boolean equals(org.apache.hadoop.hive.ql.plan.api.Stage that)">37</method>
			<method name="public int getStageCountersSize()">2</method>
			<method name="public boolean isStarted()">1</method>
			<method name="public void setStageId(String stageId)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void setStageCountersIsSet(boolean value)">2</method>
			<method name="public void setDoneIsSet(boolean value)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.Stage deepCopy()">1</method>
			<method name="public volatile boolean isSet(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="public void setStageIdIsSet(boolean value)">2</method>
			<method name="public void setFieldValue(org.apache.hadoop.hive.ql.plan.api.Stage$_Fields field, Object value)">9</method>
			<method name="public void unsetTaskList()">1</method>
			<method name="public void unsetStageId()">1</method>
			<method name="public void setStageAttributes(java.util.Map stageAttributes)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.StageType getStageType()">1</method>
			<method name="public void unsetStarted()">1</method>
			<method name="public void unsetStageType()">1</method>
			<method name="public boolean isSetStarted()">1</method>
			<method name="public void validate()">1</method>
			<method name="public boolean isDone()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setStartedIsSet(boolean value)">1</method>
			<method name="public volatile void setFieldValue(org.apache.thrift.TFieldIdEnum x0, Object x1)">1</method>
			<method name="public boolean isSetTaskList()">2</method>
			<method name="public volatile int compareTo(Object x0)">1</method>
			<method name="public void putToStageAttributes(String key, String val)">2</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.api.Stage other)">0</method>
			<method name="public void setTaskList(java.util.List taskList)">1</method>
			<method name="public int getStageAttributesSize()">2</method>
			<method name="public Object getFieldValue(org.apache.hadoop.hive.ql.plan.api.Stage$_Fields field)">2</method>
			<method name="public void _init_(String stageId, org.apache.hadoop.hive.ql.plan.api.StageType stageType, java.util.Map stageAttributes, java.util.Map stageCounters, java.util.List taskList, boolean done, boolean started)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.Stage$_Fields fieldForId(int fieldId)">1</method>
			<method name="public boolean equals(Object that)">3</method>
			<method name="public boolean isSetStageType()">2</method>
			<method name="public boolean isSetDone()">1</method>
			<method name="public void clear()">1</method>
			<method name="public void setStarted(boolean started)">1</method>
			<method name="public void setDone(boolean done)">1</method>
			<method name="public java.util.Map getStageAttributes()">1</method>
			<method name="public volatile org.apache.thrift.TBase deepCopy()">1</method>
			<method name="public volatile Object getFieldValue(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="private void writeObject(java.io.ObjectOutputStream out)">1</method>
			<method name="public boolean isSetStageId()">2</method>
			<method name="public void addToTaskList(org.apache.hadoop.hive.ql.plan.api.Task elem)">2</method>
			<method name="public void read(org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public void write(org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public void putToStageCounters(String key, long val)">2</method>
			<method name="public boolean isSetStageCounters()">2</method>
			<method name="public java.util.Map getStageCounters()">1</method>
			<method name="public String getStageId()">1</method>
			<method name="public void setStageCounters(java.util.Map stageCounters)">1</method>
			<method name="public void setTaskListIsSet(boolean value)">2</method>
			<method name="public String toString()">12</method>
			<method name="public void setStageType(org.apache.hadoop.hive.ql.plan.api.StageType stageType)">1</method>
			<method name="public java.util.List getTaskList()">1</method>
			<method name="public java.util.Iterator getTaskListIterator()">2</method>
			<method name="public void unsetStageAttributes()">1</method>
			<method name="public boolean isSet(org.apache.hadoop.hive.ql.plan.api.Stage$_Fields field)">3</method>
			<method name="public int compareTo(org.apache.hadoop.hive.ql.plan.api.Stage other)">23</method>
			<method name="public boolean isSetStageAttributes()">2</method>
			<method name="public int getTaskListSize()">2</method>
			<method name="public void unsetStageCounters()">1</method>
			<method name="public void unsetDone()">1</method>
			<method name="public int hashCode()">1</method>
			<method name="public void setStageAttributesIsSet(boolean value)">2</method>
			<method name="private void readObject(java.io.ObjectInputStream in)">1</method>
			<method name="public volatile org.apache.thrift.TFieldIdEnum fieldForId(int x0)">1</method>
			<method name="public void setStageTypeIsSet(boolean value)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.TypedSerDe</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>1</noc>
		<cbo>10</cbo>
		<rfc>23</rfc>
		<lcom>30</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>7</npm>
		<lcom3>0.90625</lcom3>
		<loc>100</loc>
		<dam>0.75</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.25</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.666666666666666</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getObjectInspector()">1</method>
			<method name="public void _init_(java.lang.reflect.Type objectType)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object deserialize(org.apache.hadoop.io.Writable blob)">1</method>
			<method name="public Class getSerializedClass()">1</method>
			<method name="public org.apache.hadoop.io.Writable serialize(Object obj, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objInspector)">1</method>
			<method name="public void initialize(org.apache.hadoop.conf.Configuration job, java.util.Properties tbl)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.SerDeStats getSerDeStats()">1</method>
			<method name="protected org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory$ObjectInspectorOptions getObjectInspectorOptions()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ConditionalResolver</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>8</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract java.util.List getTasks(org.apache.hadoop.hive.conf.HiveConf, Object)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.lineage.Generator</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>27</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>15</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>130</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>64.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext transform(org.apache.hadoop.hive.ql.parse.ParseContext pctx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFDayOfMonth</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>13</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>0.16666666666666674</lcom3>
		<loc>69</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>21.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable t)">2</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.Text dateString)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.StandardUnionObjectInspector</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>16</rfc>
		<lcom>19</lcom>
		<ca>5</ca>
		<ce>4</ce>
		<npm>7</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>56</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.47619047619047616</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.857142857142857</amc>
		<cc>
			<method name="public byte getTag(Object o)">2</method>
			<method name="public Object getField(Object o)">2</method>
			<method name="public String getTypeName()">1</method>
			<method name="public void _init_(java.util.List ois)">0</method>
			<method name="public String toString()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
			<method name="public java.util.List getObjectInspectors()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.DelimitedJSONSerDe</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>22</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>13</ce>
		<npm>2</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>62</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4444444444444444</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.25</amc>
		<cc>
			<method name="protected void serializeField(org.apache.hadoop.hive.serde2.ByteStream$Output out, Object obj, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objInspector, org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe$SerDeParameters serdeParams)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object deserialize(org.apache.hadoop.io.Writable field)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.MapOperator$Counter</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>34</loc>
		<dam>0.5</dam>
		<moa>2</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.MapOperator$Counter valueOf(String name)">1</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.MapOperator$Counter[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.NoMatchingMethodException</name>
		<wmc>1</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>8</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>27</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>25.0</amc>
		<cc>
			<method name="public void _init_(Class funcClass, java.util.List argTypeInfos, java.util.List methods)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.DDLTask$1</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>8</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>44</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.333333333333334</amc>
		<cc>
			<method name="public volatile int compare(Object x0, Object x1)">1</method>
			<method name="public int compare(org.apache.hadoop.hive.ql.lockmgr.HiveLock o1, org.apache.hadoop.hive.ql.lockmgr.HiveLock o2)">4</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.exec.DDLTask)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.DDLTask$2</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>61</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>58.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFMap</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>25</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>16</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>299</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>58.2</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$dropTableStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFFindInSet</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>123</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>60.0</amc>
		<cc>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.Text s, org.apache.hadoop.io.Text txtarray)">14</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.server.TThreadPoolServer$Args</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>3</npm>
		<lcom3>0.75</lcom3>
		<loc>33</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.666666666666666</amc>
		<cc>
			<method name="public void _init_(org.apache.thrift.transport.TServerTransport transport)">0</method>
			<method name="public org.apache.thrift.server.TThreadPoolServer$Args maxWorkerThreads(int n)">1</method>
			<method name="public org.apache.thrift.server.TThreadPoolServer$Args minWorkerThreads(int n)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.MapJoinFactory$TableScanMapJoin</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>28</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>12</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>116</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>37.333333333333336</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.ppd.ExprWalkerProcFactory$FieldExprProcessor</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>17</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>93</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>29.666666666666668</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.SettableDoubleObjectInspector</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Object set(Object, double)">1</method>
			<method name="public abstract Object create(double)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde.test.ThriftTestObj$_Fields</name>
		<wmc>9</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>24</rfc>
		<lcom>26</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>0.7857142857142857</lcom3>
		<loc>140</loc>
		<dam>0.5714285714285714</dam>
		<moa>4</moa>
		<mfa>0.65</mfa>
		<cam>0.3125</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>13.777777777777779</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.serde.test.ThriftTestObj$_Fields findByThriftId(int fieldId)">2</method>
			<method name="public static org.apache.hadoop.hive.serde.test.ThriftTestObj$_Fields[] values()">1</method>
			<method name="private void _init_(String, int, short thriftId, String fieldName)">0</method>
			<method name="public String getFieldName()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde.test.ThriftTestObj$_Fields valueOf(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.serde.test.ThriftTestObj$_Fields findByThriftIdOrThrow(int fieldId)">2</method>
			<method name="public short getThriftFieldId()">1</method>
			<method name="public static org.apache.hadoop.hive.serde.test.ThriftTestObj$_Fields findByName(String name)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.objectinspector.LazyBinaryObjectInspectorFactory</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>16</rfc>
		<lcom>9</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>4</npm>
		<lcom3>0.7333333333333333</lcom3>
		<loc>129</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>20.0</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.lazybinary.objectinspector.LazyBinaryStructObjectInspector getLazyBinaryStructObjectInspector(java.util.List structFieldNames, java.util.List structFieldObjectInspectors, java.util.List structFieldComments)">3</method>
			<method name="public static org.apache.hadoop.hive.serde2.lazybinary.objectinspector.LazyBinaryMapObjectInspector getLazyBinaryMapObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector mapKeyObjectInspector, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector mapValueObjectInspector)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.lazybinary.objectinspector.LazyBinaryListObjectInspector getLazyBinaryListObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector listElementObjectInspector)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.lazybinary.objectinspector.LazyBinaryStructObjectInspector getLazyBinaryStructObjectInspector(java.util.List structFieldNames, java.util.List structFieldObjectInspectors)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$groupByExpression_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$revokeRole_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tableBuckets_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.security.authorization.PrivilegeRegistry</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>12</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>4</npm>
		<lcom3>0.25</lcom3>
		<loc>85</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.25</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.8</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.security.authorization.Privilege getPrivilege(int privilegeToken)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.security.authorization.Privilege getPrivilege(org.apache.hadoop.hive.ql.security.authorization.Privilege$PrivilegeType privilegeType)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.security.authorization.Privilege getPrivilege(String privilegeName)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.TokenMgrError</name>
		<wmc>6</wmc>
		<dit>3</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>19</rfc>
		<lcom>15</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>1.1199999999999999</lcom3>
		<loc>184</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.875</mfa>
		<cam>0.5</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>28.833333333333332</amc>
		<cc>
			<method name="public void _init_(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar, int reason)">0</method>
			<method name="public void _init_()">0</method>
			<method name="protected static String LexicalError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar)">2</method>
			<method name="public String getMessage()">1</method>
			<method name="protected static final String addEscapes(String str)">14</method>
			<method name="public void _init_(String message, int reason)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>29</cbo>
		<rfc>56</rfc>
		<lcom>41</lcom>
		<ca>3</ca>
		<ce>27</ce>
		<npm>6</npm>
		<lcom3>0.8</lcom3>
		<loc>412</loc>
		<dam>0.75</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.32857142857142857</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>36.09090909090909</amc>
		<cc>
			<method name="private org.apache.hadoop.hive.ql.plan.ExprNodeDesc extractConstant(org.apache.hadoop.hive.ql.plan.ExprNodeDesc expr)">3</method>
			<method name="private org.apache.hadoop.hive.ql.plan.ExprNodeConstantDesc foldConstant(org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc func)">11</method>
			<method name="public void clearAllowedColumnNames()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="static org.apache.hadoop.hive.ql.plan.ExprNodeDesc access$000(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer x0, org.apache.hadoop.hive.ql.plan.ExprNodeDesc x1, java.util.List x2, Object[] x3)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ExprNodeDesc analyzePredicate(org.apache.hadoop.hive.ql.plan.ExprNodeDesc predicate, java.util.List searchConditions)">1</method>
			<method name="public void addComparisonOp(String udfName)">1</method>
			<method name="private transient org.apache.hadoop.hive.ql.plan.ExprNodeDesc analyzeExpr(org.apache.hadoop.hive.ql.plan.ExprNodeDesc expr, java.util.List searchConditions, Object[] nodeOutputs)">16</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ExprNodeDesc translateSearchConditions(java.util.List searchConditions)">3</method>
			<method name="public void allowColumnName(String columnName)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$dropIndexStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.ppd.OpWalkerInfo</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>18</rfc>
		<lcom>8</lcom>
		<ca>10</ca>
		<ce>8</ce>
		<npm>8</npm>
		<lcom3>0.75</lcom3>
		<loc>71</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.2857142857142857</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.375</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.parse.RowResolver getRowResolver(org.apache.hadoop.hive.ql.lib.Node op)">1</method>
			<method name="public java.util.List getCandidateFilterOps()">1</method>
			<method name="public void addCandidateFilterOp(org.apache.hadoop.hive.ql.exec.FilterOperator fop)">1</method>
			<method name="public org.apache.hadoop.hive.ql.ppd.ExprWalkerInfo putPrunedPreds(org.apache.hadoop.hive.ql.exec.Operator op, org.apache.hadoop.hive.ql.ppd.ExprWalkerInfo value)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.OpParseContext put(org.apache.hadoop.hive.ql.exec.Operator key, org.apache.hadoop.hive.ql.parse.OpParseContext value)">1</method>
			<method name="public org.apache.hadoop.hive.ql.ppd.ExprWalkerInfo getPrunedPreds(org.apache.hadoop.hive.ql.exec.Operator op)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext getParseContext()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.parse.ParseContext pGraphContext)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter$ShortConverter</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>36</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector inputOI, org.apache.hadoop.hive.serde2.objectinspector.primitive.SettableShortObjectInspector outputOI)">0</method>
			<method name="public Object convert(Object input)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeDefinition</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat$1</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>2</npm>
		<lcom3>0.25</lcom3>
		<loc>26</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, org.apache.hadoop.io.SequenceFile$Writer)">0</method>
			<method name="public void close(boolean abort)">1</method>
			<method name="public void write(org.apache.hadoop.io.Writable r)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.formatting.TextMetaDataFormatter</name>
		<wmc>14</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>20</cbo>
		<rfc>79</rfc>
		<lcom>79</lcom>
		<ca>1</ca>
		<ce>19</ce>
		<npm>12</npm>
		<lcom3>0.9487179487179488</lcom3>
		<loc>878</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.28205128205128205</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>61.5</amc>
		<cc>
			<method name="public void showTables(java.io.DataOutputStream out, java.util.Set tables)">1</method>
			<method name="public void consoleError(org.apache.hadoop.hive.ql.session.SessionState$LogHelper console, String msg, String detail, int errorCode)">1</method>
			<method name="public void logWarn(java.io.OutputStream out, String msg, int errorCode)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void consoleError(org.apache.hadoop.hive.ql.session.SessionState$LogHelper console, String msg, int errorCode)">1</method>
			<method name="public void describeTable(java.io.DataOutputStream outStream, String colPath, String tableName, org.apache.hadoop.hive.ql.metadata.Table tbl, org.apache.hadoop.hive.ql.metadata.Partition part, java.util.List cols, boolean isFormatted, boolean isExt)">1</method>
			<method name="public void error(java.io.OutputStream out, String msg, int errorCode)">1</method>
			<method name="public void showDatabaseDescription(java.io.DataOutputStream outStream, String database, String comment, String location, java.util.Map params)">1</method>
			<method name="public void showTablePartitons(java.io.DataOutputStream outStream, java.util.List parts)">1</method>
			<method name="public void showTableStatus(java.io.DataOutputStream outStream, org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.conf.HiveConf conf, java.util.List tbls, java.util.Map part, org.apache.hadoop.hive.ql.metadata.Partition par)">1</method>
			<method name="public void logInfo(java.io.OutputStream out, String msg, int errorCode)">1</method>
			<method name="private void writeFileSystemStats(java.io.DataOutputStream outStream, org.apache.hadoop.hive.conf.HiveConf conf, java.util.List locations, org.apache.hadoop.fs.Path tblPath, boolean partSpecified, int indent)">1</method>
			<method name="public void showDatabases(java.io.DataOutputStream outStream, java.util.List databases)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceBitwiseOrExpression_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyBinaryObjectInspector</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>10</rfc>
		<lcom>21</lcom>
		<ca>3</ca>
		<ce>8</ce>
		<npm>6</npm>
		<lcom3>2.0</lcom3>
		<loc>62</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.9285714285714286</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.857142857142857</amc>
		<cc>
			<method name="public volatile org.apache.hadoop.io.Writable getPrimitiveWritableObject(Object x0)">1</method>
			<method name="public org.apache.hadoop.io.BytesWritable getPrimitiveWritableObject(Object o)">2</method>
			<method name="protected void _init_()">0</method>
			<method name="public volatile Object getPrimitiveJavaObject(Object x0)">1</method>
			<method name="public volatile Object getPrimitiveWritableObject(Object x0)">1</method>
			<method name="public Object copyObject(Object o)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.lazy.ByteArrayRef getPrimitiveJavaObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeFunction</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>12</rfc>
		<lcom>10</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>5</npm>
		<lcom3>1.25</lcom3>
		<loc>56</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.0</amc>
		<cc>
			<method name="public byte getType()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeFieldList getFieldList()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int i)">0</method>
			<method name="public String toString()">1</method>
			<method name="public void _init_(int i)">0</method>
		</cc>
	</class>
	<class>
		<name>org.json.HTTPTokener</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>9</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>61</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>29.5</amc>
		<cc>
			<method name="public void _init_(String arg0)">0</method>
			<method name="public String nextToken()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.security.HadoopDefaultAuthenticator</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>14</rfc>
		<lcom>9</lcom>
		<ca>0</ca>
		<ce>6</ce>
		<npm>6</npm>
		<lcom3>0.8</lcom3>
		<loc>58</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.166666666666666</amc>
		<cc>
			<method name="public java.util.List getGroupNames()">1</method>
			<method name="public org.apache.hadoop.conf.Configuration getConf()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setConf(org.apache.hadoop.conf.Configuration conf)">3</method>
			<method name="public String getUserName()">1</method>
			<method name="public void destroy()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HiveKey$Comparator</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>22</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.0</amc>
		<cc>
			<method name="public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2)">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.ParseDriver$HiveParserX</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>27</rfc>
		<lcom>13</lcom>
		<ca>1</ca>
		<ce>12</ce>
		<npm>6</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>250</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.35714285714285715</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>34.42857142857143</amc>
		<cc>
			<method name="public String getErrorHeader(org.antlr.runtime.RecognitionException e)">3</method>
			<method name="public void displayRecognitionError(String[] tokenNames, org.antlr.runtime.RecognitionException e)">1</method>
			<method name="public String getErrorMessage(org.antlr.runtime.RecognitionException e, String[] tokenNames)">9</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.parse.ParseDriver, org.antlr.runtime.TokenStream input)">0</method>
			<method name="public void recoverFromMismatchedSet(org.antlr.runtime.IntStream input, org.antlr.runtime.RecognitionException re, org.antlr.runtime.BitSet follow)">1</method>
			<method name="public java.util.ArrayList getErrors()">1</method>
			<method name="protected void mismatch(org.antlr.runtime.IntStream input, int ttype, org.antlr.runtime.BitSet follow)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.stats.StatsFactory</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>15</rfc>
		<lcom>2</lcom>
		<ca>3</ca>
		<ce>9</ce>
		<npm>4</npm>
		<lcom3>0.6875</lcom3>
		<loc>109</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.25</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>20.0</amc>
		<cc>
			<method name="public static boolean setImplementation(String configurationParam, org.apache.hadoop.conf.Configuration conf)">5</method>
			<method name="public static org.apache.hadoop.hive.ql.stats.StatsAggregator getStatsAggregator()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.stats.StatsPublisher getStatsPublisher()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.TUnion</name>
		<wmc>26</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>64</rfc>
		<lcom>225</lcom>
		<ca>0</ca>
		<ce>8</ce>
		<npm>13</npm>
		<lcom3>0.5</lcom3>
		<loc>381</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.16083916083916083</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.576923076923077</amc>
		<cc>
			<method name="public void read(org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public void write(org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public void setFieldValue(org.apache.thrift.TFieldIdEnum fieldId, Object value)">1</method>
			<method name="public Object getFieldValue(org.apache.thrift.TFieldIdEnum fieldId)">2</method>
			<method name="protected void _init_(org.apache.thrift.TFieldIdEnum setField, Object value)">0</method>
			<method name="protected abstract org.apache.thrift.protocol.TField getFieldDesc(org.apache.thrift.TFieldIdEnum)">1</method>
			<method name="public final void clear()">1</method>
			<method name="public String toString()">3</method>
			<method name="public org.apache.thrift.TFieldIdEnum getSetField()">1</method>
			<method name="public Object getFieldValue(int fieldId)">1</method>
			<method name="protected abstract org.apache.thrift.TFieldIdEnum enumForId(short)">1</method>
			<method name="private static java.util.List deepCopyList(java.util.List list)">2</method>
			<method name="private static java.util.Map deepCopyMap(java.util.Map map)">2</method>
			<method name="public void setFieldValue(int fieldId, Object value)">1</method>
			<method name="protected abstract void checkType(org.apache.thrift.TFieldIdEnum, Object)">1</method>
			<method name="protected abstract void writeValue(org.apache.thrift.protocol.TProtocol)">1</method>
			<method name="public Object getFieldValue()">1</method>
			<method name="protected abstract org.apache.thrift.protocol.TStruct getStructDesc()">1</method>
			<method name="public boolean isSet(org.apache.thrift.TFieldIdEnum fieldId)">2</method>
			<method name="private static java.util.Set deepCopySet(java.util.Set set)">2</method>
			<method name="protected void _init_()">0</method>
			<method name="protected abstract Object readValue(org.apache.thrift.protocol.TProtocol, org.apache.thrift.protocol.TField)">1</method>
			<method name="public boolean isSet()">2</method>
			<method name="private static Object deepCopyObject(Object o)">6</method>
			<method name="public boolean isSet(int fieldId)">1</method>
			<method name="protected void _init_(org.apache.thrift.TUnion other)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.DDLWork</name>
		<wmc>113</wmc>
		<dit>1</dit>
		<noc>1</noc>
		<cbo>38</cbo>
		<rfc>114</rfc>
		<lcom>6076</lcom>
		<ca>5</ca>
		<ce>34</ce>
		<npm>113</npm>
		<lcom3>0.9590201465201466</lcom3>
		<loc>717</loc>
		<dam>0.9743589743589743</dam>
		<moa>35</moa>
		<mfa>0.0</mfa>
		<cam>0.05285816790241569</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public void setCreateDatabaseDesc(org.apache.hadoop.hive.ql.plan.CreateDatabaseDesc createDatabaseDesc)">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.GrantRevokeRoleDDL grantRevokeRoleDDL)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.CreateViewDesc getCreateVwDesc()">1</method>
			<method name="public void setGrantDesc(org.apache.hadoop.hive.ql.plan.GrantDesc grantDesc)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.AlterTableSimpleDesc getAlterTblSimpleDesc()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.DescFunctionDesc getDescFunctionDesc()">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.DropTableDesc dropTblDesc)">0</method>
			<method name="public void setRevokeDesc(org.apache.hadoop.hive.ql.plan.RevokeDesc revokeDesc)">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.LockTableDesc lockTblDesc)">0</method>
			<method name="public void setDropTblDesc(org.apache.hadoop.hive.ql.plan.DropTableDesc dropTblDesc)">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.ShowTableStatusDesc showTblStatusDesc)">0</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ShowDatabasesDesc getShowDatabasesDesc()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.MsckDesc getMsckDesc()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ShowGrantDesc getShowGrantDesc()">1</method>
			<method name="public void setLockTblDesc(org.apache.hadoop.hive.ql.plan.LockTableDesc lockTblDesc)">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.DropDatabaseDesc dropDatabaseDesc)">0</method>
			<method name="public org.apache.hadoop.hive.ql.parse.AlterTablePartMergeFilesDesc getMergeFilesDesc()">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.CreateViewDesc createVwDesc)">0</method>
			<method name="public void setNeedLock(boolean needLock)">1</method>
			<method name="public void setRoleDDLDesc(org.apache.hadoop.hive.ql.plan.RoleDDLDesc roleDDLDesc)">1</method>
			<method name="public void setDropDatabaseDesc(org.apache.hadoop.hive.ql.plan.DropDatabaseDesc dropDatabaseDesc)">1</method>
			<method name="public void setDescFuncDesc(org.apache.hadoop.hive.ql.plan.DescFunctionDesc descFuncDesc)">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.CreateTableDesc createTblDesc)">0</method>
			<method name="public void setDescTblDesc(org.apache.hadoop.hive.ql.plan.DescTableDesc descTblDesc)">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.RenamePartitionDesc renamePartitionDesc)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.RevokeDesc getRevokeDesc()">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.ShowIndexesDesc showIndexesDesc)">0</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.DescFunctionDesc descFuncDesc)">0</method>
			<method name="public java.util.HashSet getOutputs()">1</method>
			<method name="public void setMergeFilesDesc(org.apache.hadoop.hive.ql.parse.AlterTablePartMergeFilesDesc mergeDesc)">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.parse.AlterTablePartMergeFilesDesc mergeDesc)">0</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.AlterTableDesc alterTblDesc)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.CreateViewDesc getCreateViewDesc()">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.RevokeDesc revokeDesc)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ShowFunctionsDesc getShowFuncsDesc()">1</method>
			<method name="public void setCreateTblDesc(org.apache.hadoop.hive.ql.plan.CreateTableDesc createTblDesc)">1</method>
			<method name="public java.util.HashSet getInputs()">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.ShowPartitionsDesc showPartsDesc)">0</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.ShowFunctionsDesc showFuncsDesc)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.CreateDatabaseDesc getCreateDatabaseDesc()">1</method>
			<method name="public void setGrantRevokeRoleDDL(org.apache.hadoop.hive.ql.plan.GrantRevokeRoleDDL grantRevokeRoleDDL)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.AlterTableDesc getAlterTblDesc()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ShowTablesDesc getShowTblsDesc()">1</method>
			<method name="public void setAlterTblSimpleDesc(org.apache.hadoop.hive.ql.plan.AlterTableSimpleDesc desc)">1</method>
			<method name="public void setDropIdxDesc(org.apache.hadoop.hive.ql.plan.DropIndexDesc dropIdxDesc)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.DescTableDesc getDescTblDesc()">1</method>
			<method name="public void setShowPartsDesc(org.apache.hadoop.hive.ql.plan.ShowPartitionsDesc showPartsDesc)">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.RoleDDLDesc roleDDLDesc)">0</method>
			<method name="public void setAlterTblDesc(org.apache.hadoop.hive.ql.plan.AlterTableDesc alterTblDesc)">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.MsckDesc checkDesc)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.AlterIndexDesc alterIndex)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.RoleDDLDesc getRoleDDLDesc()">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.AddPartitionDesc addPartitionDesc)">0</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.ShowDatabasesDesc showDatabasesDesc)">0</method>
			<method name="public void setShowTblsDesc(org.apache.hadoop.hive.ql.plan.ShowTablesDesc showTblsDesc)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.CreateTableLikeDesc getCreateTblLikeDesc()">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.ShowLocksDesc showLocksDesc)">0</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.CreateIndexDesc createIndex)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ShowIndexesDesc getShowIndexesDesc()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.GrantRevokeRoleDDL getGrantRevokeRoleDDL()">1</method>
			<method name="public void setShowLocksDesc(org.apache.hadoop.hive.ql.plan.ShowLocksDesc showLocksDesc)">1</method>
			<method name="public boolean getNeedLock()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.GrantDesc getGrantDesc()">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.ShowTablesDesc showTblsDesc)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.AlterDatabaseDesc getAlterDatabaseDesc()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.AddPartitionDesc getAddPartitionDesc()">1</method>
			<method name="public void setCreateTblLikeDesc(org.apache.hadoop.hive.ql.plan.CreateTableLikeDesc createTblLikeDesc)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.AlterIndexDesc getAlterIndexDesc()">1</method>
			<method name="public void setSwitchDatabaseDesc(org.apache.hadoop.hive.ql.plan.SwitchDatabaseDesc switchDatabaseDesc)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.DropDatabaseDesc getDropDatabaseDesc()">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.DescDatabaseDesc descDatabaseDesc)">0</method>
			<method name="public void setAlterIndexDesc(org.apache.hadoop.hive.ql.plan.AlterIndexDesc alterIndexDesc)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.CreateTableDesc getCreateTblDesc()">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.UnlockTableDesc unlockTblDesc)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.DropIndexDesc getDropIdxDesc()">1</method>
			<method name="public void setRenamePartitionDesc(org.apache.hadoop.hive.ql.plan.RenamePartitionDesc renamePartitionDesc)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ShowPartitionsDesc getShowPartsDesc()">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.SwitchDatabaseDesc switchDatabaseDesc)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.UnlockTableDesc getUnlockTblDesc()">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.CreateTableLikeDesc createTblLikeDesc)">0</method>
			<method name="public void setShowIndexesDesc(org.apache.hadoop.hive.ql.plan.ShowIndexesDesc showIndexesDesc)">1</method>
			<method name="public void setShowDatabasesDesc(org.apache.hadoop.hive.ql.plan.ShowDatabasesDesc showDatabasesDesc)">1</method>
			<method name="public void setInputs(java.util.HashSet inputs)">1</method>
			<method name="public void setDescFunctionDesc(org.apache.hadoop.hive.ql.plan.DescFunctionDesc descFunctionDesc)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.SwitchDatabaseDesc getSwitchDatabaseDesc()">1</method>
			<method name="public void setMsckDesc(org.apache.hadoop.hive.ql.plan.MsckDesc msckDesc)">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.GrantDesc grantDesc)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.DescDatabaseDesc getDescDatabaseDesc()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ShowTableStatusDesc getShowTblStatusDesc()">1</method>
			<method name="public void setAlterDatabaseDesc(org.apache.hadoop.hive.ql.plan.AlterDatabaseDesc alterDbDesc)">1</method>
			<method name="public void setOutputs(java.util.HashSet outputs)">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.AlterTableSimpleDesc simpleDesc)">0</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.CreateDatabaseDesc createDatabaseDesc)">0</method>
			<method name="public void setCreateIndexDesc(org.apache.hadoop.hive.ql.plan.CreateIndexDesc createIndexDesc)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.DropTableDesc getDropTblDesc()">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs)">0</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.AlterDatabaseDesc alterDbDesc)">0</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.AlterIndexDesc alterIdxDesc)">0</method>
			<method name="public void setShowGrantDesc(org.apache.hadoop.hive.ql.plan.ShowGrantDesc showGrantDesc)">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.DropIndexDesc dropIndexDesc)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.LockTableDesc getLockTblDesc()">1</method>
			<method name="public void setShowFuncsDesc(org.apache.hadoop.hive.ql.plan.ShowFunctionsDesc showFuncsDesc)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.RenamePartitionDesc getRenamePartitionDesc()">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.ShowGrantDesc showGrant)">0</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.DescTableDesc descTblDesc)">0</method>
			<method name="public void setShowTblStatusDesc(org.apache.hadoop.hive.ql.plan.ShowTableStatusDesc showTblStatusDesc)">1</method>
			<method name="public void setCreateViewDesc(org.apache.hadoop.hive.ql.plan.CreateViewDesc createVwDesc)">1</method>
			<method name="public void setAddPartitionDesc(org.apache.hadoop.hive.ql.plan.AddPartitionDesc addPartitionDesc)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ShowLocksDesc getShowLocksDesc()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.CreateIndexDesc getCreateIndexDesc()">1</method>
			<method name="public void setUnlockTblDesc(org.apache.hadoop.hive.ql.plan.UnlockTableDesc unlockTblDesc)">1</method>
			<method name="public void setCreateVwDesc(org.apache.hadoop.hive.ql.plan.CreateViewDesc createVwDesc)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.SwitchDatabaseDesc</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>4</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>22</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void setDatabaseName(String databaseName)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public String getDatabaseName()">1</method>
			<method name="public void _init_(String databaseName)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.RecordReader</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>4</rfc>
		<lcom>6</lcom>
		<ca>4</ca>
		<ce>2</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.hadoop.io.Writable createRow()">1</method>
			<method name="public abstract void initialize(java.io.InputStream, org.apache.hadoop.conf.Configuration, java.util.Properties)">1</method>
			<method name="public abstract int next(org.apache.hadoop.io.Writable)">1</method>
			<method name="public abstract void close()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.ppd.OpProcFactory$DefaultPPD</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>7</noc>
		<cbo>22</cbo>
		<rfc>38</rfc>
		<lcom>10</lcom>
		<ca>8</ca>
		<ce>15</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>275</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4444444444444444</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>54.0</amc>
		<cc>
			<method name="protected void logExpr(org.apache.hadoop.hive.ql.lib.Node nd, org.apache.hadoop.hive.ql.ppd.ExprWalkerInfo ewi)">2</method>
			<method name="public void _init_()">0</method>
			<method name="protected org.apache.hadoop.hive.ql.ppd.ExprWalkerInfo mergeChildrenPred(org.apache.hadoop.hive.ql.lib.Node nd, org.apache.hadoop.hive.ql.ppd.OpWalkerInfo owi, java.util.Set excludedAliases, boolean ignoreAliases)">1</method>
			<method name="protected boolean mergeWithChildrenPred(org.apache.hadoop.hive.ql.lib.Node nd, org.apache.hadoop.hive.ql.ppd.OpWalkerInfo owi, org.apache.hadoop.hive.ql.ppd.ExprWalkerInfo ewi, java.util.Set aliases, boolean ignoreAliases)">1</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixArchive_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixClusterbySortby_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileKeyBufferWrapper</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>9</rfc>
		<lcom>13</lcom>
		<ca>2</ca>
		<ce>4</ce>
		<npm>5</npm>
		<lcom3>1.1</lcom3>
		<loc>45</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.2777777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.5</amc>
		<cc>
			<method name="public volatile int compareTo(Object x0)">1</method>
			<method name="public int compareTo(org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileKeyBufferWrapper o)">1</method>
			<method name="protected void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileKeyBufferWrapper create(org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer currentKeyBufferObj)">1</method>
			<method name="public void write(java.io.DataOutput out)">1</method>
			<method name="public void readFields(java.io.DataInput in)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixDropPartitions_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeBool</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>15</rfc>
		<lcom>28</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>8</npm>
		<lcom3>2.0</lcom3>
		<loc>51</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.375</amc>
		<cc>
			<method name="public Object deserialize(Object reuse, org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public Boolean getRealTypeInstance()">1</method>
			<method name="public void serialize(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public byte getType()">1</method>
			<method name="public Class getRealType()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int i)">0</method>
			<method name="public String toString()">1</method>
			<method name="public void _init_(int i)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFLike</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>29</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>5</ce>
		<npm>3</npm>
		<lcom3>0.65</lcom3>
		<loc>411</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>80.2</amc>
		<cc>
			<method name="public static String likePatternToRegExp(String likePattern)">8</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.BooleanWritable evaluate(org.apache.hadoop.io.Text s, org.apache.hadoop.io.Text likePattern)">9</method>
			<method name="private static boolean find(org.apache.hadoop.io.Text s, org.apache.hadoop.io.Text sub, int startS, int endS)">5</method>
			<method name="private void parseSimplePattern(String likePattern)">10</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.io.NonSyncByteArrayInputStream</name>
		<wmc>10</wmc>
		<dit>3</dit>
		<noc>1</noc>
		<cbo>2</cbo>
		<rfc>15</rfc>
		<lcom>5</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>10</npm>
		<lcom3>2.0</lcom3>
		<loc>165</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.7083333333333334</mfa>
		<cam>0.45</cam>
		<ic>2</ic>
		<cbm>9</cbm>
		<amc>15.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public int read()">2</method>
			<method name="public int available()">1</method>
			<method name="public int getPosition()">1</method>
			<method name="public int read(byte[] b, int off, int len)">8</method>
			<method name="public void _init_(byte[] bs)">0</method>
			<method name="public long skip(long n)">3</method>
			<method name="public void reset(byte[] input, int start, int length)">1</method>
			<method name="public int getLength()">1</method>
			<method name="public void _init_(byte[] buf, int offset, int length)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeExtends</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory</name>
		<wmc>15</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>73</cbo>
		<rfc>63</rfc>
		<lcom>87</lcom>
		<ca>53</ca>
		<ce>21</ce>
		<npm>11</npm>
		<lcom3>0.875</lcom3>
		<loc>553</loc>
		<dam>0.125</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.20408163265306123</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>35.333333333333336</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.StandardConstantListObjectInspector getStandardConstantListObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector listElementObjectInspector, java.util.List constantValue)">1</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ColumnarStructObjectInspector getColumnarStructObjectInspector(java.util.List structFieldNames, java.util.List structFieldObjectInspectors, java.util.List structFieldComments)">3</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.StandardMapObjectInspector getStandardMapObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector mapKeyObjectInspector, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector mapValueObjectInspector)">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ColumnarStructObjectInspector getColumnarStructObjectInspector(java.util.List structFieldNames, java.util.List structFieldObjectInspectors)">1</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.StandardConstantMapObjectInspector getStandardConstantMapObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector mapKeyObjectInspector, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector mapValueObjectInspector, java.util.Map constantValue)">1</method>
			<method name="private static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getReflectionObjectInspectorNoCache(java.lang.reflect.Type t, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory$ObjectInspectorOptions options)">16</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getReflectionObjectInspector(java.lang.reflect.Type t, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory$ObjectInspectorOptions options)">2</method>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.StandardUnionObjectInspector getStandardUnionObjectInspector(java.util.List unionObjectInspectors)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.StandardListObjectInspector getStandardListObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector listElementObjectInspector)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.StandardStructObjectInspector getStandardStructObjectInspector(java.util.List structFieldNames, java.util.List structFieldObjectInspectors)">1</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.StandardStructObjectInspector getStandardStructObjectInspector(java.util.List structFieldNames, java.util.List structFieldObjectInspectors, java.util.List structComments)">3</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.UnionStructObjectInspector getUnionStructObjectInspector(java.util.List structObjectInspectors)">2</method>
			<method name="private static void verifyObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory$ObjectInspectorOptions option, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory$ObjectInspectorOptions checkOption, Class[] classes)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector$MyField</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>13</rfc>
		<lcom>7</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>0.625</lcom3>
		<loc>60</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4642857142857143</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public int getFieldID()">1</method>
			<method name="public void _init_(int fieldID, String fieldName, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector fieldObjectInspector, String fieldComment)">0</method>
			<method name="public String getFieldComment()">1</method>
			<method name="public String getFieldName()">1</method>
			<method name="public void _init_(int fieldID, String fieldName, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector fieldObjectInspector)">0</method>
			<method name="public String toString()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getFieldObjectInspector()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.ShimLoader</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>27</cbo>
		<rfc>26</rfc>
		<lcom>24</lcom>
		<ca>23</ca>
		<ce>4</ce>
		<npm>4</npm>
		<lcom3>0.8571428571428571</lcom3>
		<loc>183</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.17857142857142858</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>21.375</amc>
		<cc>
			<method name="public static synchronized org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge getHadoopThriftAuthBridge()">2</method>
			<method name="private void _init_()">0</method>
			<method name="public static synchronized org.apache.hadoop.hive.shims.HadoopShims getHadoopShims()">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static synchronized org.apache.hadoop.hive.shims.JettyShims getJettyShims()">2</method>
			<method name="public static String getMajorVersion()">4</method>
			<method name="private static Object createShim(String className, Class xface)">1</method>
			<method name="private static Object loadShims(java.util.Map classMap, Class xface)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server$TUGIAssumingProcessor</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>30</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>17</ce>
		<npm>1</npm>
		<lcom3>0.6666666666666667</lcom3>
		<loc>133</loc>
		<dam>0.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>64.0</amc>
		<cc>
			<method name="public boolean process(org.apache.thrift.protocol.TProtocol inProt, org.apache.thrift.protocol.TProtocol outProt)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server, org.apache.thrift.TProcessor wrapped, org.apache.hadoop.hive.thrift.DelegationTokenSecretManager secretManager)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeFieldList</name>
		<wmc>12</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>20</cbo>
		<rfc>60</rfc>
		<lcom>30</lcom>
		<ca>5</ca>
		<ce>16</ce>
		<npm>7</npm>
		<lcom3>0.7727272727272727</lcom3>
		<loc>576</loc>
		<dam>0.75</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.2857142857142857</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>46.333333333333336</amc>
		<cc>
			<method name="public Object deserialize(Object reuse, org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="protected org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeBase getFieldByName(String fieldname)">1</method>
			<method name="public void initialize()">3</method>
			<method name="public final org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeField[] getChildren()">2</method>
			<method name="public void serialize(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private int getNumFields()">1</method>
			<method name="private org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeBase getFieldByFieldId(int i)">1</method>
			<method name="private org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeField getField(int i)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int i)">0</method>
			<method name="public String toString()">2</method>
			<method name="public void _init_(int i)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$autoRebuild_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Utilities$SQLCommand</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>5</noc>
		<cbo>8</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>8</ca>
		<ce>0</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>7</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.5</amc>
		<cc>
			<method name="public Object run(java.sql.PreparedStatement stmt)">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Utilities$StreamPrinter</name>
		<wmc>2</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>13</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>84</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.9846153846153847</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>39.5</amc>
		<cc>
			<method name="public void _init_(java.io.InputStream is, String type, java.io.PrintStream os)">0</method>
			<method name="public void run()">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.CopyWork</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>10</rfc>
		<lcom>22</lcom>
		<ca>4</ca>
		<ce>0</ce>
		<npm>9</npm>
		<lcom3>0.78125</lcom3>
		<loc>55</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.666666666666667</amc>
		<cc>
			<method name="public void setToPath(String toPath)">1</method>
			<method name="public String getToPath()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public boolean isErrorOnSrcEmpty()">1</method>
			<method name="public void _init_(String fromPath, String toPath)">0</method>
			<method name="public void setErrorOnSrcEmpty(boolean errorOnSrcEmpty)">1</method>
			<method name="public void setFromPath(String fromPath)">1</method>
			<method name="public void _init_(String fromPath, String toPath, boolean errorOnSrcEmpty)">0</method>
			<method name="public String getFromPath()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyUtils$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>77</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>75.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.SettableTimestampObjectInspector</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>5</rfc>
		<lcom>10</lcom>
		<ca>6</ca>
		<ce>2</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Object create(java.sql.Timestamp)">1</method>
			<method name="public abstract Object set(Object, org.apache.hadoop.hive.serde2.io.TimestampWritable)">1</method>
			<method name="public abstract Object set(Object, java.sql.Timestamp)">1</method>
			<method name="public abstract Object set(Object, byte[], int)">1</method>
			<method name="public abstract Object create(byte[], int)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>40</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>40</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.xml.UDFXPathDouble</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>18</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public double evaluate(String xml, String path)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFOPBitXor</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>14</rfc>
		<lcom>10</lcom>
		<ca>0</ca>
		<ce>5</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>78</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.36</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.6</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.hive.serde2.io.ByteWritable a, org.apache.hadoop.hive.serde2.io.ByteWritable b)">3</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.hive.serde2.io.ShortWritable a, org.apache.hadoop.hive.serde2.io.ShortWritable b)">3</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.LongWritable a, org.apache.hadoop.io.LongWritable b)">3</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.IntWritable a, org.apache.hadoop.io.IntWritable b)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat$IgnoreKeyWriter</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>4</npm>
		<lcom3>0.0</lcom3>
		<loc>29</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.0</amc>
		<cc>
			<method name="public void close(org.apache.hadoop.mapred.Reporter reporter)">1</method>
			<method name="public synchronized void write(org.apache.hadoop.io.WritableComparable key, org.apache.hadoop.io.Writable value)">1</method>
			<method name="public volatile void write(Object x0, Object x1)">1</method>
			<method name="public void _init_(org.apache.hadoop.mapred.RecordWriter writer)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.xml.GenericUDFXPath</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>29</rfc>
		<lcom>7</lcom>
		<ca>0</ca>
		<ce>14</ce>
		<npm>4</npm>
		<lcom3>0.7</lcom3>
		<loc>166</loc>
		<dam>0.8333333333333334</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.36</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>25.666666666666668</amc>
		<cc>
			<method name="private java.util.List eval(String xml, String path)">4</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.rcfile.merge.MergeWork</name>
		<wmc>14</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>34</rfc>
		<lcom>67</lcom>
		<ca>3</ca>
		<ce>6</ce>
		<npm>14</npm>
		<lcom3>0.8269230769230769</lcom3>
		<loc>140</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.21428571428571427</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.714285714285714</amc>
		<cc>
			<method name="public void _init_(java.util.List inputPaths, String outputDir, boolean hasDynamicPartitions)">0</method>
			<method name="public java.util.List getInputPaths()">1</method>
			<method name="public void setOutputDir(String outputDir)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(java.util.List inputPaths, String outputDir)">0</method>
			<method name="public void setInputPaths(java.util.List inputPaths)">1</method>
			<method name="public Long getMinSplitSize()">1</method>
			<method name="public Class getMapperClass()">1</method>
			<method name="public void setHasDynamicPartitions(boolean hasDynamicPartitions)">1</method>
			<method name="public boolean hasDynamicPartitions()">1</method>
			<method name="public void resolveDynamicPartitionMerge(org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.fs.Path path, org.apache.hadoop.hive.ql.plan.TableDesc tblDesc, java.util.ArrayList aliases, org.apache.hadoop.hive.ql.plan.PartitionDesc partDesc)">1</method>
			<method name="public String getOutputDir()">1</method>
			<method name="public String getInputformat()">1</method>
			<method name="public boolean isGatheringStats()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceStarOperator_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.LineageInfo$DependencyKey</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>9</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>5</npm>
		<lcom3>0.5833333333333334</lcom3>
		<loc>90</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>16.4</amc>
		<cc>
			<method name="public int hashCode()">3</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.hooks.LineageInfo$DataContainer dc, org.apache.hadoop.hive.metastore.api.FieldSchema fld)">0</method>
			<method name="public org.apache.hadoop.hive.metastore.api.FieldSchema getFieldSchema()">1</method>
			<method name="public boolean equals(Object obj)">6</method>
			<method name="public org.apache.hadoop.hive.ql.hooks.LineageInfo$DataContainer getDataContainer()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$dropFunctionStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeAsync</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lib.Dispatcher</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>42</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>40</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public transient abstract Object dispatch(org.apache.hadoop.hive.ql.lib.Node, java.util.Stack, Object[])">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFStdSample$GenericUDAFStdSampleEvaluator</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>6</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>40</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.0</amc>
		<cc>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TBinaryProtocol</name>
		<wmc>48</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>78</rfc>
		<lcom>918</lcom>
		<ca>3</ca>
		<ce>10</ce>
		<npm>45</npm>
		<lcom3>0.9177304964539007</lcom3>
		<loc>972</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.08635794743429287</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.9375</amc>
		<cc>
			<method name="public void readFieldEnd()">1</method>
			<method name="public void writeSetEnd()">1</method>
			<method name="public void writeI16(short i16)">1</method>
			<method name="public void writeString(String str)">1</method>
			<method name="public void writeDouble(double dub)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public boolean readBool()">1</method>
			<method name="public void writeStructEnd()">1</method>
			<method name="public void writeStructBegin(org.apache.thrift.protocol.TStruct struct)">1</method>
			<method name="public void writeFieldBegin(org.apache.thrift.protocol.TField field)">1</method>
			<method name="public org.apache.thrift.protocol.TMap readMapBegin()">1</method>
			<method name="private int readAll(byte[] buf, int off, int len)">1</method>
			<method name="public String readStringBody(int size)">1</method>
			<method name="public void readStructEnd()">1</method>
			<method name="public void writeBinary(java.nio.ByteBuffer bin)">1</method>
			<method name="public org.apache.thrift.protocol.TStruct readStructBegin()">1</method>
			<method name="public void writeFieldStop()">1</method>
			<method name="public void writeMapBegin(org.apache.thrift.protocol.TMap map)">1</method>
			<method name="public org.apache.thrift.protocol.TSet readSetBegin()">1</method>
			<method name="public void writeListEnd()">1</method>
			<method name="public org.apache.thrift.protocol.TMessage readMessageBegin()">1</method>
			<method name="public String readString()">1</method>
			<method name="public void _init_(org.apache.thrift.transport.TTransport trans)">0</method>
			<method name="public void readListEnd()">1</method>
			<method name="protected void checkReadLength(int length)">1</method>
			<method name="public void writeMessageBegin(org.apache.thrift.protocol.TMessage message)">1</method>
			<method name="public void writeMapEnd()">1</method>
			<method name="public long readI64()">1</method>
			<method name="public void readMessageEnd()">1</method>
			<method name="public void writeListBegin(org.apache.thrift.protocol.TList list)">1</method>
			<method name="public void writeFieldEnd()">1</method>
			<method name="public short readI16()">1</method>
			<method name="public org.apache.thrift.protocol.TField readFieldBegin()">1</method>
			<method name="public int readI32()">1</method>
			<method name="public void readMapEnd()">1</method>
			<method name="public void _init_(org.apache.thrift.transport.TTransport trans, boolean strictRead, boolean strictWrite)">0</method>
			<method name="public void writeBool(boolean b)">1</method>
			<method name="public void writeI64(long i64)">1</method>
			<method name="public org.apache.thrift.protocol.TList readListBegin()">1</method>
			<method name="public double readDouble()">1</method>
			<method name="public void writeMessageEnd()">1</method>
			<method name="public void readSetEnd()">1</method>
			<method name="public void writeByte(byte b)">1</method>
			<method name="public void writeSetBegin(org.apache.thrift.protocol.TSet set)">1</method>
			<method name="public void writeI32(int i32)">1</method>
			<method name="public byte readByte()">1</method>
			<method name="public java.nio.ByteBuffer readBinary()">1</method>
			<method name="public void setReadLength(int readLength)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceStarExpression_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFStdSample</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>12</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>73</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>35.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] parameters)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$explainStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer</name>
		<wmc>15</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>31</rfc>
		<lcom>3</lcom>
		<ca>7</ca>
		<ce>3</ce>
		<npm>6</npm>
		<lcom3>0.5285714285714286</lcom3>
		<loc>307</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.21904761904761905</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.133333333333333</amc>
		<cc>
			<method name="public int compareTo(Object arg0)">1</method>
			<method name="static int[] access$400(org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer x0)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public int getSize()">1</method>
			<method name="static int[] access$300(org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer x0)">1</method>
			<method name="public void write(java.io.DataOutput out)">1</method>
			<method name="void setColumnLenInfo(int columnValueLen, org.apache.hadoop.hive.ql.io.NonSyncDataOutputBuffer colValLenBuffer, int columnUncompressedValueLen, int columnIndex)">1</method>
			<method name="public void readFields(java.io.DataInput in)">1</method>
			<method name="static int access$600(org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer x0)">1</method>
			<method name="void _init_(int numberRows, int columnNum)">0</method>
			<method name="static int access$800(org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer x0)">1</method>
			<method name="static int access$802(org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer x0, int x1)">1</method>
			<method name="public int getColumnNumber()">1</method>
			<method name="void _init_(int columnNumber)">0</method>
			<method name="static org.apache.hadoop.hive.ql.io.NonSyncDataOutputBuffer[] access$1100(org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer x0)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TSimpleJSONProtocol$Context</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>2</noc>
		<cbo>4</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>1.0</lcom3>
		<loc>10</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.5</amc>
		<cc>
			<method name="protected void _init_(org.apache.thrift.protocol.TSimpleJSONProtocol)">0</method>
			<method name="protected void write()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyLongObjectInspector</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>9</rfc>
		<lcom>6</lcom>
		<ca>4</ca>
		<ce>7</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>33</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.875</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.25</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public long get(Object o)">1</method>
			<method name="public Object getPrimitiveJavaObject(Object o)">2</method>
			<method name="public Object copyObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableConstantDoubleObjectInspector</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>16</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public volatile Object getWritableConstantValue()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable getWritableConstantValue()">1</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.io.DoubleWritable value)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.MapJoinMetaData</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>13</rfc>
		<lcom>1</lcom>
		<ca>6</ca>
		<ce>1</ce>
		<npm>5</npm>
		<lcom3>0.6</lcom3>
		<loc>38</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.26666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public static void put(Integer key, org.apache.hadoop.hive.ql.exec.HashTableSinkOperator$HashTableSinkObjectCtx value)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static java.util.ArrayList getList()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.HashTableSinkOperator$HashTableSinkObjectCtx get(Integer key)">1</method>
			<method name="public static void clear()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.LoadTableDesc</name>
		<wmc>19</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>23</rfc>
		<lcom>103</lcom>
		<ca>11</ca>
		<ce>3</ce>
		<npm>18</npm>
		<lcom3>0.7777777777777778</lcom3>
		<loc>159</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.3508771929824561</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.947368421052632</amc>
		<cc>
			<method name="public boolean getHoldDDLTime()">1</method>
			<method name="public boolean getInheritTableSpecs()">1</method>
			<method name="public String getTmpDir()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.DynamicPartitionCtx getDPCtx()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(String sourceDir, String tmpDir, org.apache.hadoop.hive.ql.plan.TableDesc table, java.util.Map partitionSpec)">0</method>
			<method name="public void setTmpDir(String tmp)">1</method>
			<method name="public void setInheritTableSpecs(boolean inheritTableSpecs)">1</method>
			<method name="public void _init_(String sourceDir, String tmpDir, org.apache.hadoop.hive.ql.plan.TableDesc table, org.apache.hadoop.hive.ql.plan.DynamicPartitionCtx dpCtx)">0</method>
			<method name="public void setHoldDDLTime(boolean ddlTime)">1</method>
			<method name="public java.util.Map getPartitionSpec()">1</method>
			<method name="public void _init_(String sourceDir, String tmpDir, org.apache.hadoop.hive.ql.plan.TableDesc table, java.util.Map partitionSpec, boolean replace)">0</method>
			<method name="public void setDPCtx(org.apache.hadoop.hive.ql.plan.DynamicPartitionCtx dpCtx)">1</method>
			<method name="private void init(String sourceDir, String tmpDir, org.apache.hadoop.hive.ql.plan.TableDesc table, java.util.Map partitionSpec, boolean replace)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.TableDesc getTable()">1</method>
			<method name="public void setReplace(boolean replace)">1</method>
			<method name="public void setTable(org.apache.hadoop.hive.ql.plan.TableDesc table)">1</method>
			<method name="public boolean getReplace()">1</method>
			<method name="public void setPartitionSpec(java.util.Map partitionSpec)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.pcr.PcrExprProcCtx</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>5</npm>
		<lcom3>0.5</lcom3>
		<loc>30</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.6</amc>
		<cc>
			<method name="public void _init_(String tabAlias, java.util.List partList)">0</method>
			<method name="public void setPartList(java.util.List partList)">1</method>
			<method name="public java.util.List getPartList()">1</method>
			<method name="public void setTabAlias(String tabAlias)">1</method>
			<method name="public String getTabAlias()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceUnaryPrefixExpression_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ScriptOperator$OutputStreamProcessor</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>9</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>3</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>44</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.666666666666666</amc>
		<cc>
			<method name="public void close()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.ScriptOperator, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector rowInspector)">0</method>
			<method name="public void processLine(org.apache.hadoop.io.Writable line)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server$TUGIAssumingProcessor$1</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>6</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>37</loc>
		<dam>0.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.333333333333334</amc>
		<cc>
			<method name="public volatile Object run()">1</method>
			<method name="public Boolean run()">1</method>
			<method name="void _init_(org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server$TUGIAssumingProcessor, org.apache.thrift.protocol.TProtocol, org.apache.thrift.protocol.TProtocol)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.pcr.PartitionConditionRemover</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>24</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>17</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>78</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>24.666666666666668</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext transform(org.apache.hadoop.hive.ql.parse.ParseContext pctx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFConv</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>18</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>372</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.45714285714285713</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>51.857142857142854</amc>
		<cc>
			<method name="private void decode(long val, int radix)">2</method>
			<method name="private void byte2char(int radix, int fromPos)">2</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text n, org.apache.hadoop.io.IntWritable fromBase, org.apache.hadoop.io.IntWritable toBase)">20</method>
			<method name="private void char2byte(int radix, int fromPos)">2</method>
			<method name="public void _init_()">0</method>
			<method name="private long unsignedLongDiv(long x, int m)">2</method>
			<method name="private long encode(int radix, int fromPos)">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFAverage</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>15</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>12</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>80</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>25.333333333333332</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] parameters)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.HashTableSinkDesc</name>
		<wmc>51</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>88</rfc>
		<lcom>1111</lcom>
		<ca>3</ca>
		<ce>4</ce>
		<npm>50</npm>
		<lcom3>0.9592</lcom3>
		<loc>406</loc>
		<dam>1.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.12418300653594772</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.470588235294118</amc>
		<cc>
			<method name="public Byte[] getTagOrder()">1</method>
			<method name="public void setBucketFileNameMapping(java.util.LinkedHashMap bucketFileNameMapping)">1</method>
			<method name="public void setHandleSkewJoin(boolean handleSkewJoin)">1</method>
			<method name="public java.util.LinkedHashMap getBucketFileNameMapping()">1</method>
			<method name="public void setExprs(java.util.Map exprs)">1</method>
			<method name="private void initRetainExprList()">3</method>
			<method name="public void setBigKeysDirMap(java.util.Map bigKeysDirMap)">1</method>
			<method name="public boolean isNoOuterJoin()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.TableDesc getKeyTblDesc()">1</method>
			<method name="public java.util.List getValueTblDescs()">1</method>
			<method name="public java.util.Map getBigKeysDirMap()">1</method>
			<method name="public java.util.Map getExprs()">1</method>
			<method name="public void setFilters(java.util.Map filters)">1</method>
			<method name="public java.util.List getOutputColumnNames()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setNoOuterJoin(boolean noOuterJoin)">1</method>
			<method name="public void setBigTableAlias(String bigTableAlias)">1</method>
			<method name="public void setAliasBucketFileNameMapping(java.util.LinkedHashMap aliasBucketFileNameMapping)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.TableDesc getKeyTableDesc()">1</method>
			<method name="public void setKeyTblDesc(org.apache.hadoop.hive.ql.plan.TableDesc keyTblDesc)">1</method>
			<method name="public void setPosBigTable(int posBigTable)">1</method>
			<method name="public void setValueTblDescs(java.util.List valueTblDescs)">1</method>
			<method name="public void setSkewKeyDefinition(int skewKeyDefinition)">1</method>
			<method name="public void setValueTblFilteredDescs(java.util.List valueTblFilteredDescs)">1</method>
			<method name="public void setDumpFilePrefix(String dumpFilePrefix)">1</method>
			<method name="public java.util.Map getFilters()">1</method>
			<method name="public boolean isHandleSkewJoin()">1</method>
			<method name="public String getDumpFilePrefix()">1</method>
			<method name="public int getPosBigTable()">1</method>
			<method name="public java.util.Map getSkewKeysValuesTables()">1</method>
			<method name="public void setReversedExprs(java.util.Map reversedExprs)">1</method>
			<method name="public void setSmallKeysDirMap(java.util.Map smallKeysDirMap)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.MapJoinDesc clone)">0</method>
			<method name="public String getBigTableAlias()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.JoinCondDesc[] getConds()">1</method>
			<method name="public void setRetainList(java.util.Map retainList)">1</method>
			<method name="public java.util.Map getReversedExprs()">1</method>
			<method name="public java.util.Map getRetainList()">1</method>
			<method name="public void setKeys(java.util.Map keys)">1</method>
			<method name="public void setConds(org.apache.hadoop.hive.ql.plan.JoinCondDesc[] conds)">1</method>
			<method name="public java.util.LinkedHashMap getAliasBucketFileNameMapping()">1</method>
			<method name="public void setTagOrder(Byte[] tagOrder)">1</method>
			<method name="public int getSkewKeyDefinition()">1</method>
			<method name="public float getHashtableMemoryUsage()">1</method>
			<method name="public java.util.Map getSmallKeysDirMap()">1</method>
			<method name="public java.util.List getValueTblFilteredDescs()">1</method>
			<method name="public void setOutputColumnNames(java.util.List outputColumnNames)">1</method>
			<method name="public void setHashtableMemoryUsage(float hashtableMemoryUsage)">1</method>
			<method name="public void setSkewKeysValuesTables(java.util.Map skewKeysValuesTables)">1</method>
			<method name="public void setKeyTableDesc(org.apache.hadoop.hive.ql.plan.TableDesc keyTableDesc)">1</method>
			<method name="public java.util.Map getKeys()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HiveNullValueSequenceFileOutputFormat$1</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>16</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>2</npm>
		<lcom3>0.25</lcom3>
		<loc>61</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.666666666666668</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.ql.io.HiveNullValueSequenceFileOutputFormat, org.apache.hadoop.io.SequenceFile$Writer)">0</method>
			<method name="public void close(boolean abort)">1</method>
			<method name="public void write(org.apache.hadoop.io.Writable r)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeConstList</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.JobDebugger$TaskInfo</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>0.5</lcom3>
		<loc>29</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.75</amc>
		<cc>
			<method name="public String getJobId()">1</method>
			<method name="public void addLogUrl(String logUrl)">1</method>
			<method name="public void _init_(String jobId)">0</method>
			<method name="public java.util.Set getLogUrls()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.log.PerfLogger</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>35</rfc>
		<lcom>18</lcom>
		<ca>2</ca>
		<ce>8</ce>
		<npm>7</npm>
		<lcom3>1.0</lcom3>
		<loc>196</loc>
		<dam>0.26666666666666666</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.11111111111111</amc>
		<cc>
			<method name="public Long getEndTime(String method)">1</method>
			<method name="protected void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Long getStartTime(String method)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.log.PerfLogger getPerfLogger(boolean resetPerfLogger)">4</method>
			<method name="public long PerfLogEnd(org.apache.commons.logging.Log _log, String method)">3</method>
			<method name="public void PerfLogBegin(org.apache.commons.logging.Log _log, String method)">1</method>
			<method name="public void close(org.apache.commons.logging.Log _log, org.apache.hadoop.hive.ql.QueryPlan queryPlan)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.log.PerfLogger getPerfLogger()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.TokenStoreDelegationTokenSecretManager$ExpiredTokenRemover</name>
		<wmc>2</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>22</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>1</npm>
		<lcom3>0.6666666666666667</lcom3>
		<loc>108</loc>
		<dam>0.6666666666666666</dam>
		<moa>1</moa>
		<mfa>0.9846153846153847</mfa>
		<cam>0.75</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>51.5</amc>
		<cc>
			<method name="protected void _init_(org.apache.hadoop.hive.thrift.TokenStoreDelegationTokenSecretManager)">0</method>
			<method name="public void run()">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeField</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>8</rfc>
		<lcom>6</lcom>
		<ca>3</ca>
		<ce>6</ce>
		<npm>4</npm>
		<lcom3>1.3333333333333333</lcom3>
		<loc>31</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.25</amc>
		<cc>
			<method name="public boolean isSkippable()">2</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int i)">0</method>
			<method name="public org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeFieldType getFieldType()">1</method>
			<method name="public void _init_(int i)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$descFuncNames_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.JoinCond</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>11</rfc>
		<lcom>19</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>10</npm>
		<lcom3>0.7777777777777778</lcom3>
		<loc>62</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.8</amc>
		<cc>
			<method name="public void setLeft(int left)">1</method>
			<method name="public boolean getPreserved()">1</method>
			<method name="public void _init_(boolean p)">0</method>
			<method name="public void setJoinType(org.apache.hadoop.hive.ql.parse.JoinType joinType)">1</method>
			<method name="public void setRight(int right)">1</method>
			<method name="public void _init_(int left, int right, org.apache.hadoop.hive.ql.parse.JoinType joinType)">0</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.parse.JoinType getJoinType()">1</method>
			<method name="public int getRight()">1</method>
			<method name="public int getLeft()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ExecMapperContext</name>
		<wmc>21</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>19</cbo>
		<rfc>36</rfc>
		<lcom>130</lcom>
		<ca>8</ca>
		<ce>12</ce>
		<npm>19</npm>
		<lcom3>0.8800000000000001</lcom3>
		<loc>190</loc>
		<dam>0.9</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.1875</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.571428571428571</amc>
		<cc>
			<method name="public String getCurrentBigBucketFile()">1</method>
			<method name="public String getCurrentInputFile()">1</method>
			<method name="public void setFetchOperators(java.util.Map fetchOperators)">1</method>
			<method name="public void setCurrentInputFile(String currentInputFile)">1</method>
			<method name="public void setJc(org.apache.hadoop.mapred.JobConf jc)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Integer getFileId()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.MapredLocalWork getLocalWork()">1</method>
			<method name="public boolean inputFileChanged()">4</method>
			<method name="public void setFileId(Integer fileId)">1</method>
			<method name="public org.apache.hadoop.hive.ql.io.IOContext getIoCxt()">1</method>
			<method name="public void setLocalWork(org.apache.hadoop.hive.ql.plan.MapredLocalWork localWork)">1</method>
			<method name="public void setIoCxt(org.apache.hadoop.hive.ql.io.IOContext ioCxt)">1</method>
			<method name="public void setLastInputFile(String lastInputFile)">1</method>
			<method name="public String getLastInputFile()">1</method>
			<method name="public org.apache.hadoop.mapred.JobConf getJc()">1</method>
			<method name="private void setUpFetchOpContext(org.apache.hadoop.hive.ql.exec.FetchOperator fetchOp, String alias)">1</method>
			<method name="public void resetRow()">1</method>
			<method name="public java.util.Map getFetchOperators()">1</method>
			<method name="public void setCurrentBigBucketFile(String currentBigBucketFile)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFDateDiff</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>19</rfc>
		<lcom>32</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>5</npm>
		<lcom3>0.5625</lcom3>
		<loc>112</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4222222222222222</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.222222222222221</amc>
		<cc>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable t1, org.apache.hadoop.hive.serde2.io.TimestampWritable t2)">1</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable t, org.apache.hadoop.io.Text dateString)">1</method>
			<method name="private java.util.Date toDate(org.apache.hadoop.hive.serde2.io.TimestampWritable t)">2</method>
			<method name="public void _init_()">0</method>
			<method name="private java.util.Date format(String dateString)">1</method>
			<method name="private java.util.Date toDate(org.apache.hadoop.io.Text dateString)">2</method>
			<method name="private org.apache.hadoop.io.IntWritable evaluate(java.util.Date date, java.util.Date date2)">3</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.Text dateString, org.apache.hadoop.hive.serde2.io.TimestampWritable t)">1</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.Text dateString1, org.apache.hadoop.io.Text dateString2)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$metastoreCheck_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.lineage.ExprProcFactory$DefaultExprProcessor</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>10</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>41</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.333333333333334</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$NumExprProcessor</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>17</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>105</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>51.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.NullStructSerDe</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>10</rfc>
		<lcom>21</lcom>
		<ca>2</ca>
		<ce>8</ce>
		<npm>7</npm>
		<lcom3>2.0</lcom3>
		<loc>24</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2857142857142857</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.4285714285714284</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getObjectInspector()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public Object deserialize(org.apache.hadoop.io.Writable blob)">1</method>
			<method name="public Class getSerializedClass()">1</method>
			<method name="public org.apache.hadoop.io.Writable serialize(Object obj, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objInspector)">1</method>
			<method name="public void initialize(org.apache.hadoop.conf.Configuration conf, java.util.Properties tbl)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.SerDeStats getSerDeStats()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>19</cbo>
		<rfc>49</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>19</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>330</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4583333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>64.8</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="protected org.apache.hadoop.fs.FileStatus[] listStatus(org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.fs.Path path)">1</method>
			<method name="public org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit split, org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.mapred.Reporter reporter)">1</method>
			<method name="public org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf job, int numSplits)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ReduceSinkDesc</name>
		<wmc>26</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>30</rfc>
		<lcom>245</lcom>
		<ca>12</ca>
		<ce>1</ce>
		<npm>26</npm>
		<lcom3>0.9233333333333333</lcom3>
		<loc>168</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.2692307692307692</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public void setNumReducers(int numReducers)">1</method>
			<method name="public java.util.List getDistinctColumnIndices()">1</method>
			<method name="public java.util.ArrayList getOutputValueColumnNames()">1</method>
			<method name="public void setValueCols(java.util.ArrayList valueCols)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.TableDesc getValueSerializeInfo()">1</method>
			<method name="public java.util.ArrayList getOutputKeyColumnNames()">1</method>
			<method name="public int getNumReducers()">1</method>
			<method name="public void setPartitionCols(java.util.ArrayList partitionCols)">1</method>
			<method name="public void setOutputValueColumnNames(java.util.ArrayList outputValueColumnNames)">1</method>
			<method name="public void _init_(java.util.ArrayList keyCols, int numDistributionKeys, java.util.ArrayList valueCols, java.util.ArrayList outputKeyColumnNames, java.util.List distinctColumnIndices, java.util.ArrayList outputValueColumnNames, int tag, java.util.ArrayList partitionCols, int numReducers, org.apache.hadoop.hive.ql.plan.TableDesc keySerializeInfo, org.apache.hadoop.hive.ql.plan.TableDesc valueSerializeInfo)">0</method>
			<method name="public void setValueSerializeInfo(org.apache.hadoop.hive.ql.plan.TableDesc valueSerializeInfo)">1</method>
			<method name="public int getTag()">1</method>
			<method name="public void setNumDistributionKeys(int numKeys)">1</method>
			<method name="public void setTag(int tag)">1</method>
			<method name="public String getOrder()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.ArrayList getKeyCols()">1</method>
			<method name="public void setDistinctColumnIndices(java.util.List distinctColumnIndices)">1</method>
			<method name="public java.util.ArrayList getValueCols()">1</method>
			<method name="public java.util.ArrayList getPartitionCols()">1</method>
			<method name="public void setKeyCols(java.util.ArrayList keyCols)">1</method>
			<method name="public int getNumDistributionKeys()">1</method>
			<method name="public void setKeySerializeInfo(org.apache.hadoop.hive.ql.plan.TableDesc keySerializeInfo)">1</method>
			<method name="public void setOutputKeyColumnNames(java.util.ArrayList outputKeyColumnNames)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.TableDesc getKeySerializeInfo()">1</method>
			<method name="public void setOrder(String orderStr)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.HiveDriverRunHook</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void preDriverRun(org.apache.hadoop.hive.ql.HiveDriverRunHookContext)">1</method>
			<method name="public abstract void postDriverRun(org.apache.hadoop.hive.ql.HiveDriverRunHookContext)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$execStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$GlobalLimitCtx</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>10</rfc>
		<lcom>2</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>9</npm>
		<lcom3>0.65625</lcom3>
		<loc>65</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.777777777777778</amc>
		<cc>
			<method name="public void enableOpt(int globalLimit)">1</method>
			<method name="public boolean ifHasTransformOrUDTF()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public boolean isEnable()">1</method>
			<method name="public void setLastReduceLimitDesc(org.apache.hadoop.hive.ql.plan.LimitDesc lastReduceLimitDesc)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.LimitDesc getLastReduceLimitDesc()">1</method>
			<method name="public void setHasTransformOrUDTF(boolean hasTransformOrUDTF)">1</method>
			<method name="public int getGlobalLimit()">1</method>
			<method name="public void disableOpt()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ppr.OpProcFactory$FilterPPR</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>18</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>13</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>121</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4166666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>39.333333333333336</amc>
		<cc>
			<method name="private void addPruningPred(java.util.Map opToPPR, org.apache.hadoop.hive.ql.exec.TableScanOperator top, org.apache.hadoop.hive.ql.plan.ExprNodeDesc new_ppr_pred)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.SettableShortObjectInspector</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Object set(Object, short)">1</method>
			<method name="public abstract Object create(short)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>26</cbo>
		<rfc>38</rfc>
		<lcom>45</lcom>
		<ca>7</ca>
		<ce>25</ce>
		<npm>8</npm>
		<lcom3>1.0</lcom3>
		<loc>166</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.1111111111111111</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.5</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$ColumnExprProcessor getColumnExprProcessor()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$BoolExprProcessor getBoolExprProcessor()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$DefaultExprProcessor getDefaultExprProcessor()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$StrExprProcessor getStrExprProcessor()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$NullExprProcessor getNullExprProcessor()">1</method>
			<method name="public static java.util.HashMap genExprNode(org.apache.hadoop.hive.ql.parse.ASTNode expr, org.apache.hadoop.hive.ql.parse.TypeCheckCtx tcCtx)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$NumExprProcessor getNumExprProcessor()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.ExprNodeDesc processGByExpr(org.apache.hadoop.hive.ql.lib.Node nd, Object procCtx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ExplosionDesc</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>7</rfc>
		<lcom>3</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>6</npm>
		<lcom3>0.8</lcom3>
		<loc>35</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.333333333333333</amc>
		<cc>
			<method name="public String getFieldName()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public int getPosition()">1</method>
			<method name="public void setFieldName(String fieldName)">1</method>
			<method name="public void _init_(String fieldName, int position)">0</method>
			<method name="public void setPosition(int position)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$atomExpression_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lib.NodeProcessorCtx</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>154</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>154</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lib.Utils</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>12</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>70</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>22.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.Node getNthAncestor(java.util.Stack st, int n)">7</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.FunctionSemanticAnalyzer</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>19</cbo>
		<rfc>24</rfc>
		<lcom>6</lcom>
		<ca>1</ca>
		<ce>18</ce>
		<npm>2</npm>
		<lcom3>0.75</lcom3>
		<loc>120</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>22.8</amc>
		<cc>
			<method name="public void analyzeInternal(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void analyzeCreateFunction(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.conf.HiveConf conf)">0</method>
			<method name="private void analyzeDropFunction(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyByteObjectInspector</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>9</rfc>
		<lcom>6</lcom>
		<ca>4</ca>
		<ce>7</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>33</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.875</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.25</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public byte get(Object o)">1</method>
			<method name="public Object getPrimitiveJavaObject(Object o)">2</method>
			<method name="public Object copyObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.NGramEstimator$1</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>6</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>25</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public volatile int compare(Object x0, Object x1)">1</method>
			<method name="public int compare(java.util.Map$Entry o1, java.util.Map$Entry o2)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.udf.generic.NGramEstimator)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.NGramEstimator$2</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>6</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>25</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public volatile int compare(Object x0, Object x1)">1</method>
			<method name="public int compare(java.util.Map$Entry o1, java.util.Map$Entry o2)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.udf.generic.NGramEstimator)">0</method>
		</cc>
	</class>
	<class>
		<name>org.json.JSONObject</name>
		<wmc>65</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>19</cbo>
		<rfc>164</rfc>
		<lcom>1886</lcom>
		<ca>15</ca>
		<ce>6</ce>
		<npm>58</npm>
		<lcom3>0.5625</lcom3>
		<loc>1980</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.130859375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>29.43076923076923</amc>
		<cc>
			<method name="public String getString(String arg0)">1</method>
			<method name="public int getInt(String arg0)">1</method>
			<method name="public org.json.JSONObject put(String arg0, boolean arg1)">1</method>
			<method name="public org.json.JSONObject put(String arg0, Object arg1)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public boolean has(String arg0)">1</method>
			<method name="public Object opt(String arg0)">2</method>
			<method name="public int optInt(String arg0)">1</method>
			<method name="public boolean isNull(String arg0)">1</method>
			<method name="public static Object stringToValue(String arg0)">14</method>
			<method name="public Object get(String arg0)">1</method>
			<method name="static String valueToString(Object arg0)">1</method>
			<method name="public long optLong(String arg0, long arg1)">1</method>
			<method name="public org.json.JSONObject accumulate(String arg0, Object arg1)">1</method>
			<method name="public org.json.JSONObject getJSONObject(String arg0)">1</method>
			<method name="public int optInt(String arg0, int arg1)">1</method>
			<method name="public void _init_(org.json.JSONTokener arg0)">0</method>
			<method name="public int length()">1</method>
			<method name="String toString(int arg0, int arg1)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public org.json.JSONArray optJSONArray(String arg0)">2</method>
			<method name="public org.json.JSONObject putOnce(String arg0, Object arg1)">1</method>
			<method name="private boolean isStandardProperty(Class arg0)">11</method>
			<method name="public void _init_(Object arg0)">0</method>
			<method name="public String toString(int arg0)">1</method>
			<method name="private void populateInternalMap(Object arg0, boolean arg1)">15</method>
			<method name="public java.io.Writer write(java.io.Writer arg0)">1</method>
			<method name="public org.json.JSONObject append(String arg0, Object arg1)">1</method>
			<method name="public void _init_(java.util.Map arg0)">0</method>
			<method name="public boolean optBoolean(String arg0)">1</method>
			<method name="public void _init_(Object arg0, boolean arg1)">0</method>
			<method name="public static String doubleToString(double arg0)">8</method>
			<method name="public org.json.JSONArray toJSONArray(org.json.JSONArray arg0)">1</method>
			<method name="public boolean getBoolean(String arg0)">1</method>
			<method name="public static String[] getNames(Object arg0)">4</method>
			<method name="public void _init_(String arg0)">0</method>
			<method name="public java.util.Iterator keys()">1</method>
			<method name="public long optLong(String arg0)">1</method>
			<method name="public org.json.JSONObject putOpt(String arg0, Object arg1)">1</method>
			<method name="public void _init_(org.json.JSONObject arg0, String[] arg1)">0</method>
			<method name="public org.json.JSONObject put(String arg0, int arg1)">1</method>
			<method name="public org.json.JSONObject put(String arg0, java.util.Map arg1)">1</method>
			<method name="public double getDouble(String arg0)">1</method>
			<method name="public org.json.JSONObject put(String arg0, double arg1)">1</method>
			<method name="public org.json.JSONObject optJSONObject(String arg0)">2</method>
			<method name="public boolean optBoolean(String arg0, boolean arg1)">1</method>
			<method name="public org.json.JSONObject put(String arg0, java.util.Collection arg1)">1</method>
			<method name="public Object remove(String arg0)">1</method>
			<method name="public String toString()">3</method>
			<method name="public double optDouble(String arg0)">1</method>
			<method name="public String optString(String arg0)">1</method>
			<method name="public org.json.JSONObject put(String arg0, long arg1)">1</method>
			<method name="static void testValidity(Object arg0)">1</method>
			<method name="public long getLong(String arg0)">1</method>
			<method name="public static String[] getNames(org.json.JSONObject arg0)">3</method>
			<method name="public static String quote(String arg0)">19</method>
			<method name="public String optString(String arg0, String arg1)">2</method>
			<method name="public static String numberToString(Number arg0)">1</method>
			<method name="public java.util.Iterator sortedKeys()">1</method>
			<method name="public org.json.JSONArray getJSONArray(String arg0)">1</method>
			<method name="public double optDouble(String arg0, double arg1)">2</method>
			<method name="static String valueToString(Object arg0, int arg1, int arg2)">1</method>
			<method name="public org.json.JSONArray names()">3</method>
			<method name="public void _init_(java.util.Map arg0, boolean arg1)">0</method>
			<method name="public void _init_(Object arg0, String[] arg1)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TType</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>18</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.session.SessionState$ResourceHook</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>5</ca>
		<ce>0</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract String preHook(java.util.Set, String)">1</method>
			<method name="public abstract boolean postHook(java.util.Set, String)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.server.TThreadPoolServer$1</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</name>
		<wmc>13</wmc>
		<dit>1</dit>
		<noc>1</noc>
		<cbo>34</cbo>
		<rfc>98</rfc>
		<lcom>48</lcom>
		<ca>4</ca>
		<ce>31</ce>
		<npm>11</npm>
		<lcom3>0.8589743589743589</lcom3>
		<loc>971</loc>
		<dam>0.38461538461538464</dam>
		<moa>6</moa>
		<mfa>0.0</mfa>
		<cam>0.17777777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>72.6923076923077</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe$SerDeParameters initSerdeParams(org.apache.hadoop.conf.Configuration job, java.util.Properties tbl, String serdeName)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getObjectInspector()">1</method>
			<method name="public static void serialize(org.apache.hadoop.hive.serde2.ByteStream$Output out, Object obj, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objInspector, byte[] separators, int level, org.apache.hadoop.io.Text nullSequence, boolean escaped, byte escapeChar, boolean[] needsEscape)">1</method>
			<method name="public static byte getByte(String altValue, byte defaultVal)">3</method>
			<method name="protected void serializeField(org.apache.hadoop.hive.serde2.ByteStream$Output out, Object obj, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objInspector, org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe$SerDeParameters serdeParams)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Class getSerializedClass()">1</method>
			<method name="public org.apache.hadoop.io.Writable serialize(Object obj, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objInspector)">1</method>
			<method name="public void initialize(org.apache.hadoop.conf.Configuration job, java.util.Properties tbl)">1</method>
			<method name="public String toString()">1</method>
			<method name="public Object deserialize(org.apache.hadoop.io.Writable field)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.SerDeStats getSerDeStats()">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.AbstractGenericUDFEWAHBitmapBop</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>2</noc>
		<cbo>21</cbo>
		<rfc>41</rfc>
		<lcom>16</lcom>
		<ca>2</ca>
		<ce>19</ce>
		<npm>3</npm>
		<lcom3>0.8285714285714285</lcom3>
		<loc>330</loc>
		<dam>0.8</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.2857142857142857</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>39.625</amc>
		<cc>
			<method name="protected javaewah.EWAHCompressedBitmap wordArrayToBitmap(Object b)">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="protected java.util.List bitmapToWordArray(javaewah.EWAHCompressedBitmap bitmap)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="void _init_(String name)">0</method>
			<method name="public String getDisplayString(String[] children)">3</method>
			<method name="protected abstract javaewah.EWAHCompressedBitmap bitmapBop(javaewah.EWAHCompressedBitmap, javaewah.EWAHCompressedBitmap)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.KeyWrapperFactory$TextKeyWrapper</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>15</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>8</npm>
		<lcom3>0.3125</lcom3>
		<loc>158</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.30158730158730157</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.11111111111111</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.exec.KeyWrapper copyKey()">1</method>
			<method name="private void _init_(org.apache.hadoop.hive.ql.exec.KeyWrapperFactory, int hashcode, Object key, boolean isCopy)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.KeyWrapperFactory, boolean isCopy)">0</method>
			<method name="public Object[] getKeyArray()">1</method>
			<method name="public int hashCode()">1</method>
			<method name="public void setHashKey()">2</method>
			<method name="public void getNewKey(Object row, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector rowInspector)">1</method>
			<method name="public boolean equals(Object other)">6</method>
			<method name="public void copyKey(org.apache.hadoop.hive.ql.exec.KeyWrapper oldWrapper)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.meta_data.SetMetaData</name>
		<wmc>1</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public void _init_(byte type, org.apache.thrift.meta_data.FieldValueMetaData eMetaData)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFStd</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>12</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>73</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>35.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] parameters)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$indexProperties_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeStruct</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>12</rfc>
		<lcom>10</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>5</npm>
		<lcom3>1.25</lcom3>
		<loc>56</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.0</amc>
		<cc>
			<method name="public byte getType()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeFieldList getFieldList()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int i)">0</method>
			<method name="public String toString()">1</method>
			<method name="public void _init_(int i)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.classification.InterfaceStability$Evolving</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.MapJoinResolver</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>8</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>6</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>31</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext resolve(org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext pctx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TStandardFile</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>14</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>6</npm>
		<lcom3>0.5</lcom3>
		<loc>57</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4444444444444444</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.166666666666666</amc>
		<cc>
			<method name="public java.io.InputStream getInputStream()">1</method>
			<method name="public void _init_(String path)">0</method>
			<method name="public java.io.OutputStream getOutputStream()">1</method>
			<method name="public long length()">1</method>
			<method name="public void close()">1</method>
			<method name="public void seek(long pos)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.CombineHiveKey</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>11</rfc>
		<lcom>13</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>6</npm>
		<lcom3>0.75</lcom3>
		<loc>48</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4583333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.571428571428571</amc>
		<cc>
			<method name="public int compareTo(Object w)">2</method>
			<method name="public void _init_(Object key)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object getKey()">1</method>
			<method name="public void write(java.io.DataOutput out)">1</method>
			<method name="public void setKey(Object key)">1</method>
			<method name="public void readFields(java.io.DataInput in)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.server.TThreadPoolServer</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>23</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>3</npm>
		<lcom3>0.72</lcom3>
		<loc>142</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>21.833333333333332</amc>
		<cc>
			<method name="public void stop()">1</method>
			<method name="public void _init_(org.apache.thrift.server.TThreadPoolServer$Args args)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="static org.slf4j.Logger access$200()">1</method>
			<method name="public void serve()">3</method>
			<method name="static boolean access$100(org.apache.thrift.server.TThreadPoolServer x0)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.SimpleCharStream</name>
		<wmc>36</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>48</rfc>
		<lcom>338</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>31</npm>
		<lcom3>0.43214285714285716</lcom3>
		<loc>1108</loc>
		<dam>0.6875</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3134920634920635</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>29.333333333333332</amc>
		<cc>
			<method name="protected void FillBuff()">1</method>
			<method name="protected int getTabSize(int i)">1</method>
			<method name="public void _init_(java.io.Reader dstream, int startline, int startcolumn, int buffersize)">0</method>
			<method name="public void _init_(java.io.Reader dstream)">0</method>
			<method name="public void ReInit(java.io.InputStream dstream, String encoding, int startline, int startcolumn, int buffersize)">1</method>
			<method name="protected void UpdateLineColumn(char c)">5</method>
			<method name="public int getLine()">1</method>
			<method name="public void ReInit(java.io.Reader dstream, int startline, int startcolumn)">1</method>
			<method name="public void _init_(java.io.InputStream dstream)">0</method>
			<method name="public void adjustBeginLineColumn(int newLine, int newCol)">7</method>
			<method name="protected void setTabSize(int i)">1</method>
			<method name="public void backup(int amount)">2</method>
			<method name="public void ReInit(java.io.Reader dstream)">1</method>
			<method name="public int getBeginLine()">1</method>
			<method name="public void ReInit(java.io.InputStream dstream, String encoding, int startline, int startcolumn)">1</method>
			<method name="public void _init_(java.io.InputStream dstream, String encoding)">0</method>
			<method name="public void _init_(java.io.InputStream dstream, int startline, int startcolumn)">0</method>
			<method name="protected void ExpandBuff(boolean wrapAround)">2</method>
			<method name="public void _init_(java.io.Reader dstream, int startline, int startcolumn)">0</method>
			<method name="public void ReInit(java.io.InputStream dstream, int startline, int startcolumn)">1</method>
			<method name="public void _init_(java.io.InputStream dstream, String encoding, int startline, int startcolumn)">0</method>
			<method name="public void ReInit(java.io.InputStream dstream)">1</method>
			<method name="public void ReInit(java.io.Reader dstream, int startline, int startcolumn, int buffersize)">3</method>
			<method name="public char readChar()">1</method>
			<method name="public void ReInit(java.io.InputStream dstream, String encoding)">1</method>
			<method name="public void _init_(java.io.InputStream dstream, int startline, int startcolumn, int buffersize)">0</method>
			<method name="public char BeginToken()">1</method>
			<method name="public int getColumn()">1</method>
			<method name="public void Done()">1</method>
			<method name="public int getEndColumn()">1</method>
			<method name="public void _init_(java.io.InputStream dstream, String encoding, int startline, int startcolumn, int buffersize)">0</method>
			<method name="public char[] GetSuffix(int len)">2</method>
			<method name="public void ReInit(java.io.InputStream dstream, int startline, int startcolumn, int buffersize)">1</method>
			<method name="public int getEndLine()">1</method>
			<method name="public String GetImage()">2</method>
			<method name="public int getBeginColumn()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFToByte</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>23</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>12</ce>
		<npm>10</npm>
		<lcom3>0.1111111111111111</lcom3>
		<loc>138</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.19</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.7</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.io.NullWritable i)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.io.IntWritable i)">2</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable i)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.io.BooleanWritable i)">3</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable i)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.io.Text i)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.io.LongWritable i)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.io.FloatWritable i)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.hive.serde2.io.ShortWritable i)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.ShortStack</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>13</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>6</npm>
		<lcom3>0.16666666666666666</lcom3>
		<loc>135</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.42857142857142855</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.0</amc>
		<cc>
			<method name="public void clear()">1</method>
			<method name="private void grow()">1</method>
			<method name="public void _init_(int initialCapacity)">0</method>
			<method name="public short pop()">1</method>
			<method name="public void push(short pushed)">2</method>
			<method name="public short peek()">1</method>
			<method name="public String toString()">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFPower</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>28</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable a, org.apache.hadoop.hive.serde2.io.DoubleWritable b)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.RecordWriter</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>3</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>3</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void write(org.apache.hadoop.io.Writable)">1</method>
			<method name="public abstract void close()">1</method>
			<method name="public abstract void initialize(java.io.OutputStream, org.apache.hadoop.conf.Configuration)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$destination_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$stringLiteralSequence_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TSaslServerTransport$TSaslServerDefinition</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>24</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.0</amc>
		<cc>
			<method name="public void _init_(String mechanism, String protocol, String serverName, java.util.Map props, javax.security.auth.callback.CallbackHandler cbh)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.FetchWork</name>
		<wmc>24</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>39</rfc>
		<lcom>192</lcom>
		<ca>12</ca>
		<ce>2</ce>
		<npm>24</npm>
		<lcom3>0.8532608695652174</lcom3>
		<loc>240</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.2708333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.666666666666666</amc>
		<cc>
			<method name="public int getLimit()">1</method>
			<method name="public void setPartDesc(java.util.ArrayList partDesc)">1</method>
			<method name="public java.util.ArrayList getPartDesc()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setSerializationNullFormat(String format)">1</method>
			<method name="public java.util.ArrayList getPartDir()">1</method>
			<method name="public String getTblDir()">1</method>
			<method name="public void _init_(String tblDir, org.apache.hadoop.hive.ql.plan.TableDesc tblDesc)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.TableDesc getTblDesc()">1</method>
			<method name="public void setLimit(int limit)">1</method>
			<method name="public java.util.List getPartDirPath()">1</method>
			<method name="public String getSerializationNullFormat()">1</method>
			<method name="public void setTblDesc(org.apache.hadoop.hive.ql.plan.TableDesc tblDesc)">1</method>
			<method name="public void setTblDir(String tblDir)">1</method>
			<method name="public void setPartDir(java.util.ArrayList partDir)">1</method>
			<method name="public void _init_(java.util.List partDir, java.util.List partDesc)">0</method>
			<method name="public void _init_(String tblDir, org.apache.hadoop.hive.ql.plan.TableDesc tblDesc, int limit)">0</method>
			<method name="public static java.util.List convertStringToPathArray(java.util.List paths)">3</method>
			<method name="public void setLeastNumRows(int leastNumRows)">1</method>
			<method name="public void _init_(java.util.List partDir, java.util.List partDesc, int limit)">0</method>
			<method name="public static java.util.List convertPathToStringArray(java.util.List paths)">3</method>
			<method name="public int getLeastNumRows()">1</method>
			<method name="public org.apache.hadoop.fs.Path getTblDirPath()">1</method>
			<method name="public String toString()">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory$ColumnPrunerReduceSinkProc</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>39</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>15</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>219</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>71.66666666666667</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceEqualOperator_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFSum</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>16</rfc>
		<lcom>3</lcom>
		<ca>3</ca>
		<ce>13</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>84</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.666666666666668</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] parameters)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.RCFileRecordReader</name>
		<wmc>17</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>31</rfc>
		<lcom>54</lcom>
		<ca>2</ca>
		<ce>9</ce>
		<npm>15</npm>
		<lcom3>0.725</lcom3>
		<loc>211</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.21008403361344538</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.117647058823529</amc>
		<cc>
			<method name="public long getStart()">1</method>
			<method name="public float getProgress()">1</method>
			<method name="public void sync(long pos)">1</method>
			<method name="public volatile boolean next(Object x0, Object x1)">1</method>
			<method name="public void close()">1</method>
			<method name="public void resetBuffer()">1</method>
			<method name="public volatile Object createKey()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.columnar.BytesRefArrayWritable createValue()">1</method>
			<method name="public org.apache.hadoop.io.LongWritable createKey()">1</method>
			<method name="protected void seek(long pos)">1</method>
			<method name="protected boolean next(org.apache.hadoop.io.LongWritable key)">1</method>
			<method name="public volatile Object createValue()">1</method>
			<method name="public Class getKeyClass()">1</method>
			<method name="public long getPos()">1</method>
			<method name="public void _init_(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.mapred.FileSplit split)">0</method>
			<method name="public Class getValueClass()">1</method>
			<method name="public boolean next(org.apache.hadoop.io.LongWritable key, org.apache.hadoop.hive.serde2.columnar.BytesRefArrayWritable value)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.xml.UDFXPathInteger</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>18</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public int evaluate(String xml, String path)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde.test.InnerStruct$_Fields</name>
		<wmc>9</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>24</rfc>
		<lcom>26</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>0.8</lcom3>
		<loc>110</loc>
		<dam>0.8</dam>
		<moa>2</moa>
		<mfa>0.65</mfa>
		<cam>0.3125</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>10.666666666666666</amc>
		<cc>
			<method name="private void _init_(String, int, short thriftId, String fieldName)">0</method>
			<method name="public static org.apache.hadoop.hive.serde.test.InnerStruct$_Fields findByThriftId(int fieldId)">3</method>
			<method name="public static org.apache.hadoop.hive.serde.test.InnerStruct$_Fields[] values()">1</method>
			<method name="public String getFieldName()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde.test.InnerStruct$_Fields findByName(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.serde.test.InnerStruct$_Fields findByThriftIdOrThrow(int fieldId)">2</method>
			<method name="public static org.apache.hadoop.hive.serde.test.InnerStruct$_Fields valueOf(String name)">1</method>
			<method name="public short getThriftFieldId()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.DriverContext</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>15</rfc>
		<lcom>10</lcom>
		<ca>15</ca>
		<ce>2</ce>
		<npm>8</npm>
		<lcom3>0.7142857142857143</lcom3>
		<loc>76</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.3</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.125</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.Context getCtx()">1</method>
			<method name="public int getCurJobNo()">1</method>
			<method name="public static boolean isLaunchable(org.apache.hadoop.hive.ql.exec.Task tsk)">4</method>
			<method name="public java.util.Queue getRunnable()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(java.util.Queue runnable, org.apache.hadoop.hive.ql.Context ctx)">0</method>
			<method name="public void addToRunnable(org.apache.hadoop.hive.ql.exec.Task tsk)">1</method>
			<method name="public void incCurJobNo(int amount)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Utilities</name>
		<wmc>100</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>144</cbo>
		<rfc>385</rfc>
		<lcom>4786</lcom>
		<ca>73</ca>
		<ce>83</ce>
		<npm>90</npm>
		<lcom3>0.987772461456672</lcom3>
		<loc>4105</loc>
		<dam>0.2631578947368421</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.03718031377605846</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>39.86</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.plan.TableDesc getTableDesc(String cols, String colTypes)">1</method>
			<method name="private static void createEmptyBuckets(org.apache.hadoop.conf.Configuration hconf, java.util.ArrayList paths, org.apache.hadoop.hive.ql.plan.FileSinkDesc conf)">1</method>
			<method name="public static boolean isEmptyPath(org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.fs.Path dirPath)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.QueryPlan deserializeQueryPlan(java.io.InputStream in, org.apache.hadoop.conf.Configuration conf)">3</method>
			<method name="public static java.util.List getColumnNames(java.util.Properties props)">5</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.ExprNodeDesc deserializeExpression(String s, org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="public static void mvFileToFinalPath(String specPath, org.apache.hadoop.conf.Configuration hconf, boolean success, org.apache.commons.logging.Log log, org.apache.hadoop.hive.ql.plan.DynamicPartitionCtx dpCtx, org.apache.hadoop.hive.ql.plan.FileSinkDesc conf)">1</method>
			<method name="private void _init_()">0</method>
			<method name="public static java.util.List mergeUniqElems(java.util.List src, java.util.List dest)">5</method>
			<method name="public static org.apache.hadoop.fs.Path toTaskTempPath(org.apache.hadoop.fs.Path orig)">2</method>
			<method name="private static String replaceTaskIdFromFilename(String filename, String oldTaskId, String newTaskId)">5</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.MapredWork getMapRedWork(org.apache.hadoop.conf.Configuration job)">5</method>
			<method name="public static org.apache.hadoop.hive.ql.io.RCFile$Writer createRCFileWriter(org.apache.hadoop.mapred.JobConf jc, org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path file, boolean isCompressed)">1</method>
			<method name="public static java.sql.Connection connectWithRetry(String connectionString, int waitWindow, int maxRetries)">1</method>
			<method name="public static String replaceTaskIdFromFilename(String filename, int bucketNum)">1</method>
			<method name="public static transient java.util.Properties makeProperties(String[] olist)">2</method>
			<method name="public static void setColumnTypeList(org.apache.hadoop.mapred.JobConf jobConf, org.apache.hadoop.hive.ql.exec.Operator op)">4</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.MapredLocalWork deserializeMapRedLocalWork(java.io.InputStream in, org.apache.hadoop.conf.Configuration conf)">3</method>
			<method name="public static java.sql.PreparedStatement prepareWithRetry(java.sql.Connection conn, String stmt, int waitWindow, int maxRetries)">1</method>
			<method name="public static String getResourceFiles(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.hive.ql.session.SessionState$ResourceType t)">4</method>
			<method name="public static boolean supportCombineFileInputFormat()">2</method>
			<method name="public static org.apache.hadoop.fs.Path toTaskTempPath(String orig)">1</method>
			<method name="public static org.apache.hadoop.fs.FileStatus[] getFileStatusRecurse(org.apache.hadoop.fs.Path path, int level, org.apache.hadoop.fs.FileSystem fs)">1</method>
			<method name="public static boolean isEmptyPath(org.apache.hadoop.mapred.JobConf job, String dirPath, org.apache.hadoop.hive.ql.Context ctx)">1</method>
			<method name="public static void clearMapRedWork(org.apache.hadoop.conf.Configuration job)">3</method>
			<method name="private static boolean supportedJDOFuncs(org.apache.hadoop.hive.ql.udf.generic.GenericUDF func)">4</method>
			<method name="public static String generateTarFileName(String name)">1</method>
			<method name="public static boolean contentsEqual(java.io.InputStream is1, java.io.InputStream is2, boolean ignoreWhitespace)">1</method>
			<method name="public static void removeFromClassPath(String[] pathsToRemove)">1</method>
			<method name="public static String now()">1</method>
			<method name="public static void addMapWork(org.apache.hadoop.hive.ql.plan.MapredWork mr, org.apache.hadoop.hive.ql.metadata.Table tbl, String alias, org.apache.hadoop.hive.ql.exec.Operator work)">1</method>
			<method name="public static String generateFileName(Byte tag, String bigBucketFileName)">1</method>
			<method name="public static void serializeMapRedWork(org.apache.hadoop.hive.ql.plan.MapredWork w, java.io.OutputStream out)">3</method>
			<method name="public static String getTaskIdFromFilename(String filename)">3</method>
			<method name="public static org.apache.hadoop.io.SequenceFile$Writer createSequenceWriter(org.apache.hadoop.mapred.JobConf jc, org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path file, Class keyClass, Class valClass)">1</method>
			<method name="public static String getHiveJobID(org.apache.hadoop.conf.Configuration job)">2</method>
			<method name="public static org.apache.hadoop.fs.Path toTempPath(org.apache.hadoop.fs.Path orig)">2</method>
			<method name="public static java.util.List getColumnNamesFromSortCols(java.util.List sortCols)">2</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.TableDesc getTableDesc(org.apache.hadoop.hive.ql.metadata.Table tbl)">1</method>
			<method name="public static long getRandomWaitTime(int baseWindow, int failures, java.util.Random r)">1</method>
			<method name="public static java.io.OutputStream createCompressedStream(org.apache.hadoop.mapred.JobConf jc, java.io.OutputStream out, boolean isCompressed)">1</method>
			<method name="public static String escapeSqlLike(String key)">6</method>
			<method name="public static java.util.List getFieldSchemaString(java.util.List fl)">4</method>
			<method name="private static String replaceTaskId(String taskId, int bucketNum)">2</method>
			<method name="public static void rename(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path src, org.apache.hadoop.fs.Path dst)">1</method>
			<method name="public static String generateTmpURI(String baseURI, String id)">1</method>
			<method name="public static String formatMsecToStr(long msec)">8</method>
			<method name="public static org.apache.hadoop.io.SequenceFile$Writer createSequenceWriter(org.apache.hadoop.mapred.JobConf jc, org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path file, Class keyClass, Class valClass, boolean isCompressed)">1</method>
			<method name="public static Class getBuiltinUtilsClass()">1</method>
			<method name="public static void serializeMapRedLocalWork(org.apache.hadoop.hive.ql.plan.MapredLocalWork w, java.io.OutputStream out)">3</method>
			<method name="public static void reworkMapRedWork(org.apache.hadoop.hive.ql.exec.Task task, boolean reworkMapredWork, org.apache.hadoop.hive.conf.HiveConf conf)">1</method>
			<method name="public static int getDefaultNotificationInterval(org.apache.hadoop.conf.Configuration hconf)">2</method>
			<method name="public static void removeTempOrDuplicateFiles(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path path)">1</method>
			<method name="private static String getOpTreeSkel_helper(org.apache.hadoop.hive.ql.exec.Operator op, String indent)">4</method>
			<method name="public static java.io.OutputStream createCompressedStream(org.apache.hadoop.mapred.JobConf jc, java.io.OutputStream out)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.stats.StatsPublisher getStatsPublisher(org.apache.hadoop.mapred.JobConf jc)">2</method>
			<method name="public static String getOpTreeSkel(org.apache.hadoop.hive.ql.exec.Operator op)">1</method>
			<method name="public static org.apache.hadoop.fs.ContentSummary getInputSummary(org.apache.hadoop.hive.ql.Context ctx, org.apache.hadoop.hive.ql.plan.MapredWork work, org.apache.hadoop.fs.PathFilter filter)">1</method>
			<method name="public static String getTaskId(org.apache.hadoop.conf.Configuration hconf)">4</method>
			<method name="public static boolean isTempPath(org.apache.hadoop.fs.FileStatus file)">3</method>
			<method name="public static void serializeQueryPlan(org.apache.hadoop.hive.ql.QueryPlan plan, java.io.OutputStream out)">1</method>
			<method name="public static org.apache.hadoop.fs.Path toTempPath(String orig)">1</method>
			<method name="public static java.util.List getColumnTypes(java.util.Properties props)">5</method>
			<method name="public static void renameOrMoveFiles(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path src, org.apache.hadoop.fs.Path dst)">1</method>
			<method name="private static boolean isWhitespace(int c)">2</method>
			<method name="public static java.util.List getColumnNamesFromFieldSchema(java.util.List partCols)">2</method>
			<method name="public static transient java.util.ArrayList makeList(Object[] olist)">2</method>
			<method name="public static ClassLoader addToClassPath(ClassLoader cloader, String[] newPaths)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.PartitionDesc getPartitionDescFromTableDesc(org.apache.hadoop.hive.ql.plan.TableDesc tblDesc, org.apache.hadoop.hive.ql.metadata.Partition part)">1</method>
			<method name="public static void validatePartSpec(org.apache.hadoop.hive.ql.metadata.Table tbl, java.util.Map partSpec)">1</method>
			<method name="public static String getFileExtension(org.apache.hadoop.mapred.JobConf jc, boolean isCompressed)">1</method>
			<method name="public static void serializeTasks(org.apache.hadoop.hive.ql.exec.Task t, java.io.OutputStream out)">3</method>
			<method name="private static void getMRTasks(java.util.List tasks, java.util.List mrTasks)">4</method>
			<method name="public static java.util.List getFullDPSpecs(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.hive.ql.plan.DynamicPartitionCtx dpCtx)">1</method>
			<method name="public static void validateColumnNames(java.util.List colNames, java.util.List checkCols)">1</method>
			<method name="public static void setMapRedWork(org.apache.hadoop.conf.Configuration job, org.apache.hadoop.hive.ql.plan.MapredWork w, String hiveScratchDir)">2</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.PartitionDesc getPartitionDesc(org.apache.hadoop.hive.ql.metadata.Partition part)">1</method>
			<method name="public static String getFileExtension(org.apache.hadoop.mapred.JobConf jc, boolean isCompressed, org.apache.hadoop.hive.ql.io.HiveOutputFormat hiveOutputFormat)">4</method>
			<method name="public static java.util.HashMap removeTempOrDuplicateFiles(org.apache.hadoop.fs.FileStatus[] items, org.apache.hadoop.fs.FileSystem fs)">1</method>
			<method name="public static double showTime(long time)">1</method>
			<method name="public static boolean checkJDOPushDown(org.apache.hadoop.hive.ql.metadata.Table tab, org.apache.hadoop.hive.ql.plan.ExprNodeDesc expr)">8</method>
			<method name="public static Object executeWithRetry(org.apache.hadoop.hive.ql.exec.Utilities$SQLCommand cmd, java.sql.PreparedStatement stmt, int baseWindow, int maxRetries)">1</method>
			<method name="static org.apache.commons.logging.Log access$000()">1</method>
			<method name="public static void setColumnNameList(org.apache.hadoop.mapred.JobConf jobConf, org.apache.hadoop.hive.ql.exec.Operator op)">4</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.Utilities$StreamStatus readColumn(java.io.DataInput in, java.io.OutputStream out)">1</method>
			<method name="public static String generatePath(String baseURI, String dumpFilePrefix, Byte tag, String bigBucketFileName)">1</method>
			<method name="public static String generatePath(org.apache.hadoop.fs.Path baseURI, String filename)">1</method>
			<method name="public static String generateTarURI(org.apache.hadoop.fs.Path baseURI, String filename)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.MapredWork deserializeMapRedWork(java.io.InputStream in, org.apache.hadoop.conf.Configuration conf)">3</method>
			<method name="public static java.util.List getMRTasks(java.util.List tasks)">2</method>
			<method name="public static String abbreviate(String str, int max)">2</method>
			<method name="public static void copyTableJobPropertiesToConf(org.apache.hadoop.hive.ql.plan.TableDesc tbl, org.apache.hadoop.mapred.JobConf job)">3</method>
			<method name="public static transient java.util.HashMap makeMap(Object[] olist)">2</method>
			<method name="public static String getNameMessage(Exception e)">1</method>
			<method name="public static java.util.ArrayList removeTempOrDuplicateFiles(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path path, org.apache.hadoop.hive.ql.plan.DynamicPartitionCtx dpCtx)">1</method>
			<method name="public static String generateTarURI(String baseURI, String filename)">1</method>
			<method name="public static String serializeExpression(org.apache.hadoop.hive.ql.plan.ExprNodeDesc expr)">1</method>
			<method name="public static String formatBinaryString(byte[] array, int start, int length)">3</method>
			<method name="public static String realFile(String newFile, org.apache.hadoop.conf.Configuration conf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$columnRefOrder_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.meta_data.ListMetaData</name>
		<wmc>1</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>8</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public void _init_(byte type, org.apache.thrift.meta_data.FieldValueMetaData eMetaData)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.CommandNeedRetryException</name>
		<wmc>4</wmc>
		<dit>3</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>8</rfc>
		<lcom>6</lcom>
		<ca>4</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>1.3333333333333333</lcom3>
		<loc>21</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>1.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(Throwable cause)">0</method>
			<method name="public void _init_(String message, Throwable cause)">0</method>
			<method name="public void _init_(String message)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.HiveIndexQueryContext</name>
		<wmc>13</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>16</rfc>
		<lcom>50</lcom>
		<ca>5</ca>
		<ce>1</ce>
		<npm>13</npm>
		<lcom3>0.8611111111111112</lcom3>
		<loc>86</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.24358974358974358</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.153846153846154</amc>
		<cc>
			<method name="public void setIndexIntermediateFile(String indexIntermediateFile)">1</method>
			<method name="public String getIndexInputFormat()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ExprNodeDesc getResidualPredicate()">1</method>
			<method name="public void addAdditionalSemanticInputs(java.util.HashSet additionalParseInputs)">2</method>
			<method name="public java.util.Set getQueryPartitions()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setResidualPredicate(org.apache.hadoop.hive.ql.plan.ExprNodeDesc residualPredicate)">1</method>
			<method name="public void setQueryTasks(java.util.List indexQueryTasks)">1</method>
			<method name="public void setIndexInputFormat(String indexInputFormat)">1</method>
			<method name="public String getIndexIntermediateFile()">1</method>
			<method name="public void setQueryPartitions(java.util.Set queryPartitions)">1</method>
			<method name="public java.util.HashSet getAdditionalSemanticInputs()">1</method>
			<method name="public java.util.List getQueryTasks()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.HadoopShims$JobTrackerState</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>5</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.888888888888889</lcom3>
		<loc>45</loc>
		<dam>0.3333333333333333</dam>
		<moa>3</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>9.5</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.shims.HadoopShims$JobTrackerState valueOf(String name)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.shims.HadoopShims$JobTrackerState[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFPercentileApprox</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>20</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>16</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>311</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>102.33333333333333</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFParameterInfo info)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.Optimizer</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>21</cbo>
		<rfc>27</rfc>
		<lcom>2</lcom>
		<ca>1</ca>
		<ce>20</ce>
		<npm>5</npm>
		<lcom3>0.625</lcom3>
		<loc>170</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>32.6</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext optimize()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void initialize(org.apache.hadoop.hive.conf.HiveConf hiveConf)">8</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext getPctx()">1</method>
			<method name="public void setPctx(org.apache.hadoop.hive.ql.parse.ParseContext pctx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.server.TNonblockingServer$AbstractNonblockingServerArgs</name>
		<wmc>1</wmc>
		<dit>0</dit>
		<noc>2</noc>
		<cbo>9</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>5</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>15</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.0</amc>
		<cc>
			<method name="public void _init_(org.apache.thrift.transport.TNonblockingServerTransport transport)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.UDTFOperator</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>20</cbo>
		<rfc>29</rfc>
		<lcom>9</lcom>
		<ca>2</ca>
		<ce>19</ce>
		<npm>5</npm>
		<lcom3>0.9444444444444445</lcom3>
		<loc>166</loc>
		<dam>0.3333333333333333</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.34285714285714286</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>21.857142857142858</amc>
		<cc>
			<method name="public void forwardUDTFOutput(Object o)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void processOp(Object row, int tag)">1</method>
			<method name="public String getName()">1</method>
			<method name="protected void closeOp(boolean abort)">1</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.JobCloseFeedBack$FeedBackType</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.888888888888889</lcom3>
		<loc>45</loc>
		<dam>0.3333333333333333</dam>
		<moa>3</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>9.5</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.exec.JobCloseFeedBack$FeedBackType[] values()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.JobCloseFeedBack$FeedBackType valueOf(String name)">1</method>
			<method name="private void _init_(String, int)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.processors.DfsProcessor</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>25</rfc>
		<lcom>2</lcom>
		<ca>1</ca>
		<ce>11</ce>
		<npm>3</npm>
		<lcom3>0.7777777777777777</lcom3>
		<loc>94</loc>
		<dam>0.3333333333333333</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>21.75</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.processors.CommandProcessorResponse run(String command)">4</method>
			<method name="public void init()">1</method>
			<method name="public void _init_(org.apache.hadoop.conf.Configuration conf)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFHour</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>13</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>0.25</lcom3>
		<loc>86</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.333333333333332</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable t)">2</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.Text dateString)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TFramedTransport$Factory</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>3</npm>
		<lcom3>0.0</lcom3>
		<loc>23</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.333333333333333</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(int maxLength)">0</method>
			<method name="public org.apache.thrift.transport.TTransport getTransport(org.apache.thrift.transport.TTransport base)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector$PrimitiveCategory</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>74</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>73</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9743589743589745</lcom3>
		<loc>155</loc>
		<dam>0.07692307692307693</dam>
		<moa>13</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>34.5</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector$PrimitiveCategory valueOf(String name)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector$PrimitiveCategory[] values()">1</method>
			<method name="private void _init_(String, int)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.GenMROperator</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>12</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>37</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>17.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ExprNodeGenericFuncEvaluator</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>19</cbo>
		<rfc>28</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>18</ce>
		<npm>5</npm>
		<lcom3>0.6</lcom3>
		<loc>311</loc>
		<dam>0.25</dam>
		<moa>5</moa>
		<mfa>0.0</mfa>
		<cam>0.45</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>49.5</amc>
		<cc>
			<method name="public Integer compare(Object row)">1</method>
			<method name="public boolean isDeterministic()">4</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(Object row)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector rowInspector)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc expr)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$havingClause_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$charSetStringLiteral_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeSenum</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$partitionVal_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyBooleanObjectInspector</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>9</rfc>
		<lcom>6</lcom>
		<ca>4</ca>
		<ce>7</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>33</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.875</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.25</amc>
		<cc>
			<method name="public boolean get(Object o)">1</method>
			<method name="void _init_()">0</method>
			<method name="public Object getPrimitiveJavaObject(Object o)">2</method>
			<method name="public Object copyObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.ByteStream$Input</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>8</rfc>
		<lcom>11</lcom>
		<ca>10</ca>
		<ce>1</ce>
		<npm>6</npm>
		<lcom3>2.0</lcom3>
		<loc>40</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6111111111111112</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.666666666666667</amc>
		<cc>
			<method name="public byte[] getData()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(byte[] buf)">0</method>
			<method name="public int getCount()">1</method>
			<method name="public void _init_(byte[] buf, int offset, int length)">0</method>
			<method name="public void reset(byte[] argBuf, int argCount)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.pcr.PcrOpWalkerCtx$OpToDeleteInfo</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>20</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.Operator parent, org.apache.hadoop.hive.ql.exec.FilterOperator operator)">0</method>
			<method name="public org.apache.hadoop.hive.ql.exec.Operator getParent()">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.FilterOperator getOperator()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.ParseDriver</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>20</cbo>
		<rfc>30</rfc>
		<lcom>13</lcom>
		<ca>7</ca>
		<ce>16</ce>
		<npm>4</npm>
		<lcom3>0.611111111111111</lcom3>
		<loc>806</loc>
		<dam>0.6666666666666666</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4444444444444444</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>113.71428571428571</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static java.util.Collection getKeywords()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ASTNode parse(String command, org.apache.hadoop.hive.ql.Context ctx)">1</method>
			<method name="private static String xlate(String name)">2</method>
			<method name="static String access$000(String x0)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ASTNode parse(String command)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.OpParseContext</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>13</ca>
		<ce>1</ce>
		<npm>4</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>22</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.parse.RowResolver getRowResolver()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.parse.RowResolver rr)">0</method>
			<method name="public void setRowResolver(org.apache.hadoop.hive.ql.parse.RowResolver rr)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.TByteArrayOutputStream</name>
		<wmc>4</wmc>
		<dit>3</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>6</rfc>
		<lcom>6</lcom>
		<ca>5</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>17</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.8947368421052632</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.25</amc>
		<cc>
			<method name="public int len()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(int size)">0</method>
			<method name="public byte[] get()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.io.TimestampWritable</name>
		<wmc>41</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>44</cbo>
		<rfc>77</rfc>
		<lcom>560</lcom>
		<ca>38</ca>
		<ce>7</ce>
		<npm>31</npm>
		<lcom3>0.7403846153846153</lcom3>
		<loc>899</loc>
		<dam>0.9230769230769231</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.11666666666666667</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>20.609756097560975</amc>
		<cc>
			<method name="public boolean equals(Object o)">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="public int compareTo(org.apache.hadoop.hive.serde2.io.TimestampWritable t)">3</method>
			<method name="public double getDouble()">2</method>
			<method name="public void write(java.io.DataOutput out)">1</method>
			<method name="private void checkBytes()">2</method>
			<method name="private void populateTimestamp()">1</method>
			<method name="public void set(java.sql.Timestamp t)">2</method>
			<method name="public void readFields(java.io.DataInput in)">1</method>
			<method name="public void setBinarySortable(byte[] bytes, int offset)">2</method>
			<method name="public int getSeconds()">2</method>
			<method name="public java.sql.Timestamp getTimestamp()">2</method>
			<method name="public void _init_(byte[] bytes, int offset)">0</method>
			<method name="private static void setSecondsBytes(long millis, byte[] b, int offset, boolean hasDecimal)">2</method>
			<method name="public void set(byte[] bytes, int offset)">1</method>
			<method name="public String toString()">5</method>
			<method name="public void set(org.apache.hadoop.hive.serde2.io.TimestampWritable t)">3</method>
			<method name="public byte[] getBytes()">1</method>
			<method name="public static java.sql.Timestamp doubleToTimestamp(double f)">1</method>
			<method name="private static void intToBytes(int value, byte[] dest, int offset)">1</method>
			<method name="public static void setTimestamp(java.sql.Timestamp t, byte[] bytes, int offset)">1</method>
			<method name="public static void convertTimestampToBytes(java.sql.Timestamp t, byte[] b, int offset)">2</method>
			<method name="private static int bytesToInt(byte[] bytes, int offset)">1</method>
			<method name="public void writeToByteStream(org.apache.hadoop.hive.serde2.ByteStream$Output byteStream)">1</method>
			<method name="public void _init_()">0</method>
			<method name="private int getDecimalLength()">1</method>
			<method name="private int getTotalLength()">1</method>
			<method name="private static boolean setNanosBytes(int nanos, byte[] b, int offset)">4</method>
			<method name="private void clearTimestamp()">1</method>
			<method name="public byte[] getBinarySortable()">1</method>
			<method name="public static java.sql.Timestamp createTimestamp(byte[] bytes, int offset)">1</method>
			<method name="public volatile int compareTo(Object x0)">1</method>
			<method name="public static boolean hasDecimal(byte b)">2</method>
			<method name="public int hashCode()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.io.TimestampWritable t)">0</method>
			<method name="public static int getNanos(byte[] bytes, int offset)">3</method>
			<method name="public static int getSeconds(byte[] bytes, int offset)">1</method>
			<method name="public int getNanos()">2</method>
			<method name="public static java.sql.Timestamp floatToTimestamp(float f)">1</method>
			<method name="public void write(java.io.OutputStream out)">1</method>
			<method name="public void _init_(java.sql.Timestamp t)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFSqrt</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>31</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable i)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyCtx</name>
		<wmc>43</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>20</cbo>
		<rfc>74</rfc>
		<lcom>741</lcom>
		<ca>6</ca>
		<ce>19</ce>
		<npm>37</npm>
		<lcom3>0.9035087719298245</lcom3>
		<loc>483</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.19047619047619047</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.790697674418604</amc>
		<cc>
			<method name="public void setAggFuncColsFetchException(boolean aggFuncColsFetchException)">1</method>
			<method name="public boolean isCountOfOne()">1</method>
			<method name="public void setAggFuncColList(java.util.Set aggFuncColList)">1</method>
			<method name="public java.util.Set getSelectColumnsList()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void setSelectColumnsList(java.util.Set selectColumnsList)">1</method>
			<method name="boolean isIndexUsableForQueryBranchRewrite(org.apache.hadoop.hive.metastore.api.Index index, java.util.Set indexKeyNames)">9</method>
			<method name="public void setAggFuncIsNotCount(boolean aggFuncIsNotCount)">1</method>
			<method name="public void setBaseTableName(String baseTableName)">1</method>
			<method name="public String getAggFunction()">1</method>
			<method name="public java.util.Set getAggFuncColList()">1</method>
			<method name="public java.util.Set getPredicateColumnsList()">1</method>
			<method name="public void setQueryHasMultipleTables(boolean queryHasMultipleTables)">1</method>
			<method name="public void addTable(String baseTableName, String indexTableName)">1</method>
			<method name="public String getBaseTableName()">1</method>
			<method name="public boolean isAggFuncColsFetchException()">1</method>
			<method name="public void setQueryHasGroupBy(boolean queryHasGroupBy)">1</method>
			<method name="void resetCanApplyCtx()">1</method>
			<method name="private void _init_(org.apache.hadoop.hive.ql.parse.ParseContext parseContext)">0</method>
			<method name="void populateRewriteVars(org.apache.hadoop.hive.ql.exec.Operator topOp)">1</method>
			<method name="public boolean isSelClauseColsFetchException()">1</method>
			<method name="public void setCountOfOne(boolean countOfOne)">1</method>
			<method name="public boolean isCountOnAllCols()">1</method>
			<method name="public boolean isWhrClauseColsFetchException()">1</method>
			<method name="public boolean isQueryHasGroupBy()">1</method>
			<method name="public java.util.Set getGbKeyNameList()">1</method>
			<method name="public boolean isGbyKeysFetchException()">1</method>
			<method name="public void setAggFuncCnt(int aggFuncCnt)">1</method>
			<method name="public void setPredicateColumnsList(java.util.Set predicateColumnsList)">1</method>
			<method name="public int getAggFuncCnt()">1</method>
			<method name="public java.util.Map getBaseToIdxTableMap()">1</method>
			<method name="public String findBaseTable(String baseTableName)">1</method>
			<method name="private org.apache.hadoop.hive.ql.lib.NodeProcessor getDefaultProc()">1</method>
			<method name="public void setAggFunction(String aggFunction)">1</method>
			<method name="public void setGbKeyNameList(java.util.Set gbKeyNameList)">1</method>
			<method name="public void setCountOnAllCols(boolean countOnAllCols)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyCtx getInstance(org.apache.hadoop.hive.ql.parse.ParseContext parseContext)">1</method>
			<method name="public boolean isAggFuncIsNotCount()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext getParseContext()">1</method>
			<method name="public void setSelClauseColsFetchException(boolean selClauseColsFetchException)">1</method>
			<method name="public void setWhrClauseColsFetchException(boolean whrClauseColsFetchException)">1</method>
			<method name="public void setGbyKeysFetchException(boolean gbyKeysFetchException)">1</method>
			<method name="public boolean isQueryHasMultipleTables()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$distributeByClause_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.QueryPlan</name>
		<wmc>44</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>19</cbo>
		<rfc>109</rfc>
		<lcom>564</lcom>
		<ca>0</ca>
		<ce>19</ce>
		<npm>41</npm>
		<lcom3>0.8054968287526428</lcom3>
		<loc>913</loc>
		<dam>0.9090909090909091</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.1375968992248062</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>19.5</amc>
		<cc>
			<method name="public void clear()">1</method>
			<method name="public Object getFieldValue(org.apache.hadoop.hive.ql.plan.api.QueryPlan$_Fields field)">2</method>
			<method name="public void setStarted(boolean started)">1</method>
			<method name="public boolean isSetQueries()">2</method>
			<method name="public void setDone(boolean done)">1</method>
			<method name="public boolean isStarted()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public volatile org.apache.thrift.TBase deepCopy()">1</method>
			<method name="public void setDoneIsSet(boolean value)">1</method>
			<method name="public volatile Object getFieldValue(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="private void writeObject(java.io.ObjectOutputStream out)">1</method>
			<method name="public boolean isSet(org.apache.hadoop.hive.ql.plan.api.QueryPlan$_Fields field)">3</method>
			<method name="public void read(org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public void unsetQueries()">1</method>
			<method name="public java.util.List getQueries()">1</method>
			<method name="public void write(org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public volatile boolean isSet(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.QueryPlan$_Fields fieldForId(int fieldId)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.QueryPlan deepCopy()">1</method>
			<method name="public int getQueriesSize()">2</method>
			<method name="public boolean equals(org.apache.hadoop.hive.ql.plan.api.QueryPlan that)">17</method>
			<method name="public void _init_(java.util.List queries, boolean done, boolean started)">0</method>
			<method name="public String toString()">4</method>
			<method name="public void unsetStarted()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.api.QueryPlan other)">0</method>
			<method name="public boolean isSetStarted()">1</method>
			<method name="public void setQueries(java.util.List queries)">1</method>
			<method name="public java.util.Iterator getQueriesIterator()">2</method>
			<method name="public void validate()">1</method>
			<method name="public void setQueriesIsSet(boolean value)">2</method>
			<method name="public boolean isDone()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setStartedIsSet(boolean value)">1</method>
			<method name="public volatile void setFieldValue(org.apache.thrift.TFieldIdEnum x0, Object x1)">1</method>
			<method name="public void addToQueries(org.apache.hadoop.hive.ql.plan.api.Query elem)">2</method>
			<method name="public int compareTo(org.apache.hadoop.hive.ql.plan.api.QueryPlan other)">11</method>
			<method name="public volatile int compareTo(Object x0)">1</method>
			<method name="public void unsetDone()">1</method>
			<method name="public int hashCode()">1</method>
			<method name="private void readObject(java.io.ObjectInputStream in)">1</method>
			<method name="public boolean equals(Object that)">3</method>
			<method name="public void setFieldValue(org.apache.hadoop.hive.ql.plan.api.QueryPlan$_Fields field, Object value)">5</method>
			<method name="public volatile org.apache.thrift.TFieldIdEnum fieldForId(int x0)">1</method>
			<method name="public boolean isSetDone()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryLong</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>15</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>1</npm>
		<lcom3>0.5</lcom3>
		<loc>71</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.25</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryLong copy)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableLongObjectInspector oi)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.TimestampObjectInspector</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>10</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract java.sql.Timestamp getPrimitiveJavaObject(Object)">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.io.TimestampWritable getPrimitiveWritableObject(Object)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$ColumnExprProcessor</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>40</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>17</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>199</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>65.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.HiveMetaStoreChecker</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>65</rfc>
		<lcom>15</lcom>
		<ca>1</ca>
		<ce>16</ce>
		<npm>2</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>531</loc>
		<dam>0.6666666666666666</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.35555555555555557</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>51.8</amc>
		<cc>
			<method name="private void getAllLeafDirs(org.apache.hadoop.fs.Path basePath, java.util.Set allDirs)">1</method>
			<method name="private String getPartitionName(org.apache.hadoop.fs.Path tablePath, org.apache.hadoop.fs.Path partitionPath)">4</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Hive hive)">0</method>
			<method name="public void checkMetastore(String dbName, String tableName, java.util.List partitions, org.apache.hadoop.hive.ql.metadata.CheckResult result)">1</method>
			<method name="void findUnknownPartitions(org.apache.hadoop.hive.ql.metadata.Table table, java.util.Set partPaths, org.apache.hadoop.hive.ql.metadata.CheckResult result)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void getAllLeafDirs(org.apache.hadoop.fs.Path basePath, java.util.Set allDirs, org.apache.hadoop.fs.FileSystem fs)">1</method>
			<method name="void checkTable(org.apache.hadoop.hive.ql.metadata.Table table, java.util.List parts, boolean findUnknownPartitions, org.apache.hadoop.hive.ql.metadata.CheckResult result)">1</method>
			<method name="void checkTable(String dbName, String tableName, java.util.List partitions, org.apache.hadoop.hive.ql.metadata.CheckResult result)">1</method>
			<method name="void findUnknownTables(String dbName, java.util.List tables, org.apache.hadoop.hive.ql.metadata.CheckResult result)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lockmgr.LockException</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>8</rfc>
		<lcom>6</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>4</npm>
		<lcom3>1.3333333333333333</lcom3>
		<loc>21</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(Throwable cause)">0</method>
			<method name="public void _init_(String message, Throwable cause)">0</method>
			<method name="public void _init_(String message)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.Adjacency$_Fields</name>
		<wmc>9</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>24</rfc>
		<lcom>26</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>0.7857142857142857</lcom3>
		<loc>140</loc>
		<dam>0.5714285714285714</dam>
		<moa>4</moa>
		<mfa>0.65</mfa>
		<cam>0.3125</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>13.777777777777779</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Adjacency$_Fields findByName(String name)">1</method>
			<method name="private void _init_(String, int, short thriftId, String fieldName)">0</method>
			<method name="public String getFieldName()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Adjacency$_Fields[] values()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Adjacency$_Fields findByThriftIdOrThrow(int fieldId)">2</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Adjacency$_Fields valueOf(String name)">1</method>
			<method name="public short getThriftFieldId()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Adjacency$_Fields findByThriftId(int fieldId)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFStd$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>70</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>68.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazydio.LazyDioBoolean</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>12</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>3</npm>
		<lcom3>1.0</lcom3>
		<loc>83</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyBooleanObjectInspector oi)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazydio.LazyDioBoolean copy)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.GenMRFileSink1</name>
		<wmc>13</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>57</cbo>
		<rfc>169</rfc>
		<lcom>66</lcom>
		<ca>1</ca>
		<ce>57</ce>
		<npm>2</npm>
		<lcom3>0.75</lcom3>
		<loc>1281</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.22685185185185186</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>97.38461538461539</amc>
		<cc>
			<method name="private org.apache.hadoop.hive.ql.plan.MapredWork createMergeTask(org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.hive.ql.exec.Operator topOp, org.apache.hadoop.hive.ql.plan.FileSinkDesc fsDesc)">1</method>
			<method name="private void createMergeJob(org.apache.hadoop.hive.ql.exec.FileSinkOperator fsOp, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext ctx, String finalName)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.ConditionalTask createCondTask(org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.hive.ql.exec.Task currTask, org.apache.hadoop.hive.ql.plan.MoveWork mvWork, org.apache.hadoop.hive.ql.plan.MapredWork mergeWork, String inputPath)">1</method>
			<method name="private void LinkMoveTask(org.apache.hadoop.hive.ql.optimizer.GenMRProcContext ctx, org.apache.hadoop.hive.ql.exec.FileSinkOperator newOutput, org.apache.hadoop.hive.ql.exec.ConditionalTask cndTsk)">3</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx opProcCtx, Object[] nodeOutputs)">1</method>
			<method name="private void createMapReduce4Merge(org.apache.hadoop.hive.ql.exec.FileSinkOperator fsOp, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext ctx, String finalName)">1</method>
			<method name="private void addStatsTask(org.apache.hadoop.hive.ql.exec.FileSinkOperator nd, org.apache.hadoop.hive.ql.exec.MoveTask mvTask, org.apache.hadoop.hive.ql.exec.Task currTask, org.apache.hadoop.hive.conf.HiveConf hconf)">5</method>
			<method name="private String processFS(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx opProcCtx, boolean chDir)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Task findMoveTask(java.util.List mvTasks, org.apache.hadoop.hive.ql.exec.FileSinkOperator fsOp)">4</method>
			<method name="private org.apache.hadoop.hive.ql.plan.MapredWork createRCFileMergeTask(org.apache.hadoop.hive.ql.plan.FileSinkDesc fsInputDesc, String finalName, boolean hasDynamicPartitions)">1</method>
			<method name="private void createMap4Merge(org.apache.hadoop.hive.ql.exec.FileSinkOperator fsInput, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext ctx, String finalName)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFOPBitOr</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>14</rfc>
		<lcom>10</lcom>
		<ca>0</ca>
		<ce>5</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>78</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.36</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.6</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.hive.serde2.io.ByteWritable a, org.apache.hadoop.hive.serde2.io.ByteWritable b)">3</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.hive.serde2.io.ShortWritable a, org.apache.hadoop.hive.serde2.io.ShortWritable b)">3</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.LongWritable a, org.apache.hadoop.io.LongWritable b)">3</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.IntWritable a, org.apache.hadoop.io.IntWritable b)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFFloor</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>25</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable i)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.lineage.OpProcFactory$LateralViewJoinLineage</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>16</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>14</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>110</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>35.333333333333336</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.bitmap.BitmapIndexHandler</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>27</cbo>
		<rfc>76</rfc>
		<lcom>34</lcom>
		<ca>0</ca>
		<ce>27</ce>
		<npm>5</npm>
		<lcom3>1.0</lcom3>
		<loc>664</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.25</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>72.55555555555556</amc>
		<cc>
			<method name="public boolean checkQuerySize(long querySize, org.apache.hadoop.hive.conf.HiveConf hiveConf)">1</method>
			<method name="public boolean usesIndexTable()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void analyzeIndexDefinition(org.apache.hadoop.hive.metastore.api.Table baseTable, org.apache.hadoop.hive.metastore.api.Index index, org.apache.hadoop.hive.metastore.api.Table indexTable)">1</method>
			<method name="private org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer getIndexPredicateAnalyzer(java.util.List indexes, java.util.Set queryPartitions)">4</method>
			<method name="private java.util.Map decomposePredicate(org.apache.hadoop.hive.ql.plan.ExprNodeDesc predicate, java.util.List indexes, org.apache.hadoop.hive.ql.index.HiveIndexQueryContext queryContext)">4</method>
			<method name="protected org.apache.hadoop.hive.ql.exec.Task getIndexBuilderMapRedTask(java.util.Set inputs, java.util.Set outputs, java.util.List indexField, boolean partitioned, org.apache.hadoop.hive.ql.plan.PartitionDesc indexTblPartDesc, String indexTableName, org.apache.hadoop.hive.ql.plan.PartitionDesc baseTablePartDesc, String baseTableName, String dbName)">1</method>
			<method name="public void generateIndexQuery(java.util.List indexes, org.apache.hadoop.hive.ql.plan.ExprNodeDesc predicate, org.apache.hadoop.hive.ql.parse.ParseContext pctx, org.apache.hadoop.hive.ql.index.HiveIndexQueryContext queryContext)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.MapJoinResolver$LocalMapJoinProcCtx</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>13</rfc>
		<lcom>15</lcom>
		<ca>3</ca>
		<ce>4</ce>
		<npm>10</npm>
		<lcom3>0.75</lcom3>
		<loc>68</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.2833333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.4</amc>
		<cc>
			<method name="public void addDummyParentOp(org.apache.hadoop.hive.ql.exec.Operator op)">1</method>
			<method name="public void setDummyParentOp(java.util.List op)">1</method>
			<method name="public java.util.List getDummyParentOp()">1</method>
			<method name="public void setFollowedByGroupBy(boolean isFollowedByGroupBy)">1</method>
			<method name="public boolean isFollowedByGroupBy()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext getParseCtx()">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.Task getCurrentTask()">1</method>
			<method name="public void setCurrentTask(org.apache.hadoop.hive.ql.exec.Task currentTask)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.Task task, org.apache.hadoop.hive.ql.parse.ParseContext parseCtx)">0</method>
			<method name="public void setParseCtx(org.apache.hadoop.hive.ql.parse.ParseContext parseCtx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ppr.ExprProcCtx</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>5</npm>
		<lcom3>0.5</lcom3>
		<loc>30</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.6</amc>
		<cc>
			<method name="public void setHasNonPartCols(boolean val)">1</method>
			<method name="public void _init_(String tabAlias)">0</method>
			<method name="public boolean getHasNonPartCols()">1</method>
			<method name="public void setTabAlias(String tabAlias)">1</method>
			<method name="public String getTabAlias()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceFieldExpression_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.RCFileInputFormat</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>13</rfc>
		<lcom>3</lcom>
		<ca>0</ca>
		<ce>14</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>76</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.42857142857142855</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>24.333333333333332</amc>
		<cc>
			<method name="public boolean validateInput(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.hive.conf.HiveConf conf, java.util.ArrayList files)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit split, org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.mapred.Reporter reporter)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TJSONProtocol$LookaheadReader</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>0</npm>
		<lcom3>0.16666666666666674</lcom3>
		<loc>57</loc>
		<dam>0.6666666666666666</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>17.0</amc>
		<cc>
			<method name="protected byte read()">1</method>
			<method name="protected byte peek()">1</method>
			<method name="protected void _init_(org.apache.thrift.protocol.TJSONProtocol)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.server.TNonblockingServer$SelectThread</name>
		<wmc>11</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>54</rfc>
		<lcom>7</lcom>
		<ca>2</ca>
		<ce>7</ce>
		<npm>5</npm>
		<lcom3>0.625</lcom3>
		<loc>293</loc>
		<dam>0.75</dam>
		<moa>2</moa>
		<mfa>0.8648648648648649</mfa>
		<cam>0.3090909090909091</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>25.272727272727273</amc>
		<cc>
			<method name="public void requestSelectInterestChange(org.apache.thrift.server.TNonblockingServer$FrameBuffer frameBuffer)">1</method>
			<method name="public void wakeupSelector()">1</method>
			<method name="private void handleRead(java.nio.channels.SelectionKey key)">4</method>
			<method name="public boolean isStopped()">1</method>
			<method name="private void cleanupSelectionkey(java.nio.channels.SelectionKey key)">2</method>
			<method name="private void handleAccept()">1</method>
			<method name="public void run()">2</method>
			<method name="private void select()">5</method>
			<method name="public void _init_(org.apache.thrift.server.TNonblockingServer, org.apache.thrift.transport.TNonblockingServerTransport serverTransport)">0</method>
			<method name="private void handleWrite(java.nio.channels.SelectionKey key)">2</method>
			<method name="private void processInterestChanges()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters$IdentityConverter</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>7</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object convert(Object input)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.CreateFunctionDesc</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>3</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>6</npm>
		<lcom3>0.8</lcom3>
		<loc>35</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.333333333333333</amc>
		<cc>
			<method name="public void _init_(String functionName, String className)">0</method>
			<method name="public void _init_()">0</method>
			<method name="public void setFunctionName(String functionName)">1</method>
			<method name="public String getFunctionName()">1</method>
			<method name="public String getClassName()">1</method>
			<method name="public void setClassName(String className)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.pcr.PcrExprProcFactory$DefaultExprProcessor</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>7</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>37</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.io.ByteWritable</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>35</cbo>
		<rfc>18</rfc>
		<lcom>0</lcom>
		<ca>32</ca>
		<ce>3</ce>
		<npm>10</npm>
		<lcom3>0.1</lcom3>
		<loc>83</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.32</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>6.454545454545454</amc>
		<cc>
			<method name="public boolean equals(Object o)">4</method>
			<method name="public int hashCode()">1</method>
			<method name="public byte get()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(byte b)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void write(java.io.DataOutput out)">1</method>
			<method name="public void set(byte value)">1</method>
			<method name="public String toString()">1</method>
			<method name="public void readFields(java.io.DataInput in)">1</method>
			<method name="public int compareTo(Object o)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.LineageInfo$Dependency</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>8</rfc>
		<lcom>15</lcom>
		<ca>16</ca>
		<ce>1</ce>
		<npm>7</npm>
		<lcom3>0.9166666666666666</lcom3>
		<loc>35</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.35714285714285715</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.4285714285714284</amc>
		<cc>
			<method name="public void setBaseCols(java.util.List baseCols)">1</method>
			<method name="public void setExpr(String expr)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.List getBaseCols()">1</method>
			<method name="public String getExpr()">1</method>
			<method name="public void setType(org.apache.hadoop.hive.ql.hooks.LineageInfo$DependencyType type)">1</method>
			<method name="public org.apache.hadoop.hive.ql.hooks.LineageInfo$DependencyType getType()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeSimpleNode</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>4</noc>
		<cbo>7</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>5</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>14</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int i)">0</method>
			<method name="public void _init_(int i)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceAmpersandExpression_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>256</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>255</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract String getTypeName()">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedencePlusOperator_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeService</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ExprNodeConstantDesc</name>
		<wmc>12</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>30</cbo>
		<rfc>29</rfc>
		<lcom>24</lcom>
		<ca>21</ca>
		<ce>9</ce>
		<npm>12</npm>
		<lcom3>0.5909090909090909</lcom3>
		<loc>137</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4722222222222222</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.25</amc>
		<cc>
			<method name="public void _init_(Object value)">0</method>
			<method name="public volatile org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getWritableObjectInspector()">1</method>
			<method name="public void setValue(Object value)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo typeInfo, Object value)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ExprNodeDesc clone()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ConstantObjectInspector getWritableObjectInspector()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public volatile Object clone()">1</method>
			<method name="public boolean isSame(Object o)">4</method>
			<method name="public String getExprString()">3</method>
			<method name="public String toString()">1</method>
			<method name="public Object getValue()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeList</name>
		<wmc>12</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>42</rfc>
		<lcom>64</lcom>
		<ca>2</ca>
		<ce>11</ce>
		<npm>11</npm>
		<lcom3>1.0</lcom3>
		<loc>247</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3181818181818182</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.416666666666668</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeBase getElementType()">1</method>
			<method name="public void serialize(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public byte getType()">1</method>
			<method name="public boolean isList()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Class getRealType()">1</method>
			<method name="public java.util.ArrayList deserialize(Object reuse, org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public volatile Object deserialize(Object x0, org.apache.thrift.protocol.TProtocol x1)">1</method>
			<method name="public boolean isPrimitive()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int i)">0</method>
			<method name="public String toString()">1</method>
			<method name="public void _init_(int i)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.HiveStoragePredicateHandler</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.hadoop.hive.ql.metadata.HiveStoragePredicateHandler$DecomposedPredicate decomposePredicate(org.apache.hadoop.mapred.JobConf, org.apache.hadoop.hive.serde2.Deserializer, org.apache.hadoop.hive.ql.plan.ExprNodeDesc)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TCompactProtocol$Types</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>16</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="private void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFTimestamp</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>17</rfc>
		<lcom>6</lcom>
		<ca>0</ca>
		<ce>11</ce>
		<npm>4</npm>
		<lcom3>0.8333333333333333</lcom3>
		<loc>104</loc>
		<dam>0.6666666666666666</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.2</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.OneNullRowInputFormat$DummyInputSplit</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>6</rfc>
		<lcom>10</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>15</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.0</amc>
		<cc>
			<method name="public long getLength()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void readFields(java.io.DataInput arg0)">1</method>
			<method name="public String[] getLocations()">1</method>
			<method name="public void write(java.io.DataOutput arg0)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.BucketMapJoinOptimizer</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>25</rfc>
		<lcom>19</lcom>
		<ca>5</ca>
		<ce>16</ce>
		<npm>2</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>122</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.285714285714285</amc>
		<cc>
			<method name="private org.apache.hadoop.hive.ql.lib.NodeProcessor getBucketMapjoinProc(org.apache.hadoop.hive.ql.parse.ParseContext pctx)">1</method>
			<method name="static org.apache.commons.logging.Log access$000()">1</method>
			<method name="private org.apache.hadoop.hive.ql.lib.NodeProcessor getDefaultProc()">1</method>
			<method name="private org.apache.hadoop.hive.ql.lib.NodeProcessor getBucketMapjoinRejectProc(org.apache.hadoop.hive.ql.parse.ParseContext pctx)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext transform(org.apache.hadoop.hive.ql.parse.ParseContext pctx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server</name>
		<wmc>12</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>28</cbo>
		<rfc>60</rfc>
		<lcom>30</lcom>
		<ca>3</ca>
		<ce>27</ce>
		<npm>8</npm>
		<lcom3>1.0</lcom3>
		<loc>317</loc>
		<dam>0.05555555555555555</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.36363636363636365</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>23.916666666666668</amc>
		<cc>
			<method name="public String getDelegationToken(String owner, String renewer)">1</method>
			<method name="public long renewDelegationToken(String tokenStrForm)">1</method>
			<method name="void _init_(String x0, String x1, org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$1 x2)">0</method>
			<method name="public org.apache.thrift.transport.TTransportFactory createTransportFactory()">1</method>
			<method name="public org.apache.thrift.TProcessor wrapProcessor(org.apache.thrift.TProcessor processor)">1</method>
			<method name="public void startDelegationTokenSecretManager(org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="private void _init_(String keytabFile, String principalConf)">0</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public java.net.InetAddress getRemoteAddress()">1</method>
			<method name="protected org.apache.hadoop.hive.thrift.DelegationTokenStore getTokenStore(org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="public void cancelDelegationToken(String tokenStrForm)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.Entity</name>
		<wmc>29</wmc>
		<dit>1</dit>
		<noc>2</noc>
		<cbo>7</cbo>
		<rfc>46</rfc>
		<lcom>152</lcom>
		<ca>2</ca>
		<ce>5</ce>
		<npm>28</npm>
		<lcom3>0.6785714285714286</lcom3>
		<loc>319</loc>
		<dam>1.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.20689655172413793</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>9.758620689655173</amc>
		<cc>
			<method name="public boolean equals(Object o)">3</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Partition getPartition()">1</method>
			<method name="public String getName()">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Table getTable()">1</method>
			<method name="public boolean isComplete()">1</method>
			<method name="public void setT(org.apache.hadoop.hive.ql.metadata.Table t)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.DummyPartition p, boolean complete)">0</method>
			<method name="public java.net.URI getLocation()">1</method>
			<method name="public String getD()">1</method>
			<method name="public void setComplete(boolean complete)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Partition p, boolean complete)">0</method>
			<method name="public String toString()">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Partition getP()">1</method>
			<method name="public void _init_(String d, boolean islocal)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Table t)">0</method>
			<method name="public void setTyp(org.apache.hadoop.hive.ql.hooks.Entity$Type typ)">1</method>
			<method name="public void _init_(String d, boolean islocal, boolean complete)">0</method>
			<method name="public java.util.Map getParameters()">2</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.hooks.Entity$Type getType()">1</method>
			<method name="private String computeName()">2</method>
			<method name="public void setD(String d)">1</method>
			<method name="public org.apache.hadoop.hive.ql.hooks.Entity$Type getTyp()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Partition p)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Table t, boolean complete)">0</method>
			<method name="public int hashCode()">1</method>
			<method name="public void setP(org.apache.hadoop.hive.ql.metadata.Partition p)">1</method>
			<method name="public void setName(String name)">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Table getT()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.async.TAsyncClient</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>20</rfc>
		<lcom>23</lcom>
		<ca>3</ca>
		<ce>4</ce>
		<npm>8</npm>
		<lcom3>0.7666666666666666</lcom3>
		<loc>111</loc>
		<dam>1.0</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.30303030303030304</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.545454545454545</amc>
		<cc>
			<method name="protected void onError(Exception exception)">1</method>
			<method name="protected void checkReady()">3</method>
			<method name="public void _init_(org.apache.thrift.protocol.TProtocolFactory protocolFactory, org.apache.thrift.async.TAsyncClientManager manager, org.apache.thrift.transport.TNonblockingTransport transport, long timeout)">0</method>
			<method name="public org.apache.thrift.protocol.TProtocolFactory getProtocolFactory()">1</method>
			<method name="public Exception getError()">1</method>
			<method name="public boolean hasError()">2</method>
			<method name="public void setTimeout(long timeout)">1</method>
			<method name="public boolean hasTimeout()">2</method>
			<method name="public long getTimeout()">1</method>
			<method name="protected void onComplete()">1</method>
			<method name="public void _init_(org.apache.thrift.protocol.TProtocolFactory protocolFactory, org.apache.thrift.async.TAsyncClientManager manager, org.apache.thrift.transport.TNonblockingTransport transport)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$fromSource_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$hintItem_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypei16</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>15</rfc>
		<lcom>21</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>7</npm>
		<lcom3>2.0</lcom3>
		<loc>50</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.35714285714285715</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.142857142857143</amc>
		<cc>
			<method name="public Object deserialize(Object reuse, org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public void serialize(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public byte getType()">1</method>
			<method name="public Class getRealType()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int i)">0</method>
			<method name="public String toString()">1</method>
			<method name="public void _init_(int i)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.DefaultUDAFEvaluatorResolver</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>1</noc>
		<cbo>6</cbo>
		<rfc>20</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>148</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>47.666666666666664</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="public void _init_(Class udafClass)">0</method>
			<method name="public Class getEvaluatorClass(java.util.List argClasses)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TNonblockingTransport</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>7</cbo>
		<rfc>7</rfc>
		<lcom>15</lcom>
		<ca>6</ca>
		<ce>1</ce>
		<npm>6</npm>
		<lcom3>2.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4166666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.5</amc>
		<cc>
			<method name="public abstract boolean startConnect()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public abstract int write(java.nio.ByteBuffer)">1</method>
			<method name="public abstract boolean finishConnect()">1</method>
			<method name="public abstract int read(java.nio.ByteBuffer)">1</method>
			<method name="public abstract java.nio.channels.SelectionKey registerSelector(java.nio.channels.Selector, int)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tableFileFormat_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryDouble</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>15</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>1</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>54</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.25</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryDouble copy)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableDoubleObjectInspector oi)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TBinaryProtocol$Factory</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>4</ca>
		<ce>4</ce>
		<npm>4</npm>
		<lcom3>0.3333333333333333</lcom3>
		<loc>54</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.75</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(boolean strictRead, boolean strictWrite, int readLength)">0</method>
			<method name="public void _init_(boolean strictRead, boolean strictWrite)">0</method>
			<method name="public org.apache.thrift.protocol.TProtocol getProtocol(org.apache.thrift.transport.TTransport trans)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$whereClause_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ShowLocksDesc</name>
		<wmc>12</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>14</rfc>
		<lcom>42</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>12</npm>
		<lcom3>0.9350649350649352</lcom3>
		<loc>70</loc>
		<dam>0.42857142857142855</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.25</amc>
		<cc>
			<method name="public void setPartSpecs(java.util.HashMap partSpec)">1</method>
			<method name="public java.util.HashMap getPartSpec()">1</method>
			<method name="public String getResFile()">1</method>
			<method name="public String getTableName()">1</method>
			<method name="public String getSchema()">1</method>
			<method name="public String getTable()">1</method>
			<method name="public void setResFile(String resFile)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public boolean isExt()">1</method>
			<method name="public void setTableName(String tableName)">1</method>
			<method name="public void _init_(org.apache.hadoop.fs.Path resFile, String tableName, java.util.HashMap partSpec, boolean isExt)">0</method>
			<method name="public void setExt(boolean isExt)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryVoid</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>5</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>12</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableVoidObjectInspector oi)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryVoid copy)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.HiveIndexResult$IBucket</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>10</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>5</npm>
		<lcom3>0.5</lcom3>
		<loc>51</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.8</amc>
		<cc>
			<method name="public void add(Long offset)">1</method>
			<method name="public void _init_(String n)">0</method>
			<method name="public boolean equals(Object obj)">3</method>
			<method name="public String getName()">1</method>
			<method name="public java.util.SortedSet getOffsets()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFOPBitAnd</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>14</rfc>
		<lcom>10</lcom>
		<ca>0</ca>
		<ce>5</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>78</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.36</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.6</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.hive.serde2.io.ByteWritable a, org.apache.hadoop.hive.serde2.io.ByteWritable b)">3</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.hive.serde2.io.ShortWritable a, org.apache.hadoop.hive.serde2.io.ShortWritable b)">3</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.LongWritable a, org.apache.hadoop.io.LongWritable b)">3</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.IntWritable a, org.apache.hadoop.io.IntWritable b)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Hadoop20Shims$InputSplitShim</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>15</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>0.3333333333333333</lcom3>
		<loc>65</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3142857142857143</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.mapred.lib.CombineFileSplit old)">0</method>
			<method name="public void shrinkSplit(long length)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void write(java.io.DataOutput out)">1</method>
			<method name="public long getShrinkedLength()">1</method>
			<method name="public boolean isShrinked()">1</method>
			<method name="public void readFields(java.io.DataInput in)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter$StringConverter</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>14</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector inputOI)">0</method>
			<method name="public Object convert(Object input)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveSemanticAnalyzerHookContext</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>4</rfc>
		<lcom>6</lcom>
		<ca>4</ca>
		<ce>4</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract java.util.Set getInputs()">1</method>
			<method name="public abstract java.util.Set getOutputs()">1</method>
			<method name="public abstract org.apache.hadoop.hive.ql.metadata.Hive getHive()">1</method>
			<method name="public abstract void update(org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.FunctionTask</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>29</rfc>
		<lcom>39</lcom>
		<ca>0</ca>
		<ce>16</ce>
		<npm>5</npm>
		<lcom3>0.925925925925926</lcom3>
		<loc>144</loc>
		<dam>0.6666666666666666</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.2698412698412698</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.1</amc>
		<cc>
			<method name="public int execute(org.apache.hadoop.hive.ql.DriverContext driverContext)">3</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="private Class getUdfClass(org.apache.hadoop.hive.ql.plan.CreateFunctionDesc desc)">1</method>
			<method name="protected void localizeMRTmpFilesImpl(org.apache.hadoop.hive.ql.Context ctx)">1</method>
			<method name="public String getName()">1</method>
			<method name="private int createFunction(org.apache.hadoop.hive.ql.plan.CreateFunctionDesc createFunctionDesc)">2</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.StageType getType()">1</method>
			<method name="private int dropFunction(org.apache.hadoop.hive.ql.plan.DropFunctionDesc dropFunctionDesc)">1</method>
			<method name="public void initialize(org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.hive.ql.QueryPlan queryPlan, org.apache.hadoop.hive.ql.DriverContext ctx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.json.Test$1Obj</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>16</rfc>
		<lcom>16</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>8</npm>
		<lcom3>0.6190476190476192</lcom3>
		<loc>83</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.34375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.0</amc>
		<cc>
			<method name="public String getBENT()">1</method>
			<method name="public boolean isBoolean()">1</method>
			<method name="public void _init_(String arg0, double arg1, boolean arg2)">0</method>
			<method name="public String toJSONString()">1</method>
			<method name="public String getX()">1</method>
			<method name="public String getString()">1</method>
			<method name="public String toString()">1</method>
			<method name="public double getNumber()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.CombineHiveInputFormat</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>31</cbo>
		<rfc>101</rfc>
		<lcom>15</lcom>
		<ca>0</ca>
		<ce>31</ce>
		<npm>3</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>807</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3148148148148148</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>114.14285714285714</amc>
		<cc>
			<method name="java.util.Map removeScheme(java.util.Map pathToAliases)">2</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="private java.util.List sampleSplits(java.util.List splits)">14</method>
			<method name="public org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit split, org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.mapred.Reporter reporter)">1</method>
			<method name="private transient void processPaths(org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.hive.shims.HadoopShims$CombineFileInputFormatShim combine, java.util.List iss, org.apache.hadoop.fs.Path[] path)">1</method>
			<method name="public org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf job, int numSplits)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TTransportException</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>36</cbo>
		<rfc>13</rfc>
		<lcom>0</lcom>
		<ca>35</ca>
		<ce>1</ce>
		<npm>9</npm>
		<lcom3>0.9642857142857143</lcom3>
		<loc>87</loc>
		<dam>0.2857142857142857</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.888888888888889</amc>
		<cc>
			<method name="public void _init_(int type)">0</method>
			<method name="public void _init_(int type, String message)">0</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(Throwable cause)">0</method>
			<method name="public void _init_(int type, String message, Throwable cause)">0</method>
			<method name="public void _init_(int type, Throwable cause)">0</method>
			<method name="public int getType()">1</method>
			<method name="public void _init_(String message, Throwable cause)">0</method>
			<method name="public void _init_(String message)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.GenMRSkewJoinProcessor</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>35</cbo>
		<rfc>118</rfc>
		<lcom>7</lcom>
		<ca>1</ca>
		<ce>34</ce>
		<npm>2</npm>
		<lcom3>0.5555555555555556</lcom3>
		<loc>1020</loc>
		<dam>0.8333333333333334</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2857142857142857</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>143.85714285714286</amc>
		<cc>
			<method name="public static void processSkewJoin(org.apache.hadoop.hive.ql.exec.JoinOperator joinOp, org.apache.hadoop.hive.ql.exec.Task currTask, org.apache.hadoop.hive.ql.parse.ParseContext parseCtx)">1</method>
			<method name="private void _init_()">0</method>
			<method name="static String getBigKeysDir(String baseDir, Byte srcTbl)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static boolean skewJoinEnabled(org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.hive.ql.exec.JoinOperator joinOp)">6</method>
			<method name="static String getBigKeysSkewJoinResultDir(String baseDir, Byte srcTbl)">1</method>
			<method name="static String getSmallKeysDir(String baseDir, Byte srcTblBigTbl, Byte srcTblSmallTbl)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFMin$GenericUDAFMinEvaluator</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>17</rfc>
		<lcom>28</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>8</npm>
		<lcom3>0.8125</lcom3>
		<loc>123</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.3541666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.222222222222221</amc>
		<cc>
			<method name="public void iterate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object[] parameters)">1</method>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector init(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode m, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] parameters)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer getNewAggregationBuffer()">1</method>
			<method name="public void merge(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object partial)">1</method>
			<method name="public Object terminatePartial(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void reset(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.GenMRProcContext</name>
		<wmc>36</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>24</cbo>
		<rfc>44</rfc>
		<lcom>534</lcom>
		<ca>15</ca>
		<ce>9</ce>
		<npm>36</npm>
		<lcom3>0.9476190476190476</lcom3>
		<loc>254</loc>
		<dam>1.0</dam>
		<moa>6</moa>
		<mfa>0.0</mfa>
		<cam>0.12301587301587301</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.555555555555555</amc>
		<cc>
			<method name="public void setSeenFileSinkOps(java.util.List seenFileSinkOps)">1</method>
			<method name="public java.util.List getRootOps()">1</method>
			<method name="public java.util.List getMvTask()">1</method>
			<method name="public org.apache.hadoop.hive.ql.optimizer.GenMRProcContext$GenMRUnionCtx getUnionTask(org.apache.hadoop.hive.ql.exec.UnionOperator op)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext getParseCtx()">1</method>
			<method name="public void setCurrMapJoinOp(org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator currMapJoinOp)">1</method>
			<method name="public void setParseCtx(org.apache.hadoop.hive.ql.parse.ParseContext parseCtx)">1</method>
			<method name="public java.util.Set getOutputs()">1</method>
			<method name="public void setRootTasks(java.util.List rootTasks)">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.UnionOperator getCurrUnionOp()">1</method>
			<method name="public void setConf(org.apache.hadoop.hive.conf.HiveConf conf)">1</method>
			<method name="public void setMapCurrCtx(java.util.LinkedHashMap mapCurrCtx)">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator getCurrMapJoinOp()">1</method>
			<method name="public void setRootOps(java.util.List rootOps)">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.Operator getCurrTopOp()">1</method>
			<method name="public void setCurrUnionOp(org.apache.hadoop.hive.ql.exec.UnionOperator currUnionOp)">1</method>
			<method name="public java.util.Set getInputs()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public String getCurrAliasId()">1</method>
			<method name="public org.apache.hadoop.hive.conf.HiveConf getConf()">1</method>
			<method name="public java.util.List getRootTasks()">1</method>
			<method name="public org.apache.hadoop.hive.ql.optimizer.GenMRProcContext$GenMRMapJoinCtx getMapJoinCtx(org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator op)">1</method>
			<method name="public void setMvTask(java.util.List mvTask)">1</method>
			<method name="public void setCurrTopOp(org.apache.hadoop.hive.ql.exec.Operator currTopOp)">1</method>
			<method name="public void setOpTaskMap(java.util.HashMap opTaskMap)">1</method>
			<method name="public void setMapJoinCtx(org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator op, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext$GenMRMapJoinCtx mjCtx)">1</method>
			<method name="public java.util.HashMap getOpTaskMap()">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.Task getCurrTask()">1</method>
			<method name="public void setCurrAliasId(String currAliasId)">1</method>
			<method name="public java.util.List getSeenOps()">1</method>
			<method name="public java.util.LinkedHashMap getMapCurrCtx()">1</method>
			<method name="public void setUnionTask(org.apache.hadoop.hive.ql.exec.UnionOperator op, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext$GenMRUnionCtx uTask)">1</method>
			<method name="public void setSeenOps(java.util.List seenOps)">1</method>
			<method name="public void setCurrTask(org.apache.hadoop.hive.ql.exec.Task currTask)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.conf.HiveConf conf, java.util.HashMap opTaskMap, java.util.List seenOps, org.apache.hadoop.hive.ql.parse.ParseContext parseCtx, java.util.List mvTask, java.util.List rootTasks, java.util.LinkedHashMap mapCurrCtx, java.util.Set inputs, java.util.Set outputs)">0</method>
			<method name="public java.util.List getSeenFileSinkOps()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeFunctionType</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$nullCondition_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.TBaseHelper</name>
		<wmc>23</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>65</rfc>
		<lcom>241</lcom>
		<ca>13</ca>
		<ce>2</ce>
		<npm>21</npm>
		<lcom3>0.8181818181818182</lcom3>
		<loc>538</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.07102272727272728</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>22.347826086956523</amc>
		<cc>
			<method name="public static String paddedByteString(byte b)">1</method>
			<method name="public static int compareTo(byte[] a, byte[] b)">4</method>
			<method name="public static int compareTo(int a, int b)">3</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static int compareTo(java.util.List a, java.util.List b)">4</method>
			<method name="public static int compareTo(Object o1, Object o2)">6</method>
			<method name="public static int compareTo(byte a, byte b)">3</method>
			<method name="public static int compareTo(java.util.Map a, java.util.Map b)">5</method>
			<method name="public static java.nio.ByteBuffer copyBinary(java.nio.ByteBuffer orig)">3</method>
			<method name="public static int compareTo(Comparable a, Comparable b)">1</method>
			<method name="public static int compareTo(boolean a, boolean b)">1</method>
			<method name="public static void toString(java.nio.ByteBuffer bb, StringBuilder sb)">5</method>
			<method name="public static boolean wrapsFullArray(java.nio.ByteBuffer byteBuffer)">5</method>
			<method name="private void _init_()">0</method>
			<method name="public static int compareTo(String a, String b)">1</method>
			<method name="public static int compareTo(short a, short b)">3</method>
			<method name="public static byte[] copyBinary(byte[] orig)">2</method>
			<method name="public static int compareTo(java.util.Set a, java.util.Set b)">5</method>
			<method name="public static byte[] byteBufferToByteArray(java.nio.ByteBuffer byteBuffer)">2</method>
			<method name="public static int compareTo(long a, long b)">3</method>
			<method name="public static java.nio.ByteBuffer rightSize(java.nio.ByteBuffer in)">3</method>
			<method name="public static int byteBufferToByteArray(java.nio.ByteBuffer byteBuffer, byte[] target, int offset)">1</method>
			<method name="public static int compareTo(double a, double b)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$selectItem_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler</name>
		<wmc>11</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>33</cbo>
		<rfc>95</rfc>
		<lcom>43</lcom>
		<ca>1</ca>
		<ce>32</ce>
		<npm>5</npm>
		<lcom3>0.86</lcom3>
		<loc>797</loc>
		<dam>0.8</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.21428571428571427</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>71.0</amc>
		<cc>
			<method name="public boolean checkQuerySize(long querySize, org.apache.hadoop.hive.conf.HiveConf hiveConf)">4</method>
			<method name="private org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer getIndexPredicateAnalyzer(org.apache.hadoop.hive.metastore.api.Index index, java.util.Set queryPartitions)">4</method>
			<method name="public boolean usesIndexTable()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void analyzeIndexDefinition(org.apache.hadoop.hive.metastore.api.Table baseTable, org.apache.hadoop.hive.metastore.api.Index index, org.apache.hadoop.hive.metastore.api.Table indexTable)">1</method>
			<method name="private boolean findIndexColumnFilter(java.util.Collection operators)">5</method>
			<method name="private org.apache.hadoop.hive.ql.metadata.HiveStoragePredicateHandler$DecomposedPredicate decomposePredicate(org.apache.hadoop.hive.ql.plan.ExprNodeDesc predicate, org.apache.hadoop.hive.metastore.api.Index index, java.util.Set queryPartitions)">4</method>
			<method name="private boolean findIndexColumnExprNodeDesc(org.apache.hadoop.hive.ql.plan.ExprNodeDesc expression)">10</method>
			<method name="public void generateIndexQuery(java.util.List indexes, org.apache.hadoop.hive.ql.plan.ExprNodeDesc predicate, org.apache.hadoop.hive.ql.parse.ParseContext pctx, org.apache.hadoop.hive.ql.index.HiveIndexQueryContext queryContext)">9</method>
			<method name="protected org.apache.hadoop.hive.ql.exec.Task getIndexBuilderMapRedTask(java.util.Set inputs, java.util.Set outputs, java.util.List indexField, boolean partitioned, org.apache.hadoop.hive.ql.plan.PartitionDesc indexTblPartDesc, String indexTableName, org.apache.hadoop.hive.ql.plan.PartitionDesc baseTablePartDesc, String baseTableName, String dbName)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lockmgr.HiveLockManager</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>10</rfc>
		<lcom>45</lcom>
		<ca>4</ca>
		<ce>5</ce>
		<npm>10</npm>
		<lcom3>2.0</lcom3>
		<loc>10</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void prepareRetry()">1</method>
			<method name="public abstract void setContext(org.apache.hadoop.hive.ql.lockmgr.HiveLockManagerCtx)">1</method>
			<method name="public abstract void releaseLocks(java.util.List)">1</method>
			<method name="public abstract void refresh()">1</method>
			<method name="public abstract void close()">1</method>
			<method name="public abstract void unlock(org.apache.hadoop.hive.ql.lockmgr.HiveLock)">1</method>
			<method name="public abstract java.util.List getLocks(org.apache.hadoop.hive.ql.lockmgr.HiveLockObject, boolean, boolean)">1</method>
			<method name="public abstract org.apache.hadoop.hive.ql.lockmgr.HiveLock lock(org.apache.hadoop.hive.ql.lockmgr.HiveLockObject, org.apache.hadoop.hive.ql.lockmgr.HiveLockMode, boolean)">1</method>
			<method name="public abstract java.util.List getLocks(boolean, boolean)">1</method>
			<method name="public abstract java.util.List lock(java.util.List, boolean)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$listType_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFRound</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>16</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>68</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>21.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable n)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable n, org.apache.hadoop.io.IntWritable i)">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.objectinspector.LazyBinaryMapObjectInspector</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>9</rfc>
		<lcom>6</lcom>
		<ca>4</ca>
		<ce>3</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>35</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.75</amc>
		<cc>
			<method name="public int getMapSize(Object data)">2</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector mapKeyObjectInspector, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector mapValueObjectInspector)">0</method>
			<method name="public java.util.Map getMap(Object data)">2</method>
			<method name="public Object getMapValueElement(Object data, Object key)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammarTokenManager</name>
		<wmc>37</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>53</rfc>
		<lcom>58</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>7</npm>
		<lcom3>0.6356209150326797</lcom3>
		<loc>4081</loc>
		<dam>0.23529411764705882</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>108.83783783783784</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.SimpleCharStream stream, int lexState)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="private int jjMoveStringLiteralDfa0_0()">2</method>
			<method name="protected org.apache.hadoop.hive.serde2.dynamic_type.Token jjFillToken()">2</method>
			<method name="private int jjMoveStringLiteralDfa13_0(long old0, long active0)">7</method>
			<method name="private int jjMoveStringLiteralDfa11_0(long old0, long active0)">8</method>
			<method name="private void jjCheckNAddStates(int start, int end)">2</method>
			<method name="private int jjMoveStringLiteralDfa3_0(long old0, long active0)">9</method>
			<method name="private int jjMoveStringLiteralDfa5_0(long old0, long active0)">7</method>
			<method name="private int jjMoveStringLiteralDfa2_0(long old0, long active0)">8</method>
			<method name="private int jjMoveStringLiteralDfa12_0(long old0, long active0)">10</method>
			<method name="private void ReInitRounds()">2</method>
			<method name="private int jjMoveStringLiteralDfa17_0(long old0, long active0)">5</method>
			<method name="public void ReInit(org.apache.hadoop.hive.serde2.dynamic_type.SimpleCharStream stream)">1</method>
			<method name="public void ReInit(org.apache.hadoop.hive.serde2.dynamic_type.SimpleCharStream stream, int lexState)">1</method>
			<method name="public void SwitchTo(int lexState)">3</method>
			<method name="private int jjMoveNfa_0(int startState, int curPos)">104</method>
			<method name="private int jjMoveStringLiteralDfa7_0(long old0, long active0)">6</method>
			<method name="private int jjMoveStringLiteralDfa9_0(long old0, long active0)">3</method>
			<method name="private void jjCheckNAdd(int state)">2</method>
			<method name="private int jjMoveStringLiteralDfa15_0(long old0, long active0)">8</method>
			<method name="private void jjCheckNAddTwoStates(int state1, int state2)">1</method>
			<method name="private int jjMoveStringLiteralDfa10_0(long old0, long active0)">4</method>
			<method name="private int jjMoveStringLiteralDfa6_0(long old0, long active0)">8</method>
			<method name="private final int jjStartNfa_0(int pos, long active0, long active1)">1</method>
			<method name="private int jjMoveStringLiteralDfa16_0(long old0, long active0)">4</method>
			<method name="private final int jjStopStringLiteralDfa_0(int pos, long active0, long active1)">31</method>
			<method name="public void setDebugStream(java.io.PrintStream ds)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.dynamic_type.Token getNextToken()">9</method>
			<method name="private void jjAddStates(int start, int end)">2</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.SimpleCharStream stream)">0</method>
			<method name="private int jjStartNfaWithStates_0(int pos, int kind, int state)">1</method>
			<method name="private int jjMoveStringLiteralDfa4_0(long old0, long active0)">7</method>
			<method name="private int jjMoveStringLiteralDfa1_0(long active0)">2</method>
			<method name="private int jjMoveStringLiteralDfa14_0(long old0, long active0)">6</method>
			<method name="private int jjMoveStringLiteralDfa8_0(long old0, long active0)">7</method>
			<method name="private int jjStopAtPos(int pos, int kind)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeSet</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>38</rfc>
		<lcom>22</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>8</npm>
		<lcom3>0.9285714285714286</lcom3>
		<loc>149</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>17.375</amc>
		<cc>
			<method name="public Object deserialize(Object reuse, org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeBase getElementType()">1</method>
			<method name="public void serialize(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public byte getType()">1</method>
			<method name="public Class getRealType()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int i)">0</method>
			<method name="public String toString()">1</method>
			<method name="public void _init_(int i)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.TaskRunner</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>10</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>3</ce>
		<npm>4</npm>
		<lcom3>0.3333333333333333</lcom3>
		<loc>44</loc>
		<dam>1.0</dam>
		<moa>3</moa>
		<mfa>0.9552238805970149</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.25</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.exec.Task getTask()">1</method>
			<method name="public void run()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.Task tsk, org.apache.hadoop.hive.ql.exec.TaskResult result)">0</method>
			<method name="public void runSequential()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$hintClause_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.ByteStreamTypedSerDe</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>7</cbo>
		<rfc>9</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>34</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.0</amc>
		<cc>
			<method name="public void _init_(java.lang.reflect.Type objectType)">0</method>
			<method name="public Object deserialize(org.apache.hadoop.io.Writable field)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.MapredLocalWork</name>
		<wmc>18</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>26</rfc>
		<lcom>113</lcom>
		<ca>15</ca>
		<ce>4</ce>
		<npm>18</npm>
		<lcom3>0.9117647058823529</lcom3>
		<loc>125</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.21428571428571427</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.5</amc>
		<cc>
			<method name="public void setStageID(String stageID)">1</method>
			<method name="public String getTmpFileURI()">1</method>
			<method name="public void deriveExplainAttributes()">4</method>
			<method name="public java.util.List getDummyParentOp()">1</method>
			<method name="public boolean getInputFileChangeSensitive()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setAliasToFetchWork(java.util.LinkedHashMap aliasToFetchWork)">1</method>
			<method name="public void setBucketMapjoinContext(org.apache.hadoop.hive.ql.plan.MapredLocalWork$BucketMapJoinContext bucketMapjoinContext)">1</method>
			<method name="public java.util.LinkedHashMap getAliasToFetchWork()">1</method>
			<method name="public void setAliasToWork(java.util.LinkedHashMap aliasToWork)">1</method>
			<method name="public void _init_(java.util.LinkedHashMap aliasToWork, java.util.LinkedHashMap aliasToFetchWork)">0</method>
			<method name="public void setDummyParentOp(java.util.List op)">1</method>
			<method name="public String getStageID()">1</method>
			<method name="public void setTmpFileURI(String tmpFileURI)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.MapredLocalWork$BucketMapJoinContext getBucketMapjoinContext()">1</method>
			<method name="public void setInputFileChangeSensitive(boolean inputFileChangeSensitive)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.MapredLocalWork clone)">0</method>
			<method name="public java.util.LinkedHashMap getAliasToWork()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNull</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>15</rfc>
		<lcom>6</lcom>
		<ca>0</ca>
		<ce>9</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>69</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.4</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.meta_data.MapMetaData</name>
		<wmc>1</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>5</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>13</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.0</amc>
		<cc>
			<method name="public void _init_(byte type, org.apache.thrift.meta_data.FieldValueMetaData kMetaData, org.apache.thrift.meta_data.FieldValueMetaData vMetaData)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lib.Rule</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract String getName()">1</method>
			<method name="public abstract int cost(java.util.Stack)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ByteWritable</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>14</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>8</npm>
		<lcom3>0.125</lcom3>
		<loc>90</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.35</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>8.88888888888889</amc>
		<cc>
			<method name="public void _init_(int b)">0</method>
			<method name="public boolean equals(Object o)">4</method>
			<method name="public int hashCode()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void write(java.io.DataOutput out)">1</method>
			<method name="public void set(int b)">1</method>
			<method name="public void readFields(java.io.DataInput in)">1</method>
			<method name="public int compareTo(Object o)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsAggregator</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>50</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>12</ce>
		<npm>5</npm>
		<lcom3>0.4</lcom3>
		<loc>492</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>79.33333333333333</amc>
		<cc>
			<method name="public boolean closeConnection()">3</method>
			<method name="public void _init_()">0</method>
			<method name="static int access$000(org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsAggregator x0)">1</method>
			<method name="public boolean cleanUp(String rowID)">2</method>
			<method name="public String aggregateStats(String fileID, String statType)">4</method>
			<method name="public boolean connect(org.apache.hadoop.conf.Configuration hiveconf)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.async.TAsyncClientFactory</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.thrift.async.TAsyncClient getAsyncClient(org.apache.thrift.transport.TNonblockingTransport)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.classification.InterfaceAudience</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="private void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.JavaTimestampObjectInspector</name>
		<wmc>11</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>19</rfc>
		<lcom>55</lcom>
		<ca>2</ca>
		<ce>5</ce>
		<npm>10</npm>
		<lcom3>2.0</lcom3>
		<loc>82</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3939393939393939</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.454545454545454</amc>
		<cc>
			<method name="public Object create(java.sql.Timestamp value)">1</method>
			<method name="protected void _init_()">0</method>
			<method name="public Object set(Object o, java.sql.Timestamp value)">1</method>
			<method name="public Object set(Object o, byte[] bytes, int offset)">1</method>
			<method name="public volatile Object getPrimitiveJavaObject(Object x0)">1</method>
			<method name="public Object set(Object o, org.apache.hadoop.hive.serde2.io.TimestampWritable tw)">1</method>
			<method name="public volatile Object getPrimitiveWritableObject(Object x0)">1</method>
			<method name="public Object create(byte[] bytes, int offset)">1</method>
			<method name="public java.sql.Timestamp get(Object o)">1</method>
			<method name="public java.sql.Timestamp getPrimitiveJavaObject(Object o)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.TimestampWritable getPrimitiveWritableObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterViewStatementSuffix_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$unlockStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ExecMapper$reportStats</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>12</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>38</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>17.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.mapred.Reporter rp)">0</method>
			<method name="public void func(org.apache.hadoop.hive.ql.exec.Operator op)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixRename_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ExprNodeGenericFuncEvaluator$DeferredExprObject</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>1</npm>
		<lcom3>0.0</lcom3>
		<loc>20</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.0</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.ql.exec.ExprNodeGenericFuncEvaluator, org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator eval)">0</method>
			<method name="public Object get()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsSetupConstants</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.session.SessionState$LogHelper</name>
		<wmc>12</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>36</cbo>
		<rfc>22</rfc>
		<lcom>58</lcom>
		<ca>34</ca>
		<ce>3</ce>
		<npm>12</npm>
		<lcom3>0.6363636363636364</lcom3>
		<loc>146</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3958333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.0</amc>
		<cc>
			<method name="public void printError(String error)">1</method>
			<method name="public void printInfo(String info)">1</method>
			<method name="public boolean getIsSilent()">2</method>
			<method name="public java.io.PrintStream getErrStream()">3</method>
			<method name="public void _init_(org.apache.commons.logging.Log LOG)">0</method>
			<method name="public void printError(String error, String detail)">1</method>
			<method name="public java.io.PrintStream getOutStream()">3</method>
			<method name="public java.io.PrintStream getChildOutStream()">3</method>
			<method name="public java.io.PrintStream getChildErrStream()">3</method>
			<method name="public java.io.PrintStream getInfoStream()">3</method>
			<method name="public void printInfo(String info, String detail)">2</method>
			<method name="public void _init_(org.apache.commons.logging.Log LOG, boolean isSilent)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.formatting.MetaDataFormatter</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>11</rfc>
		<lcom>55</lcom>
		<ca>3</ca>
		<ce>6</ce>
		<npm>11</npm>
		<lcom3>1.1</lcom3>
		<loc>14</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3051948051948052</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void consoleError(org.apache.hadoop.hive.ql.session.SessionState$LogHelper, String, String, int)">1</method>
			<method name="public abstract void consoleError(org.apache.hadoop.hive.ql.session.SessionState$LogHelper, String, int)">1</method>
			<method name="public abstract void error(java.io.OutputStream, String, int)">1</method>
			<method name="public abstract void showTableStatus(java.io.DataOutputStream, org.apache.hadoop.hive.ql.metadata.Hive, org.apache.hadoop.hive.conf.HiveConf, java.util.List, java.util.Map, org.apache.hadoop.hive.ql.metadata.Partition)">1</method>
			<method name="public abstract void showTables(java.io.DataOutputStream, java.util.Set)">1</method>
			<method name="public abstract void logWarn(java.io.OutputStream, String, int)">1</method>
			<method name="public abstract void describeTable(java.io.DataOutputStream, String, String, org.apache.hadoop.hive.ql.metadata.Table, org.apache.hadoop.hive.ql.metadata.Partition, java.util.List, boolean, boolean)">1</method>
			<method name="public abstract void showDatabaseDescription(java.io.DataOutputStream, String, String, String, java.util.Map)">1</method>
			<method name="public abstract void logInfo(java.io.OutputStream, String, int)">1</method>
			<method name="public abstract void showDatabases(java.io.DataOutputStream, java.util.List)">1</method>
			<method name="public abstract void showTablePartitons(java.io.DataOutputStream, java.util.List)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TSet</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>4</rfc>
		<lcom>3</lcom>
		<ca>9</ca>
		<ce>1</ce>
		<npm>3</npm>
		<lcom3>0.0</lcom3>
		<loc>26</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(org.apache.thrift.protocol.TList list)">0</method>
			<method name="public void _init_(byte t, int s)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.SettableBooleanObjectInspector</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Object create(boolean)">1</method>
			<method name="public abstract Object set(Object, boolean)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$RowFormatParams</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>16</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>8</ce>
		<npm>0</npm>
		<lcom3>0.5714285714285714</lcom3>
		<loc>130</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>40.0</amc>
		<cc>
			<method name="protected void analyzeRowFormat(org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$AnalyzeCreateCommonVars shared, org.apache.hadoop.hive.ql.parse.ASTNode child)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPLessThan</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>17</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>17</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>202</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>100.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.StandardConstantMapObjectInspector</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>18</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.666666666666667</amc>
		<cc>
			<method name="public volatile Object getWritableConstantValue()">1</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector mapKeyObjectInspector, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector mapValueObjectInspector, java.util.Map value)">0</method>
			<method name="public java.util.Map getWritableConstantValue()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndexCtx</name>
		<wmc>14</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>19</cbo>
		<rfc>28</rfc>
		<lcom>67</lcom>
		<ca>6</ca>
		<ce>18</ce>
		<npm>12</npm>
		<lcom3>0.8269230769230769</lcom3>
		<loc>158</loc>
		<dam>1.0</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.22448979591836735</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.714285714285714</amc>
		<cc>
			<method name="public void setEval(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator eval)">1</method>
			<method name="public String getIndexName()">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Hive getHiveDb()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ExprNodeColumnDesc getAggrExprNode()">1</method>
			<method name="public java.util.Map getOpc()">1</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEval()">1</method>
			<method name="public void setAggrExprNode(org.apache.hadoop.hive.ql.plan.ExprNodeColumnDesc aggrExprNode)">1</method>
			<method name="private org.apache.hadoop.hive.ql.lib.NodeProcessor getDefaultProc()">1</method>
			<method name="public String getBaseTableName()">1</method>
			<method name="public String getAggregateFunction()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndexCtx getInstance(org.apache.hadoop.hive.ql.parse.ParseContext parseContext, org.apache.hadoop.hive.ql.metadata.Hive hiveDb, String indexTableName, String baseTableName, String aggregateFunction)">1</method>
			<method name="private void _init_(org.apache.hadoop.hive.ql.parse.ParseContext parseContext, org.apache.hadoop.hive.ql.metadata.Hive hiveDb, String indexTableName, String baseTableName, String aggregateFunction)">0</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext getParseContext()">1</method>
			<method name="public void invokeRewriteQueryProc(org.apache.hadoop.hive.ql.exec.Operator topOp)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory$ColumnPrunerGroupByProc</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>15</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>10</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>79</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>38.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$privilegeList_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory$ObjectInspectorOptions</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>9</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9166666666666666</lcom3>
		<loc>56</loc>
		<dam>0.25</dam>
		<moa>4</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>12.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory$ObjectInspectorOptions valueOf(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory$ObjectInspectorOptions[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.DelegationTokenStore</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>8</rfc>
		<lcom>28</lcom>
		<ca>4</ca>
		<ce>4</ce>
		<npm>8</npm>
		<lcom3>2.0</lcom3>
		<loc>8</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$DelegationTokenInformation getToken(org.apache.hadoop.hive.thrift.DelegationTokenIdentifier)">1</method>
			<method name="public abstract boolean removeToken(org.apache.hadoop.hive.thrift.DelegationTokenIdentifier)">1</method>
			<method name="public abstract boolean removeMasterKey(int)">1</method>
			<method name="public abstract java.util.List getAllDelegationTokenIdentifiers()">1</method>
			<method name="public abstract int addMasterKey(String)">1</method>
			<method name="public abstract void updateMasterKey(int, String)">1</method>
			<method name="public abstract String[] getMasterKeys()">1</method>
			<method name="public abstract boolean addToken(org.apache.hadoop.hive.thrift.DelegationTokenIdentifier, org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$DelegationTokenInformation)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixProtectMode_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lockmgr.HiveLockMode</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>9</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.888888888888889</lcom3>
		<loc>45</loc>
		<dam>0.3333333333333333</dam>
		<moa>3</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>9.5</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.lockmgr.HiveLockMode[] values()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lockmgr.HiveLockMode valueOf(String name)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.thrift.test.Complex$_Fields</name>
		<wmc>9</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>24</rfc>
		<lcom>26</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>0.775</lcom3>
		<loc>185</loc>
		<dam>0.4</dam>
		<moa>7</moa>
		<mfa>0.65</mfa>
		<cam>0.3125</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>18.444444444444443</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.serde2.thrift.test.Complex$_Fields findByThriftIdOrThrow(int fieldId)">2</method>
			<method name="private void _init_(String, int, short thriftId, String fieldName)">0</method>
			<method name="public String getFieldName()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.thrift.test.Complex$_Fields[] values()">1</method>
			<method name="public short getThriftFieldId()">1</method>
			<method name="public static org.apache.hadoop.hive.serde2.thrift.test.Complex$_Fields valueOf(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.serde2.thrift.test.Complex$_Fields findByName(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.serde2.thrift.test.Complex$_Fields findByThriftId(int fieldId)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ListObjectsEqualComparer$FieldComparer</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>16</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>15</ce>
		<npm>2</npm>
		<lcom3>0.41176470588235303</lcom3>
		<loc>255</loc>
		<dam>0.9411764705882353</dam>
		<moa>17</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>118.0</amc>
		<cc>
			<method name="public boolean areEqual(Object o0, Object o1)">11</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.ListObjectsEqualComparer, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi0, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi1)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFHistogramNumeric$GenericUDAFHistogramNumericEvaluator</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>38</rfc>
		<lcom>28</lcom>
		<ca>1</ca>
		<ce>16</ce>
		<npm>8</npm>
		<lcom3>0.84375</lcom3>
		<loc>272</loc>
		<dam>0.75</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.3541666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>28.77777777777778</amc>
		<cc>
			<method name="public void iterate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object[] parameters)">1</method>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector init(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode m, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] parameters)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer getNewAggregationBuffer()">1</method>
			<method name="public void reset(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void merge(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object partial)">1</method>
			<method name="public Object terminatePartial(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFArray</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>21</rfc>
		<lcom>2</lcom>
		<ca>0</ca>
		<ce>14</ce>
		<npm>4</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>161</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>38.75</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ppr.ExprProcFactory</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>27</rfc>
		<lcom>15</lcom>
		<ca>1</ca>
		<ce>14</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>121</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.16666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.166666666666668</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getGenericFuncProcessor()">1</method>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getColumnProcessor()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getFieldProcessor()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getDefaultExprProcessor()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.ExprNodeDesc genPruner(String tabAlias, org.apache.hadoop.hive.ql.plan.ExprNodeDesc pred, boolean hasNonPartCols)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.UnparseTranslator$Translation</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>8</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>1.0</lcom3>
		<loc>26</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.parse.UnparseTranslator$1 x0)">0</method>
			<method name="public String toString()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.HiveStorageHandler</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>8</rfc>
		<lcom>28</lcom>
		<ca>8</ca>
		<ce>5</ce>
		<npm>8</npm>
		<lcom3>2.0</lcom3>
		<loc>8</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Class getInputFormatClass()">1</method>
			<method name="public abstract void configureTableJobProperties(org.apache.hadoop.hive.ql.plan.TableDesc, java.util.Map)">1</method>
			<method name="public abstract Class getOutputFormatClass()">1</method>
			<method name="public abstract void configureInputJobProperties(org.apache.hadoop.hive.ql.plan.TableDesc, java.util.Map)">1</method>
			<method name="public abstract Class getSerDeClass()">1</method>
			<method name="public abstract void configureOutputJobProperties(org.apache.hadoop.hive.ql.plan.TableDesc, java.util.Map)">1</method>
			<method name="public abstract org.apache.hadoop.hive.ql.security.authorization.HiveAuthorizationProvider getAuthorizationProvider()">1</method>
			<method name="public abstract org.apache.hadoop.hive.metastore.HiveMetaHook getMetaHook()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TBase64Utils</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>6</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>1.0</lcom3>
		<loc>1269</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>315.75</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="static final void decode(byte[] src, int srcOff, int len, byte[] dst, int dstOff)">3</method>
			<method name="static final void encode(byte[] src, int srcOff, int len, byte[] dst, int dstOff)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$expression_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.fs.ProxyLocalFileSystem</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>15</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>5</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>58</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.0</amc>
		<cc>
			<method name="public void initialize(java.net.URI name, org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(org.apache.hadoop.fs.FileSystem fs)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.StructField</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>50</cbo>
		<rfc>3</rfc>
		<lcom>3</lcom>
		<ca>49</ca>
		<ce>1</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>3</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getFieldObjectInspector()">1</method>
			<method name="public abstract String getFieldName()">1</method>
			<method name="public abstract String getFieldComment()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.HadoopJobExecHook</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>3</rfc>
		<lcom>3</lcom>
		<ca>4</ca>
		<ce>3</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>3</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract boolean checkFatalErrors(org.apache.hadoop.mapred.Counters, StringBuilder)">1</method>
			<method name="public abstract void updateCounters(org.apache.hadoop.mapred.Counters, org.apache.hadoop.mapred.RunningJob)">1</method>
			<method name="public abstract void logPlanProgress(org.apache.hadoop.hive.ql.session.SessionState)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TSaslTransport$SaslParticipant</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>21</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>8</npm>
		<lcom3>0.14285714285714285</lcom3>
		<loc>104</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.75</amc>
		<cc>
			<method name="public boolean isComplete()">2</method>
			<method name="public byte[] evaluateChallengeOrResponse(byte[] challengeOrResponse)">1</method>
			<method name="public void _init_(javax.security.sasl.SaslServer saslServer)">0</method>
			<method name="public void _init_(javax.security.sasl.SaslClient saslClient)">0</method>
			<method name="public Object getNegotiatedProperty(String propName)">2</method>
			<method name="public byte[] unwrap(byte[] buf, int off, int len)">1</method>
			<method name="public void dispose()">1</method>
			<method name="public byte[] wrap(byte[] buf, int off, int len)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$orReplace_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixMergeFiles_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyStruct</name>
		<wmc>15</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>45</rfc>
		<lcom>41</lcom>
		<ca>3</ca>
		<ce>13</ce>
		<npm>6</npm>
		<lcom3>0.7777777777777778</lcom3>
		<loc>402</loc>
		<dam>0.1111111111111111</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.22448979591836735</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>25.2</amc>
		<cc>
			<method name="protected void setFields(org.apache.hadoop.hive.serde2.lazy.LazyObject[] fields)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object getField(int fieldID)">2</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector oi)">0</method>
			<method name="protected void setParsed(boolean parsed)">1</method>
			<method name="protected boolean[] getFieldInited()">1</method>
			<method name="private void parse()">17</method>
			<method name="public Object getObject()">1</method>
			<method name="public long getRawDataSerializedSize()">1</method>
			<method name="protected org.apache.hadoop.hive.serde2.lazy.LazyObject[] getFields()">1</method>
			<method name="public java.util.ArrayList getFieldsAsList()">4</method>
			<method name="protected void setFieldInited(boolean[] fieldInited)">1</method>
			<method name="protected boolean getParsed()">1</method>
			<method name="private Object uncheckedGetField(int fieldID)">5</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.persistence.MRU</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>16</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>1</ce>
		<npm>7</npm>
		<lcom3>0.5</lcom3>
		<loc>118</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.88888888888889</amc>
		<cc>
			<method name="public void clear()">2</method>
			<method name="public void moveToHead(org.apache.hadoop.hive.ql.exec.persistence.DCLLItem v)">4</method>
			<method name="public org.apache.hadoop.hive.ql.exec.persistence.DCLLItem put(org.apache.hadoop.hive.ql.exec.persistence.DCLLItem item)">1</method>
			<method name="private void addToHead(org.apache.hadoop.hive.ql.exec.persistence.DCLLItem v)">2</method>
			<method name="public org.apache.hadoop.hive.ql.exec.persistence.DCLLItem head()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void remove(org.apache.hadoop.hive.ql.exec.persistence.DCLLItem v)">4</method>
			<method name="public org.apache.hadoop.hive.ql.exec.persistence.DCLLItem tail()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.Token</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>4</rfc>
		<lcom>3</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>3</npm>
		<lcom3>1.4375</lcom3>
		<loc>23</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public String toString()">1</method>
			<method name="public static final org.apache.hadoop.hive.serde2.dynamic_type.Token newToken(int ofKind)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>12</rfc>
		<lcom>12</lcom>
		<ca>13</ca>
		<ce>4</ce>
		<npm>9</npm>
		<lcom3>0.8</lcom3>
		<loc>65</loc>
		<dam>1.0</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.35185185185185186</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.666666666666667</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.Context getContext()">1</method>
			<method name="public void addToRootTask(org.apache.hadoop.hive.ql.exec.Task tsk)">1</method>
			<method name="public void removeFromRootTask(org.apache.hadoop.hive.ql.exec.Task tsk)">1</method>
			<method name="public org.apache.hadoop.hive.conf.HiveConf getConf()">1</method>
			<method name="public void setParseContext(org.apache.hadoop.hive.ql.parse.ParseContext parseContext)">1</method>
			<method name="public void setConf(org.apache.hadoop.hive.conf.HiveConf conf)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.hive.ql.parse.ParseContext parseContext, org.apache.hadoop.hive.ql.Context context, java.util.List rootTasks, org.apache.hadoop.hive.ql.exec.Task fetchTask)">0</method>
			<method name="public void setContext(org.apache.hadoop.hive.ql.Context context)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext getParseContext()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tabTypeExpr_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.JavaStringObjectInspector</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>10</rfc>
		<lcom>36</lcom>
		<ca>7</ca>
		<ce>5</ce>
		<npm>8</npm>
		<lcom3>2.0</lcom3>
		<loc>52</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5277777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.777777777777778</amc>
		<cc>
			<method name="public Object create(org.apache.hadoop.io.Text value)">2</method>
			<method name="void _init_()">0</method>
			<method name="public Object set(Object o, org.apache.hadoop.io.Text value)">2</method>
			<method name="public Object set(Object o, String value)">1</method>
			<method name="public volatile Object getPrimitiveJavaObject(Object x0)">1</method>
			<method name="public volatile Object getPrimitiveWritableObject(Object x0)">1</method>
			<method name="public Object create(String value)">1</method>
			<method name="public org.apache.hadoop.io.Text getPrimitiveWritableObject(Object o)">2</method>
			<method name="public String getPrimitiveJavaObject(Object o)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.Task</name>
		<wmc>73</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>26</cbo>
		<rfc>172</rfc>
		<lcom>1664</lcom>
		<ca>2</ca>
		<ce>24</ce>
		<npm>70</npm>
		<lcom3>0.8518518518518519</lcom3>
		<loc>2090</loc>
		<dam>0.9523809523809523</dam>
		<moa>11</moa>
		<mfa>0.0</mfa>
		<cam>0.09395424836601307</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>27.34246575342466</amc>
		<cc>
			<method name="public boolean isSet(org.apache.hadoop.hive.ql.plan.api.Task$_Fields field)">3</method>
			<method name="public boolean isStarted()">1</method>
			<method name="public void setTaskAttributesIsSet(boolean value)">2</method>
			<method name="public void setTaskCounters(java.util.Map taskCounters)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void setDoneIsSet(boolean value)">1</method>
			<method name="public void setTaskCountersIsSet(boolean value)">2</method>
			<method name="public volatile boolean isSet(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="public void putToTaskCounters(String key, long val)">2</method>
			<method name="public void setTaskAttributes(java.util.Map taskAttributes)">1</method>
			<method name="public void setOperatorGraph(org.apache.hadoop.hive.ql.plan.api.Graph operatorGraph)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.Task deepCopy()">1</method>
			<method name="public void unsetStarted()">1</method>
			<method name="public void unsetTaskAttributes()">1</method>
			<method name="public boolean isSetStarted()">1</method>
			<method name="public void setTaskId(String taskId)">1</method>
			<method name="public void validate()">1</method>
			<method name="public boolean isDone()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void unsetTaskId()">1</method>
			<method name="public void setStartedIsSet(boolean value)">1</method>
			<method name="public volatile void setFieldValue(org.apache.thrift.TFieldIdEnum x0, Object x1)">1</method>
			<method name="public volatile int compareTo(Object x0)">1</method>
			<method name="public void setFieldValue(org.apache.hadoop.hive.ql.plan.api.Task$_Fields field, Object value)">10</method>
			<method name="public Object getFieldValue(org.apache.hadoop.hive.ql.plan.api.Task$_Fields field)">2</method>
			<method name="public int getTaskCountersSize()">2</method>
			<method name="public String getTaskId()">1</method>
			<method name="public boolean isSetTaskType()">2</method>
			<method name="public java.util.Map getTaskAttributes()">1</method>
			<method name="public void addToOperatorList(org.apache.hadoop.hive.ql.plan.api.Operator elem)">2</method>
			<method name="public int compareTo(org.apache.hadoop.hive.ql.plan.api.Task other)">26</method>
			<method name="public boolean equals(Object that)">3</method>
			<method name="public java.util.Iterator getOperatorListIterator()">2</method>
			<method name="public boolean isSetDone()">1</method>
			<method name="public void clear()">1</method>
			<method name="public void setStarted(boolean started)">1</method>
			<method name="public void unsetOperatorGraph()">1</method>
			<method name="public void unsetTaskCounters()">1</method>
			<method name="public void setDone(boolean done)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.Graph getOperatorGraph()">1</method>
			<method name="public volatile org.apache.thrift.TBase deepCopy()">1</method>
			<method name="public volatile Object getFieldValue(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="private void writeObject(java.io.ObjectOutputStream out)">1</method>
			<method name="public void read(org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public java.util.Map getTaskCounters()">1</method>
			<method name="public java.util.List getOperatorList()">1</method>
			<method name="public void write(org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public void setOperatorListIsSet(boolean value)">2</method>
			<method name="public int getOperatorListSize()">2</method>
			<method name="public boolean isSetTaskAttributes()">2</method>
			<method name="public void unsetTaskType()">1</method>
			<method name="public void putToTaskAttributes(String key, String val)">2</method>
			<method name="public String toString()">16</method>
			<method name="public boolean isSetTaskId()">2</method>
			<method name="public boolean isSetOperatorGraph()">2</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.TaskType getTaskType()">1</method>
			<method name="public void _init_(String taskId, org.apache.hadoop.hive.ql.plan.api.TaskType taskType, java.util.Map taskAttributes, java.util.Map taskCounters, boolean done, boolean started)">0</method>
			<method name="public boolean isSetTaskCounters()">2</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.Task$_Fields fieldForId(int fieldId)">1</method>
			<method name="public boolean equals(org.apache.hadoop.hive.ql.plan.api.Task that)">42</method>
			<method name="public void setTaskIdIsSet(boolean value)">2</method>
			<method name="public void unsetDone()">1</method>
			<method name="public int hashCode()">1</method>
			<method name="public int getTaskAttributesSize()">2</method>
			<method name="public boolean isSetOperatorList()">2</method>
			<method name="private void readObject(java.io.ObjectInputStream in)">1</method>
			<method name="public void setTaskType(org.apache.hadoop.hive.ql.plan.api.TaskType taskType)">1</method>
			<method name="public void unsetOperatorList()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.api.Task other)">0</method>
			<method name="public void setOperatorList(java.util.List operatorList)">1</method>
			<method name="public void setOperatorGraphIsSet(boolean value)">2</method>
			<method name="public volatile org.apache.thrift.TFieldIdEnum fieldForId(int x0)">1</method>
			<method name="public void setTaskTypeIsSet(boolean value)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat$1</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>11</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>59</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4444444444444444</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>17.666666666666668</amc>
		<cc>
			<method name="public void close(boolean abort)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, java.io.OutputStream, int)">0</method>
			<method name="public void write(org.apache.hadoop.io.Writable r)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$colType_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyArray</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>29</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>9</ce>
		<npm>4</npm>
		<lcom3>0.42857142857142855</lcom3>
		<loc>355</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.40625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>42.625</amc>
		<cc>
			<method name="public int getListLength()">2</method>
			<method name="private Object uncheckedGetElement(int index)">5</method>
			<method name="public java.util.List getList()">5</method>
			<method name="private void parse()">11</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.LazyListObjectInspector oi)">0</method>
			<method name="public Object getListElementObject(int index)">4</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
			<method name="private void enlargeArrays()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$StorageFormat</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>14</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>7</ce>
		<npm>0</npm>
		<lcom3>0.125</lcom3>
		<loc>149</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>47.333333333333336</amc>
		<cc>
			<method name="protected boolean fillStorageFormat(org.apache.hadoop.hive.ql.parse.ASTNode child, org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$AnalyzeCreateCommonVars shared)">4</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer)">0</method>
			<method name="protected void fillDefaultStorageFormat(org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$AnalyzeCreateCommonVars shared)">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ExplainTask$MethodComparator</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>5</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>17</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.5</amc>
		<cc>
			<method name="public int compare(Object o1, Object o2)">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol$Factory</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>10</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.thrift.protocol.TProtocol getProtocol(org.apache.thrift.transport.TTransport trans)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.SerDeUtils$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>117</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>114.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.history.HiveHistory$Keys</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9791666666666666</lcom3>
		<loc>188</loc>
		<dam>0.0625</dam>
		<moa>16</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>42.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.history.HiveHistory$Keys[] values()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.history.HiveHistory$Keys valueOf(String name)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>84</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>82.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.MapRedStats</name>
		<wmc>14</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>23</rfc>
		<lcom>33</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>14</npm>
		<lcom3>0.782051282051282</lcom3>
		<loc>217</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2857142857142857</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.071428571428571</amc>
		<cc>
			<method name="public void setJobId(String jobId)">1</method>
			<method name="public int getNumReduce()">1</method>
			<method name="public boolean isSuccess()">1</method>
			<method name="public org.apache.hadoop.mapred.Counters getCounters()">1</method>
			<method name="public void _init_(int numMap, int numReduce, long cpuMSec, boolean ifSuccess, String jobId)">0</method>
			<method name="public void setNumMap(int numMap)">1</method>
			<method name="public void setSuccess(boolean success)">1</method>
			<method name="public void setCounters(org.apache.hadoop.mapred.Counters taskCounters)">1</method>
			<method name="public String getJobId()">1</method>
			<method name="public void setCpuMSec(long cpuMSec)">1</method>
			<method name="public int getNumMap()">1</method>
			<method name="public long getCpuMSec()">1</method>
			<method name="public String toString()">10</method>
			<method name="public void setNumReduce(int numReduce)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.SamplePruner$LimitPruneRetStatus</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9333333333333332</lcom3>
		<loc>67</loc>
		<dam>0.2</dam>
		<moa>5</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>14.5</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.SamplePruner$LimitPruneRetStatus[] values()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.SamplePruner$LimitPruneRetStatus valueOf(String name)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableStringObjectInspector</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>23</cbo>
		<rfc>14</rfc>
		<lcom>45</lcom>
		<ca>18</ca>
		<ce>5</ce>
		<npm>9</npm>
		<lcom3>2.0</lcom3>
		<loc>89</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.525</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.9</amc>
		<cc>
			<method name="public Object create(org.apache.hadoop.io.Text value)">2</method>
			<method name="void _init_()">0</method>
			<method name="public Object set(Object o, org.apache.hadoop.io.Text value)">2</method>
			<method name="public Object set(Object o, String value)">2</method>
			<method name="public volatile Object getPrimitiveJavaObject(Object x0)">1</method>
			<method name="public volatile Object getPrimitiveWritableObject(Object x0)">1</method>
			<method name="public Object create(String value)">2</method>
			<method name="public org.apache.hadoop.io.Text getPrimitiveWritableObject(Object o)">2</method>
			<method name="public String getPrimitiveJavaObject(Object o)">2</method>
			<method name="public Object copyObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.binarysortable.BinarySortableSerDe</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>48</cbo>
		<rfc>125</rfc>
		<lcom>37</lcom>
		<ca>0</ca>
		<ce>48</ce>
		<npm>7</npm>
		<lcom3>0.8818181818181818</lcom3>
		<loc>1616</loc>
		<dam>0.0</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.2</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>144.9090909090909</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getObjectInspector()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object deserialize(org.apache.hadoop.io.Writable blob)">1</method>
			<method name="static void serialize(org.apache.hadoop.hive.serde2.binarysortable.OutputByteBuffer buffer, Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, boolean invert)">11</method>
			<method name="static Object deserialize(org.apache.hadoop.hive.serde2.binarysortable.InputByteBuffer buffer, org.apache.hadoop.hive.serde2.typeinfo.TypeInfo type, boolean invert, Object reuse)">1</method>
			<method name="public Class getSerializedClass()">1</method>
			<method name="private static void serializeBytes(org.apache.hadoop.hive.serde2.binarysortable.OutputByteBuffer buffer, byte[] data, int length, boolean invert)">4</method>
			<method name="public org.apache.hadoop.io.Writable serialize(Object obj, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objInspector)">1</method>
			<method name="public void initialize(org.apache.hadoop.conf.Configuration conf, java.util.Properties tbl)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.SerDeStats getSerDeStats()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Jetty23Shims$Server</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>15</rfc>
		<lcom>6</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>45</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.25</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.shims.Jetty23Shims$1 x0)">0</method>
			<method name="private void _init_()">0</method>
			<method name="public void addWar(String war, String contextPath)">1</method>
			<method name="public void setupListenerHostPort(String listen, int port)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.persistence.MapJoinSingleKey</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>29</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>9</npm>
		<lcom3>0.125</lcom3>
		<loc>158</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.444444444444443</amc>
		<cc>
			<method name="public Object getObj()">1</method>
			<method name="public void readExternal(java.io.ObjectInput in)">1</method>
			<method name="public boolean equals(Object o)">7</method>
			<method name="public int hashCode()">2</method>
			<method name="public void setObj(Object obj)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void writeExternal(java.io.ObjectOutput out)">1</method>
			<method name="public void _init_(Object obj)">0</method>
			<method name="public boolean hasAnyNulls(boolean[] nullsafes)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.TableScanDesc</name>
		<wmc>16</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>18</rfc>
		<lcom>88</lcom>
		<ca>16</ca>
		<ce>1</ce>
		<npm>16</npm>
		<lcom3>0.9481481481481481</lcom3>
		<loc>91</loc>
		<dam>0.7777777777777778</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.325</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.125</amc>
		<cc>
			<method name="public void _init_(String alias)">0</method>
			<method name="public void setAlias(String alias)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ExprNodeDesc getFilterExpr()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setPartColumns(java.util.List partColumns)">1</method>
			<method name="public void setStatsAggPrefix(String k)">1</method>
			<method name="public java.util.List getPartColumns()">1</method>
			<method name="public void setFilterExpr(org.apache.hadoop.hive.ql.plan.ExprNodeDesc filterExpr)">1</method>
			<method name="public String getStatsAggPrefix()">1</method>
			<method name="public void setVirtualCols(java.util.List virtualCols)">1</method>
			<method name="public String getAlias()">1</method>
			<method name="public java.util.List getVirtualCols()">1</method>
			<method name="public void setGatherStats(boolean gatherStats)">1</method>
			<method name="public void _init_(String alias, java.util.List vcs)">0</method>
			<method name="public boolean isGatherStats()">1</method>
			<method name="public void addVirtualCols(java.util.List virtualCols)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ExtractDesc</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>4</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>22</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.plan.ExprNodeDesc getCol()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.ExprNodeDesc col)">0</method>
			<method name="public void setCol(org.apache.hadoop.hive.ql.plan.ExprNodeDesc col)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFPercentileApprox$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>75</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>72.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndex$NewQuerySelectSchemaProc</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>23</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>17</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>83</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4444444444444444</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.666666666666668</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, Object[] nodeOutputs)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndex$1 x0)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFMinute</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>13</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>0.25</lcom3>
		<loc>86</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.333333333333332</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable t)">2</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.Text dateString)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixRenameCol_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.MapredLocalWork$BucketMapJoinContext</name>
		<wmc>14</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>36</rfc>
		<lcom>67</lcom>
		<ca>5</ca>
		<ce>1</ce>
		<npm>13</npm>
		<lcom3>0.9102564102564104</lcom3>
		<loc>201</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.35714285714285715</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.928571428571429</amc>
		<cc>
			<method name="public java.util.LinkedHashMap getAliasBucketFileNameMapping()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setBucketFileNameMapping(java.util.LinkedHashMap bucketFileNameMapping)">1</method>
			<method name="public java.util.LinkedHashMap getAliasBucketBaseFileNameMapping()">1</method>
			<method name="private String getBaseFileName(String path)">1</method>
			<method name="public void setAliasBucketFileNameMapping(java.util.LinkedHashMap aliasBucketFileNameMapping)">1</method>
			<method name="public void setBucketMatcherClass(Class bucketMatcherClass)">1</method>
			<method name="public java.util.LinkedHashMap getBucketFileNameMapping()">1</method>
			<method name="public void setMapJoinBigTableAlias(String bigTableAlias)">1</method>
			<method name="public void setAliasBucketBaseFileNameMapping(java.util.LinkedHashMap aliasBucketBaseFileNameMapping)">1</method>
			<method name="public void deriveBucketMapJoinMapping()">7</method>
			<method name="public String getMapJoinBigTableAlias()">1</method>
			<method name="public Class getBucketMatcherClass()">1</method>
			<method name="public String toString()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFSum$GenericUDAFSumDouble</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>24</rfc>
		<lcom>24</lcom>
		<ca>1</ca>
		<ce>14</ce>
		<npm>8</npm>
		<lcom3>0.78125</lcom3>
		<loc>165</loc>
		<dam>0.5</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.3541666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.88888888888889</amc>
		<cc>
			<method name="public void iterate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object[] parameters)">1</method>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector init(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode m, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] parameters)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer getNewAggregationBuffer()">1</method>
			<method name="public void merge(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object partial)">1</method>
			<method name="public Object terminatePartial(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void reset(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.TextRecordReader</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>10</rfc>
		<lcom>6</lcom>
		<ca>0</ca>
		<ce>5</ce>
		<npm>5</npm>
		<lcom3>0.8333333333333333</lcom3>
		<loc>48</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.36</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.0</amc>
		<cc>
			<method name="public void initialize(java.io.InputStream in, org.apache.hadoop.conf.Configuration conf, java.util.Properties tbl)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void close()">1</method>
			<method name="public int next(org.apache.hadoop.io.Writable row)">1</method>
			<method name="public org.apache.hadoop.io.Writable createRow()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.HadoopShims$InputSplitShim</name>
		<wmc>14</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>14</rfc>
		<lcom>91</lcom>
		<ca>8</ca>
		<ce>3</ce>
		<npm>14</npm>
		<lcom3>2.0</lcom3>
		<loc>14</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2857142857142857</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.hadoop.mapred.JobConf getJob()">1</method>
			<method name="public abstract String toString()">1</method>
			<method name="public abstract void readFields(java.io.DataInput)">1</method>
			<method name="public abstract long getOffset(int)">1</method>
			<method name="public abstract long[] getStartOffsets()">1</method>
			<method name="public abstract org.apache.hadoop.fs.Path[] getPaths()">1</method>
			<method name="public abstract String[] getLocations()">1</method>
			<method name="public abstract long getLength(int)">1</method>
			<method name="public abstract org.apache.hadoop.fs.Path getPath(int)">1</method>
			<method name="public abstract int getNumPaths()">1</method>
			<method name="public abstract void write(java.io.DataOutput)">1</method>
			<method name="public abstract long[] getLengths()">1</method>
			<method name="public abstract void shrinkSplit(long)">1</method>
			<method name="public abstract long getLength()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$columnNameCommentList_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.SimpleMapEqualComparer</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>12</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>60</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>29.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public int compare(Object o1, org.apache.hadoop.hive.serde2.objectinspector.MapObjectInspector moi1, Object o2, org.apache.hadoop.hive.serde2.objectinspector.MapObjectInspector moi2)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.GroupByOptimizer</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>22</rfc>
		<lcom>13</lcom>
		<ca>4</ca>
		<ce>15</ce>
		<npm>2</npm>
		<lcom3>0.8</lcom3>
		<loc>77</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.666666666666666</amc>
		<cc>
			<method name="static org.apache.commons.logging.Log access$000()">1</method>
			<method name="private org.apache.hadoop.hive.ql.lib.NodeProcessor getDefaultProc()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext transform(org.apache.hadoop.hive.ql.parse.ParseContext pctx)">1</method>
			<method name="private org.apache.hadoop.hive.ql.lib.NodeProcessor getMapAggreSortedGroupbyProc(org.apache.hadoop.hive.ql.parse.ParseContext pctx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ExecReducer</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>30</cbo>
		<rfc>82</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>30</ce>
		<npm>4</npm>
		<lcom3>0.7181818181818181</lcom3>
		<loc>729</loc>
		<dam>0.7272727272727273</dam>
		<moa>7</moa>
		<mfa>0.0</mfa>
		<cam>0.3142857142857143</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>116.83333333333333</amc>
		<cc>
			<method name="private long getNextCntr(long cntr)">2</method>
			<method name="public void configure(org.apache.hadoop.mapred.JobConf job)">2</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void close()">5</method>
			<method name="public void reduce(Object key, java.util.Iterator values, org.apache.hadoop.mapred.OutputCollector output, org.apache.hadoop.mapred.Reporter reporter)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$sortByClause_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$hintArgs_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDTFParseUrlTuple</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>43</rfc>
		<lcom>12</lcom>
		<ca>0</ca>
		<ce>16</ce>
		<npm>5</npm>
		<lcom3>0.7582417582417582</lcom3>
		<loc>571</loc>
		<dam>0.07692307692307693</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.2857142857142857</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>68.75</amc>
		<cc>
			<method name="private String evaluate(java.net.URL url, int index)">5</method>
			<method name="public void process(Object[] o)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void close()">1</method>
			<method name="private String evaluateQuery(String query, String key)">5</method>
			<method name="public String toString()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] args)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.PartitionSpec$PredicateSpec</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>12</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>7</npm>
		<lcom3>0.611111111111111</lcom3>
		<loc>62</loc>
		<dam>0.6666666666666666</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5714285714285714</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>7.428571428571429</amc>
		<cc>
			<method name="public String getOperator()">1</method>
			<method name="public String getValue()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.PartitionSpec)">0</method>
			<method name="public void setValue(String value)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.PartitionSpec, String operator, String value)">0</method>
			<method name="public String toString()">2</method>
			<method name="public void setOperator(String operator)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.UDFArgumentException</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>4</noc>
		<cbo>64</cbo>
		<rfc>20</rfc>
		<lcom>22</lcom>
		<ca>62</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>0.8571428571428571</lcom3>
		<loc>114</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.875</amc>
		<cc>
			<method name="public java.util.List getArgTypeList()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(Throwable cause)">0</method>
			<method name="public void _init_(String message, Class funcClass, java.util.List argTypeInfos, java.util.List methods)">0</method>
			<method name="public void _init_(String message)">0</method>
			<method name="public java.util.List getMethods()">1</method>
			<method name="private static String getMessage(String message, Class funcClass, java.util.List argTypeInfos, java.util.List methods)">5</method>
			<method name="public Class getFunctionClass()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceAndOperator_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableBinaryObjectInspector</name>
		<wmc>15</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>19</rfc>
		<lcom>105</lcom>
		<ca>4</ca>
		<ce>6</ce>
		<npm>14</npm>
		<lcom3>2.0</lcom3>
		<loc>141</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.55</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.4</amc>
		<cc>
			<method name="public org.apache.hadoop.io.BytesWritable getPrimitiveWritableObject(Object o)">2</method>
			<method name="void _init_()">0</method>
			<method name="public volatile Object copyObject(Object x0)">1</method>
			<method name="public volatile Object getPrimitiveWritableObject(Object x0)">1</method>
			<method name="public volatile Object set(Object x0, org.apache.hadoop.hive.serde2.lazy.ByteArrayRef x1)">1</method>
			<method name="public org.apache.hadoop.io.BytesWritable set(Object o, org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bb)">2</method>
			<method name="public org.apache.hadoop.io.BytesWritable create(org.apache.hadoop.io.BytesWritable bw)">2</method>
			<method name="public volatile Object set(Object x0, org.apache.hadoop.io.BytesWritable x1)">1</method>
			<method name="public org.apache.hadoop.io.BytesWritable copyObject(Object o)">2</method>
			<method name="public volatile Object create(org.apache.hadoop.io.BytesWritable x0)">1</method>
			<method name="public volatile Object create(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef x0)">1</method>
			<method name="public org.apache.hadoop.io.BytesWritable set(Object o, org.apache.hadoop.io.BytesWritable bw)">2</method>
			<method name="public org.apache.hadoop.io.BytesWritable create(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bb)">1</method>
			<method name="public volatile Object getPrimitiveJavaObject(Object x0)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.lazy.ByteArrayRef getPrimitiveJavaObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.HadoopShims$MiniDFSShim</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>5</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.hadoop.fs.FileSystem getFileSystem()">1</method>
			<method name="public abstract void shutdown()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.thrift.ThriftDeserializer</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>14</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>9</ce>
		<npm>5</npm>
		<lcom3>0.5</lcom3>
		<loc>60</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.8</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getObjectInspector()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void initialize(org.apache.hadoop.conf.Configuration job, java.util.Properties tbl)">1</method>
			<method name="public Object deserialize(org.apache.hadoop.io.Writable field)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.SerDeStats getSerDeStats()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDAFWrongArgLengthForTestCase$UDAFWrongArgLengthForTestCaseEvaluator</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>10</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>6</npm>
		<lcom3>0.5</lcom3>
		<loc>51</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.166666666666667</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public boolean merge()">1</method>
			<method name="public org.apache.hadoop.io.LongWritable terminatePartial()">1</method>
			<method name="public boolean iterate(Object o)">3</method>
			<method name="public void init()">1</method>
			<method name="public org.apache.hadoop.io.LongWritable terminate()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.history.HiveHistory$QueryInfo</name>
		<wmc>1</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>16</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCovarianceSample$GenericUDAFCovarianceSampleEvaluator</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>5</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>39</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.5</amc>
		<cc>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableShortObjectInspector</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>9</cbo>
		<rfc>11</rfc>
		<lcom>15</lcom>
		<ca>4</ca>
		<ce>5</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>45</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.5</amc>
		<cc>
			<method name="public short get(Object o)">1</method>
			<method name="public Object create(short value)">1</method>
			<method name="void _init_()">0</method>
			<method name="public Object set(Object o, short value)">1</method>
			<method name="public Object getPrimitiveJavaObject(Object o)">2</method>
			<method name="public Object copyObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$expressionList_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.CombineHiveRecordReader</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>34</rfc>
		<lcom>15</lcom>
		<ca>0</ca>
		<ce>15</ce>
		<npm>10</npm>
		<lcom3>2.0</lcom3>
		<loc>137</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2125</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.7</amc>
		<cc>
			<method name="public volatile Object createKey()">1</method>
			<method name="public org.apache.hadoop.io.Writable createValue()">1</method>
			<method name="public volatile boolean doNext(Object x0, Object x1)">1</method>
			<method name="public float getProgress()">1</method>
			<method name="public boolean doNext(org.apache.hadoop.io.WritableComparable key, org.apache.hadoop.io.Writable value)">1</method>
			<method name="public volatile Object createValue()">1</method>
			<method name="public long getPos()">1</method>
			<method name="public org.apache.hadoop.io.WritableComparable createKey()">1</method>
			<method name="public void doClose()">1</method>
			<method name="public void _init_(org.apache.hadoop.mapred.InputSplit split, org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.mapred.Reporter reporter, Integer partition)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFRegExpExtract</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>12</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>1</ce>
		<npm>3</npm>
		<lcom3>0.0</lcom3>
		<loc>60</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.333333333333332</amc>
		<cc>
			<method name="public String evaluate(String s, String regex, Integer extractIndex)">6</method>
			<method name="public void _init_()">0</method>
			<method name="public String evaluate(String s, String regex)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$BoolExprProcessor</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>11</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>12</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>58</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFLog10</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>8</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>37</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.666666666666666</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable a)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryMap</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>35</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>15</ce>
		<npm>4</npm>
		<lcom3>0.5163398692810458</lcom3>
		<loc>533</loc>
		<dam>0.058823529411764705</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.35555555555555557</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>50.6</amc>
		<cc>
			<method name="private org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryObject uncheckedGetValue(int index)">4</method>
			<method name="public Object getMapValueElement(Object key)">7</method>
			<method name="public int getMapSize()">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="public java.util.Map getMap()">8</method>
			<method name="private org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryPrimitive uncheckedGetKey(int index)">4</method>
			<method name="private void parse()">7</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.lazybinary.objectinspector.LazyBinaryMapObjectInspector oi)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
			<method name="protected void adjustArraySize(int newSize)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.FlatFileInputFormat</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>7</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>2</npm>
		<lcom3>1.5</lcom3>
		<loc>21</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4444444444444444</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.666666666666667</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit split, org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.mapred.Reporter reporter)">1</method>
			<method name="protected boolean isSplittable(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path filename)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceBitwiseXorExpression_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.GenMapRedWalker</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>12</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>5</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>53</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>25.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.lib.Dispatcher disp)">0</method>
			<method name="public void walk(org.apache.hadoop.hive.ql.lib.Node nd)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileMergeMapper</name>
		<wmc>11</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>30</cbo>
		<rfc>57</rfc>
		<lcom>19</lcom>
		<ca>1</ca>
		<ce>29</ce>
		<npm>7</npm>
		<lcom3>0.6882352941176471</lcom3>
		<loc>477</loc>
		<dam>0.058823529411764705</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.23636363636363636</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>40.81818181818182</amc>
		<cc>
			<method name="public volatile void map(Object x0, Object x1, org.apache.hadoop.mapred.OutputCollector x2, org.apache.hadoop.mapred.Reporter x3)">1</method>
			<method name="public void configure(org.apache.hadoop.mapred.JobConf job)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void checkPartitionsMatch(org.apache.hadoop.fs.Path inputPath)">1</method>
			<method name="public void close()">1</method>
			<method name="private void fixTmpPath(org.apache.hadoop.fs.Path inputPath)">1</method>
			<method name="public static void jobClose(String outputPath, boolean success, org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.hive.ql.session.SessionState$LogHelper console)">1</method>
			<method name="public void map(Object k, org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileValueBufferWrapper value, org.apache.hadoop.mapred.OutputCollector output, org.apache.hadoop.mapred.Reporter reporter)">1</method>
			<method name="public static org.apache.hadoop.fs.Path backupOutputPath(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path outpath, org.apache.hadoop.mapred.JobConf job)">1</method>
			<method name="private void updatePaths(org.apache.hadoop.fs.Path tmpPath, org.apache.hadoop.fs.Path taskTmpPath)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.JavaLongObjectInspector</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>9</rfc>
		<lcom>10</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>30</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public Object set(Object o, long value)">1</method>
			<method name="public Object getPrimitiveWritableObject(Object o)">2</method>
			<method name="public Object create(long value)">1</method>
			<method name="public long get(Object o)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.LimitDesc</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>6</npm>
		<lcom3>0.7333333333333333</lcom3>
		<loc>38</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.833333333333333</amc>
		<cc>
			<method name="public int getLimit()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setLeastRows(int leastRows)">1</method>
			<method name="public int getLeastRows()">1</method>
			<method name="public void _init_(int limit)">0</method>
			<method name="public void setLimit(int limit)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$subQuerySource_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEWAHBitmap$GenericUDAFEWAHBitmapEvaluator</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>20</cbo>
		<rfc>35</rfc>
		<lcom>39</lcom>
		<ca>1</ca>
		<ce>20</ce>
		<npm>8</npm>
		<lcom3>0.9333333333333333</lcom3>
		<loc>231</loc>
		<dam>0.8</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.2777777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>21.6</amc>
		<cc>
			<method name="public void iterate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object[] parameters)">1</method>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector init(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode m, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] parameters)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer getNewAggregationBuffer()">1</method>
			<method name="public Object terminatePartial(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void merge(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object partial)">1</method>
			<method name="public void reset(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="private void addBitmap(int newRow, org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEWAHBitmap$GenericUDAFEWAHBitmapEvaluator$BitmapAgg myagg)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$function_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils</name>
		<wmc>30</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>92</cbo>
		<rfc>87</rfc>
		<lcom>331</lcom>
		<ca>71</ca>
		<ce>21</ce>
		<npm>27</npm>
		<lcom3>0.9553752535496958</lcom3>
		<loc>1385</loc>
		<dam>0.0</dam>
		<moa>12</moa>
		<mfa>0.0</mfa>
		<cam>0.1810344827586207</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>44.6</amc>
		<cc>
			<method name="public static java.sql.Timestamp getTimestamp(Object o, org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector oi)">6</method>
			<method name="public static boolean isPrimitiveJavaClass(Class clazz)">2</method>
			<method name="public static String getTypeNameFromPrimitiveJava(Class clazz)">3</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils$PrimitiveTypeEntry getTypeEntryFromPrimitiveJavaClass(Class clazz)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils$PrimitiveTypeEntry getTypeEntryFromPrimitiveJava(Class clazz)">2</method>
			<method name="private void _init_()">0</method>
			<method name="public static boolean comparePrimitiveObjects(Object o1, org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector oi1, Object o2, org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector oi2)">12</method>
			<method name="public static org.apache.hadoop.io.BytesWritable getBinary(Object o, org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector oi)">3</method>
			<method name="public static int getInt(Object o, org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector oi)">4</method>
			<method name="public static String getString(Object o, org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector oi)">3</method>
			<method name="public static boolean isPrimitiveJava(Class clazz)">3</method>
			<method name="public static double convertPrimitiveToDouble(Object o, org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector oi)">3</method>
			<method name="public static String getTypeNameFromPrimitiveWritable(Class clazz)">2</method>
			<method name="public static boolean isPrimitiveWritableClass(Class clazz)">2</method>
			<method name="public static short getShort(Object o, org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector oi)">1</method>
			<method name="public static Class getJavaPrimitiveClassFromObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">3</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils$PrimitiveTypeEntry getTypeEntryFromPrimitiveJavaType(Class clazz)">1</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils$PrimitiveTypeEntry getTypeEntryFromPrimitiveCategory(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector$PrimitiveCategory category)">1</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils$PrimitiveTypeEntry getTypeEntryFromPrimitiveWritableClass(Class clazz)">1</method>
			<method name="public static boolean comparePrimitiveObjectsWithConversion(Object o1, org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector oi1, Object o2, org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector oi2)">5</method>
			<method name="public static Class primitiveJavaTypeToClass(Class clazz)">2</method>
			<method name="public static boolean isPrimitiveJavaType(Class clazz)">2</method>
			<method name="public static double getDouble(Object o, org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector oi)">3</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils$PrimitiveTypeEntry getTypeEntryFromTypeName(String typeName)">1</method>
			<method name="public static float getFloat(Object o, org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector oi)">1</method>
			<method name="static void registerType(org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils$PrimitiveTypeEntry t)">6</method>
			<method name="public static long getLong(Object o, org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector oi)">4</method>
			<method name="public static boolean getBoolean(Object o, org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector oi)">12</method>
			<method name="public static byte getByte(Object o, org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector oi)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.ParseException</name>
		<wmc>2</wmc>
		<dit>3</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>10</rfc>
		<lcom>0</lcom>
		<ca>5</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>38</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.9545454545454546</mfa>
		<cam>0.75</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>17.0</amc>
		<cc>
			<method name="public String getMessage()">2</method>
			<method name="public void _init_(java.util.ArrayList errors)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Operator$State</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9166666666666666</lcom3>
		<loc>56</loc>
		<dam>0.25</dam>
		<moa>4</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>12.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.Operator$State valueOf(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.Operator$State[] values()">1</method>
			<method name="private void _init_(String, int)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils$TypeInfoParser</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>34</rfc>
		<lcom>9</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>2</npm>
		<lcom3>0.5416666666666666</lcom3>
		<loc>546</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.47619047619047616</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>76.42857142857143</amc>
		<cc>
			<method name="private org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils$TypeInfoParser$Token expect(String item, String alternative)">14</method>
			<method name="public void _init_(String typeInfoString)">0</method>
			<method name="private org.apache.hadoop.hive.serde2.typeinfo.TypeInfo parseType()">11</method>
			<method name="private org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils$TypeInfoParser$Token expect(String item)">1</method>
			<method name="private static boolean isTypeChar(char c)">4</method>
			<method name="private static java.util.ArrayList tokenize(String typeInfoString)">5</method>
			<method name="public java.util.ArrayList parseTypeInfos()">6</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryFactory$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>117</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>114.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFSecond</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>13</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>0.25</lcom3>
		<loc>86</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.333333333333332</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable t)">2</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.Text dateString)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.IndexUtils</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>28</cbo>
		<rfc>69</rfc>
		<lcom>23</lcom>
		<ca>6</ca>
		<ce>22</ce>
		<npm>3</npm>
		<lcom3>0.5555555555555556</lcom3>
		<loc>490</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.21428571428571427</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>47.8</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="private static boolean containsPartition(org.apache.hadoop.hive.ql.metadata.Hive hive, org.apache.hadoop.hive.ql.metadata.Partition part, java.util.Map indexes)">1</method>
			<method name="private static boolean isIndexTableFresh(org.apache.hadoop.hive.ql.metadata.Hive hive, java.util.List indexes, org.apache.hadoop.hive.ql.metadata.Table src)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private static boolean isIndexPartitionFresh(org.apache.hadoop.hive.ql.metadata.Hive hive, org.apache.hadoop.hive.metastore.api.Index index, org.apache.hadoop.hive.ql.metadata.Partition part)">1</method>
			<method name="private static java.util.List getIndexTables(org.apache.hadoop.hive.ql.metadata.Hive hive, org.apache.hadoop.hive.ql.metadata.Partition part, java.util.Map indexes)">1</method>
			<method name="private java.util.List getIndexTables(org.apache.hadoop.hive.ql.metadata.Hive hive, org.apache.hadoop.hive.ql.metadata.Table table, java.util.Map indexes)">1</method>
			<method name="public static java.util.Set checkPartitionsCoveredByIndex(org.apache.hadoop.hive.ql.exec.TableScanOperator tableScan, org.apache.hadoop.hive.ql.parse.ParseContext pctx, java.util.Map indexes)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.Task createRootTask(org.apache.hadoop.hive.conf.HiveConf builderConf, java.util.Set inputs, java.util.Set outputs, StringBuilder command, java.util.LinkedHashMap partSpec, String indexTableName, String dbName)">1</method>
			<method name="public static java.util.List getIndexes(org.apache.hadoop.hive.ql.metadata.Table baseTableMetaData, java.util.List matchIndexTypes)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.IOPrepareCache</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>13</rfc>
		<lcom>7</lcom>
		<ca>4</ca>
		<ce>0</ce>
		<npm>6</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>59</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.142857142857143</amc>
		<cc>
			<method name="public void clear()">2</method>
			<method name="public java.util.Map allocatePartitionDescMap()">2</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.io.IOPrepareCache get()">2</method>
			<method name="public java.util.Map getPartitionDescMap()">1</method>
			<method name="public void setPartitionDescMap(java.util.Map partitionDescMap)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.MapJoinProcessor$MapJoinFS</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>7</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>27</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ppr.ExprProcFactory$FieldExprProcessor</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>12</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>87</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>27.666666666666668</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.HiveOperation$PrivilegeAgreement</name>
		<wmc>13</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>14</rfc>
		<lcom>62</lcom>
		<ca>0</ca>
		<ce>1</ce>
		<npm>13</npm>
		<lcom3>0.9166666666666666</lcom3>
		<loc>80</loc>
		<dam>1.0</dam>
		<moa>8</moa>
		<mfa>0.0</mfa>
		<cam>0.6538461538461539</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.538461538461538</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.security.authorization.Privilege[] getOutputTableLevelRequiredPriv()">1</method>
			<method name="public org.apache.hadoop.hive.ql.security.authorization.Privilege[] getInputTableLevelRequiredPriv()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.HiveOperation$PrivilegeAgreement putColumnLevelRequiredPriv(org.apache.hadoop.hive.ql.security.authorization.Privilege[] inputColumnLevelPriv, org.apache.hadoop.hive.ql.security.authorization.Privilege[] outputColumnLevelPriv)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.HiveOperation$PrivilegeAgreement putDBLevelRequiredPriv(org.apache.hadoop.hive.ql.security.authorization.Privilege[] inputDBLevelRequiredPriv, org.apache.hadoop.hive.ql.security.authorization.Privilege[] outputDBLevelRequiredPriv)">1</method>
			<method name="public org.apache.hadoop.hive.ql.security.authorization.Privilege[] getInputColumnLevelRequiredPriv()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.HiveOperation$PrivilegeAgreement putUserLevelRequiredPriv(org.apache.hadoop.hive.ql.security.authorization.Privilege[] inputUserLevelRequiredPriv, org.apache.hadoop.hive.ql.security.authorization.Privilege[] outputUserLevelRequiredPriv)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.security.authorization.Privilege[] getOutputColumnLevelRequiredPriv()">1</method>
			<method name="public org.apache.hadoop.hive.ql.security.authorization.Privilege[] getOutputDBLevelRequiredPriv()">1</method>
			<method name="public org.apache.hadoop.hive.ql.security.authorization.Privilege[] getOutputUserLevelRequiredPriv()">1</method>
			<method name="public org.apache.hadoop.hive.ql.security.authorization.Privilege[] getInputUserLevelRequiredPriv()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.HiveOperation$PrivilegeAgreement putTableLevelRequiredPriv(org.apache.hadoop.hive.ql.security.authorization.Privilege[] inputTableLevelRequiredPriv, org.apache.hadoop.hive.ql.security.authorization.Privilege[] outputTableLevelRequiredPriv)">1</method>
			<method name="public org.apache.hadoop.hive.ql.security.authorization.Privilege[] getInputDBLevelRequiredPriv()">1</method>
		</cc>
	</class>
	<class>
		<name>org.json.Test</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>107</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>12</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>1816</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>907.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public static void main(String[] arg0)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.JobTrackerURLResolver</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>13</rfc>
		<lcom>1</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>46</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>22.0</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public static String getURL(org.apache.hadoop.mapred.JobConf conf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TSaslTransport$NegotiationStatus</name>
		<wmc>6</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>14</rfc>
		<lcom>9</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>4</npm>
		<lcom3>0.9</lcom3>
		<loc>128</loc>
		<dam>0.375</dam>
		<moa>6</moa>
		<mfa>0.7647058823529411</mfa>
		<cam>0.35</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>19.0</amc>
		<cc>
			<method name="public static org.apache.thrift.transport.TSaslTransport$NegotiationStatus[] values()">1</method>
			<method name="public static org.apache.thrift.transport.TSaslTransport$NegotiationStatus byValue(byte val)">1</method>
			<method name="public byte getValue()">1</method>
			<method name="public static org.apache.thrift.transport.TSaslTransport$NegotiationStatus valueOf(String name)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int, byte val)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPEqualOrLessThan$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>56</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>54.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter$TimestampConverter</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>36</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector inputOI, org.apache.hadoop.hive.serde2.objectinspector.primitive.SettableTimestampObjectInspector outputOI)">0</method>
			<method name="public Object convert(Object input)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.binarysortable.InputByteBuffer</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>16</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>9</npm>
		<lcom3>0.45833333333333337</lcom3>
		<loc>119</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3611111111111111</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.88888888888889</amc>
		<cc>
			<method name="public String dumpHex()">3</method>
			<method name="public final int tell()">1</method>
			<method name="public void reset(byte[] data, int start, int end)">1</method>
			<method name="public final byte read()">1</method>
			<method name="public final byte read(boolean invert)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public final byte[] getData()">1</method>
			<method name="public final int getEnd()">1</method>
			<method name="public final void seek(int position)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.metrics.Metrics$1</name>
		<wmc>3</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>4</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>13</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.8461538461538461</mfa>
		<cam>1.0</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>3.3333333333333335</amc>
		<cc>
			<method name="protected volatile Object initialValue()">1</method>
			<method name="void _init_()">0</method>
			<method name="protected synchronized java.util.HashMap initialValue()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileValueBufferWrapper</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>8</rfc>
		<lcom>10</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>5</npm>
		<lcom3>0.75</lcom3>
		<loc>30</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.36</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.8</amc>
		<cc>
			<method name="public volatile int compareTo(Object x0)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void write(java.io.DataOutput out)">1</method>
			<method name="public int compareTo(org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileValueBufferWrapper o)">1</method>
			<method name="public void readFields(java.io.DataInput in)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.CollectDesc</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>22</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void setBufferSize(Integer bufferSize)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(Integer bufferSize)">0</method>
			<method name="public Integer getBufferSize()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.lineage.OpProcFactory$ReduceSinkLineage</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>19</cbo>
		<rfc>25</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>19</ce>
		<npm>2</npm>
		<lcom3>0.75</lcom3>
		<loc>119</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>38.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.columnar.ColumnarStructBase$FieldInfo</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>14</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>3</npm>
		<lcom3>0.5238095238095238</lcom3>
		<loc>140</loc>
		<dam>0.0</dam>
		<moa>5</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>32.25</amc>
		<cc>
			<method name="public long getSerializedSize()">2</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.columnar.ColumnarStructBase, org.apache.hadoop.hive.serde2.lazy.LazyObjectBase lazyObject, boolean fieldSkipped, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.columnar.BytesRefWritable col)">2</method>
			<method name="protected Object uncheckedGetField()">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.StandardUnionObjectInspector$StandardUnion</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>13</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>7</npm>
		<lcom3>0.5</lcom3>
		<loc>48</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5238095238095238</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.571428571428571</amc>
		<cc>
			<method name="public void _init_(byte tag, Object object)">0</method>
			<method name="public void setObject(Object o)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public String toString()">1</method>
			<method name="public byte getTag()">1</method>
			<method name="public void setTag(byte tag)">1</method>
			<method name="public Object getObject()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.SkewJoinResolver</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>8</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>7</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>31</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext resolve(org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext pctx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.thrift.ThriftByteStreamTypedSerDe</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>13</rfc>
		<lcom>8</lcom>
		<ca>1</ca>
		<ce>12</ce>
		<npm>3</npm>
		<lcom3>0.6875</lcom3>
		<loc>76</loc>
		<dam>1.0</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.36666666666666664</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.4</amc>
		<cc>
			<method name="public void _init_(java.lang.reflect.Type objectType, org.apache.thrift.protocol.TProtocolFactory inFactory, org.apache.thrift.protocol.TProtocolFactory outFactory)">0</method>
			<method name="public void initialize(org.apache.hadoop.conf.Configuration job, java.util.Properties tbl)">1</method>
			<method name="public Object deserialize(org.apache.hadoop.io.Writable field)">1</method>
			<method name="private void init(org.apache.thrift.protocol.TProtocolFactory inFactory, org.apache.thrift.protocol.TProtocolFactory outFactory)">1</method>
			<method name="protected org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory$ObjectInspectorOptions getObjectInspectorOptions()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsPublisher$2</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>19</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public volatile Object run(java.sql.PreparedStatement x0)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsPublisher)">0</method>
			<method name="public Void run(java.sql.PreparedStatement stmt)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>100</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>99</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9444444444444443</lcom3>
		<loc>78</loc>
		<dam>0.16666666666666666</dam>
		<moa>6</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>17.0</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category[] values()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category valueOf(String name)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsPublisher$1</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>5</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>21</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.666666666666667</amc>
		<cc>
			<method name="public volatile Object run(java.sql.PreparedStatement x0)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.stats.jdbc.JDBCStatsPublisher)">0</method>
			<method name="public Void run(java.sql.PreparedStatement stmt)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$havingCondition_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.StageType</name>
		<wmc>6</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>9</rfc>
		<lcom>9</lcom>
		<ca>15</ca>
		<ce>2</ce>
		<npm>4</npm>
		<lcom3>0.7833333333333333</lcom3>
		<loc>176</loc>
		<dam>0.16666666666666666</dam>
		<moa>11</moa>
		<mfa>0.7647058823529411</mfa>
		<cam>0.4</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>26.333333333333332</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.StageType findByValue(int value)">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="public int getValue()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.StageType[] values()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.StageType valueOf(String name)">1</method>
			<method name="private void _init_(String, int, int value)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFLower</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>24</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.5</amc>
		<cc>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text s)">2</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.HiveDriverRunHookContext</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils</name>
		<wmc>27</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>100</cbo>
		<rfc>135</rfc>
		<lcom>347</lcom>
		<ca>57</ca>
		<ce>48</ce>
		<npm>25</npm>
		<lcom3>0.9615384615384616</lcom3>
		<loc>1978</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.11538461538461539</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>72.18518518518519</amc>
		<cc>
			<method name="public static boolean compareTypes(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector o1, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector o2)">20</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static boolean isConstantObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">1</method>
			<method name="public static java.lang.reflect.Field[] getDeclaredNonStaticFields(Class c)">4</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getWritableObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">3</method>
			<method name="public static Object copyToStandardObject(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils$ObjectInspectorCopyOption objectInspectorOption)">7</method>
			<method name="public static Object copyToStandardJavaObject(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">1</method>
			<method name="private void _init_()">0</method>
			<method name="public static int compare(Object o1, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi1, Object o2, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi2)">1</method>
			<method name="public static String getFieldTypes(org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector soi)">3</method>
			<method name="public static String getTypeNameFromJavaClass(java.lang.reflect.Type t)">1</method>
			<method name="public static boolean compareSupported(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">5</method>
			<method name="public static boolean supportsConstantObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getStandardObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils$ObjectInspectorCopyOption objectInspectorOption)">5</method>
			<method name="public static Object getWritableConstantValue(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">1</method>
			<method name="public static int compare(Object o1, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi1, Object o2, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi2, org.apache.hadoop.hive.serde2.objectinspector.MapEqualComparer mapEqualComparer)">28</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ConstantObjectInspector getConstantObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, Object value)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.StructField getStandardStructFieldRef(String fieldName, java.util.List fields)">3</method>
			<method name="public static Object copyToStandardObject(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">1</method>
			<method name="public static String getStandardStructTypeName(org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector soi)">3</method>
			<method name="public static String getStandardUnionTypeName(org.apache.hadoop.hive.serde2.objectinspector.UnionObjectInspector uoi)">3</method>
			<method name="public static String getObjectInspectorName(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">6</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getStandardObjectInspector(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">1</method>
			<method name="public static int hashCode(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objIns)">8</method>
			<method name="public static int compare(Object[] o1, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] oi1, Object[] o2, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] oi2)">9</method>
			<method name="public static void partialCopyToStandardObject(java.util.List result, Object row, int startCol, int numCols, org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector soi, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils$ObjectInspectorCopyOption objectInspectorOption)">2</method>
			<method name="public static String getFieldNames(org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector soi)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.QBParseInfo</name>
		<wmc>69</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>104</rfc>
		<lcom>2050</lcom>
		<ca>5</ca>
		<ce>7</ce>
		<npm>68</npm>
		<lcom3>0.9592760180995474</lcom3>
		<loc>721</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.19264705882352942</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.072463768115941</amc>
		<cc>
			<method name="public void setHints(org.apache.hadoop.hive.ql.parse.ASTNode hint)">1</method>
			<method name="public java.util.HashMap getDestToClusterBy()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public int getOuterQueryLimit()">1</method>
			<method name="public void setDistinctFuncExprsForClause(String clause, java.util.List ast)">1</method>
			<method name="public java.util.List getLateralViewsForAlias(String alias)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ASTNode getSelForClause(String clause)">1</method>
			<method name="public Integer getDestLimit(String dest)">1</method>
			<method name="public String getAlias()">1</method>
			<method name="public void setDistributeByExprForClause(String clause, org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="public boolean hasExprToColumnAlias(org.apache.hadoop.hive.ql.parse.ASTNode expr)">1</method>
			<method name="public void setJoinExpr(org.apache.hadoop.hive.ql.parse.ASTNode joinExpr)">1</method>
			<method name="public void setWhrExprForClause(String clause, org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="public java.util.HashMap getAggregationExprsForClause(String clause)">1</method>
			<method name="public void setOuterQueryLimit(int outerQueryLimit)">1</method>
			<method name="public java.util.HashMap getDestToOrderBy()">1</method>
			<method name="public void setOrderByExprForClause(String clause, org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="public boolean getIsSubQ()">1</method>
			<method name="public java.util.HashMap getDestToSortBy()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ASTNode getWhrForClause(String clause)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$tableSpec getTableSpec(String tName)">1</method>
			<method name="public void setIsAnalyzeCommand(boolean isAnalyzeCommand)">1</method>
			<method name="public java.util.Map getAliasToLateralViews()">1</method>
			<method name="public void setDestLimit(String dest, Integer limit)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ASTNode getSrcForAlias(String alias)">1</method>
			<method name="public void addTableSpec(String tName, org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$tableSpec tSpec)">1</method>
			<method name="public void setIsInsertToTable(boolean isInsertToTable)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ASTNode getClusterByForClause(String clause)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$tableSpec getTableSpec()">1</method>
			<method name="public boolean isInsertToTable()">1</method>
			<method name="public java.util.Set getClauseNamesForDest()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ASTNode getJoinExpr()">1</method>
			<method name="public java.util.List getDistinctFuncExprsForClause(String clause)">1</method>
			<method name="public void addLateralViewForAlias(String alias, org.apache.hadoop.hive.ql.parse.ASTNode lateralView)">2</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ASTNode getDistributeByForClause(String clause)">1</method>
			<method name="public boolean isAnalyzeCommand()">1</method>
			<method name="public java.util.HashMap getDestToDistributeBy()">1</method>
			<method name="public java.util.Set getClauseNames()">1</method>
			<method name="public java.util.HashMap getDestToWhereExpr()">1</method>
			<method name="public void setDestForClause(String clause, org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="public java.util.HashMap getDestToGroupBy()">1</method>
			<method name="public java.util.Map getAllExprToColumnAlias()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ASTNode getOrderByForClause(String clause)">1</method>
			<method name="public void setTabSample(String alias, org.apache.hadoop.hive.ql.parse.TableSample tableSample)">1</method>
			<method name="public void addInsertIntoTable(String table)">1</method>
			<method name="public java.util.HashMap getNameToSample()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ASTNode getGroupByForClause(String clause)">1</method>
			<method name="public void setAggregationExprsForClause(String clause, java.util.LinkedHashMap aggregationTrees)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ASTNode getHavingForClause(String clause)">1</method>
			<method name="public java.util.HashMap getDestToDistinctFuncExprs()">1</method>
			<method name="public boolean isInsertIntoTable(String table)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ASTNode getHints()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.TableSample getTabSample(String alias)">1</method>
			<method name="public java.util.LinkedHashMap getDestToAggregationExprs()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ASTNode getSortByForClause(String clause)">1</method>
			<method name="public void setSortByExprForClause(String clause, org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="public void setHavingExprForClause(String clause, org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="public String getExprToColumnAlias(org.apache.hadoop.hive.ql.parse.ASTNode expr)">1</method>
			<method name="public java.util.Map getDestToHaving()">1</method>
			<method name="public void addAggregationExprsForClause(String clause, java.util.LinkedHashMap aggregationTrees)">2</method>
			<method name="public void setGroupByExprForClause(String clause, org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="public void _init_(String alias, boolean isSubQ)">0</method>
			<method name="public void setClusterByExprForClause(String clause, org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="public java.util.HashMap getDestToLimit()">1</method>
			<method name="public void setExprToColumnAlias(org.apache.hadoop.hive.ql.parse.ASTNode expr, String alias)">1</method>
			<method name="public void setSelExprForClause(String clause, org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="public boolean isSelectStarQuery()">13</method>
			<method name="public void setSrcForAlias(String alias, org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ASTNode getDestForClause(String clause)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.GenMRProcContext$GenMRUnionCtx</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>13</rfc>
		<lcom>15</lcom>
		<ca>4</ca>
		<ce>3</ce>
		<npm>10</npm>
		<lcom3>0.75</lcom3>
		<loc>73</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.25</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.9</amc>
		<cc>
			<method name="public void setListTopOperators(java.util.List listTopOperators)">1</method>
			<method name="public java.util.List getTaskTmpDir()">1</method>
			<method name="public java.util.List getListTopOperators()">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.Task getUTask()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.List getTTDesc()">1</method>
			<method name="public void addListTopOperators(org.apache.hadoop.hive.ql.exec.Operator topOperator)">1</method>
			<method name="public void setUTask(org.apache.hadoop.hive.ql.exec.Task uTask)">1</method>
			<method name="public void addTaskTmpDir(String taskTmpDir)">1</method>
			<method name="public void addTTDesc(org.apache.hadoop.hive.ql.plan.TableDesc tt_desc)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.OneNullRowInputFormat</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>11</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>11</ce>
		<npm>4</npm>
		<lcom3>1.0</lcom3>
		<loc>42</loc>
		<dam>0.25</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.6</amc>
		<cc>
			<method name="public org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit arg0, org.apache.hadoop.mapred.JobConf arg1, org.apache.hadoop.mapred.Reporter arg2)">1</method>
			<method name="public void configure(org.apache.hadoop.mapred.JobConf job)">1</method>
			<method name="public org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf arg0, int arg1)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$dbLocation_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.InputFormatChecker</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract boolean validateInput(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.hive.conf.HiveConf, java.util.ArrayList)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>77</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>75.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Hadoop20Shims$1</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>1</npm>
		<lcom3>1.0</lcom3>
		<loc>14</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.5</amc>
		<cc>
			<method name="public org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit split, org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.mapred.Reporter reporter)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.shims.Hadoop20Shims)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableConstantFloatObjectInspector</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>16</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public volatile Object getWritableConstantValue()">1</method>
			<method name="void _init_(org.apache.hadoop.io.FloatWritable value)">0</method>
			<method name="public org.apache.hadoop.io.FloatWritable getWritableConstantValue()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Hadoop20Shims$3</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>21</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeString</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>15</rfc>
		<lcom>28</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>8</npm>
		<lcom3>2.0</lcom3>
		<loc>48</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3541666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public Object deserialize(Object reuse, org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public void serialize(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public byte getType()">1</method>
			<method name="public Class getRealType()">1</method>
			<method name="public String deserialize(org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int i)">0</method>
			<method name="public String toString()">1</method>
			<method name="public void _init_(int i)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Hadoop20Shims$2</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>1</npm>
		<lcom3>0.5</lcom3>
		<loc>19</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.5</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.shims.Hadoop20Shims, org.apache.hadoop.conf.Configuration x0, org.apache.hadoop.mapreduce.TaskAttemptID x1, org.apache.hadoop.util.Progressable)">0</method>
			<method name="public void progress()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.RenamePartitionDesc</name>
		<wmc>12</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>14</rfc>
		<lcom>40</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>12</npm>
		<lcom3>0.8787878787878788</lcom3>
		<loc>77</loc>
		<dam>0.16666666666666666</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3958333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.916666666666667</amc>
		<cc>
			<method name="public String getDbName()">1</method>
			<method name="public void _init_(String dbName, String tableName, java.util.Map oldPartSpec, java.util.Map newPartSpec)">0</method>
			<method name="public java.util.LinkedHashMap getOldPartSpec()">1</method>
			<method name="public String getTableName()">1</method>
			<method name="public void setLocation(String location)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setNewPartSpec(java.util.LinkedHashMap partSpec)">1</method>
			<method name="public java.util.LinkedHashMap getNewPartSpec()">1</method>
			<method name="public void setOldPartSpec(java.util.LinkedHashMap partSpec)">1</method>
			<method name="public void setTableName(String tableName)">1</method>
			<method name="public void setDbName(String dbName)">1</method>
			<method name="public String getLocation()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TMemoryBuffer</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>23</rfc>
		<lcom>3</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>10</npm>
		<lcom3>0.6111111111111112</lcom3>
		<loc>123</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.1</amc>
		<cc>
			<method name="public int length()">1</method>
			<method name="public boolean isOpen()">1</method>
			<method name="public void open()">1</method>
			<method name="public byte[] getArray()">1</method>
			<method name="public void write(byte[] buf, int off, int len)">1</method>
			<method name="public void _init_(int size)">0</method>
			<method name="public void close()">1</method>
			<method name="public String toString(String enc)">1</method>
			<method name="public String inspect()">3</method>
			<method name="public int read(byte[] buf, int off, int len)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.CheckResult</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>11</rfc>
		<lcom>12</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>9</npm>
		<lcom3>0.75</lcom3>
		<loc>64</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.7222222222222222</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.666666666666667</amc>
		<cc>
			<method name="public void setTablesNotInMs(java.util.List tablesNotInMs)">1</method>
			<method name="public void setTablesNotOnFs(java.util.List tablesNotOnFs)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.List getPartitionsNotOnFs()">1</method>
			<method name="public void setPartitionsNotOnFs(java.util.List partitionsNotOnFs)">1</method>
			<method name="public void setPartitionsNotInMs(java.util.List partitionsNotInMs)">1</method>
			<method name="public java.util.List getTablesNotOnFs()">1</method>
			<method name="public java.util.List getPartitionsNotInMs()">1</method>
			<method name="public java.util.List getTablesNotInMs()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFConcat</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>13</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>112</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>36.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient org.apache.hadoop.io.BytesWritable evaluate(org.apache.hadoop.io.BytesWritable[] bw)">4</method>
			<method name="public transient org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text[] args)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.HadoopShimsSecure$1</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>1</npm>
		<lcom3>1.0</lcom3>
		<loc>14</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.5</amc>
		<cc>
			<method name="public org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit split, org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.mapred.Reporter reporter)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.shims.HadoopShimsSecure)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.HiveHarFileSystem</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>14</rfc>
		<lcom>3</lcom>
		<ca>0</ca>
		<ce>5</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>128</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>41.666666666666664</amc>
		<cc>
			<method name="public org.apache.hadoop.fs.ContentSummary getContentSummary(org.apache.hadoop.fs.Path f)">1</method>
			<method name="public org.apache.hadoop.fs.BlockLocation[] getFileBlockLocations(org.apache.hadoop.fs.FileStatus file, long start, long len)">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.unionproc.UnionProcFactory$MapJoinUnion</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>10</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>39</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.session.SessionState</name>
		<wmc>55</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>53</cbo>
		<rfc>150</rfc>
		<lcom>1319</lcom>
		<ca>34</ca>
		<ce>23</ce>
		<npm>51</npm>
		<lcom3>0.9544753086419753</lcom3>
		<loc>1017</loc>
		<dam>0.7083333333333334</dam>
		<moa>8</moa>
		<mfa>0.0</mfa>
		<cam>0.10978835978835978</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>17.054545454545455</amc>
		<cc>
			<method name="public java.util.Map getHiveVariables()">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.session.SessionState$LogHelper getConsole()">2</method>
			<method name="private static String makeSessionId()">1</method>
			<method name="private String downloadResource(String value, boolean convertToUnix)">6</method>
			<method name="public java.util.Map getLocalMapRedErrors()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.conf.HiveConf conf)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.session.SessionState$ResourceType find_resource_type(String s)">2</method>
			<method name="public void setStackTraces(java.util.Map stackTraces)">1</method>
			<method name="public void setIsSilent(boolean isSilent)">2</method>
			<method name="public org.apache.hadoop.hive.ql.session.LineageState getLineageState()">1</method>
			<method name="public String add_resource(org.apache.hadoop.hive.ql.session.SessionState$ResourceType t, String value)">1</method>
			<method name="public java.util.List getLastMapRedStatsList()">1</method>
			<method name="public void setCreateTableGrants(org.apache.hadoop.hive.ql.session.CreateTableAutomaticGrant createTableGrants)">1</method>
			<method name="public java.io.File getTmpOutputFile()">1</method>
			<method name="public void setConf(org.apache.hadoop.hive.conf.HiveConf conf)">1</method>
			<method name="public void delete_resource(org.apache.hadoop.hive.ql.session.SessionState$ResourceType t)">3</method>
			<method name="public void setIsVerbose(boolean isVerbose)">1</method>
			<method name="public void setTmpOutputFile(java.io.File f)">1</method>
			<method name="public org.apache.hadoop.hive.ql.security.HiveAuthenticationProvider getAuthenticator()">1</method>
			<method name="public java.util.Set list_resource(org.apache.hadoop.hive.ql.session.SessionState$ResourceType t, java.util.List filter)">4</method>
			<method name="public void addLocalMapRedErrors(String id, java.util.List localMapRedErrors)">2</method>
			<method name="public String getCommandType()">2</method>
			<method name="public void setLastMapRedStatsList(java.util.List lastMapRedStatsList)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.Map getStackTraces()">1</method>
			<method name="public java.util.Map getOverriddenConfigurations()">2</method>
			<method name="public String add_resource(org.apache.hadoop.hive.ql.session.SessionState$ResourceType t, String value, boolean convertToUnix)">3</method>
			<method name="public boolean getIsSilent()">2</method>
			<method name="public static org.apache.hadoop.hive.ql.session.SessionState start(org.apache.hadoop.hive.ql.session.SessionState startSs)">4</method>
			<method name="public boolean getIsVerbose()">1</method>
			<method name="public static boolean registerJar(String newJar)">1</method>
			<method name="public void setOverriddenConfigurations(java.util.Map overriddenConfigurations)">1</method>
			<method name="public String getSessionId()">1</method>
			<method name="public org.apache.hadoop.hive.ql.session.CreateTableAutomaticGrant getCreateTableGrants()">1</method>
			<method name="public org.apache.hadoop.hive.ql.history.HiveHistory getHiveHistory()">1</method>
			<method name="public boolean delete_resource(org.apache.hadoop.hive.ql.session.SessionState$ResourceType t, String value)">4</method>
			<method name="public static org.apache.hadoop.hive.ql.session.SessionState get()">1</method>
			<method name="private java.util.Set getResourceMap(org.apache.hadoop.hive.ql.session.SessionState$ResourceType t)">2</method>
			<method name="public void setCmd(String cmdString)">1</method>
			<method name="public void setAuthorizer(org.apache.hadoop.hive.ql.security.authorization.HiveAuthorizationProvider authorizer)">1</method>
			<method name="public void add_builtin_resource(org.apache.hadoop.hive.ql.session.SessionState$ResourceType t, String value)">1</method>
			<method name="public String getCmd()">1</method>
			<method name="public static String getMatchingSchemaAsRegex()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.session.SessionState start(org.apache.hadoop.hive.conf.HiveConf conf)">1</method>
			<method name="public void setCommandType(org.apache.hadoop.hive.ql.plan.HiveOperation commandType)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.HiveOperation getHiveOperation()">1</method>
			<method name="public org.apache.hadoop.hive.conf.HiveConf getConf()">1</method>
			<method name="public void setHiveVariables(java.util.Map hiveVariables)">1</method>
			<method name="public org.apache.hadoop.hive.ql.security.authorization.HiveAuthorizationProvider getAuthorizer()">1</method>
			<method name="public void setLocalMapRedErrors(java.util.Map localMapRedErrors)">1</method>
			<method name="public String getQueryId()">1</method>
			<method name="public static boolean unregisterJar(String jarsToUnregister)">1</method>
			<method name="public void setAuthenticator(org.apache.hadoop.hive.ql.security.HiveAuthenticationProvider authenticator)">1</method>
			<method name="public static String validateFile(java.util.Set curFiles, String newFile)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.lineage.LineageCtx</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>6</rfc>
		<lcom>2</lcom>
		<ca>15</ca>
		<ce>4</ce>
		<npm>4</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>41</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.4166666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.75</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.optimizer.lineage.LineageCtx$Index getIndex()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext getParseCtx()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.parse.ParseContext pctx)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.hooks.LineageInfo$DependencyType getNewDependencyType(org.apache.hadoop.hive.ql.hooks.LineageInfo$DependencyType old_type, org.apache.hadoop.hive.ql.hooks.LineageInfo$DependencyType curr_type)">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter$TextConverter</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>22</cbo>
		<rfc>38</rfc>
		<lcom>2</lcom>
		<ca>2</ca>
		<ce>20</ce>
		<npm>3</npm>
		<lcom3>0.3333333333333333</lcom3>
		<loc>282</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>68.25</amc>
		<cc>
			<method name="public org.apache.hadoop.io.Text convert(Object input)">5</method>
			<method name="public volatile Object convert(Object x0)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector inputOI)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$NullExprProcessor</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>6</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>25</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPLessThan$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>56</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>54.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.history.HiveHistory$RecordTypes</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9629629629629629</lcom3>
		<loc>111</loc>
		<dam>0.1111111111111111</dam>
		<moa>9</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>24.5</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.history.HiveHistory$RecordTypes[] values()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.history.HiveHistory$RecordTypes valueOf(String name)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.JavaBinaryObjectInspector</name>
		<wmc>15</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>15</rfc>
		<lcom>105</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>14</npm>
		<lcom3>2.0</lcom3>
		<loc>140</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.55</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.333333333333334</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.lazy.ByteArrayRef set(Object o, org.apache.hadoop.io.BytesWritable bw)">2</method>
			<method name="public org.apache.hadoop.io.BytesWritable getPrimitiveWritableObject(Object o)">2</method>
			<method name="void _init_()">0</method>
			<method name="public volatile Object copyObject(Object x0)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.lazy.ByteArrayRef create(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bb)">1</method>
			<method name="public volatile Object getPrimitiveWritableObject(Object x0)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.lazy.ByteArrayRef set(Object o, org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bb)">1</method>
			<method name="public volatile Object set(Object x0, org.apache.hadoop.hive.serde2.lazy.ByteArrayRef x1)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.lazy.ByteArrayRef copyObject(Object o)">2</method>
			<method name="public volatile Object set(Object x0, org.apache.hadoop.io.BytesWritable x1)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.lazy.ByteArrayRef create(org.apache.hadoop.io.BytesWritable bw)">2</method>
			<method name="public volatile Object create(org.apache.hadoop.io.BytesWritable x0)">1</method>
			<method name="public volatile Object create(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef x0)">1</method>
			<method name="public volatile Object getPrimitiveJavaObject(Object x0)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.lazy.ByteArrayRef getPrimitiveJavaObject(Object o)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterIndexStatementSuffix_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.session.LineageState</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>18</rfc>
		<lcom>0</lcom>
		<ca>6</ca>
		<ce>9</ce>
		<npm>5</npm>
		<lcom3>0.5833333333333334</lcom3>
		<loc>76</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.36666666666666664</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.6</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.hooks.LineageInfo getLineageInfo()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setIndex(org.apache.hadoop.hive.ql.optimizer.lineage.LineageCtx$Index index)">1</method>
			<method name="public void setLineage(String dir, org.apache.hadoop.hive.ql.hooks.LineageInfo$DataContainer dc, java.util.List cols)">3</method>
			<method name="public void mapDirToFop(String dir, org.apache.hadoop.hive.ql.exec.FileSinkOperator fop)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory$ColumnPrunerJoinProc</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>6</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>8</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>20</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$createRoleStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.Table</name>
		<wmc>82</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>79</cbo>
		<rfc>200</rfc>
		<lcom>449</lcom>
		<ca>53</ca>
		<ce>27</ce>
		<npm>75</npm>
		<lcom3>0.8545953360768176</lcom3>
		<loc>1388</loc>
		<dam>0.8888888888888888</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.1111111111111111</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.817073170731707</amc>
		<cc>
			<method name="public int getLastAccessTime()">1</method>
			<method name="public int getNumBuckets()">1</method>
			<method name="public void setViewOriginalText(String viewOriginalText)">1</method>
			<method name="protected void replaceFiles(org.apache.hadoop.fs.Path srcf)">1</method>
			<method name="public org.apache.hadoop.hive.metastore.ProtectMode getProtectMode()">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void setRetention(int retention)">1</method>
			<method name="public java.util.List getAllCols()">1</method>
			<method name="static org.apache.hadoop.hive.metastore.api.Table getEmptyTable(String databaseName, String tableName)">1</method>
			<method name="public java.util.List getPartitionKeys()">1</method>
			<method name="public java.util.ArrayList getFields()">1</method>
			<method name="public java.util.List getSortCols()">1</method>
			<method name="public String getBucketingDimensionId()">4</method>
			<method name="public java.util.List getCols()">2</method>
			<method name="public java.util.List getPartCols()">2</method>
			<method name="public void setFields(java.util.List fields)">1</method>
			<method name="private org.apache.hadoop.hive.serde2.Deserializer getDeserializerFromMetaStore()">1</method>
			<method name="public void checkValidity()">1</method>
			<method name="public void setSerializationLib(String lib)">1</method>
			<method name="public String getProperty(String name)">1</method>
			<method name="public final java.util.Properties getSchema()">1</method>
			<method name="public void setTableName(String tableName)">1</method>
			<method name="public void setTTable(org.apache.hadoop.hive.metastore.api.Table tTable)">1</method>
			<method name="public void unsetDataLocation()">1</method>
			<method name="public void setTableType(org.apache.hadoop.hive.metastore.TableType tableType)">1</method>
			<method name="public void setViewExpandedText(String viewExpandedText)">1</method>
			<method name="public String getSerializationLib()">1</method>
			<method name="public java.util.Map getParameters()">1</method>
			<method name="public void setDataLocation(java.net.URI uri)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public boolean isOffline()">1</method>
			<method name="public final boolean isValidSpec(java.util.Map spec)">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.HiveStorageHandler getStorageHandler()">2</method>
			<method name="public void setPartCols(java.util.List partCols)">1</method>
			<method name="public void setDbName(String databaseName)">1</method>
			<method name="public java.util.List getBucketCols()">1</method>
			<method name="private boolean isField(String col)">2</method>
			<method name="public void setInputFormatClass(Class inputFormatClass)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.metastore.api.Table table)">0</method>
			<method name="public String getDbName()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.StructField getField(String fld)">1</method>
			<method name="public void setSortCols(java.util.List sortOrder)">1</method>
			<method name="public boolean isView()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.Deserializer getDeserializer()">2</method>
			<method name="public void setBucketCols(java.util.List bucketCols)">1</method>
			<method name="public final java.net.URI getDataLocation()">3</method>
			<method name="private org.apache.hadoop.hive.metastore.api.SerDeInfo getSerdeInfo()">1</method>
			<method name="public String getViewOriginalText()">1</method>
			<method name="public java.util.List getAllIndexes(short max)">1</method>
			<method name="public boolean isPartitioned()">3</method>
			<method name="public org.apache.hadoop.hive.metastore.TableType getTableType()">1</method>
			<method name="public final Class getOutputFormatClass()">5</method>
			<method name="public void setInputFormatClass(String name)">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Table copy()">1</method>
			<method name="public org.apache.hadoop.hive.metastore.api.Table getTTable()">1</method>
			<method name="public String getSerdeParam(String param)">1</method>
			<method name="public void setLastAccessTime(int lastAccessTime)">1</method>
			<method name="public void setOutputFormatClass(Class outputFormatClass)">1</method>
			<method name="public void _init_(String databaseName, String tableName)">0</method>
			<method name="public void setProperty(String name, String value)">1</method>
			<method name="public boolean canDrop()">5</method>
			<method name="public void setProtectMode(org.apache.hadoop.hive.metastore.ProtectMode protectMode)">1</method>
			<method name="public void setCreateTime(int createTime)">1</method>
			<method name="public final Class getInputFormatClass()">4</method>
			<method name="public final org.apache.hadoop.fs.Path getPath()">2</method>
			<method name="public String toString()">1</method>
			<method name="public java.util.LinkedHashMap createSpec(org.apache.hadoop.hive.metastore.api.Partition tp)">2</method>
			<method name="public boolean canWrite()">3</method>
			<method name="public void setOutputFormatClass(String name)">1</method>
			<method name="public String setSerdeParam(String param, String value)">1</method>
			<method name="public boolean isNonNative()">2</method>
			<method name="public String getViewExpandedText()">1</method>
			<method name="public String getCompleteName()">1</method>
			<method name="public void setNumBuckets(int nb)">1</method>
			<method name="public boolean isPartitionKey(String colName)">2</method>
			<method name="protected void copyFiles(org.apache.hadoop.fs.Path srcf)">1</method>
			<method name="public int getRetention()">1</method>
			<method name="public boolean isIndexTable()">1</method>
			<method name="public void setOwner(String owner)">1</method>
			<method name="public String getOwner()">1</method>
			<method name="public void clearSerDeInfo()">1</method>
			<method name="public final String getTableName()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.OperatorFactory</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>36</rfc>
		<lcom>43</lcom>
		<ca>10</ca>
		<ce>3</ce>
		<npm>8</npm>
		<lcom3>0.1111111111111111</lcom3>
		<loc>468</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.35185185185185186</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>45.7</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.exec.Operator getAndMakeChild(java.io.Serializable conf, org.apache.hadoop.hive.ql.exec.RowSchema rwsch, java.util.List oplist)">1</method>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.Operator get(Class opClass, org.apache.hadoop.hive.ql.exec.RowSchema rwsch)">1</method>
			<method name="public static transient org.apache.hadoop.hive.ql.exec.Operator getAndMakeChild(java.io.Serializable conf, org.apache.hadoop.hive.ql.exec.RowSchema rwsch, org.apache.hadoop.hive.ql.exec.Operator[] oplist)">1</method>
			<method name="public static transient org.apache.hadoop.hive.ql.exec.Operator getAndMakeChild(java.io.Serializable conf, org.apache.hadoop.hive.ql.exec.Operator[] oplist)">5</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static transient org.apache.hadoop.hive.ql.exec.Operator get(java.io.Serializable conf, org.apache.hadoop.hive.ql.exec.Operator[] oplist)">5</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.Operator getAndMakeChild(java.io.Serializable conf, java.util.List oplist)">5</method>
			<method name="public static transient org.apache.hadoop.hive.ql.exec.Operator get(java.io.Serializable conf, org.apache.hadoop.hive.ql.exec.RowSchema rwsch, org.apache.hadoop.hive.ql.exec.Operator[] oplist)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.Operator get(Class opClass)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tableRowFormat_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TJSONProtocol$JSONPairContext</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>9</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>0</npm>
		<lcom3>0.22222222222222218</lcom3>
		<loc>80</loc>
		<dam>0.6666666666666666</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.25</amc>
		<cc>
			<method name="protected boolean escapeNum()">1</method>
			<method name="protected void write()">1</method>
			<method name="protected void read()">1</method>
			<method name="protected void _init_(org.apache.thrift.protocol.TJSONProtocol)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.SkewJoinHandler</name>
		<wmc>13</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>24</cbo>
		<rfc>72</rfc>
		<lcom>26</lcom>
		<ca>1</ca>
		<ce>23</ce>
		<npm>6</npm>
		<lcom3>0.7824074074074074</lcom3>
		<loc>786</loc>
		<dam>0.7222222222222222</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.2222222222222222</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>58.07692307692308</amc>
		<cc>
			<method name="public void close(boolean abort)">1</method>
			<method name="public void updateSkewJoinJobCounter(int tag)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.CommonJoinOperator joinOp)">0</method>
			<method name="public void handleSkew(int tag)">1</method>
			<method name="void endGroup()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void setSkewJoinJobCounter(org.apache.hadoop.io.LongWritable skewjoinFollowupJobs)">1</method>
			<method name="private void commitOutputPathToFinalPath(String specPath, boolean ignoreNonExisting)">1</method>
			<method name="private void delete(org.apache.hadoop.fs.Path operatorOutputPath, org.apache.hadoop.fs.FileSystem fs)">1</method>
			<method name="public void initiliaze(org.apache.hadoop.conf.Configuration hconf)">6</method>
			<method name="private org.apache.hadoop.fs.Path getOperatorOutputPath(String specPath)">1</method>
			<method name="private void commit()">1</method>
			<method name="private org.apache.hadoop.fs.Path getOperatorFinalPath(String specPath)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.lineage.ExprProcCtx</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>3</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>20</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.exec.Operator getInputOperator()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.optimizer.lineage.LineageCtx lctx, org.apache.hadoop.hive.ql.exec.Operator inpOp)">0</method>
			<method name="public org.apache.hadoop.hive.ql.optimizer.lineage.LineageCtx getLineageCtx()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFCoalesce</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>15</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>6</ce>
		<npm>4</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>131</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>31.25</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lockmgr.HiveLock</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>1</noc>
		<cbo>7</cbo>
		<rfc>4</rfc>
		<lcom>3</lcom>
		<ca>5</ca>
		<ce>2</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>6</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>1.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public abstract org.apache.hadoop.hive.ql.lockmgr.HiveLockMode getHiveLockMode()">1</method>
			<method name="public abstract org.apache.hadoop.hive.ql.lockmgr.HiveLockObject getHiveLockObject()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.Hook</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>6</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.HashTableDummyOperator</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>18</rfc>
		<lcom>15</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>5</npm>
		<lcom3>1.2</lcom3>
		<loc>50</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.166666666666667</amc>
		<cc>
			<method name="public void closeOp(boolean abort)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void processOp(Object row, int tag)">1</method>
			<method name="public String getName()">1</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$dbPropertiesList_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.xml.UDFXPathFloat</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>18</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.5</amc>
		<cc>
			<method name="public float evaluate(String xml, String path)">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$caseExpression_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.HadoopJobExecHelper$1</name>
		<wmc>2</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>7</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.9846153846153847</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.5</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public void run()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.MapJoinProcessor</name>
		<wmc>20</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>55</cbo>
		<rfc>187</rfc>
		<lcom>172</lcom>
		<ca>6</ca>
		<ce>52</ce>
		<npm>11</npm>
		<lcom3>0.8421052631578947</lcom3>
		<loc>1702</loc>
		<dam>0.6666666666666666</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.14661654135338345</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>83.95</amc>
		<cc>
			<method name="public static void checkMapJoin(int mapJoinPos, org.apache.hadoop.hive.ql.plan.JoinCondDesc[] condns)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext transform(org.apache.hadoop.hive.ql.parse.ParseContext pactx)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator putOpInsertMap(org.apache.hadoop.hive.ql.exec.Operator op, org.apache.hadoop.hive.ql.parse.RowResolver rr)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getCurrentMapJoin()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getMapJoinFS()">1</method>
			<method name="private static void addRejectMapJoinToCtx(org.apache.hadoop.hive.ql.optimizer.MapJoinProcessor$MapJoinWalkerCtx ctx, org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator mapjoin)">6</method>
			<method name="static void access$100(org.apache.hadoop.hive.ql.optimizer.MapJoinProcessor$MapJoinWalkerCtx x0, org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator x1)">1</method>
			<method name="private static String genMapJoinLocalWork(org.apache.hadoop.hive.ql.plan.MapredWork newWork, org.apache.hadoop.hive.ql.exec.MapJoinOperator mapJoinOp, int bigTablePos)">1</method>
			<method name="private static void addNoReducerMapJoinToCtx(org.apache.hadoop.hive.ql.optimizer.MapJoinProcessor$MapJoinWalkerCtx ctx, org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator mapJoin)">5</method>
			<method name="public org.apache.hadoop.hive.ql.exec.MapJoinOperator generateMapJoinOperator(org.apache.hadoop.hive.ql.parse.ParseContext pctx, org.apache.hadoop.hive.ql.exec.JoinOperator op, org.apache.hadoop.hive.ql.parse.QBJoinTree joinTree, int mapJoinPos)">1</method>
			<method name="public static java.util.HashSet getBigTableCandidates(org.apache.hadoop.hive.ql.plan.JoinCondDesc[] condns)">12</method>
			<method name="private void genSelectPlan(org.apache.hadoop.hive.ql.parse.ParseContext pctx, org.apache.hadoop.hive.ql.exec.MapJoinOperator input)">1</method>
			<method name="public static String genMapJoinOpAndLocalWork(org.apache.hadoop.hive.ql.plan.MapredWork newWork, org.apache.hadoop.hive.ql.exec.JoinOperator op, int mapJoinPos)">1</method>
			<method name="static void access$000(org.apache.hadoop.hive.ql.optimizer.MapJoinProcessor$MapJoinWalkerCtx x0, org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator x1)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.MapJoinOperator convertMapJoin(java.util.LinkedHashMap opParseCtxMap, org.apache.hadoop.hive.ql.exec.JoinOperator op, org.apache.hadoop.hive.ql.parse.QBJoinTree joinTree, int mapJoinPos, boolean noCheckOuterJoin)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getDefault()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getMapJoinDefault()">1</method>
			<method name="private int mapSideJoin(org.apache.hadoop.hive.ql.exec.JoinOperator op, org.apache.hadoop.hive.ql.parse.QBJoinTree joinTree)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.JoinOperator$SkewkeyTableCounter</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>34</loc>
		<dam>0.5</dam>
		<moa>2</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.JoinOperator$SkewkeyTableCounter valueOf(String name)">1</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.JoinOperator$SkewkeyTableCounter[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFVariance$GenericUDAFVarianceEvaluator</name>
		<wmc>11</wmc>
		<dit>0</dit>
		<noc>3</noc>
		<cbo>25</cbo>
		<rfc>36</rfc>
		<lcom>41</lcom>
		<ca>4</ca>
		<ce>22</ce>
		<npm>10</npm>
		<lcom3>0.8833333333333334</lcom3>
		<loc>504</loc>
		<dam>0.9166666666666666</dam>
		<moa>9</moa>
		<mfa>0.0</mfa>
		<cam>0.2857142857142857</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>43.72727272727273</amc>
		<cc>
			<method name="public void iterate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object[] parameters)">1</method>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector init(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode m, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] parameters)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable getResult()">1</method>
			<method name="public void setResult(org.apache.hadoop.hive.serde2.io.DoubleWritable result)">1</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer getNewAggregationBuffer()">1</method>
			<method name="public void merge(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object partial)">1</method>
			<method name="public Object terminatePartial(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void reset(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.HookContext</name>
		<wmc>20</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>31</rfc>
		<lcom>138</lcom>
		<ca>2</ca>
		<ce>11</ce>
		<npm>20</npm>
		<lcom3>0.8538011695906432</lcom3>
		<loc>142</loc>
		<dam>1.0</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.17</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.65</amc>
		<cc>
			<method name="public java.util.Map getInputPathToContentSummary()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.QueryPlan queryPlan, org.apache.hadoop.hive.conf.HiveConf conf)">0</method>
			<method name="public void setCompleteTaskList(java.util.List completeTaskList)">1</method>
			<method name="public org.apache.hadoop.hive.conf.HiveConf getConf()">1</method>
			<method name="public void addCompleteTask(org.apache.hadoop.hive.ql.exec.TaskRunner completeTaskRunner)">1</method>
			<method name="public void setUgi(org.apache.hadoop.security.UserGroupInformation ugi)">1</method>
			<method name="public void setOutputs(java.util.Set outputs)">1</method>
			<method name="public void setHookType(org.apache.hadoop.hive.ql.hooks.HookContext$HookType hookType)">1</method>
			<method name="public void setLinfo(org.apache.hadoop.hive.ql.hooks.LineageInfo linfo)">1</method>
			<method name="public org.apache.hadoop.hive.ql.QueryPlan getQueryPlan()">1</method>
			<method name="public java.util.Set getOutputs()">1</method>
			<method name="public org.apache.hadoop.security.UserGroupInformation getUgi()">1</method>
			<method name="public java.util.List getCompleteTaskList()">1</method>
			<method name="public void setInputs(java.util.Set inputs)">1</method>
			<method name="public void setConf(org.apache.hadoop.hive.conf.HiveConf conf)">1</method>
			<method name="public org.apache.hadoop.hive.ql.hooks.LineageInfo getLinfo()">1</method>
			<method name="public org.apache.hadoop.hive.ql.hooks.HookContext$HookType getHookType()">1</method>
			<method name="public void setQueryPlan(org.apache.hadoop.hive.ql.QueryPlan queryPlan)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.QueryPlan queryPlan, org.apache.hadoop.hive.conf.HiveConf conf, java.util.Map inputPathToContentSummary)">0</method>
			<method name="public java.util.Set getInputs()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ExprNodeFieldDesc</name>
		<wmc>15</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>31</rfc>
		<lcom>0</lcom>
		<ca>8</ca>
		<ce>3</ce>
		<npm>15</npm>
		<lcom3>0.6428571428571429</lcom3>
		<loc>164</loc>
		<dam>0.25</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.25555555555555554</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.666666666666666</amc>
		<cc>
			<method name="public Boolean getIsList()">1</method>
			<method name="public void setIsList(Boolean isList)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ExprNodeDesc getDesc()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ExprNodeDesc clone()">1</method>
			<method name="public String getFieldName()">1</method>
			<method name="public void setDesc(org.apache.hadoop.hive.ql.plan.ExprNodeDesc desc)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.List getChildren()">1</method>
			<method name="public volatile Object clone()">1</method>
			<method name="public void setFieldName(String fieldName)">1</method>
			<method name="public boolean isSame(Object o)">6</method>
			<method name="public String getExprString()">1</method>
			<method name="public String toString()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo typeInfo, org.apache.hadoop.hive.ql.plan.ExprNodeDesc desc, String fieldName, Boolean isList)">0</method>
			<method name="public java.util.List getCols()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.ZooKeeperTokenStore$ZooKeeperWatcher</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>12</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>1</npm>
		<lcom3>0.0</lcom3>
		<loc>36</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.666666666666666</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.thrift.ZooKeeperTokenStore x0, org.apache.hadoop.hive.thrift.ZooKeeperTokenStore$1 x1)">0</method>
			<method name="public void process(org.apache.zookeeper.WatchedEvent event)">2</method>
			<method name="private void _init_(org.apache.hadoop.hive.thrift.ZooKeeperTokenStore)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryUtils$VLong</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>12</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.UnionOperator</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>26</cbo>
		<rfc>31</rfc>
		<lcom>11</lcom>
		<ca>15</ca>
		<ce>11</ce>
		<npm>4</npm>
		<lcom3>0.8571428571428571</lcom3>
		<loc>314</loc>
		<dam>0.14285714285714285</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>50.166666666666664</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public synchronized void processOp(Object row, int tag)">1</method>
			<method name="public String getName()">1</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.JobDebugger</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>51</rfc>
		<lcom>13</lcom>
		<ca>2</ca>
		<ce>11</ce>
		<npm>3</npm>
		<lcom3>0.6571428571428571</lcom3>
		<loc>409</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.2597402597402597</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>35.54545454545455</amc>
		<cc>
			<method name="static org.apache.hadoop.hive.ql.session.SessionState$LogHelper access$000(org.apache.hadoop.hive.ql.exec.JobDebugger x0)">1</method>
			<method name="static org.apache.hadoop.mapred.RunningJob access$100(org.apache.hadoop.hive.ql.exec.JobDebugger x0)">1</method>
			<method name="private void showJobFailDebugInfo()">1</method>
			<method name="static java.util.Map access$400(org.apache.hadoop.hive.ql.exec.JobDebugger x0)">1</method>
			<method name="public void run()">1</method>
			<method name="public void _init_(org.apache.hadoop.mapred.JobConf conf, org.apache.hadoop.mapred.RunningJob rj, org.apache.hadoop.hive.ql.session.SessionState$LogHelper console, java.util.Map stackTraces)">0</method>
			<method name="static String access$300(org.apache.hadoop.hive.ql.exec.JobDebugger x0, String x1, String x2)">1</method>
			<method name="static java.util.Set access$500(org.apache.hadoop.hive.ql.exec.JobDebugger x0)">1</method>
			<method name="static java.util.Map access$200(org.apache.hadoop.hive.ql.exec.JobDebugger x0)">1</method>
			<method name="public void _init_(org.apache.hadoop.mapred.JobConf conf, org.apache.hadoop.mapred.RunningJob rj, org.apache.hadoop.hive.ql.session.SessionState$LogHelper console)">0</method>
			<method name="private String getTaskAttemptLogUrl(String taskTrackerHttpAddress, String taskAttemptId)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeFieldType</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>6</rfc>
		<lcom>3</lcom>
		<ca>7</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>1.5</lcom3>
		<loc>18</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.666666666666667</amc>
		<cc>
			<method name="protected org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeBase getMyType()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int i)">0</method>
			<method name="public void _init_(int i)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPAnd</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>16</rfc>
		<lcom>4</lcom>
		<ca>2</ca>
		<ce>10</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>142</loc>
		<dam>0.25</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.6</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter$LongConverter</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>36</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector inputOI, org.apache.hadoop.hive.serde2.objectinspector.primitive.SettableLongObjectInspector outputOI)">0</method>
			<method name="public Object convert(Object input)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.IntObjectInspector</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>21</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>20</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract int get(Object)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ColumnarStructObjectInspector$MyField</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>13</rfc>
		<lcom>7</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>0.625</lcom3>
		<loc>60</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4642857142857143</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public int getFieldID()">1</method>
			<method name="public void _init_(int fieldID, String fieldName, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector fieldObjectInspector, String fieldComment)">0</method>
			<method name="public String getFieldComment()">1</method>
			<method name="public String getFieldName()">1</method>
			<method name="public void _init_(int fieldID, String fieldName, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector fieldObjectInspector)">0</method>
			<method name="public String toString()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getFieldObjectInspector()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixFileFormat_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ArchiveUtils$HarPathHelper</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>27</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>132</loc>
		<dam>0.6666666666666666</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>63.5</amc>
		<cc>
			<method name="public java.net.URI getHarUri(java.net.URI original)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.conf.HiveConf hconf, java.net.URI archive, java.net.URI originalBase)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyProcFactory$CheckFilterProc</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>16</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>11</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>58</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4444444444444444</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.333333333333332</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyProcFactory$1 x0)">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFToInteger</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>23</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>12</ce>
		<npm>10</npm>
		<lcom3>0.1111111111111111</lcom3>
		<loc>132</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.19</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.1</amc>
		<cc>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable i)">2</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.Text i)">2</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.FloatWritable i)">2</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.hive.serde2.io.ByteWritable i)">2</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.NullWritable i)">1</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.LongWritable i)">2</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable i)">2</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.hive.serde2.io.ShortWritable i)">2</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.BooleanWritable i)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TCompactProtocol$Factory</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>10</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.thrift.protocol.TProtocol getProtocol(org.apache.thrift.transport.TTransport trans)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ReflectionStructObjectInspector</name>
		<wmc>12</wmc>
		<dit>0</dit>
		<noc>2</noc>
		<cbo>11</cbo>
		<rfc>38</rfc>
		<lcom>46</lcom>
		<ca>3</ca>
		<ce>8</ce>
		<npm>9</npm>
		<lcom3>0.8181818181818182</lcom3>
		<loc>250</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.30303030303030304</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.583333333333332</amc>
		<cc>
			<method name="public boolean shouldIgnoreField(String name)">1</method>
			<method name="void init(Class objectClass, java.util.List structFieldObjectInspectors)">9</method>
			<method name="void _init_()">0</method>
			<method name="public Object create()">1</method>
			<method name="public Object getStructFieldData(Object data, org.apache.hadoop.hive.serde2.objectinspector.StructField fieldRef)">3</method>
			<method name="public Object setStructFieldData(Object struct, org.apache.hadoop.hive.serde2.objectinspector.StructField field, Object fieldValue)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public java.util.List getStructFieldsDataAsList(Object data)">3</method>
			<method name="public java.util.List getAllStructFieldRefs()">1</method>
			<method name="public String getTypeName()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.StructField getStructFieldRef(String fieldName)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.FilterOperator$Counter</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.888888888888889</lcom3>
		<loc>45</loc>
		<dam>0.3333333333333333</dam>
		<moa>3</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>9.5</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.FilterOperator$Counter valueOf(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.FilterOperator$Counter[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementChangeColPosition_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveLexer</name>
		<wmc>256</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>12</cbo>
		<rfc>272</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>11</ce>
		<npm>255</npm>
		<lcom3>1.0038351212228378</lcom3>
		<loc>10953</loc>
		<dam>0.002004008016032064</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5019607843137255</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>39.8359375</amc>
		<cc>
			<method name="public final void mKW_BEFORE()">1</method>
			<method name="public final void mKW_PARTITION()">1</method>
			<method name="public final void mKW_DIRECTORY()">1</method>
			<method name="public final void mKW_LATERAL()">1</method>
			<method name="public final void mKW_CROSS()">1</method>
			<method name="public final void mLSQUARE()">1</method>
			<method name="public final void mKW_DATA()">1</method>
			<method name="public final void mKW_INPUTFORMAT()">1</method>
			<method name="public final void mKW_COMMENT()">1</method>
			<method name="public final void mRCURLY()">1</method>
			<method name="public final void mKW_BOTH()">1</method>
			<method name="public final void mKW_DATETIME()">1</method>
			<method name="public final void mKW_MATERIALIZED()">1</method>
			<method name="public final void mKW_BETWEEN()">1</method>
			<method name="public final void mKW_UNIQUEJOIN()">1</method>
			<method name="public final void mKW_CAST()">1</method>
			<method name="public final void mKW_STATISTICS()">1</method>
			<method name="public final void mCOLON()">1</method>
			<method name="public final void mKW_SET()">1</method>
			<method name="public final void mDOT()">1</method>
			<method name="public final void mKW_OVERWRITE()">1</method>
			<method name="public final void mKW_KEYS()">1</method>
			<method name="public final void mKW_IS()">1</method>
			<method name="public final void mKW_ANALYZE()">1</method>
			<method name="public final void mKW_EXTERNAL()">1</method>
			<method name="public final void mKW_STORED()">1</method>
			<method name="public final void mRSQUARE()">1</method>
			<method name="public final void mKW_TRUE()">1</method>
			<method name="public final void mKW_DESCRIBE()">1</method>
			<method name="public final void mKW_BUCKET()">1</method>
			<method name="public final void mKW_REBUILD()">1</method>
			<method name="public final void mKW_HOLD_DDLTIME()">1</method>
			<method name="public final void mKW_SELECT()">1</method>
			<method name="public final void mKW_LEFT()">1</method>
			<method name="public final void mKW_READONLY()">1</method>
			<method name="public final void mKW_LOCATION()">1</method>
			<method name="public final void mKW_OUTPUTFORMAT()">1</method>
			<method name="public final void mKW_RECORDREADER()">1</method>
			<method name="public final void mKW_PERCENT()">1</method>
			<method name="public final void mPLUS()">1</method>
			<method name="public final void mMINUS()">1</method>
			<method name="public final void mLPAREN()">1</method>
			<method name="public final void mKW_TRANSFORM()">1</method>
			<method name="public final void mKW_LIMIT()">1</method>
			<method name="public final void mHexDigit()">1</method>
			<method name="public final void mKW_CASE()">1</method>
			<method name="public final void mRPAREN()">1</method>
			<method name="public final void mKW_ALL()">1</method>
			<method name="public final void mKW_CHANGE()">1</method>
			<method name="public final void mKW_COLLECTION()">1</method>
			<method name="public final void mKW_TO()">1</method>
			<method name="public final void mKW_TABLESAMPLE()">1</method>
			<method name="public final void mKW_UTCTIMESTAMP()">1</method>
			<method name="public final void mKW_PLUS()">1</method>
			<method name="public final void mKW_DISTRIBUTE()">1</method>
			<method name="public final void mKW_EXPLAIN()">1</method>
			<method name="public final void mKW_SORT()">1</method>
			<method name="public final void mKW_INPUTDRIVER()">1</method>
			<method name="public final void mKW_RCFILE()">1</method>
			<method name="public final void mKW_TRIGGER()">1</method>
			<method name="public final void mKW_IN()">1</method>
			<method name="public final void mKW_FUNCTIONS()">1</method>
			<method name="public final void mKW_THEN()">1</method>
			<method name="public final void mKW_UNION()">1</method>
			<method name="public final void mKW_TABLE()">1</method>
			<method name="public final void mKW_CLUSTER()">1</method>
			<method name="public final void mKW_FULL()">1</method>
			<method name="public final void mKW_OFFLINE()">1</method>
			<method name="public final void mKW_CASCADE()">1</method>
			<method name="public final void mGREATERTHANOREQUALTO()">1</method>
			<method name="public final void mKW_EXCLUSIVE()">1</method>
			<method name="public final void mKW_EXPORT()">1</method>
			<method name="public final void mKW_TEMPORARY()">1</method>
			<method name="public final void mDigit()">1</method>
			<method name="public final void mDIV()">1</method>
			<method name="public final void mKW_INTO()">1</method>
			<method name="public final void mKW_SEMI()">1</method>
			<method name="public final void mKW_PROCEDURE()">1</method>
			<method name="public final void mKW_GRANT()">1</method>
			<method name="public final void mKW_CLUSTERED()">1</method>
			<method name="public final void mMOD()">1</method>
			<method name="public final void mKW_FORMAT()">1</method>
			<method name="public final void mKW_LIKE()">1</method>
			<method name="public final void mCharSetName()">1</method>
			<method name="public void _init_(org.antlr.runtime.CharStream input)">0</method>
			<method name="public final void mDIVIDE()">1</method>
			<method name="public final void mKW_CONCATENATE()">1</method>
			<method name="public final void mKW_WHILE()">1</method>
			<method name="public final void mKW_UTC()">1</method>
			<method name="public final void mLCURLY()">1</method>
			<method name="public final void mKW_DEFERRED()">1</method>
			<method name="public final void mBITWISEXOR()">1</method>
			<method name="public final void mKW_DISABLE()">1</method>
			<method name="public final void mKW_SMALLINT()">1</method>
			<method name="public final void mKW_TEXTFILE()">1</method>
			<method name="public final void mKW_SCHEMA()">1</method>
			<method name="public final void mDOLLAR()">1</method>
			<method name="public final void mKW_AS()">1</method>
			<method name="public final void mTinyintLiteral()">1</method>
			<method name="public final void mKW_AFTER()">1</method>
			<method name="public final void mKW_STRING()">1</method>
			<method name="public final void mKW_DELETE()">1</method>
			<method name="public final void mLESSTHAN()">1</method>
			<method name="public final void mKW_CONTINUE()">1</method>
			<method name="public final void mKW_DATE()">1</method>
			<method name="public final void mKW_REPLACE()">1</method>
			<method name="public final void mKW_STREAMTABLE()">1</method>
			<method name="public final void mGREATERTHAN()">1</method>
			<method name="public final void mKW_MSCK()">1</method>
			<method name="public final void mKW_ASC()">1</method>
			<method name="public final void mKW_TIMESTAMP()">1</method>
			<method name="public final void mKW_BINARY()">1</method>
			<method name="public final void mKW_SORTED()">1</method>
			<method name="public final void mKW_RIGHT()">1</method>
			<method name="public final void mKW_HAVING()">1</method>
			<method name="public void mTokens()">1</method>
			<method name="public final void mKW_BOOLEAN()">1</method>
			<method name="public final void mKW_REGEXP()">1</method>
			<method name="public final void mKW_FUNCTION()">1</method>
			<method name="public final void mKW_REDUCE()">1</method>
			<method name="public final void mKW_USING()">1</method>
			<method name="public final void mKW_NULL()">1</method>
			<method name="public final void mKW_SEQUENCEFILE()">1</method>
			<method name="public final void mKW_BUCKETS()">1</method>
			<method name="public final void mKW_REPAIR()">1</method>
			<method name="public final void mKW_LOAD()">1</method>
			<method name="public final void mKW_RANGE()">1</method>
			<method name="public final void mKW_LOCKS()">1</method>
			<method name="public final void mKW_DOUBLE()">1</method>
			<method name="public final void mKW_ALTER()">1</method>
			<method name="public final void mKW_ORDER()">1</method>
			<method name="public final void mKW_VIEW()">1</method>
			<method name="public final void mCharSetLiteral()">1</method>
			<method name="public final void mKW_BIGINT()">1</method>
			<method name="public final void mKW_OUTPUTDRIVER()">1</method>
			<method name="public final void mKW_MINUS()">1</method>
			<method name="public final void mKW_OUT()">1</method>
			<method name="public final void mCOMMENT()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public final void mKW_COMPUTE()">1</method>
			<method name="public final void mKW_INPATH()">1</method>
			<method name="public final void mKW_MAPJOIN()">1</method>
			<method name="public final void mKW_FILEFORMAT()">1</method>
			<method name="public final void mKW_SSL()">1</method>
			<method name="public final void mKW_EXISTS()">1</method>
			<method name="public final void mKW_CURSOR()">1</method>
			<method name="public final void mKW_PURGE()">1</method>
			<method name="public final void mKW_INT()">1</method>
			<method name="public final void mKW_SCHEMAS()">1</method>
			<method name="public final void mKW_IMPORT()">1</method>
			<method name="public final void mKW_BY()">1</method>
			<method name="public final void mKW_COLUMNS()">1</method>
			<method name="public final void mKW_UNSIGNED()">1</method>
			<method name="public final void mKW_UNDO()">1</method>
			<method name="public final void mKW_TERMINATED()">1</method>
			<method name="public final void mRegexComponent()">1</method>
			<method name="public final void mKW_FLOAT()">1</method>
			<method name="public final void mKW_OUTER()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public final void mKW_WITH()">1</method>
			<method name="public final void mKW_DESC()">1</method>
			<method name="public final void mSEMICOLON()">1</method>
			<method name="public final void mKW_ROW()">1</method>
			<method name="public final void mKW_TABLES()">1</method>
			<method name="public final void mKW_FALSE()">1</method>
			<method name="public final void mKW_ITEMS()">1</method>
			<method name="public final void mKW_WHEN()">1</method>
			<method name="public final void mKW_DBPROPERTIES()">1</method>
			<method name="public final void mKW_JOIN()">1</method>
			<method name="public final void mExponent()">1</method>
			<method name="public final void mLetter()">1</method>
			<method name="public final void mKW_ENABLE()">1</method>
			<method name="public final void mKW_SHOW_DATABASE()">1</method>
			<method name="public final void mKW_SHARED()">1</method>
			<method name="public final void mStringLiteral()">1</method>
			<method name="public final void mKW_OF()">1</method>
			<method name="public final void mKW_UNIONTYPE()">1</method>
			<method name="public final void mKW_WHERE()">1</method>
			<method name="public final void mKW_ESCAPED()">1</method>
			<method name="public final void mKW_PARTITIONS()">1</method>
			<method name="public final void mKW_FETCH()">1</method>
			<method name="public final void mKW_ARRAY()">1</method>
			<method name="public final void mKW_NOT()">3</method>
			<method name="public final void mKW_DATABASE()">1</method>
			<method name="public final void mKW_AND()">1</method>
			<method name="public final void mBigintLiteral()">1</method>
			<method name="public final void mKW_ELSE()">1</method>
			<method name="public final void mKW_ELEM_TYPE()">1</method>
			<method name="public final void mKW_READS()">1</method>
			<method name="public final void mKW_UNARCHIVE()">1</method>
			<method name="public final void mKW_PARTITIONED()">1</method>
			<method name="public final void mKW_RLIKE()">1</method>
			<method name="public final void mKW_KEY_TYPE()">1</method>
			<method name="public final void mIdentifier()">1</method>
			<method name="public String getGrammarFileName()">1</method>
			<method name="public final void mKW_INDEX()">1</method>
			<method name="public final void mKW_LONG()">1</method>
			<method name="public final void mKW_RESTRICT()">1</method>
			<method name="public final void mKW_FORMATTED()">1</method>
			<method name="public final void mKW_READ()">1</method>
			<method name="public final void mQUESTION()">1</method>
			<method name="public final void mTILDE()">1</method>
			<method name="public final void mKW_TBLPROPERTIES()">1</method>
			<method name="public final void mKW_COLUMN()">1</method>
			<method name="public final void mKW_INSERT()">1</method>
			<method name="public final void mKW_REVOKE()">1</method>
			<method name="public final void mKW_DISTINCT()">1</method>
			<method name="public final void mKW_SERDEPROPERTIES()">1</method>
			<method name="public final void mKW_TOUCH()">1</method>
			<method name="public final void mNumber()">2</method>
			<method name="public final void mKW_DATABASES()">1</method>
			<method name="public final void mKW_PRESERVE()">1</method>
			<method name="public final void mKW_ADD()">1</method>
			<method name="public final void mKW_EXTENDED()">1</method>
			<method name="public final void mKW_USE()">1</method>
			<method name="public final void mKW_OR()">1</method>
			<method name="public final void mKW_LINES()">1</method>
			<method name="public final void mKW_ON()">1</method>
			<method name="public final void mKW_DROP()">1</method>
			<method name="public final void mKW_LOCK()">1</method>
			<method name="public final void mKW_RENAME()">1</method>
			<method name="public final void mKW_INTERSECT()">1</method>
			<method name="public final void mSmallintLiteral()">1</method>
			<method name="public final void mEQUAL()">3</method>
			<method name="public final void mKW_FIELDS()">1</method>
			<method name="public final void mKW_IF()">1</method>
			<method name="public final void mBITWISEOR()">1</method>
			<method name="public final void mKW_UNLOCK()">1</method>
			<method name="public final void mKW_DELIMITED()">1</method>
			<method name="public final void mKW_FROM()">1</method>
			<method name="public final void mSTAR()">1</method>
			<method name="public final void mLESSTHANOREQUALTO()">1</method>
			<method name="public final void mKW_GROUP()">1</method>
			<method name="public final void mNOTEQUAL()">3</method>
			<method name="public final void mKW_UPDATE()">1</method>
			<method name="public final void mEQUAL_NS()">1</method>
			<method name="public final void mKW_LOCAL()">1</method>
			<method name="public final void mKW_VALUE_TYPE()">1</method>
			<method name="public final void mKW_NO_DROP()">1</method>
			<method name="public final void mKW_SERDE()">1</method>
			<method name="public final void mKW_STRUCT()">1</method>
			<method name="public final void mKW_FIRST()">1</method>
			<method name="public final void mKW_IDXPROPERTIES()">1</method>
			<method name="public final void mKW_ARCHIVE()">1</method>
			<method name="public final void mWS()">1</method>
			<method name="public final void mAMPERSAND()">1</method>
			<method name="public final void mKW_CLUSTERSTATUS()">1</method>
			<method name="public final void mKW_CREATE()">1</method>
			<method name="public final void mKW_INDEXES()">1</method>
			<method name="public final void mKW_RECORDWRITER()">1</method>
			<method name="public final void mKW_MAP()">1</method>
			<method name="public final void mKW_TINYINT()">1</method>
			<method name="public final void mKW_END()">1</method>
			<method name="public final void mKW_OPTION()">1</method>
			<method name="public final void mKW_SHOW()">1</method>
			<method name="public final void mCOMMA()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.index.RewriteGBUsingIndex</name>
		<wmc>12</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>21</cbo>
		<rfc>92</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>20</ce>
		<npm>2</npm>
		<lcom3>0.7363636363636363</lcom3>
		<loc>810</loc>
		<dam>0.9</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.24675324675324675</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>65.66666666666667</amc>
		<cc>
			<method name="boolean shouldApplyOptimization()">1</method>
			<method name="private boolean checkIfRewriteCanBeApplied(org.apache.hadoop.hive.ql.exec.TableScanOperator topOp, org.apache.hadoop.hive.ql.metadata.Table baseTable, java.util.Map indexes)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="private boolean checkIfIndexBuiltOnAllTablePartitions(org.apache.hadoop.hive.ql.exec.TableScanOperator tableScan, java.util.Map indexes)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext transform(org.apache.hadoop.hive.ql.parse.ParseContext pctx)">1</method>
			<method name="private String getName()">1</method>
			<method name="boolean ifQueryHasMultipleTables()">3</method>
			<method name="boolean checkIfAllRewriteCriteriaIsMet(org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyCtx canApplyCtx)">9</method>
			<method name="private java.util.Map getIndexesForRewrite()">1</method>
			<method name="java.util.Map getIndexToKeysMap(java.util.List indexTables)">1</method>
			<method name="private void rewriteOriginalQuery()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceBitwiseXorOperator_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TSimpleJSONProtocol</name>
		<wmc>47</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>80</rfc>
		<lcom>841</lcom>
		<ca>4</ca>
		<ce>12</ce>
		<npm>44</npm>
		<lcom3>0.936141304347826</lcom3>
		<loc>544</loc>
		<dam>0.5625</dam>
		<moa>8</moa>
		<mfa>0.0</mfa>
		<cam>0.08184143222506395</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.23404255319149</amc>
		<cc>
			<method name="public void readFieldEnd()">1</method>
			<method name="public void writeSetEnd()">1</method>
			<method name="public void writeI16(short i16)">1</method>
			<method name="protected void pushWriteContext(org.apache.thrift.protocol.TSimpleJSONProtocol$Context c)">1</method>
			<method name="public void writeString(String str)">1</method>
			<method name="public void writeDouble(double dub)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public boolean readBool()">1</method>
			<method name="public void writeStructEnd()">1</method>
			<method name="public void writeStructBegin(org.apache.thrift.protocol.TStruct struct)">1</method>
			<method name="public void writeFieldBegin(org.apache.thrift.protocol.TField field)">1</method>
			<method name="public org.apache.thrift.protocol.TMap readMapBegin()">1</method>
			<method name="protected void popWriteContext()">1</method>
			<method name="public String readStringBody(int size)">1</method>
			<method name="public void readStructEnd()">1</method>
			<method name="public void writeBinary(java.nio.ByteBuffer bin)">1</method>
			<method name="public org.apache.thrift.protocol.TStruct readStructBegin()">1</method>
			<method name="public void writeFieldStop()">1</method>
			<method name="public void writeMapBegin(org.apache.thrift.protocol.TMap map)">1</method>
			<method name="public org.apache.thrift.protocol.TSet readSetBegin()">1</method>
			<method name="public org.apache.thrift.protocol.TMessage readMessageBegin()">1</method>
			<method name="public void writeListEnd()">1</method>
			<method name="public String readString()">1</method>
			<method name="public void _init_(org.apache.thrift.transport.TTransport trans)">0</method>
			<method name="public void readListEnd()">1</method>
			<method name="public void writeMessageBegin(org.apache.thrift.protocol.TMessage message)">1</method>
			<method name="public void writeMapEnd()">1</method>
			<method name="public long readI64()">1</method>
			<method name="public void readMessageEnd()">1</method>
			<method name="public void writeFieldEnd()">1</method>
			<method name="public void writeListBegin(org.apache.thrift.protocol.TList list)">1</method>
			<method name="public short readI16()">1</method>
			<method name="public org.apache.thrift.protocol.TField readFieldBegin()">1</method>
			<method name="public int readI32()">1</method>
			<method name="public void readMapEnd()">1</method>
			<method name="public void writeBool(boolean b)">1</method>
			<method name="public void writeI64(long i64)">1</method>
			<method name="public org.apache.thrift.protocol.TList readListBegin()">1</method>
			<method name="public double readDouble()">1</method>
			<method name="public void writeMessageEnd()">1</method>
			<method name="public void readSetEnd()">1</method>
			<method name="public void writeByte(byte b)">1</method>
			<method name="public void writeSetBegin(org.apache.thrift.protocol.TSet set)">1</method>
			<method name="public void writeI32(int i32)">1</method>
			<method name="public byte readByte()">1</method>
			<method name="public java.nio.ByteBuffer readBinary()">1</method>
			<method name="public void _writeStringData(String s)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$constant_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.JavaBooleanObjectInspector</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>8</rfc>
		<lcom>10</lcom>
		<ca>2</ca>
		<ce>5</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>36</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.2</amc>
		<cc>
			<method name="public boolean get(Object o)">1</method>
			<method name="void _init_()">0</method>
			<method name="public Object getPrimitiveWritableObject(Object o)">2</method>
			<method name="public Object set(Object o, boolean value)">2</method>
			<method name="public Object create(boolean value)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.persistence.DCLLItem</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>9</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>7</npm>
		<lcom3>0.2857142857142857</lcom3>
		<loc>80</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.75</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public void insertBefore(org.apache.hadoop.hive.ql.exec.persistence.DCLLItem v)">1</method>
			<method name="public void insertAfter(org.apache.hadoop.hive.ql.exec.persistence.DCLLItem v)">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.persistence.DCLLItem getPrev()">1</method>
			<method name="public void remove()">1</method>
			<method name="public void setNext(org.apache.hadoop.hive.ql.exec.persistence.DCLLItem itm)">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.persistence.DCLLItem getNext()">1</method>
			<method name="public void setPrev(org.apache.hadoop.hive.ql.exec.persistence.DCLLItem itm)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$restrictOrCascade_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.stats.StatsAggregator</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>4</rfc>
		<lcom>6</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract boolean closeConnection()">1</method>
			<method name="public abstract boolean cleanUp(String)">1</method>
			<method name="public abstract String aggregateStats(String, String)">1</method>
			<method name="public abstract boolean connect(org.apache.hadoop.conf.Configuration)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Hadoop23Shims</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>17</rfc>
		<lcom>6</lcom>
		<ca>1</ca>
		<ce>14</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>50</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.mapreduce.TaskAttemptContext newTaskAttemptContext(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.util.Progressable progressable)">1</method>
			<method name="public org.apache.hadoop.hive.shims.HadoopShims$JobTrackerState getJobTrackerState(org.apache.hadoop.mapred.ClusterStatus clusterStatus)">3</method>
			<method name="public org.apache.hadoop.mapreduce.JobContext newJobContext(org.apache.hadoop.mapreduce.Job job)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$dropRoleStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFToDouble</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>23</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>11</ce>
		<npm>10</npm>
		<lcom3>0.1111111111111111</lcom3>
		<loc>134</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.19</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.3</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.ShortWritable i)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable i)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.io.FloatWritable i)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.io.Text i)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.io.NullWritable i)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.io.LongWritable i)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.io.IntWritable i)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.ByteWritable i)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.io.BooleanWritable i)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.AutoProgressor</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>17</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>5</ce>
		<npm>1</npm>
		<lcom3>0.0714285714285714</lcom3>
		<loc>128</loc>
		<dam>0.14285714285714285</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>39.333333333333336</amc>
		<cc>
			<method name="void _init_(String logClassName, org.apache.hadoop.mapred.Reporter reporter, int notificationInterval)">0</method>
			<method name="public void go()">2</method>
			<method name="void _init_(String logClassName, org.apache.hadoop.mapred.Reporter reporter, int notificationInterval, int timeout)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.MapJoinFactory$ReduceSinkMapJoin</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>22</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>15</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>106</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>34.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEWAHBitmap</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>10</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>11</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>46</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] parameters)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileInputFormatShim</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>14</cbo>
		<rfc>18</rfc>
		<lcom>36</lcom>
		<ca>1</ca>
		<ce>13</ce>
		<npm>9</npm>
		<lcom3>2.0</lcom3>
		<loc>119</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3492063492063492</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.222222222222221</amc>
		<cc>
			<method name="public volatile org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf x0, int x1)">1</method>
			<method name="public org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.hive.shims.HadoopShims$InputSplitShim split, org.apache.hadoop.mapred.Reporter reporter, Class rrClass)">1</method>
			<method name="public volatile org.apache.hadoop.hive.shims.HadoopShims$InputSplitShim getInputSplitShim()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public volatile org.apache.hadoop.hive.shims.HadoopShims$InputSplitShim[] getSplits(org.apache.hadoop.mapred.JobConf x0, int x1)">1</method>
			<method name="public org.apache.hadoop.hive.shims.HadoopShimsSecure$InputSplitShim getInputSplitShim()">1</method>
			<method name="public org.apache.hadoop.hive.shims.HadoopShimsSecure$InputSplitShim[] getSplits(org.apache.hadoop.mapred.JobConf job, int numSplits)">1</method>
			<method name="public transient void createPool(org.apache.hadoop.mapred.JobConf conf, org.apache.hadoop.fs.PathFilter[] filters)">1</method>
			<method name="public org.apache.hadoop.fs.Path[] getInputPathsShim(org.apache.hadoop.mapred.JobConf conf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory$ColumnPrunerLateralViewJoinProc</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>16</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>8</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>64</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>31.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$structType_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.ParseDriver$ANTLRNoCaseStringStream</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>5</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>27</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.parse.ParseDriver, String input)">0</method>
			<method name="public int LA(int i)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypei32</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>15</rfc>
		<lcom>28</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>8</npm>
		<lcom3>2.0</lcom3>
		<loc>52</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.5</amc>
		<cc>
			<method name="public Object deserialize(Object reuse, org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public void serialize(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public Integer getRealTypeInstance()">1</method>
			<method name="public byte getType()">1</method>
			<method name="public Class getRealType()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int i)">0</method>
			<method name="public String toString()">1</method>
			<method name="public void _init_(int i)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.VirtualColumn</name>
		<wmc>14</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>21</rfc>
		<lcom>45</lcom>
		<ca>8</ca>
		<ce>6</ce>
		<npm>12</npm>
		<lcom3>0.8173076923076923</lcom3>
		<loc>168</loc>
		<dam>0.5</dam>
		<moa>5</moa>
		<mfa>0.0</mfa>
		<cam>0.28205128205128205</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.428571428571429</amc>
		<cc>
			<method name="public void _init_(String name, org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo typeInfo)">0</method>
			<method name="public boolean equals(Object o)">5</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void setIsHidden(boolean isHidden)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo getTypeInfo()">1</method>
			<method name="public static java.util.List getStatsRegistry(org.apache.hadoop.conf.Configuration conf)">2</method>
			<method name="public String getName()">1</method>
			<method name="void _init_(String name, org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo typeInfo, boolean isHidden)">0</method>
			<method name="public void setTypeInfo(org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo typeInfo)">1</method>
			<method name="public static java.util.List getRegistry(org.apache.hadoop.conf.Configuration conf)">2</method>
			<method name="public void setName(String name)">1</method>
			<method name="public boolean isHidden()">1</method>
			<method name="public boolean getIsHidden()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.FileSinkOperator</name>
		<wmc>22</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>58</cbo>
		<rfc>175</rfc>
		<lcom>103</lcom>
		<ca>10</ca>
		<ce>49</ce>
		<npm>8</npm>
		<lcom3>0.8526077097505669</lcom3>
		<loc>1731</loc>
		<dam>0.9047619047619048</dam>
		<moa>11</moa>
		<mfa>0.0</mfa>
		<cam>0.1292517006802721</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>75.77272727272727</amc>
		<cc>
			<method name="public void checkOutputSpecs(org.apache.hadoop.fs.FileSystem ignored, org.apache.hadoop.mapred.JobConf job)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.FileSinkOperator$FSPaths getDynOutPaths(java.util.List row)">1</method>
			<method name="public void closeOp(boolean abort)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="private void createBucketFiles(org.apache.hadoop.hive.ql.exec.FileSinkOperator$FSPaths fsp)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void jobClose(org.apache.hadoop.conf.Configuration hconf, boolean success, org.apache.hadoop.hive.ql.exec.JobCloseFeedBack feedBack)">1</method>
			<method name="private String lsDir()">2</method>
			<method name="public void augmentPlan()">1</method>
			<method name="public void processOp(Object row, int tag)">1</method>
			<method name="private String getDynPartDirectory(java.util.List row, java.util.List dpColNames, int numDynParts)">4</method>
			<method name="static int access$000(org.apache.hadoop.hive.ql.exec.FileSinkOperator x0)">1</method>
			<method name="private void publishStats()">7</method>
			<method name="public String getName()">1</method>
			<method name="private String getPartitionSpec(org.apache.hadoop.fs.Path path, int level)">3</method>
			<method name="private void dpSetup()">10</method>
			<method name="static boolean access$200(org.apache.hadoop.hive.ql.exec.FileSinkOperator x0)">1</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
			<method name="static boolean access$100(org.apache.hadoop.hive.ql.exec.FileSinkOperator x0)">1</method>
			<method name="protected void fatalErrorMessage(StringBuilder errMsg, long counterCode)">3</method>
			<method name="private boolean updateProgress()">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TFileTransport$tailPolicy</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.7999999999999999</lcom3>
		<loc>57</loc>
		<dam>0.2</dam>
		<moa>3</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>12.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.thrift.transport.TFileTransport$tailPolicy valueOf(String name)">1</method>
			<method name="private void _init_(String, int, int timeout, int retries)">0</method>
			<method name="public static org.apache.thrift.transport.TFileTransport$tailPolicy[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFHistogramNumeric$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>70</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>68.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.classification.InterfaceStability$Stable</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.HiveInterruptCallback</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void interrupt()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.bitmap.BitmapInnerQuery</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>10</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>66</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.5</amc>
		<cc>
			<method name="public String getAlias()">1</method>
			<method name="private void constructQueryStr()">1</method>
			<method name="public void _init_(String tableName, org.apache.hadoop.hive.ql.plan.ExprNodeDesc predicate, String alias)">0</method>
			<method name="public String toString()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$columnNameTypeList_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$uniqueJoinExpr_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TSaslServerTransport</name>
		<wmc>18</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>44</rfc>
		<lcom>127</lcom>
		<ca>2</ca>
		<ce>10</ce>
		<npm>12</npm>
		<lcom3>0.7941176470588235</lcom3>
		<loc>187</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2426470588235294</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.277777777777779</amc>
		<cc>
			<method name="public volatile boolean isOpen()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void addServerDefinition(String mechanism, String protocol, String serverName, java.util.Map props, javax.security.auth.callback.CallbackHandler cbh)">1</method>
			<method name="public volatile void flush()">1</method>
			<method name="public void _init_(org.apache.thrift.transport.TTransport transport)">0</method>
			<method name="private void _init_(java.util.Map serverDefinitionMap, org.apache.thrift.transport.TTransport transport)">0</method>
			<method name="public volatile javax.security.sasl.SaslServer getSaslServer()">1</method>
			<method name="static org.slf4j.Logger access$000()">1</method>
			<method name="protected void handleSaslStartMessage()">1</method>
			<method name="public void _init_(String mechanism, String protocol, String serverName, java.util.Map props, javax.security.auth.callback.CallbackHandler cbh, org.apache.thrift.transport.TTransport transport)">0</method>
			<method name="public volatile int read(byte[] x0, int x1, int x2)">1</method>
			<method name="public volatile javax.security.sasl.SaslClient getSaslClient()">1</method>
			<method name="public volatile org.apache.thrift.transport.TTransport getUnderlyingTransport()">1</method>
			<method name="protected org.apache.thrift.transport.TSaslTransport$SaslRole getRole()">1</method>
			<method name="public volatile void open()">1</method>
			<method name="public volatile void write(byte[] x0, int x1, int x2)">1</method>
			<method name="void _init_(java.util.Map x0, org.apache.thrift.transport.TTransport x1, org.apache.thrift.transport.TSaslServerTransport$1 x2)">0</method>
			<method name="public volatile void close()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tableSample_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFRepeat</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>8</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>75</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>36.0</amc>
		<cc>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text s, org.apache.hadoop.io.IntWritable n)">7</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.IndexUpdater</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>40</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>10</ce>
		<npm>3</npm>
		<lcom3>0.3666666666666667</lcom3>
		<loc>327</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.40816326530612246</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>45.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.LoadTableDesc loadTableWork, java.util.Set inputs, org.apache.hadoop.conf.Configuration conf)">0</method>
			<method name="private void doIndexUpdate(java.util.List tblIndexes)">1</method>
			<method name="public void _init_(java.util.List loadTableWork, java.util.Set inputs, org.apache.hadoop.conf.Configuration conf)">0</method>
			<method name="private void doIndexUpdate(java.util.List tblIndexes, java.util.Map partSpec)">1</method>
			<method name="private void doIndexUpdate(org.apache.hadoop.hive.metastore.api.Index index, java.util.Map partSpec)">1</method>
			<method name="public java.util.List generateUpdateTasks()">1</method>
			<method name="private boolean containsPartition(org.apache.hadoop.hive.metastore.api.Index index, java.util.Map partSpec)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeThrows</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterDatabaseSuffixProperties_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Task$FeedType</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>34</loc>
		<dam>0.5</dam>
		<moa>2</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.exec.Task$FeedType valueOf(String name)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.Task$FeedType[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>75</cbo>
		<rfc>7</rfc>
		<lcom>21</lcom>
		<ca>73</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>2.0</lcom3>
		<loc>7</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.7142857142857143</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Object copyObject(Object)">1</method>
			<method name="public abstract Object getPrimitiveWritableObject(Object)">1</method>
			<method name="public abstract Object getPrimitiveJavaObject(Object)">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector$PrimitiveCategory getPrimitiveCategory()">1</method>
			<method name="public abstract Class getPrimitiveWritableClass()">1</method>
			<method name="public abstract Class getJavaPrimitiveClass()">1</method>
			<method name="public abstract boolean preferWritable()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFBaseNumericUnaryOp</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>2</noc>
		<cbo>9</cbo>
		<rfc>14</rfc>
		<lcom>21</lcom>
		<ca>2</ca>
		<ce>7</ce>
		<npm>7</npm>
		<lcom3>1.0</lcom3>
		<loc>46</loc>
		<dam>1.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.2653061224489796</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.714285714285714</amc>
		<cc>
			<method name="public abstract org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.LongWritable)">1</method>
			<method name="public abstract org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.IntWritable)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable)">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.hive.serde2.io.ByteWritable)">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.hive.serde2.io.ShortWritable)">1</method>
			<method name="public abstract org.apache.hadoop.io.FloatWritable evaluate(org.apache.hadoop.io.FloatWritable)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.bitmap.BitmapQuery</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract String toString()">1</method>
			<method name="public abstract String getAlias()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.FilterDesc</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>12</rfc>
		<lcom>21</lcom>
		<ca>10</ca>
		<ce>2</ce>
		<npm>11</npm>
		<lcom3>0.82</lcom3>
		<loc>71</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.45454545454545453</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public boolean isSortedFilter()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.ExprNodeDesc predicate, boolean isSamplingPred)">0</method>
			<method name="public void setIsSamplingPred(boolean isSamplingPred)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setSortedFilter(boolean isSortedFilter)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.ExprNodeDesc predicate, boolean isSamplingPred, org.apache.hadoop.hive.ql.plan.FilterDesc$sampleDesc sampleDescr)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.FilterDesc$sampleDesc getSampleDescr()">1</method>
			<method name="public boolean getIsSamplingPred()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ExprNodeDesc getPredicate()">1</method>
			<method name="public void setSampleDescr(org.apache.hadoop.hive.ql.plan.FilterDesc$sampleDesc sampleDescr)">1</method>
			<method name="public void setPredicate(org.apache.hadoop.hive.ql.plan.ExprNodeDesc predicate)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedencePlusExpression_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ppr.OpProcFactory$DefaultPPR</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>7</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.ppd.OpProcFactory$ReduceSinkPPD</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>23</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>15</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>79</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>38.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.security.authorization.DefaultHiveAuthorizationProvider</name>
		<wmc>17</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>61</rfc>
		<lcom>116</lcom>
		<ca>1</ca>
		<ce>14</ce>
		<npm>6</npm>
		<lcom3>2.0</lcom3>
		<loc>904</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2727272727272727</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>52.1764705882353</amc>
		<cc>
			<method name="public void authorize(org.apache.hadoop.hive.ql.metadata.Table table, org.apache.hadoop.hive.ql.security.authorization.Privilege[] inputRequiredPriv, org.apache.hadoop.hive.ql.security.authorization.Privilege[] outputRequiredPriv)">1</method>
			<method name="private static void setBooleanArray(boolean[] check, boolean b)">2</method>
			<method name="private java.util.List getPrivilegeStringList(java.util.Collection privCollection)">5</method>
			<method name="private static void booleanArrayOr(boolean[] output, boolean[] input)">5</method>
			<method name="private boolean authorizeUserDBAndTable(org.apache.hadoop.hive.ql.metadata.Table table, org.apache.hadoop.hive.ql.security.authorization.Privilege[] inputRequiredPriv, org.apache.hadoop.hive.ql.security.authorization.Privilege[] outputRequiredPriv, boolean[] inputCheck, boolean[] outputCheck)">1</method>
			<method name="public void _init_()">0</method>
			<method name="private boolean authorizeUserDbAndPartition(org.apache.hadoop.hive.ql.metadata.Partition part, org.apache.hadoop.hive.ql.security.authorization.Privilege[] inputRequiredPriv, org.apache.hadoop.hive.ql.security.authorization.Privilege[] outputRequiredPriv, boolean[] inputCheck, boolean[] outputCheck)">1</method>
			<method name="protected boolean authorizeUserPriv(org.apache.hadoop.hive.ql.security.authorization.Privilege[] inputRequiredPriv, boolean[] inputCheck, org.apache.hadoop.hive.ql.security.authorization.Privilege[] outputRequiredPriv, boolean[] outputCheck)">1</method>
			<method name="private boolean authorizeUserAndDBPriv(org.apache.hadoop.hive.metastore.api.Database db, org.apache.hadoop.hive.ql.security.authorization.Privilege[] inputRequiredPriv, org.apache.hadoop.hive.ql.security.authorization.Privilege[] outputRequiredPriv, boolean[] inputCheck, boolean[] outputCheck)">1</method>
			<method name="public void authorize(org.apache.hadoop.hive.ql.metadata.Partition part, org.apache.hadoop.hive.ql.security.authorization.Privilege[] inputRequiredPriv, org.apache.hadoop.hive.ql.security.authorization.Privilege[] outputRequiredPriv)">1</method>
			<method name="public void authorize(org.apache.hadoop.hive.ql.security.authorization.Privilege[] inputRequiredPriv, org.apache.hadoop.hive.ql.security.authorization.Privilege[] outputRequiredPriv)">1</method>
			<method name="private boolean matchPrivs(org.apache.hadoop.hive.ql.security.authorization.Privilege[] inputPriv, org.apache.hadoop.hive.metastore.api.PrincipalPrivilegeSet privileges, boolean[] check)">30</method>
			<method name="private int firstFalseIndex(boolean[] inputCheck)">4</method>
			<method name="public void authorize(org.apache.hadoop.hive.metastore.api.Database db, org.apache.hadoop.hive.ql.security.authorization.Privilege[] inputRequiredPriv, org.apache.hadoop.hive.ql.security.authorization.Privilege[] outputRequiredPriv)">1</method>
			<method name="public void authorize(org.apache.hadoop.hive.ql.metadata.Table table, org.apache.hadoop.hive.ql.metadata.Partition part, java.util.List columns, org.apache.hadoop.hive.ql.security.authorization.Privilege[] inputRequiredPriv, org.apache.hadoop.hive.ql.security.authorization.Privilege[] outputRequiredPriv)">1</method>
			<method name="protected boolean authorizePrivileges(org.apache.hadoop.hive.metastore.api.PrincipalPrivilegeSet privileges, org.apache.hadoop.hive.ql.security.authorization.Privilege[] inputPriv, boolean[] inputCheck, org.apache.hadoop.hive.ql.security.authorization.Privilege[] outputPriv, boolean[] outputCheck)">1</method>
			<method name="private void checkAndThrowAuthorizationException(org.apache.hadoop.hive.ql.security.authorization.Privilege[] inputRequiredPriv, org.apache.hadoop.hive.ql.security.authorization.Privilege[] outputRequiredPriv, boolean[] inputCheck, boolean[] outputCheck, String dbName, String tableName, String partitionName, String columnName)">9</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.LineageInfo$BaseColumnInfo</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>6</rfc>
		<lcom>6</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>5</npm>
		<lcom3>0.9166666666666667</lcom3>
		<loc>25</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.4</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.metastore.api.FieldSchema getColumn()">1</method>
			<method name="public void setTabAlias(org.apache.hadoop.hive.ql.hooks.LineageInfo$TableAliasInfo tabAlias)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.hooks.LineageInfo$TableAliasInfo getTabAlias()">1</method>
			<method name="public void setColumn(org.apache.hadoop.hive.metastore.api.FieldSchema column)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.thrift.TBinarySortableProtocol$Factory</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>10</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.thrift.protocol.TProtocol getProtocol(org.apache.thrift.transport.TTransport trans)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeMap</name>
		<wmc>13</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>51</rfc>
		<lcom>70</lcom>
		<ca>2</ca>
		<ce>12</ce>
		<npm>12</npm>
		<lcom3>0.8958333333333334</lcom3>
		<loc>272</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.3055555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.615384615384617</amc>
		<cc>
			<method name="public void serialize(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public byte getType()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public volatile Object deserialize(Object x0, org.apache.thrift.protocol.TProtocol x1)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int i)">0</method>
			<method name="public java.util.Map deserialize(Object reuse, org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public void _init_(int i)">0</method>
			<method name="public org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeBase getKeyType()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeBase getValueType()">1</method>
			<method name="public Class getRealType()">1</method>
			<method name="public boolean isPrimitive()">1</method>
			<method name="public String toString()">1</method>
			<method name="public boolean isMap()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFResolver2</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>4</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFParameterInfo)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFBaseCompare</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>6</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>5</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>13</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public abstract org.apache.hadoop.io.BooleanWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable, org.apache.hadoop.hive.serde2.io.DoubleWritable)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc</name>
		<wmc>19</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>41</cbo>
		<rfc>71</rfc>
		<lcom>69</lcom>
		<ca>22</ca>
		<ce>21</ce>
		<npm>18</npm>
		<lcom3>0.753968253968254</lcom3>
		<loc>520</loc>
		<dam>0.8571428571428571</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.23015873015873015</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.0</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDF getGenericUDF()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, org.apache.hadoop.hive.ql.udf.generic.GenericUDF genericUDF, java.util.List children)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ExprNodeDesc clone()">2</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo typeInfo, org.apache.hadoop.hive.ql.udf.generic.GenericUDF genericUDF, java.util.List children)">0</method>
			<method name="public java.util.List getChildren()">1</method>
			<method name="public volatile Object clone()">1</method>
			<method name="public void setSortedExpr(boolean isSortedExpr)">1</method>
			<method name="public java.util.List getChildExprs()">1</method>
			<method name="public String getExprString()">2</method>
			<method name="public java.util.List getCols()">3</method>
			<method name="public void setChildExprs(java.util.List children)">1</method>
			<method name="public boolean isSortedExpr()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getWritableObjectInspector()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc newInstance(org.apache.hadoop.hive.ql.udf.generic.GenericUDF genericUDF, java.util.List children)">1</method>
			<method name="public boolean isSame(Object o)">11</method>
			<method name="public String toString()">3</method>
			<method name="public void setGenericUDF(org.apache.hadoop.hive.ql.udf.generic.GenericUDF genericUDF)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.conf.HiveConf</name>
		<wmc>45</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>149</cbo>
		<rfc>115</rfc>
		<lcom>850</lcom>
		<ca>140</ca>
		<ce>9</ce>
		<npm>39</npm>
		<lcom3>0.8787878787878788</lcom3>
		<loc>967</loc>
		<dam>0.6666666666666666</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.1797520661157025</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>20.288888888888888</amc>
		<cc>
			<method name="public static long getLongVar(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.hive.conf.HiveConf$ConfVars var, long defaultVal)">1</method>
			<method name="public void setFloatVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars var, float val)">1</method>
			<method name="public String getUser()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static String getVar(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.hive.conf.HiveConf$ConfVars var)">3</method>
			<method name="public void _init_(org.apache.hadoop.hive.conf.HiveConf other)">0</method>
			<method name="public void setIntVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars var, int val)">1</method>
			<method name="public static int getIntVar(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.hive.conf.HiveConf$ConfVars var)">3</method>
			<method name="public static void setLongVar(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.hive.conf.HiveConf$ConfVars var, long val)">3</method>
			<method name="public static float getFloatVar(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.hive.conf.HiveConf$ConfVars var, float defaultVal)">1</method>
			<method name="public int getIntVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars var)">1</method>
			<method name="public java.util.Properties getAllProperties()">1</method>
			<method name="private static synchronized java.net.URL getConfVarURL()">2</method>
			<method name="public String getJar()">1</method>
			<method name="public void _init_(org.apache.hadoop.conf.Configuration other, Class cls)">0</method>
			<method name="private static java.util.Properties getProperties(org.apache.hadoop.conf.Configuration conf)">2</method>
			<method name="public static void setBoolVar(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.hive.conf.HiveConf$ConfVars var, boolean val)">3</method>
			<method name="public static void setFloatVar(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.hive.conf.HiveConf$ConfVars var, float val)">3</method>
			<method name="public void logVars(java.io.PrintStream ps)">3</method>
			<method name="private void applySystemProperties()">2</method>
			<method name="public String getVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars var)">1</method>
			<method name="public static void setIntVar(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.hive.conf.HiveConf$ConfVars var, int val)">3</method>
			<method name="public void setBoolVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars var, boolean val)">1</method>
			<method name="public static String getColumnInternalName(int pos)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public String getAuxJars()">1</method>
			<method name="public java.util.Properties getChangedProperties()">2</method>
			<method name="public static boolean getBoolVar(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.hive.conf.HiveConf$ConfVars var, boolean defaultVal)">1</method>
			<method name="public static float getFloatVar(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.hive.conf.HiveConf$ConfVars var)">3</method>
			<method name="public static String getVar(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.hive.conf.HiveConf$ConfVars var, String defaultVal)">1</method>
			<method name="public static void setVar(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.hive.conf.HiveConf$ConfVars var, String val)">3</method>
			<method name="public void setAuxJars(String auxJars)">1</method>
			<method name="public boolean getBoolVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars var)">1</method>
			<method name="public String getHiveSitePath()">1</method>
			<method name="public static java.util.Map getConfSystemProperties()">4</method>
			<method name="public void setVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars var, String val)">1</method>
			<method name="private void initialize(Class cls)">5</method>
			<method name="public static long getLongVar(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.hive.conf.HiveConf$ConfVars var)">3</method>
			<method name="public static boolean getBoolVar(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.hive.conf.HiveConf$ConfVars var)">3</method>
			<method name="public static int getPositionFromInternalName(String internalName)">2</method>
			<method name="public float getFloatVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars var)">1</method>
			<method name="public void _init_(Class cls)">0</method>
			<method name="private static void applyDefaultNonNullConfVars(org.apache.hadoop.conf.Configuration conf)">4</method>
			<method name="public void setLongVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars var, long val)">1</method>
			<method name="public long getLongVar(org.apache.hadoop.hive.conf.HiveConf$ConfVars var)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceOrExpression_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryUtils</name>
		<wmc>13</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>34</cbo>
		<rfc>48</rfc>
		<lcom>72</lcom>
		<ca>11</ca>
		<ce>24</ce>
		<npm>11</npm>
		<lcom3>0.9166666666666666</lcom3>
		<loc>598</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.225</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>44.69230769230769</amc>
		<cc>
			<method name="public static void writeVLong(org.apache.hadoop.hive.serde2.ByteStream$Output byteStream, long l)">1</method>
			<method name="private void _init_()">0</method>
			<method name="public static void checkObjectByteInfo(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objectInspector, byte[] bytes, int offset, org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryUtils$RecordInfo recordInfo)">4</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getLazyBinaryObjectInspectorFromTypeInfo(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo typeInfo)">4</method>
			<method name="public static int writeVLongToByteArray(byte[] bytes, int offset, long l)">7</method>
			<method name="public static long byteArrayToLong(byte[] b, int offset)">2</method>
			<method name="public static void readVInt(byte[] bytes, int offset, org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryUtils$VInt vInt)">4</method>
			<method name="public static void writeVInt(org.apache.hadoop.hive.serde2.ByteStream$Output byteStream, int i)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static short byteArrayToShort(byte[] b, int offset)">1</method>
			<method name="public static void readVLong(byte[] bytes, int offset, org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryUtils$VLong vlong)">4</method>
			<method name="public static int writeVLongToByteArray(byte[] bytes, long l)">1</method>
			<method name="public static int byteArrayToInt(byte[] b, int offset)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.HiveStoragePredicateHandler$DecomposedPredicate</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>6</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.StandardStructObjectInspector</name>
		<wmc>14</wmc>
		<dit>0</dit>
		<noc>2</noc>
		<cbo>44</cbo>
		<rfc>39</rfc>
		<lcom>31</lcom>
		<ca>36</ca>
		<ce>9</ce>
		<npm>8</npm>
		<lcom3>0.6538461538461539</lcom3>
		<loc>345</loc>
		<dam>0.25</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.36923076923076925</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>23.357142857142858</amc>
		<cc>
			<method name="public Object getStructFieldData(Object data, org.apache.hadoop.hive.serde2.objectinspector.StructField fieldRef)">14</method>
			<method name="public Object create()">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="public final org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
			<method name="public java.util.List getStructFieldsDataAsList(Object data)">5</method>
			<method name="protected void _init_(java.util.List fields)">0</method>
			<method name="public java.util.List getAllStructFieldRefs()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.StructField getStructFieldRef(String fieldName)">1</method>
			<method name="protected void _init_(java.util.List structFieldNames, java.util.List structFieldObjectInspectors)">0</method>
			<method name="protected void init(java.util.List structFieldNames, java.util.List structFieldObjectInspectors, java.util.List structFieldComments)">8</method>
			<method name="protected void _init_(java.util.List structFieldNames, java.util.List structFieldObjectInspectors, java.util.List structFieldComments)">0</method>
			<method name="public Object setStructFieldData(Object struct, org.apache.hadoop.hive.serde2.objectinspector.StructField field, Object fieldValue)">1</method>
			<method name="public String getTypeName()">1</method>
			<method name="protected void init(java.util.List fields)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.errors.MapAggrMemErrorHeuristic</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>22</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>3</npm>
		<lcom3>0.75</lcom3>
		<loc>91</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>28.666666666666668</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.exec.errors.ErrorAndSolution getErrorAndSolution()">4</method>
			<method name="public void init(String query, org.apache.hadoop.mapred.JobConf conf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Utilities$SetDelegate</name>
		<wmc>4</wmc>
		<dit>3</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>13</rfc>
		<lcom>6</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>66</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.8235294117647058</mfa>
		<cam>0.625</cam>
		<ic>2</ic>
		<cbm>4</cbm>
		<amc>15.5</amc>
		<cc>
			<method name="protected java.beans.Expression instantiate(Object oldInstance, java.beans.Encoder out)">1</method>
			<method name="protected boolean mutatesTo(Object oldInstance, Object newInstance)">1</method>
			<method name="public void _init_()">0</method>
			<method name="protected void initialize(Class type, Object oldInstance, Object newInstance, java.beans.Encoder out)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFOPDivide</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>28</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable a, org.apache.hadoop.hive.serde2.io.DoubleWritable b)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryByte</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>13</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>1</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>53</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryByte copy)">0</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableByteObjectInspector oi)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableVoidObjectInspector</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>6</rfc>
		<lcom>6</lcom>
		<ca>5</ca>
		<ce>5</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>17</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.25</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public Object getPrimitiveJavaObject(Object o)">1</method>
			<method name="public Object copyObject(Object o)">1</method>
			<method name="public Object getWritableConstantValue()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ConditionalResolverCommonJoin$AliasFileSizePair</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>34</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4444444444444444</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.333333333333334</amc>
		<cc>
			<method name="public volatile int compareTo(Object x0)">1</method>
			<method name="public int compareTo(org.apache.hadoop.hive.ql.plan.ConditionalResolverCommonJoin$AliasFileSizePair o)">2</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.plan.ConditionalResolverCommonJoin, String alias, long size)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.server.TServlet$1</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>6</rfc>
		<lcom>17</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>6</npm>
		<lcom3>0.7777777777777777</lcom3>
		<loc>41</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.39285714285714285</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.428571428571429</amc>
		<cc>
			<method name="public volatile Object setValue(Object x0)">1</method>
			<method name="public volatile Object getValue()">1</method>
			<method name="public String getValue()">1</method>
			<method name="public volatile Object getKey()">1</method>
			<method name="public String setValue(String value)">1</method>
			<method name="public String getKey()">1</method>
			<method name="void _init_(org.apache.thrift.server.TServlet, String, String)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.HadoopShims$CombineFileInputFormatShim</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>5</rfc>
		<lcom>10</lcom>
		<ca>8</ca>
		<ce>6</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.JobConf, org.apache.hadoop.hive.shims.HadoopShims$InputSplitShim, org.apache.hadoop.mapred.Reporter, Class)">1</method>
			<method name="public abstract org.apache.hadoop.hive.shims.HadoopShims$InputSplitShim getInputSplitShim()">1</method>
			<method name="public transient abstract void createPool(org.apache.hadoop.mapred.JobConf, org.apache.hadoop.fs.PathFilter[])">1</method>
			<method name="public abstract org.apache.hadoop.fs.Path[] getInputPathsShim(org.apache.hadoop.mapred.JobConf)">1</method>
			<method name="public abstract org.apache.hadoop.hive.shims.HadoopShims$InputSplitShim[] getSplits(org.apache.hadoop.mapred.JobConf, int)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.MapOperator</name>
		<wmc>13</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>38</cbo>
		<rfc>118</rfc>
		<lcom>50</lcom>
		<ca>1</ca>
		<ce>37</ce>
		<npm>10</npm>
		<lcom3>0.7666666666666666</lcom3>
		<loc>1238</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.20512820512820512</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>93.07692307692308</amc>
		<cc>
			<method name="public void closeOp(boolean abort)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void processOp(Object row, int tag)">1</method>
			<method name="public void cleanUpInputFileChangedOp()">1</method>
			<method name="public void setChildren(org.apache.hadoop.conf.Configuration hconf)">1</method>
			<method name="public void initializeAsRoot(org.apache.hadoop.conf.Configuration hconf, org.apache.hadoop.hive.ql.plan.MapredWork mrwork)">1</method>
			<method name="private void populateVirtualColumnValues()">13</method>
			<method name="private void setInspectorInput(org.apache.hadoop.hive.ql.exec.MapOperator$MapInputPath inp)">9</method>
			<method name="public String getName()">1</method>
			<method name="public void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
			<method name="public void process(org.apache.hadoop.io.Writable value)">1</method>
			<method name="private static org.apache.hadoop.hive.ql.exec.MapOperator$MapOpCtx initObjectInspector(org.apache.hadoop.hive.ql.plan.MapredWork conf, org.apache.hadoop.conf.Configuration hconf, String onefile)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.GroupByDesc</name>
		<wmc>21</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>31</rfc>
		<lcom>156</lcom>
		<ca>9</ca>
		<ce>5</ce>
		<npm>21</npm>
		<lcom3>0.861111111111111</lcom3>
		<loc>184</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.3523809523809524</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.333333333333333</amc>
		<cc>
			<method name="public float getGroupByMemoryUsage()">1</method>
			<method name="public java.util.ArrayList getOutputColumnNames()">1</method>
			<method name="public void setGroupKeyNotReductionKey(boolean groupKeyNotReductionKey)">1</method>
			<method name="public float getMemoryThreshold()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public String getModeString()">2</method>
			<method name="public void setMemoryThreshold(float memoryThreshold)">1</method>
			<method name="public void setGroupByMemoryUsage(float groupByMemoryUsage)">1</method>
			<method name="public void setKeys(java.util.ArrayList keys)">1</method>
			<method name="public java.util.ArrayList getKeys()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.GroupByDesc$Mode mode, java.util.ArrayList outputColumnNames, java.util.ArrayList keys, java.util.ArrayList aggregators, boolean groupKeyNotReductionKey, float groupByMemoryUsage, float memoryThreshold)">0</method>
			<method name="public java.util.ArrayList getAggregators()">1</method>
			<method name="public void setMode(org.apache.hadoop.hive.ql.plan.GroupByDesc$Mode mode)">1</method>
			<method name="public void setAggregators(java.util.ArrayList aggregators)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.GroupByDesc$Mode getMode()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.GroupByDesc$Mode mode, java.util.ArrayList outputColumnNames, java.util.ArrayList keys, java.util.ArrayList aggregators, boolean groupKeyNotReductionKey, boolean bucketGroup, float groupByMemoryUsage, float memoryThreshold)">0</method>
			<method name="public void setOutputColumnNames(java.util.ArrayList outputColumnNames)">1</method>
			<method name="public boolean isDistinctLike()">3</method>
			<method name="public boolean getBucketGroup()">1</method>
			<method name="public boolean getGroupKeyNotReductionKey()">1</method>
			<method name="public void setBucketGroup(boolean dataSorted)">1</method>
		</cc>
	</class>
	<class>
		<name>org.json.HTTP</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>27</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>3</npm>
		<lcom3>1.5</lcom3>
		<loc>238</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>78.0</amc>
		<cc>
			<method name="public static org.json.JSONObject toJSONObject(String arg0)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public static String toString(org.json.JSONObject arg0)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde.Constants</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>5</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>1.9428571428571428</lcom3>
		<loc>109</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>36.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFMin$GenericUDAFMinEvaluator$MinAgg</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ConditionalResolverMergeFiles</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>20</cbo>
		<rfc>76</rfc>
		<lcom>8</lcom>
		<ca>1</ca>
		<ce>19</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>489</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.42857142857142855</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>96.4</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void setupMapRedWork(org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.hive.ql.plan.MapredWork work, long targetSize, long totalSize)">2</method>
			<method name="public java.util.List getTasks(org.apache.hadoop.hive.conf.HiveConf conf, Object objCtx)">17</method>
			<method name="private long getMergeSize(org.apache.hadoop.fs.FileSystem inpFs, org.apache.hadoop.fs.Path dirPath, long avgSize)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFOPPositive</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>8</rfc>
		<lcom>21</lcom>
		<ca>0</ca>
		<ce>7</ce>
		<npm>7</npm>
		<lcom3>2.0</lcom3>
		<loc>22</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2653061224489796</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.142857142857143</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.hive.serde2.io.ShortWritable a)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable a)">1</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.LongWritable a)">1</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.IntWritable a)">1</method>
			<method name="public org.apache.hadoop.io.FloatWritable evaluate(org.apache.hadoop.io.FloatWritable a)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.hive.serde2.io.ByteWritable a)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$createIndexStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFExp</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>24</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable a)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.meta_data.EnumMetaData</name>
		<wmc>1</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>5</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public void _init_(byte type, Class sClass)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ForwardDesc</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypei64</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>15</rfc>
		<lcom>21</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>7</npm>
		<lcom3>2.0</lcom3>
		<loc>52</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.35714285714285715</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.428571428571429</amc>
		<cc>
			<method name="public Object deserialize(Object reuse, org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public void serialize(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public byte getType()">1</method>
			<method name="public Class getRealType()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int i)">0</method>
			<method name="public String toString()">1</method>
			<method name="public void _init_(int i)">0</method>
		</cc>
	</class>
	<class>
		<name>org.json.CDL</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>38</rfc>
		<lcom>55</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>10</npm>
		<lcom3>2.0</lcom3>
		<loc>292</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3181818181818182</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>25.545454545454547</amc>
		<cc>
			<method name="public static org.json.JSONArray toJSONArray(org.json.JSONArray arg0, String arg1)">1</method>
			<method name="public static org.json.JSONArray toJSONArray(org.json.JSONTokener arg0)">1</method>
			<method name="public static org.json.JSONObject rowToJSONObject(org.json.JSONArray arg0, org.json.JSONTokener arg1)">1</method>
			<method name="public static org.json.JSONArray toJSONArray(org.json.JSONArray arg0, org.json.JSONTokener arg1)">1</method>
			<method name="public static String toString(org.json.JSONArray arg0)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public static String toString(org.json.JSONArray arg0, org.json.JSONArray arg1)">1</method>
			<method name="public static org.json.JSONArray toJSONArray(String arg0)">1</method>
			<method name="public static String rowToString(org.json.JSONArray arg0)">6</method>
			<method name="public static org.json.JSONArray rowToJSONArray(org.json.JSONTokener arg0)">1</method>
			<method name="private static String getValue(org.json.JSONTokener arg0)">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer</name>
		<wmc>67</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>92</cbo>
		<rfc>354</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>90</ce>
		<npm>3</npm>
		<lcom3>0.9431818181818182</lcom3>
		<loc>5718</loc>
		<dam>0.75</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.1774891774891775</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>84.28358208955224</amc>
		<cc>
			<method name="private void analyzeDropIndex(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private void analyzeAlterTableDropParts(org.apache.hadoop.hive.ql.parse.ASTNode ast, boolean expectView)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void analyzeAlterTableRenameCol(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private java.util.List preparePartitions(org.apache.hadoop.hive.ql.metadata.Table baseTbl, java.util.HashMap partSpec, org.apache.hadoop.hive.ql.metadata.Table indexTbl, org.apache.hadoop.hive.ql.metadata.Hive db, java.util.List indexTblPartitions)">1</method>
			<method name="private void analyzeAlterIndexProps(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private java.util.List getPartitionSpecs(org.antlr.runtime.tree.CommonTree ast)">1</method>
			<method name="private void analyzeCreateIndex(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.conf.HiveConf conf)">0</method>
			<method name="private java.util.List analyzePrincipalListDef(org.apache.hadoop.hive.ql.parse.ASTNode node)">3</method>
			<method name="private void analyzeAlterTableLocation(org.apache.hadoop.hive.ql.parse.ASTNode ast, String tableName, java.util.HashMap partSpec)">1</method>
			<method name="private void analyzeAlterTableClusterSort(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.FetchTask createFetchTask(String schema)">1</method>
			<method name="private void analyzeShowTables(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private void analyzeDescFunction(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private void analyzeShowGrant(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private void analyzeLockTable(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private void addInputsOutputsAlterTable(String tableName, java.util.HashMap partSpec)">1</method>
			<method name="private java.util.List getFullPartitionSpecs(org.antlr.runtime.tree.CommonTree ast)">1</method>
			<method name="private void validatePartitionValues(java.util.Map partSpec)">1</method>
			<method name="private void analyzeGrant(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private void analyzeCreateRole(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private void analyzeDropRole(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private void analyzeDescribeTable(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private void analyzeAlterTableProps(org.apache.hadoop.hive.ql.parse.ASTNode ast, boolean expectView)">1</method>
			<method name="private void analyzeShowIndexes(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private java.util.List getIndexBuilderMapRed(String baseTableName, String indexName, java.util.HashMap partSpec)">1</method>
			<method name="private void analyzeAlterDatabase(org.apache.hadoop.hive.ql.parse.ASTNode ast)">2</method>
			<method name="private java.util.List analyzePrivilegeListDef(org.apache.hadoop.hive.ql.parse.ASTNode node)">1</method>
			<method name="private void analyzeAlterTableFileFormat(org.apache.hadoop.hive.ql.parse.ASTNode ast, String tableName, java.util.HashMap partSpec)">1</method>
			<method name="private void analyzeShowLocks(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private void analyzeMetastoreCheck(org.antlr.runtime.tree.CommonTree ast)">1</method>
			<method name="private void analyzeAlterTableRenamePart(org.apache.hadoop.hive.ql.parse.ASTNode ast, String tblName, java.util.HashMap oldPartSpec)">1</method>
			<method name="private void analyzeShowFunctions(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="static java.util.HashMap access$000(org.apache.hadoop.hive.ql.parse.ASTNode x0)">1</method>
			<method name="public static String getTypeName(int token)">1</method>
			<method name="private void analyzeShowTableStatus(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private static java.util.HashMap getPartSpec(org.apache.hadoop.hive.ql.parse.ASTNode partspec)">1</method>
			<method name="private void analyzeAlterTableModifyCols(org.apache.hadoop.hive.ql.parse.ASTNode ast, org.apache.hadoop.hive.ql.plan.AlterTableDesc$AlterTableTypes alterType)">1</method>
			<method name="private void analyzeRevoke(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private void analyzeShowDatabases(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="static java.util.HashMap getProps(org.apache.hadoop.hive.ql.parse.ASTNode prop)">1</method>
			<method name="public void analyzeInternal(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private String getFullyQualifiedName(org.apache.hadoop.hive.ql.parse.ASTNode ast)">2</method>
			<method name="private void addTablePartsOutputs(String tblName, java.util.List partSpecs, boolean allowMany)">1</method>
			<method name="private void analyzeAlterTableProtectMode(org.apache.hadoop.hive.ql.parse.ASTNode ast, String tableName, java.util.HashMap partSpec)">1</method>
			<method name="private void analyzeGrantRevokeRole(boolean grant, org.apache.hadoop.hive.ql.parse.ASTNode ast)">4</method>
			<method name="private void addTablePartsOutputs(String tblName, java.util.List partSpecs)">1</method>
			<method name="private void analyzeDropDatabase(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private org.apache.hadoop.hive.ql.plan.PrivilegeObjectDesc analyzePrivilegeObject(org.apache.hadoop.hive.ql.parse.ASTNode ast, java.util.HashSet outputs)">1</method>
			<method name="private void analyzeAlterTableTouch(org.antlr.runtime.tree.CommonTree ast)">1</method>
			<method name="private void addTableDropPartsOutputs(String tblName, java.util.List partSpecs, boolean throwIfNonExistent)">1</method>
			<method name="private void analyzeShowRoleGrant(org.apache.hadoop.hive.ql.parse.ASTNode ast)">2</method>
			<method name="private void analyzeUnlockTable(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private void analyzeAlterTableRename(org.apache.hadoop.hive.ql.parse.ASTNode ast, boolean expectView)">1</method>
			<method name="private void analyzeAlterTableSerde(org.apache.hadoop.hive.ql.parse.ASTNode ast, String tableName, java.util.HashMap partSpec)">1</method>
			<method name="private void analyzeShowPartitions(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private void analyzeAlterTableSerdeProps(org.apache.hadoop.hive.ql.parse.ASTNode ast, String tableName, java.util.HashMap partSpec)">1</method>
			<method name="private void analyzeSwitchDatabase(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private void analyzeAlterTableAddParts(org.antlr.runtime.tree.CommonTree ast, boolean expectView)">1</method>
			<method name="private void analyzeAlterTablePartMergeFiles(org.apache.hadoop.hive.ql.parse.ASTNode tablePartAST, org.apache.hadoop.hive.ql.parse.ASTNode ast, String tableName, java.util.HashMap partSpec)">1</method>
			<method name="private void analyzeDropTable(org.apache.hadoop.hive.ql.parse.ASTNode ast, boolean expectView)">1</method>
			<method name="private void analyzeCreateDatabase(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private void addTablePartsOutputs(String tblName, java.util.List partSpecs, boolean throwIfNonExistent, boolean allowMany, org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private void analyzeDescDatabase(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private void analyzeAlterTableArchive(org.antlr.runtime.tree.CommonTree ast, boolean isUnArchive)">1</method>
			<method name="private void analyzeAlterIndexRebuild(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HiveNullValueSequenceFileOutputFormat</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>13</rfc>
		<lcom>9</lcom>
		<ca>1</ca>
		<ce>14</ce>
		<npm>2</npm>
		<lcom3>0.8</lcom3>
		<loc>51</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.25</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf jc, org.apache.hadoop.fs.Path finalOutPath, Class valueClass, boolean isCompressed, java.util.Properties tableProperties, org.apache.hadoop.util.Progressable progress)">1</method>
			<method name="static org.apache.hadoop.io.Writable access$200()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="static org.apache.hadoop.hive.ql.io.HiveKey access$100(org.apache.hadoop.hive.ql.io.HiveNullValueSequenceFileOutputFormat x0)">1</method>
			<method name="static boolean access$000(org.apache.hadoop.hive.ql.io.HiveNullValueSequenceFileOutputFormat x0)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$indexTblName_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.RCFile$ValueBuffer</name>
		<wmc>17</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>41</rfc>
		<lcom>58</lcom>
		<ca>6</ca>
		<ce>10</ce>
		<npm>11</npm>
		<lcom3>0.7767857142857143</lcom3>
		<loc>518</loc>
		<dam>0.5</dam>
		<moa>5</moa>
		<mfa>0.0</mfa>
		<cam>0.18181818181818182</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>28.647058823529413</amc>
		<cc>
			<method name="public int compareTo(Object arg0)">1</method>
			<method name="static org.apache.hadoop.hive.ql.io.RCFile$ValueBuffer$LazyDecompressionCallbackImpl[] access$1200(org.apache.hadoop.hive.ql.io.RCFile$ValueBuffer x0)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static int access$500(org.apache.hadoop.hive.ql.io.RCFile$ValueBuffer x0)">1</method>
			<method name="public void write(java.io.DataOutput out)">1</method>
			<method name="public void clearColumnBuffer()">1</method>
			<method name="public void close()">3</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer currentKey, int columnNumber, boolean[] skippedCols, org.apache.hadoop.io.compress.CompressionCodec codec, boolean lazyDecompress)">0</method>
			<method name="static boolean[] access$000(org.apache.hadoop.hive.ql.io.RCFile$ValueBuffer x0)">1</method>
			<method name="public void setColumnValueBuffer(org.apache.hadoop.hive.ql.io.NonSyncDataOutputBuffer valBuffer, int addIndex)">1</method>
			<method name="public void readFields(java.io.DataInput in)">1</method>
			<method name="static org.apache.hadoop.hive.ql.io.NonSyncDataOutputBuffer[] access$200(org.apache.hadoop.hive.ql.io.RCFile$ValueBuffer x0)">1</method>
			<method name="static org.apache.hadoop.hive.ql.io.NonSyncDataOutputBuffer[] access$100(org.apache.hadoop.hive.ql.io.RCFile$ValueBuffer x0)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer keyBuffer)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer currentKey, int columnNumber, boolean[] skippedCols, org.apache.hadoop.io.compress.CompressionCodec codec)">0</method>
			<method name="static int access$510(org.apache.hadoop.hive.ql.io.RCFile$ValueBuffer x0)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer keyBuffer, boolean[] skippedColIDs)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.TSerializer</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>19</rfc>
		<lcom>8</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>5</npm>
		<lcom3>0.25</lcom3>
		<loc>74</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.2</amc>
		<cc>
			<method name="public String toString(org.apache.thrift.TBase base)">1</method>
			<method name="public byte[] serialize(org.apache.thrift.TBase base)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(org.apache.thrift.protocol.TProtocolFactory protocolFactory)">0</method>
			<method name="public String toString(org.apache.thrift.TBase base, String charset)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.UpdateInputAccessTimeHook$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>21</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.QBExpr</name>
		<wmc>15</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>23</rfc>
		<lcom>47</lcom>
		<ca>2</ca>
		<ce>4</ce>
		<npm>14</npm>
		<lcom3>0.8095238095238095</lcom3>
		<loc>204</loc>
		<dam>1.0</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.34285714285714286</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.2</amc>
		<cc>
			<method name="public void setAlias(String alias)">1</method>
			<method name="public void _init_(String alias)">0</method>
			<method name="public void setOpcode(org.apache.hadoop.hive.ql.parse.QBExpr$Opcode opcode)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void print(String msg)">2</method>
			<method name="public void setQB(org.apache.hadoop.hive.ql.parse.QB qb)">1</method>
			<method name="public void setQBExpr1(org.apache.hadoop.hive.ql.parse.QBExpr qbexpr)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.QB getQB()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.QBExpr getQBExpr2()">1</method>
			<method name="public String getAlias()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.QBExpr$Opcode getOpcode()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.parse.QBExpr$Opcode opcode, org.apache.hadoop.hive.ql.parse.QBExpr qbexpr1, org.apache.hadoop.hive.ql.parse.QBExpr qbexpr2)">0</method>
			<method name="public void setQBExpr2(org.apache.hadoop.hive.ql.parse.QBExpr qbexpr)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.parse.QB qb)">0</method>
			<method name="public org.apache.hadoop.hive.ql.parse.QBExpr getQBExpr1()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TFastFramedTransport</name>
		<wmc>14</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>41</rfc>
		<lcom>17</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>13</npm>
		<lcom3>0.7032967032967032</lcom3>
		<loc>205</loc>
		<dam>0.7142857142857143</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.42857142857142855</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.142857142857142</amc>
		<cc>
			<method name="public int getBufferPosition()">1</method>
			<method name="public void consumeBuffer(int len)">1</method>
			<method name="public void write(byte[] buf, int off, int len)">1</method>
			<method name="public void _init_(org.apache.thrift.transport.TTransport underlying)">0</method>
			<method name="public void _init_(org.apache.thrift.transport.TTransport underlying, int initialBufferCapacity, int maxLength)">0</method>
			<method name="public void close()">1</method>
			<method name="public int read(byte[] buf, int off, int len)">1</method>
			<method name="public byte[] getBuffer()">1</method>
			<method name="public boolean isOpen()">1</method>
			<method name="public void open()">1</method>
			<method name="public void flush()">1</method>
			<method name="public void _init_(org.apache.thrift.transport.TTransport underlying, int initialBufferCapacity)">0</method>
			<method name="public int getBytesRemainingInBuffer()">1</method>
			<method name="private void readFrame()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Operator</name>
		<wmc>85</wmc>
		<dit>1</dit>
		<noc>17</noc>
		<cbo>138</cbo>
		<rfc>143</rfc>
		<lcom>2648</lcom>
		<ca>117</ca>
		<ce>22</ce>
		<npm>67</npm>
		<lcom3>0.9425595238095238</lcom3>
		<loc>2220</loc>
		<dam>0.95</dam>
		<moa>6</moa>
		<mfa>0.0</mfa>
		<cam>0.06761904761904762</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>24.647058823529413</amc>
		<cc>
			<method name="public void setAlias(String alias)">3</method>
			<method name="static void _clinit_()">0</method>
			<method name="public java.util.ArrayList getChildren()">3</method>
			<method name="public boolean getDone()">3</method>
			<method name="protected void forward(Object row, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector rowInspector)">1</method>
			<method name="protected static org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector initEvaluatorsAndReturnStruct(org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator[] evals, java.util.List outputColName, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector rowInspector)">1</method>
			<method name="private String getLevelString(int level)">3</method>
			<method name="public void _init_(org.apache.hadoop.mapred.Reporter reporter)">0</method>
			<method name="protected static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] initEvaluators(org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator[] evals, int start, int length, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector rowInspector)">1</method>
			<method name="public void logStats()">2</method>
			<method name="public void cleanUpInputFileChanged()">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.RowSchema getSchema()">1</method>
			<method name="public java.util.List getChildOperators()">1</method>
			<method name="private void postProcessCounter()">2</method>
			<method name="public String getIdentifier()">1</method>
			<method name="public void setChildOperators(java.util.List childOperators)">1</method>
			<method name="public void setInputObjInspectors(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] inputObjInspectors)">1</method>
			<method name="public Object getGroupKeyObject()">1</method>
			<method name="private java.util.List getAdditionalCounters()">1</method>
			<method name="public void initializeLocalWork(org.apache.hadoop.conf.Configuration hconf)">1</method>
			<method name="public void initializeCounters()">2</method>
			<method name="public void _init_()">0</method>
			<method name="public void augmentPlan()">1</method>
			<method name="public void removeParent(org.apache.hadoop.hive.ql.exec.Operator parent)">7</method>
			<method name="public void setCounterNames(java.util.ArrayList counterNames)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] getInputObjInspectors()">1</method>
			<method name="public void setSchema(org.apache.hadoop.hive.ql.exec.RowSchema rowSchema)">1</method>
			<method name="public void setId(String id)">1</method>
			<method name="public void close(boolean abort)">1</method>
			<method name="public void setConf(java.io.Serializable conf)">1</method>
			<method name="public void passExecContext(org.apache.hadoop.hive.ql.exec.ExecMapperContext execContext)">3</method>
			<method name="public java.util.Map getStats()">2</method>
			<method name="public void cleanUpInputFileChangedOp()">1</method>
			<method name="public java.util.List getParentOperators()">1</method>
			<method name="public void setCounterNameToEnum(java.util.HashMap counterNameToEnum)">1</method>
			<method name="public void setGroupKeyObject(Object keyObject)">1</method>
			<method name="public static void resetLastEnumUsed()">1</method>
			<method name="protected void initializeChildren(org.apache.hadoop.conf.Configuration hconf)">1</method>
			<method name="public java.util.Map getColumnExprMap()">1</method>
			<method name="public void setDone(boolean done)">1</method>
			<method name="private void preProcessCounter()">3</method>
			<method name="public void endGroup()">1</method>
			<method name="public void reset()">3</method>
			<method name="public void assignCounterNameToEnum()">4</method>
			<method name="public String getName()">1</method>
			<method name="public void process(Object row, int tag)">1</method>
			<method name="public void setOutputCollector(org.apache.hadoop.mapred.OutputCollector out)">3</method>
			<method name="public java.util.HashMap getCounters()">1</method>
			<method name="protected void incrCounter(String name, long amount)">3</method>
			<method name="public void replaceChild(org.apache.hadoop.hive.ql.exec.Operator child, org.apache.hadoop.hive.ql.exec.Operator newChild)">3</method>
			<method name="public static void resetId()">1</method>
			<method name="public String getOperatorId()">1</method>
			<method name="public java.io.Serializable getConf()">1</method>
			<method name="private void initialize(org.apache.hadoop.conf.Configuration hconf, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector inputOI, int parentId)">1</method>
			<method name="public java.util.ArrayList getCounterNames()">1</method>
			<method name="public void updateCounters(org.apache.hadoop.mapred.Counters ctrs)">6</method>
			<method name="public abstract void processOp(Object, int)">1</method>
			<method name="public void setColumnExprMap(java.util.Map colExprMap)">1</method>
			<method name="protected boolean areAllParentsInitialized()">4</method>
			<method name="public boolean checkFatalErrors(org.apache.hadoop.mapred.Counters ctrs, StringBuilder errMsg)">6</method>
			<method name="public void initialize(org.apache.hadoop.conf.Configuration hconf, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] inputOIs)">1</method>
			<method name="public void startGroup()">1</method>
			<method name="protected void closeOp(boolean abort)">1</method>
			<method name="public void initOperatorId()">1</method>
			<method name="protected void fatalErrorMessage(StringBuilder errMsg, long counterValue)">1</method>
			<method name="public void preorderMap(org.apache.hadoop.hive.ql.exec.Operator$OperatorFunc opFunc)">3</method>
			<method name="public volatile java.util.List getChildren()">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.ExecMapperContext getExecContext()">1</method>
			<method name="protected boolean allInitializedParentsAreClosed()">4</method>
			<method name="public void setReporter(org.apache.hadoop.mapred.Reporter rep)">3</method>
			<method name="public void removeChildAndAdoptItsChildren(org.apache.hadoop.hive.ql.exec.Operator child)">1</method>
			<method name="public abstract org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="public void setOperatorId(String operatorId)">1</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
			<method name="public void resetStats()">2</method>
			<method name="public void setParentOperators(java.util.List parentOperators)">1</method>
			<method name="private long getNextCntr(long cntr)">2</method>
			<method name="public void jobClose(org.apache.hadoop.conf.Configuration conf, boolean success, org.apache.hadoop.hive.ql.exec.JobCloseFeedBack feedBack)">1</method>
			<method name="public void replaceParent(org.apache.hadoop.hive.ql.exec.Operator parent, org.apache.hadoop.hive.ql.exec.Operator newParent)">3</method>
			<method name="public String dump(int level)">1</method>
			<method name="protected static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] initEvaluators(org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator[] evals, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector rowInspector)">1</method>
			<method name="public java.util.HashMap getCounterNameToEnum()">1</method>
			<method name="public String dump(int level, java.util.HashSet seenOpts)">6</method>
			<method name="public void removeChild(org.apache.hadoop.hive.ql.exec.Operator child)">7</method>
			<method name="public void setExecContext(org.apache.hadoop.hive.ql.exec.ExecMapperContext execContext)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryString</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>12</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>2</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>52</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.75</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableStringObjectInspector OI)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryString copy)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableConstantShortObjectInspector</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>16</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public volatile Object getWritableConstantValue()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable getWritableConstantValue()">1</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.io.ShortWritable value)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TSaslTransport</name>
		<wmc>21</wmc>
		<dit>0</dit>
		<noc>2</noc>
		<cbo>14</cbo>
		<rfc>72</rfc>
		<lcom>2</lcom>
		<ca>2</ca>
		<ce>12</ce>
		<npm>9</npm>
		<lcom3>0.8166666666666667</lcom3>
		<loc>677</loc>
		<dam>0.9166666666666666</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.20625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>30.666666666666668</amc>
		<cc>
			<method name="public void write(byte[] buf, int off, int len)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="protected void _init_(org.apache.thrift.transport.TTransport underlyingTransport)">0</method>
			<method name="public void close()">1</method>
			<method name="protected void writeLength(int length)">1</method>
			<method name="public javax.security.sasl.SaslClient getSaslClient()">1</method>
			<method name="protected int readLength()">1</method>
			<method name="public int read(byte[] buf, int off, int len)">1</method>
			<method name="protected void sendSaslMessage(org.apache.thrift.transport.TSaslTransport$NegotiationStatus status, byte[] payload)">1</method>
			<method name="public boolean isOpen()">4</method>
			<method name="protected abstract void handleSaslStartMessage()">1</method>
			<method name="public void open()">1</method>
			<method name="public void flush()">1</method>
			<method name="protected void setSaslServer(javax.security.sasl.SaslServer saslServer)">1</method>
			<method name="public org.apache.thrift.transport.TTransport getUnderlyingTransport()">1</method>
			<method name="protected org.apache.thrift.transport.TSaslTransport$SaslResponse receiveSaslMessage()">1</method>
			<method name="public javax.security.sasl.SaslServer getSaslServer()">1</method>
			<method name="protected void sendAndThrowMessage(org.apache.thrift.transport.TSaslTransport$NegotiationStatus status, String message)">1</method>
			<method name="private void readFrame()">1</method>
			<method name="protected void _init_(javax.security.sasl.SaslClient saslClient, org.apache.thrift.transport.TTransport underlyingTransport)">0</method>
			<method name="protected abstract org.apache.thrift.transport.TSaslTransport$SaslRole getRole()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.HiveOperation</name>
		<wmc>7</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>10</rfc>
		<lcom>13</lcom>
		<ca>5</ca>
		<ce>2</ce>
		<npm>5</npm>
		<lcom3>0.9833333333333334</lcom3>
		<loc>1169</loc>
		<dam>0.05714285714285714</dam>
		<moa>69</moa>
		<mfa>0.7222222222222222</mfa>
		<cam>0.3333333333333333</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>156.0</amc>
		<cc>
			<method name="private void _init_(String, int, String operationName, org.apache.hadoop.hive.ql.security.authorization.Privilege[] inputRequiredPrivileges, org.apache.hadoop.hive.ql.security.authorization.Privilege[] outputRequiredPrivileges)">0</method>
			<method name="public org.apache.hadoop.hive.ql.security.authorization.Privilege[] getOutputRequiredPrivileges()">1</method>
			<method name="public String getOperationName()">1</method>
			<method name="public org.apache.hadoop.hive.ql.security.authorization.Privilege[] getInputRequiredPrivileges()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.HiveOperation[] values()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.HiveOperation valueOf(String name)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HiveKey</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>12</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>3</ce>
		<npm>3</npm>
		<lcom3>0.7777777777777777</lcom3>
		<loc>44</loc>
		<dam>0.6666666666666666</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.25</amc>
		<cc>
			<method name="public int hashCode()">2</method>
			<method name="public void setHashCode(int myHashCode)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.Adjacency$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>28</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol$SimpleTransportTokenizer</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>20</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>2</npm>
		<lcom3>0.25</lcom3>
		<loc>177</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.3</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>33.4</amc>
		<cc>
			<method name="static void access$000(org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol$SimpleTransportTokenizer x0)">1</method>
			<method name="private void initialize()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol, org.apache.thrift.transport.TTransport trans, String separator, int buffer_length)">0</method>
			<method name="public String nextToken()">1</method>
			<method name="private boolean fillTokenizer()">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ppr.ExprProcFactory$GenericFuncExprProcessor</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>12</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>129</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>63.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.HadoopShims</name>
		<wmc>24</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>46</cbo>
		<rfc>25</rfc>
		<lcom>276</lcom>
		<ca>26</ca>
		<ce>20</ce>
		<npm>23</npm>
		<lcom3>1.0</lcom3>
		<loc>29</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.11180124223602485</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.16666666666666666</amc>
		<cc>
			<method name="public abstract boolean isSecureShimImpl()">1</method>
			<method name="public abstract boolean usesJobShell()">1</method>
			<method name="public abstract int compareText(org.apache.hadoop.io.Text, org.apache.hadoop.io.Text)">1</method>
			<method name="public abstract org.apache.hadoop.hive.shims.HadoopShims$MiniDFSShim getMiniDfs(org.apache.hadoop.conf.Configuration, int, boolean, String[])">1</method>
			<method name="public abstract void setTmpFiles(String, String)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public abstract void prepareJobOutput(org.apache.hadoop.mapred.JobConf)">1</method>
			<method name="public abstract boolean isJobPreparing(org.apache.hadoop.mapred.RunningJob)">1</method>
			<method name="public abstract org.apache.hadoop.mapreduce.TaskAttemptContext newTaskAttemptContext(org.apache.hadoop.conf.Configuration, org.apache.hadoop.util.Progressable)">1</method>
			<method name="public abstract org.apache.hadoop.hive.shims.HadoopShims$CombineFileInputFormatShim getCombineFileInputFormat()">1</method>
			<method name="public abstract org.apache.hadoop.hive.shims.HadoopShims$JobTrackerState getJobTrackerState(org.apache.hadoop.mapred.ClusterStatus)">1</method>
			<method name="public abstract void setFloatConf(org.apache.hadoop.conf.Configuration, String, float)">1</method>
			<method name="public abstract String getShortUserName(org.apache.hadoop.security.UserGroupInformation)">1</method>
			<method name="public abstract String getInputFormatClassName()">1</method>
			<method name="public abstract String[] getTaskJobIDs(org.apache.hadoop.mapred.TaskCompletionEvent)">1</method>
			<method name="public abstract org.apache.hadoop.mapreduce.JobContext newJobContext(org.apache.hadoop.mapreduce.Job)">1</method>
			<method name="public abstract int createHadoopArchive(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, String)">1</method>
			<method name="public abstract boolean fileSystemDeleteOnExit(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)">1</method>
			<method name="public abstract String getTokenStrForm(String)">1</method>
			<method name="public abstract org.apache.hadoop.security.UserGroupInformation getUGIForConf(org.apache.hadoop.conf.Configuration)">1</method>
			<method name="public abstract org.apache.hadoop.security.UserGroupInformation createRemoteUser(String, java.util.List)">1</method>
			<method name="public abstract void doAs(org.apache.hadoop.security.UserGroupInformation, java.security.PrivilegedExceptionAction)">1</method>
			<method name="public abstract void inputFormatValidateInput(org.apache.hadoop.mapred.InputFormat, org.apache.hadoop.mapred.JobConf)">1</method>
			<method name="public abstract long getAccessTime(org.apache.hadoop.fs.FileStatus)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.MapJoinProcessor$CurrentMapJoin</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>24</rfc>
		<lcom>6</lcom>
		<ca>1</ca>
		<ce>18</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>141</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>34.25</amc>
		<cc>
			<method name="private Boolean findGrandChildSubqueryMapjoin(org.apache.hadoop.hive.ql.optimizer.MapJoinProcessor$MapJoinWalkerCtx ctx, org.apache.hadoop.hive.ql.exec.MapJoinOperator mapJoin)">12</method>
			<method name="public void _init_()">0</method>
			<method name="private boolean nonSubqueryMapJoin(org.apache.hadoop.hive.ql.parse.ParseContext pGraphContext, org.apache.hadoop.hive.ql.exec.MapJoinOperator mapJoin, org.apache.hadoop.hive.ql.exec.MapJoinOperator parentMapJoin)">3</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>21</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterProtectModeMode_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager$2</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>21</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.DefaultStorageHandler</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>13</rfc>
		<lcom>53</lcom>
		<ca>0</ca>
		<ce>7</ce>
		<npm>11</npm>
		<lcom3>0.9</lcom3>
		<loc>37</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4090909090909091</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.272727272727273</amc>
		<cc>
			<method name="public void configureInputJobProperties(org.apache.hadoop.hive.ql.plan.TableDesc tableDesc, java.util.Map jobProperties)">1</method>
			<method name="public Class getOutputFormatClass()">1</method>
			<method name="public void configureOutputJobProperties(org.apache.hadoop.hive.ql.plan.TableDesc tableDesc, java.util.Map jobProperties)">1</method>
			<method name="public org.apache.hadoop.conf.Configuration getConf()">1</method>
			<method name="public org.apache.hadoop.hive.metastore.HiveMetaHook getMetaHook()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setConf(org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="public org.apache.hadoop.hive.ql.security.authorization.HiveAuthorizationProvider getAuthorizationProvider()">1</method>
			<method name="public Class getSerDeClass()">1</method>
			<method name="public void configureTableJobProperties(org.apache.hadoop.hive.ql.plan.TableDesc tableDesc, java.util.Map jobProperties)">1</method>
			<method name="public Class getInputFormatClass()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>17</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void write(org.apache.hadoop.io.Writable)">1</method>
			<method name="public abstract void close(boolean)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager$1</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>42</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.666666666666666</amc>
		<cc>
			<method name="public volatile int compare(Object x0, Object x1)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager)">0</method>
			<method name="public int compare(org.apache.hadoop.hive.ql.lockmgr.HiveLockObj o1, org.apache.hadoop.hive.ql.lockmgr.HiveLockObj o2)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.ContentSummaryInputFormat</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>3</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.hadoop.fs.ContentSummary getContentSummary(org.apache.hadoop.fs.Path, org.apache.hadoop.mapred.JobConf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.ExportSemanticAnalyzer</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>24</cbo>
		<rfc>49</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>23</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>303</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>150.5</amc>
		<cc>
			<method name="public void analyzeInternal(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.conf.HiveConf conf)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.NumericUDAFEvaluatorResolver</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>10</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>42</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>20.0</amc>
		<cc>
			<method name="public void _init_(Class udafClass)">0</method>
			<method name="public Class getEvaluatorClass(java.util.List argTypeInfos)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.lineage.ExprProcFactory</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>20</cbo>
		<rfc>25</rfc>
		<lcom>15</lcom>
		<ca>4</ca>
		<ce>16</ce>
		<npm>6</npm>
		<lcom3>2.0</lcom3>
		<loc>119</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.16666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.833333333333332</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getGenericFuncProcessor()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getColumnProcessor()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getFieldProcessor()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getDefaultExprProcessor()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.hooks.LineageInfo$Dependency getExprDependency(org.apache.hadoop.hive.ql.optimizer.lineage.LineageCtx lctx, org.apache.hadoop.hive.ql.exec.Operator inpOp, org.apache.hadoop.hive.ql.plan.ExprNodeDesc expr)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyNonPrimitive</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>4</noc>
		<cbo>8</cbo>
		<rfc>11</rfc>
		<lcom>2</lcom>
		<ca>4</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>0.5625</lcom3>
		<loc>79</loc>
		<dam>0.75</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.0</amc>
		<cc>
			<method name="public int hashCode()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">0</method>
			<method name="public Object getObject()">1</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">6</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$dbProperties_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.AmbiguousMethodException</name>
		<wmc>1</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>8</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>27</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>25.0</amc>
		<cc>
			<method name="public void _init_(Class funcClass, java.util.List argTypeInfos, java.util.List methods)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TJSONProtocol</name>
		<wmc>71</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>124</rfc>
		<lcom>2167</lcom>
		<ca>6</ca>
		<ce>16</ce>
		<npm>43</npm>
		<lcom3>0.8502304147465438</lcom3>
		<loc>1814</loc>
		<dam>1.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.07301587301587302</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>24.112676056338028</amc>
		<cc>
			<method name="public void readFieldEnd()">1</method>
			<method name="public void writeI16(short i16)">1</method>
			<method name="private double readJSONDouble()">1</method>
			<method name="public void writeString(String str)">1</method>
			<method name="private org.apache.thrift.TByteArrayOutputStream readJSONString(boolean skipContext)">1</method>
			<method name="private byte[] readJSONBase64()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private String readJSONNumericChars()">1</method>
			<method name="public boolean readBool()">1</method>
			<method name="public void writeStructEnd()">1</method>
			<method name="private void readJSONObjectStart()">1</method>
			<method name="public void writeFieldBegin(org.apache.thrift.protocol.TField field)">1</method>
			<method name="private void writeJSONString(byte[] b)">1</method>
			<method name="private void writeJSONArrayStart()">1</method>
			<method name="private static final byte hexVal(byte ch)">1</method>
			<method name="public void writeBinary(java.nio.ByteBuffer bin)">1</method>
			<method name="private void readJSONArrayStart()">1</method>
			<method name="private void readJSONObjectEnd()">1</method>
			<method name="private void writeJSONObjectStart()">1</method>
			<method name="private void popContext()">1</method>
			<method name="private void writeJSONObjectEnd()">1</method>
			<method name="static byte[] access$000()">1</method>
			<method name="public void writeListEnd()">1</method>
			<method name="public String readString()">1</method>
			<method name="private void pushContext(org.apache.thrift.protocol.TJSONProtocol$JSONBaseContext c)">1</method>
			<method name="protected void readJSONSyntaxChar(byte[] b)">1</method>
			<method name="public void writeMessageBegin(org.apache.thrift.protocol.TMessage message)">1</method>
			<method name="public org.apache.thrift.protocol.TField readFieldBegin()">1</method>
			<method name="private void writeJSONDouble(double num)">1</method>
			<method name="public int readI32()">1</method>
			<method name="public void readMapEnd()">1</method>
			<method name="public void writeBool(boolean b)">1</method>
			<method name="public void readSetEnd()">1</method>
			<method name="public void writeSetBegin(org.apache.thrift.protocol.TSet set)">1</method>
			<method name="public byte readByte()">1</method>
			<method name="public java.nio.ByteBuffer readBinary()">1</method>
			<method name="private static final byte[] getTypeNameForTypeID(byte typeID)">1</method>
			<method name="public void writeSetEnd()">1</method>
			<method name="private void writeJSONBase64(byte[] b, int offset, int length)">1</method>
			<method name="static byte[] access$100()">1</method>
			<method name="private void readJSONArrayEnd()">1</method>
			<method name="public void writeDouble(double dub)">1</method>
			<method name="public void writeStructBegin(org.apache.thrift.protocol.TStruct struct)">1</method>
			<method name="public void reset()">1</method>
			<method name="public org.apache.thrift.protocol.TMap readMapBegin()">1</method>
			<method name="private long readJSONInteger()">1</method>
			<method name="private static final byte hexChar(byte val)">2</method>
			<method name="public void readStructEnd()">1</method>
			<method name="public org.apache.thrift.protocol.TStruct readStructBegin()">1</method>
			<method name="public void writeFieldStop()">1</method>
			<method name="public void writeMapBegin(org.apache.thrift.protocol.TMap map)">1</method>
			<method name="public org.apache.thrift.protocol.TSet readSetBegin()">1</method>
			<method name="private boolean isJSONNumeric(byte b)">2</method>
			<method name="public org.apache.thrift.protocol.TMessage readMessageBegin()">1</method>
			<method name="private static final byte getTypeIDForTypeName(byte[] name)">1</method>
			<method name="public void _init_(org.apache.thrift.transport.TTransport trans)">0</method>
			<method name="public void readListEnd()">1</method>
			<method name="public void writeMapEnd()">1</method>
			<method name="private void writeJSONArrayEnd()">1</method>
			<method name="public long readI64()">1</method>
			<method name="public void readMessageEnd()">1</method>
			<method name="public void writeFieldEnd()">1</method>
			<method name="public void writeListBegin(org.apache.thrift.protocol.TList list)">1</method>
			<method name="public short readI16()">1</method>
			<method name="public void writeI64(long i64)">1</method>
			<method name="public org.apache.thrift.protocol.TList readListBegin()">1</method>
			<method name="public double readDouble()">1</method>
			<method name="public void writeMessageEnd()">1</method>
			<method name="private void writeJSONInteger(long num)">1</method>
			<method name="public void writeByte(byte b)">1</method>
			<method name="public void writeI32(int i32)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.PrunedPartitionList</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>7</rfc>
		<lcom>1</lcom>
		<ca>10</ca>
		<ce>0</ce>
		<npm>6</npm>
		<lcom3>0.6666666666666667</lcom3>
		<loc>38</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.833333333333333</amc>
		<cc>
			<method name="public java.util.Set getUnknownPartns()">1</method>
			<method name="public java.util.Set getConfirmedPartns()">1</method>
			<method name="public void setConfirmedPartns(java.util.Set confirmedPartns)">1</method>
			<method name="public void _init_(java.util.Set confirmedPartns, java.util.Set unknownPartns, java.util.Set deniedPartns)">0</method>
			<method name="public void setUnknownPartns(java.util.Set unknownPartns)">1</method>
			<method name="public java.util.Set getDeniedPartns()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.FlatFileInputFormat$FlatFileRecordReader</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>29</rfc>
		<lcom>31</lcom>
		<ca>1</ca>
		<ce>15</ce>
		<npm>10</npm>
		<lcom3>0.8555555555555556</lcom3>
		<loc>197</loc>
		<dam>0.8</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.22857142857142856</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>17.7</amc>
		<cc>
			<method name="public volatile Object createKey()">1</method>
			<method name="public synchronized long getPos()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.io.FlatFileInputFormat, org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.mapred.FileSplit split)">0</method>
			<method name="public Void createKey()">1</method>
			<method name="public volatile boolean next(Object x0, Object x1)">1</method>
			<method name="public synchronized void close()">1</method>
			<method name="public volatile Object createValue()">1</method>
			<method name="public synchronized boolean next(Void key, org.apache.hadoop.hive.ql.io.FlatFileInputFormat$RowContainer value)">1</method>
			<method name="public synchronized float getProgress()">1</method>
			<method name="public org.apache.hadoop.hive.ql.io.FlatFileInputFormat$RowContainer createValue()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ppr.OpWalkerCtx</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>4</npm>
		<lcom3>0.5</lcom3>
		<loc>32</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.5</amc>
		<cc>
			<method name="public void addHasNonPartCols(boolean val)">3</method>
			<method name="public java.util.HashMap getOpToPartPruner()">1</method>
			<method name="public void _init_(java.util.HashMap opToPartPruner)">0</method>
			<method name="public boolean getHasNonPartCols()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableBooleanObjectInspector</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>22</cbo>
		<rfc>11</rfc>
		<lcom>15</lcom>
		<ca>17</ca>
		<ce>5</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>45</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.5</amc>
		<cc>
			<method name="public boolean get(Object o)">1</method>
			<method name="void _init_()">0</method>
			<method name="public Object set(Object o, boolean value)">1</method>
			<method name="public Object getPrimitiveJavaObject(Object o)">2</method>
			<method name="public Object create(boolean value)">1</method>
			<method name="public Object copyObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HiveOutputFormatImpl</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>11</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>11</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>37</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.333333333333334</amc>
		<cc>
			<method name="public void checkOutputSpecs(org.apache.hadoop.fs.FileSystem ignored, org.apache.hadoop.mapred.JobConf job)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.mapred.RecordWriter getRecordWriter(org.apache.hadoop.fs.FileSystem ignored, org.apache.hadoop.mapred.JobConf job, String name, org.apache.hadoop.util.Progressable progress)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.HiveUtils</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>28</cbo>
		<rfc>33</rfc>
		<lcom>45</lcom>
		<ca>17</ca>
		<ce>11</ce>
		<npm>8</npm>
		<lcom3>1.0952380952380953</lcom3>
		<loc>380</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2222222222222222</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>36.3</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.index.HiveIndexHandler getIndexHandler(org.apache.hadoop.hive.conf.HiveConf conf, String indexHandlerClass)">1</method>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.metadata.HiveStorageHandler getStorageHandler(org.apache.hadoop.conf.Configuration conf, String className)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static String getUnparsedColumnNamesFromFieldSchema(java.util.List fieldSchemas)">3</method>
			<method name="public static String escapeString(String str)">12</method>
			<method name="public static String lightEscapeString(String str)">3</method>
			<method name="public static org.apache.hadoop.hive.ql.security.authorization.HiveAuthorizationProvider getAuthorizeProviderManager(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.hive.ql.security.HiveAuthenticationProvider authenticator)">1</method>
			<method name="public static String unparseIdentifier(String identifier)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.security.HiveAuthenticationProvider getAuthenticator(org.apache.hadoop.conf.Configuration conf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.index.RewriteCanApplyProcFactory$1</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.TFilterTransport</name>
		<wmc>14</wmc>
		<dit>0</dit>
		<noc>2</noc>
		<cbo>4</cbo>
		<rfc>28</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>14</npm>
		<lcom3>0.0</lcom3>
		<loc>84</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4107142857142857</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.928571428571429</amc>
		<cc>
			<method name="public byte[] getBuffer()">1</method>
			<method name="public int getBufferPosition()">1</method>
			<method name="public boolean isOpen()">1</method>
			<method name="public void open()">1</method>
			<method name="public void consumeBuffer(int len)">1</method>
			<method name="public void write(byte[] buf, int off, int len)">1</method>
			<method name="public void flush()">1</method>
			<method name="public boolean peek()">1</method>
			<method name="public void close()">1</method>
			<method name="public int getBytesRemainingInBuffer()">1</method>
			<method name="public void _init_(org.apache.thrift.transport.TTransport wrapped)">0</method>
			<method name="public int readAll(byte[] buf, int off, int len)">1</method>
			<method name="public void write(byte[] buf)">1</method>
			<method name="public int read(byte[] buf, int off, int len)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$joinSource_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.json.JSONArray</name>
		<wmc>50</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>104</rfc>
		<lcom>1115</lcom>
		<ca>8</ca>
		<ce>3</ce>
		<npm>49</npm>
		<lcom3>0.10204081632653061</lcom3>
		<loc>956</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.18166666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.1</amc>
		<cc>
			<method name="public double optDouble(int arg0, double arg1)">1</method>
			<method name="public org.json.JSONArray put(java.util.Collection arg0)">1</method>
			<method name="public void _init_(java.util.Collection arg0, boolean arg1)">0</method>
			<method name="public org.json.JSONArray optJSONArray(int arg0)">2</method>
			<method name="public long getLong(int arg0)">1</method>
			<method name="public org.json.JSONArray put(int arg0, boolean arg1)">1</method>
			<method name="public org.json.JSONObject optJSONObject(int arg0)">2</method>
			<method name="public long optLong(int arg0, long arg1)">1</method>
			<method name="public double getDouble(int arg0)">1</method>
			<method name="public org.json.JSONArray put(int arg0, java.util.Map arg1)">1</method>
			<method name="public int length()">1</method>
			<method name="public void _init_(org.json.JSONTokener arg0)">0</method>
			<method name="String toString(int arg0, int arg1)">1</method>
			<method name="public org.json.JSONArray put(int arg0, java.util.Collection arg1)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public org.json.JSONArray put(long arg0)">1</method>
			<method name="public org.json.JSONArray getJSONArray(int arg0)">1</method>
			<method name="public double optDouble(int arg0)">1</method>
			<method name="public Object get(int arg0)">1</method>
			<method name="public void _init_(Object arg0)">0</method>
			<method name="public org.json.JSONArray put(int arg0, double arg1)">1</method>
			<method name="public String toString(int arg0)">1</method>
			<method name="public boolean getBoolean(int arg0)">1</method>
			<method name="public java.io.Writer write(java.io.Writer arg0)">1</method>
			<method name="public long optLong(int arg0)">1</method>
			<method name="public String optString(int arg0)">1</method>
			<method name="public int optInt(int arg0)">1</method>
			<method name="public Object opt(int arg0)">3</method>
			<method name="public String optString(int arg0, String arg1)">2</method>
			<method name="public boolean optBoolean(int arg0)">1</method>
			<method name="public void _init_(Object arg0, boolean arg1)">0</method>
			<method name="public org.json.JSONObject getJSONObject(int arg0)">1</method>
			<method name="public org.json.JSONArray put(Object arg0)">1</method>
			<method name="public org.json.JSONArray put(int arg0, Object arg1)">1</method>
			<method name="public void _init_(String arg0)">0</method>
			<method name="public org.json.JSONArray put(boolean arg0)">2</method>
			<method name="public int getInt(int arg0)">1</method>
			<method name="public org.json.JSONArray put(int arg0, int arg1)">1</method>
			<method name="public String getString(int arg0)">1</method>
			<method name="public org.json.JSONArray put(java.util.Map arg0)">1</method>
			<method name="public String toString()">1</method>
			<method name="public String join(String arg0)">1</method>
			<method name="public org.json.JSONArray put(int arg0, long arg1)">1</method>
			<method name="public boolean optBoolean(int arg0, boolean arg1)">1</method>
			<method name="public void _init_(java.util.Collection arg0)">0</method>
			<method name="public org.json.JSONArray put(double arg0)">1</method>
			<method name="public boolean isNull(int arg0)">1</method>
			<method name="public org.json.JSONArray put(int arg0)">1</method>
			<method name="public org.json.JSONObject toJSONObject(org.json.JSONArray arg0)">1</method>
			<method name="public int optInt(int arg0, int arg1)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeEnumDefList</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFContextNGrams$GenericUDAFContextNGramEvaluator</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>52</rfc>
		<lcom>35</lcom>
		<ca>1</ca>
		<ce>17</ce>
		<npm>8</npm>
		<lcom3>0.8765432098765432</lcom3>
		<loc>676</loc>
		<dam>0.8888888888888888</dam>
		<moa>8</moa>
		<mfa>0.0</mfa>
		<cam>0.2777777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>65.7</amc>
		<cc>
			<method name="public void iterate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object[] parameters)">1</method>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector init(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode m, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] parameters)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer getNewAggregationBuffer()">1</method>
			<method name="public void reset(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="private void processNgrams(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFContextNGrams$GenericUDAFContextNGramEvaluator$NGramAggBuf agg, java.util.ArrayList seq)">1</method>
			<method name="public Object terminatePartial(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void merge(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object obj)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFOPMultiply</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>20</rfc>
		<lcom>21</lcom>
		<ca>0</ca>
		<ce>7</ce>
		<npm>7</npm>
		<lcom3>2.0</lcom3>
		<loc>114</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2653061224489796</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.285714285714286</amc>
		<cc>
			<method name="public org.apache.hadoop.io.FloatWritable evaluate(org.apache.hadoop.io.FloatWritable a, org.apache.hadoop.io.FloatWritable b)">3</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.hive.serde2.io.ByteWritable a, org.apache.hadoop.hive.serde2.io.ByteWritable b)">3</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable a, org.apache.hadoop.hive.serde2.io.DoubleWritable b)">3</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.hive.serde2.io.ShortWritable a, org.apache.hadoop.hive.serde2.io.ShortWritable b)">3</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.LongWritable a, org.apache.hadoop.io.LongWritable b)">3</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.IntWritable a, org.apache.hadoop.io.IntWritable b)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.StatsTask$PartitionStatistics</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>1</noc>
		<cbo>3</cbo>
		<rfc>26</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>5</npm>
		<lcom3>0.375</lcom3>
		<loc>151</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.44</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>28.8</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.StatsTask)">0</method>
			<method name="public long getStat(String statType)">2</method>
			<method name="public String toString()">2</method>
			<method name="public void setStat(String statType, long value)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.StatsTask, java.util.Map st)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.RoleDDLDesc</name>
		<wmc>15</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>16</rfc>
		<lcom>77</lcom>
		<ca>3</ca>
		<ce>3</ce>
		<npm>15</npm>
		<lcom3>0.8673469387755102</lcom3>
		<loc>89</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.3466666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.466666666666667</amc>
		<cc>
			<method name="public void setOperation(org.apache.hadoop.hive.ql.plan.RoleDDLDesc$RoleOperation operation)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.RoleDDLDesc$RoleOperation getOperation()">1</method>
			<method name="public String getResFile()">1</method>
			<method name="public void setResFile(String resFile)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(String roleName, org.apache.hadoop.hive.ql.plan.RoleDDLDesc$RoleOperation operation)">0</method>
			<method name="public String getName()">1</method>
			<method name="public void _init_(String principalName, org.apache.hadoop.hive.metastore.api.PrincipalType principalType, org.apache.hadoop.hive.ql.plan.RoleDDLDesc$RoleOperation operation, String roleOwnerName)">0</method>
			<method name="public void setName(String roleName)">1</method>
			<method name="public void setGroup(boolean group)">1</method>
			<method name="public String getRoleOwnerName()">1</method>
			<method name="public void setPrincipalType(org.apache.hadoop.hive.metastore.api.PrincipalType principalType)">1</method>
			<method name="public void setRoleOwnerName(String roleOwnerName)">1</method>
			<method name="public boolean getGroup()">1</method>
			<method name="public org.apache.hadoop.hive.metastore.api.PrincipalType getPrincipalType()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.meta_data.FieldMetaData</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>17</rfc>
		<lcom>0</lcom>
		<ca>11</ca>
		<ce>1</ce>
		<npm>3</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>82</loc>
		<dam>0.25</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.3888888888888889</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.5</amc>
		<cc>
			<method name="public void _init_(String name, byte req, org.apache.thrift.meta_data.FieldValueMetaData vMetaData)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static java.util.Map getStructMetaDataMap(Class sClass)">2</method>
			<method name="public static void addStructMetaDataMap(Class sClass, java.util.Map map)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.BucketMapJoinOptimizer$2</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>1</npm>
		<lcom3>1.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.ql.optimizer.BucketMapJoinOptimizer)">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Jetty20Shims</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>5</rfc>
		<lcom>3</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>22</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.7777777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.333333333333333</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.shims.Jetty20Shims$Server startServer(String listen, int port)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public volatile org.apache.hadoop.hive.shims.JettyShims$Server startServer(String x0, int x1)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.JettyShims</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.hadoop.hive.shims.JettyShims$Server startServer(String, int)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Throttle</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>24</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>4</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>173</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>84.5</amc>
		<cc>
			<method name="public static void checkJobTracker(org.apache.hadoop.mapred.JobConf conf, org.apache.commons.logging.Log LOG)">5</method>
			<method name="private void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.SamplePruner$DefaultPPR</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>7</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveSemanticAnalyzerHookContextImpl</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>11</rfc>
		<lcom>5</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>7</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>46</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.42857142857142855</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.142857142857143</amc>
		<cc>
			<method name="public java.util.Set getOutputs()">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Hive getHive()">1</method>
			<method name="public org.apache.hadoop.conf.Configuration getConf()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setConf(org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="public void update(org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer sem)">1</method>
			<method name="public java.util.Set getInputs()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.BucketMapJoinOptimizer$1</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>1</npm>
		<lcom3>1.0</lcom3>
		<loc>22</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.5</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.ql.optimizer.BucketMapJoinOptimizer)">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$columnNameList_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDTFJSONTuple$HashCache</name>
		<wmc>2</wmc>
		<dit>4</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>19</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.9859154929577465</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.5</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="protected boolean removeEldestEntry(java.util.Map$Entry eldest)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.MemoryTokenStore</name>
		<wmc>12</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>31</rfc>
		<lcom>24</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>12</npm>
		<lcom3>0.7727272727272727</lcom3>
		<loc>138</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2916666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.166666666666666</amc>
		<cc>
			<method name="public void updateMasterKey(int keySeq, String s)">1</method>
			<method name="public org.apache.hadoop.conf.Configuration getConf()">1</method>
			<method name="public boolean addToken(org.apache.hadoop.hive.thrift.DelegationTokenIdentifier tokenIdentifier, org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$DelegationTokenInformation token)">2</method>
			<method name="public void _init_()">0</method>
			<method name="public void setConf(org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="public org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$DelegationTokenInformation getToken(org.apache.hadoop.hive.thrift.DelegationTokenIdentifier tokenIdentifier)">1</method>
			<method name="public boolean removeToken(org.apache.hadoop.hive.thrift.DelegationTokenIdentifier tokenIdentifier)">2</method>
			<method name="public void close()">1</method>
			<method name="public boolean removeMasterKey(int keySeq)">2</method>
			<method name="public int addMasterKey(String s)">1</method>
			<method name="public java.util.List getAllDelegationTokenIdentifiers()">2</method>
			<method name="public String[] getMasterKeys()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.log.PidDailyRollingFileAppender</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>10</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>21</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.5</amc>
		<cc>
			<method name="public void setFile(String file)">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.HadoopJobExecHelper$TaskInfo</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>0.5</lcom3>
		<loc>29</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.75</amc>
		<cc>
			<method name="public String getJobId()">1</method>
			<method name="public void addLogUrl(String logUrl)">1</method>
			<method name="public void _init_(String jobId)">0</method>
			<method name="public java.util.HashSet getLogUrls()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFJson$HashCache</name>
		<wmc>2</wmc>
		<dit>4</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>19</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.9859154929577465</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.5</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="protected boolean removeEldestEntry(java.util.Map$Entry eldest)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$uniqueJoinSource_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.commons.lang.WordUtils</name>
		<wmc>14</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>37</rfc>
		<lcom>91</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>13</npm>
		<lcom3>2.0</lcom3>
		<loc>558</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.27380952380952384</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>38.857142857142854</amc>
		<cc>
			<method name="public static String capitalize(String str)">1</method>
			<method name="public static String uncapitalize(String str)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public static String initials(String str)">1</method>
			<method name="public static String wrap(String str, int wrapLength, String newLineStr, boolean wrapLongWords)">9</method>
			<method name="public static String wrap(String str, int wrapLength)">1</method>
			<method name="public static String uncapitalize(String str, char[] delimiters)">8</method>
			<method name="public static String abbreviate(String str, int lower, int upper, String appendToEnd)">9</method>
			<method name="private static boolean isDelimiter(char ch, char[] delimiters)">4</method>
			<method name="public static String capitalizeFully(String str, char[] delimiters)">5</method>
			<method name="public static String initials(String str, char[] delimiters)">8</method>
			<method name="public static String capitalize(String str, char[] delimiters)">8</method>
			<method name="public static String swapCase(String str)">8</method>
			<method name="public static String capitalizeFully(String str)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.NullStructSerDe$NullStructField</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>6</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>3</npm>
		<lcom3>1.0</lcom3>
		<loc>17</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public String getFieldComment()">1</method>
			<method name="public String getFieldName()">1</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.NullStructSerDe)">0</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getFieldObjectInspector()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.ZooKeeperTokenStore</name>
		<wmc>25</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>24</cbo>
		<rfc>95</rfc>
		<lcom>104</lcom>
		<ca>1</ca>
		<ce>24</ce>
		<npm>16</npm>
		<lcom3>0.725</lcom3>
		<loc>941</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.15151515151515152</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>36.24</amc>
		<cc>
			<method name="public static String ensurePath(org.apache.zookeeper.ZooKeeper zk, String path, java.util.List acl)">1</method>
			<method name="public static int getPermFromString(String permString)">8</method>
			<method name="private org.apache.zookeeper.ZooKeeper getSession()">5</method>
			<method name="public boolean addToken(org.apache.hadoop.hive.thrift.DelegationTokenIdentifier tokenIdentifier, org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$DelegationTokenInformation token)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void setConf(org.apache.hadoop.conf.Configuration conf)">3</method>
			<method name="public org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$DelegationTokenInformation getToken(org.apache.hadoop.hive.thrift.DelegationTokenIdentifier tokenIdentifier)">1</method>
			<method name="public void close()">1</method>
			<method name="static org.slf4j.Logger access$000()">1</method>
			<method name="public org.apache.hadoop.conf.Configuration getConf()">1</method>
			<method name="static org.apache.zookeeper.ZooKeeper access$100(org.apache.hadoop.hive.thrift.ZooKeeperTokenStore x0)">1</method>
			<method name="private String getTokenPath(org.apache.hadoop.hive.thrift.DelegationTokenIdentifier tokenIdentifier)">1</method>
			<method name="public void _init_(String hostPort)">0</method>
			<method name="public static java.util.List parseACLs(String aclString)">6</method>
			<method name="private java.util.Map getAllKeys()">1</method>
			<method name="private int getSeq(String path)">1</method>
			<method name="public String[] getMasterKeys()">2</method>
			<method name="public boolean removeToken(org.apache.hadoop.hive.thrift.DelegationTokenIdentifier tokenIdentifier)">1</method>
			<method name="private void init()">3</method>
			<method name="public static transient org.apache.zookeeper.ZooKeeper createConnectedClient(String connectString, int sessionTimeout, long connectTimeout, org.apache.zookeeper.Watcher[] watchers)">1</method>
			<method name="public java.util.List getAllDelegationTokenIdentifiers()">2</method>
			<method name="public void updateMasterKey(int keySeq, String s)">1</method>
			<method name="protected void _init_()">0</method>
			<method name="public boolean removeMasterKey(int keySeq)">1</method>
			<method name="public int addMasterKey(String s)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeHeaderList</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyDoubleObjectInspector</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>9</rfc>
		<lcom>6</lcom>
		<ca>4</ca>
		<ce>7</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>33</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.875</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.25</amc>
		<cc>
			<method name="public double get(Object o)">1</method>
			<method name="void _init_()">0</method>
			<method name="public Object getPrimitiveJavaObject(Object o)">2</method>
			<method name="public Object copyObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Hadoop20Shims$CombineFileRecordReader</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>42</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>7</npm>
		<lcom3>0.7692307692307693</lcom3>
		<loc>318</loc>
		<dam>0.8461538461538461</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2962962962962963</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>29.5</amc>
		<cc>
			<method name="private boolean doNextWithExceptionHandler(Object key, Object value)">1</method>
			<method name="public Object createValue()">1</method>
			<method name="protected boolean initNextRecordReader(Object key)">1</method>
			<method name="public float getProgress()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object createKey()">1</method>
			<method name="public long getPos()">1</method>
			<method name="public void close()">1</method>
			<method name="public void _init_(org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.mapred.lib.CombineFileSplit split, org.apache.hadoop.mapred.Reporter reporter, Class rrClass)">0</method>
			<method name="public boolean next(Object key, Object value)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFBridge</name>
		<wmc>16</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>39</rfc>
		<lcom>58</lcom>
		<ca>4</ca>
		<ce>15</ce>
		<npm>15</npm>
		<lcom3>0.8518518518518519</lcom3>
		<loc>321</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.23809523809523808</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.5</amc>
		<cc>
			<method name="public String[] getRequiredJars()">1</method>
			<method name="public String getUdfClassName()">1</method>
			<method name="public String getUdfName()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void setUdfClassName(String udfClassName)">1</method>
			<method name="public void setUdfName(String udfName)">1</method>
			<method name="public boolean isOperator()">1</method>
			<method name="public void _init_(String udfName, boolean isOperator, Class udfClass)">0</method>
			<method name="public void setUdfClass(Class udfClass)">1</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public String[] getRequiredFiles()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">7</method>
			<method name="public Class getUdfClass()">1</method>
			<method name="public void setOperator(boolean isOperator)">1</method>
		</cc>
	</class>
	<class>
		<name>org.json.JSONString</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract String toJSONString()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TSimpleJSONProtocol$Factory</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>10</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.thrift.protocol.TProtocol getProtocol(org.apache.thrift.transport.TTransport trans)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tableAllColumns_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$dropPartitionVal_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Hadoop20Shims$MiniDFSShim</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>22</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.666666666666667</amc>
		<cc>
			<method name="public void shutdown()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.shims.Hadoop20Shims, org.apache.hadoop.hdfs.MiniDFSCluster cluster)">0</method>
			<method name="public org.apache.hadoop.fs.FileSystem getFileSystem()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.pcr.PcrExprProcFactory$ColumnExprProcessor</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>8</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>34</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazydio.LazyDioLong</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>12</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>3</npm>
		<lcom3>1.0</lcom3>
		<loc>83</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazydio.LazyDioLong copy)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyLongObjectInspector oi)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.IOContext$Comparison</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9333333333333332</lcom3>
		<loc>67</loc>
		<dam>0.2</dam>
		<moa>5</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>14.5</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.io.IOContext$Comparison valueOf(String name)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.io.IOContext$Comparison[] values()">1</method>
			<method name="private void _init_(String, int)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.thrift.TCTLSeparatedProtocol</name>
		<wmc>57</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>117</rfc>
		<lcom>1166</lcom>
		<ca>2</ca>
		<ce>17</ce>
		<npm>53</npm>
		<lcom3>0.9013157894736842</lcom3>
		<loc>1319</loc>
		<dam>0.8421052631578947</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.07894736842105263</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>21.473684210526315</amc>
		<cc>
			<method name="public void writeI16(short i16)">1</method>
			<method name="public void internalWriteString(String str)">1</method>
			<method name="public void readFieldEnd()">1</method>
			<method name="public void writeString(String str)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public boolean readBool()">1</method>
			<method name="public void writeStructEnd()">1</method>
			<method name="public void writeFieldBegin(org.apache.thrift.protocol.TField field)">1</method>
			<method name="public void _init_(org.apache.thrift.transport.TTransport trans, int buffer_size)">0</method>
			<method name="public void writeBinary(java.nio.ByteBuffer bin)">1</method>
			<method name="protected void internalInitialize()">3</method>
			<method name="public String getPrimarySeparator()">1</method>
			<method name="public void writeListEnd()">1</method>
			<method name="public String readString()">1</method>
			<method name="public void writeMessageBegin(org.apache.thrift.protocol.TMessage message)">1</method>
			<method name="public org.apache.thrift.protocol.TField readFieldBegin()">1</method>
			<method name="public int readI32()">1</method>
			<method name="public void writeBool(boolean b)">1</method>
			<method name="public void readMapEnd()">1</method>
			<method name="public String getSecondarySeparator()">1</method>
			<method name="public void readSetEnd()">1</method>
			<method name="public void writeSetBegin(org.apache.thrift.protocol.TSet set)">1</method>
			<method name="public byte readByte()">1</method>
			<method name="public java.nio.ByteBuffer readBinary()">1</method>
			<method name="public String getMapSeparator()">1</method>
			<method name="public void writeSetEnd()">1</method>
			<method name="public void writeDouble(double dub)">1</method>
			<method name="protected String getByteValue(String altValue, String defaultVal)">3</method>
			<method name="public void writeNull()">1</method>
			<method name="public void writeStructBegin(org.apache.thrift.protocol.TStruct struct)">1</method>
			<method name="public void skip(byte type)">2</method>
			<method name="public org.apache.thrift.protocol.TMap readMapBegin()">1</method>
			<method name="protected String[] complexSplit(String line, java.util.regex.Pattern p)">7</method>
			<method name="public void readStructEnd()">1</method>
			<method name="public org.apache.thrift.protocol.TStruct readStructBegin()">1</method>
			<method name="public void _init_(org.apache.thrift.transport.TTransport trans, String primarySeparator, String secondarySeparator, String mapSeparator, String rowSeparator, boolean returnNulls, int bufferSize)">0</method>
			<method name="public void writeFieldStop()">1</method>
			<method name="public void writeMapBegin(org.apache.thrift.protocol.TMap map)">1</method>
			<method name="public String getRowSeparator()">1</method>
			<method name="public org.apache.thrift.protocol.TSet readSetBegin()">1</method>
			<method name="public org.apache.thrift.protocol.TMessage readMessageBegin()">1</method>
			<method name="public void _init_(org.apache.thrift.transport.TTransport trans)">0</method>
			<method name="public void readListEnd()">1</method>
			<method name="public void writeMapEnd()">1</method>
			<method name="public long readI64()">1</method>
			<method name="public void writeListBegin(org.apache.thrift.protocol.TList list)">1</method>
			<method name="public void writeFieldEnd()">1</method>
			<method name="public void readMessageEnd()">1</method>
			<method name="public short readI16()">1</method>
			<method name="public void writeI64(long i64)">1</method>
			<method name="public org.apache.thrift.protocol.TList readListBegin()">1</method>
			<method name="public double readDouble()">1</method>
			<method name="public void writeMessageEnd()">1</method>
			<method name="public void writeByte(byte b)">1</method>
			<method name="public void writeI32(int i32)">1</method>
			<method name="public boolean lastPrimitiveWasNull()">1</method>
			<method name="public void initialize(org.apache.hadoop.conf.Configuration conf, java.util.Properties tbl)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$databaseComment_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.lineage.ExprProcFactory$ColumnExprProcessor</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>18</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>12</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>67</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>21.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TMessage</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>11</rfc>
		<lcom>4</lcom>
		<ca>10</ca>
		<ce>0</ce>
		<npm>5</npm>
		<lcom3>0.0</lcom3>
		<loc>78</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public boolean equals(org.apache.thrift.protocol.TMessage other)">4</method>
			<method name="public void _init_(String n, byte t, int s)">0</method>
			<method name="public boolean equals(Object other)">2</method>
			<method name="public String toString()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ExprNodeDesc$ExprNodeDescEqualityWrapper</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>4</npm>
		<lcom3>0.0</lcom3>
		<loc>32</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.75</amc>
		<cc>
			<method name="public void setExprNodeDesc(org.apache.hadoop.hive.ql.plan.ExprNodeDesc exprNodeDesc)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.ExprNodeDesc exprNodeDesc)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ExprNodeDesc getExprNodeDesc()">1</method>
			<method name="public boolean equals(Object other)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.objectinspector.LazyBinaryListObjectInspector</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>8</rfc>
		<lcom>6</lcom>
		<ca>4</ca>
		<ce>3</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>39</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.75</amc>
		<cc>
			<method name="public Object getListElement(Object data, int index)">2</method>
			<method name="public int getListLength(Object data)">2</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector listElementObjectInspector)">0</method>
			<method name="public java.util.List getList(Object data)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.JoinDesc</name>
		<wmc>39</wmc>
		<dit>1</dit>
		<noc>2</noc>
		<cbo>21</cbo>
		<rfc>59</rfc>
		<lcom>589</lcom>
		<ca>18</ca>
		<ce>3</ce>
		<npm>39</npm>
		<lcom3>0.9248120300751881</lcom3>
		<loc>536</loc>
		<dam>0.7142857142857143</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.1717948717948718</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.205128205128204</amc>
		<cc>
			<method name="public java.util.Map getExprsStringMap()">6</method>
			<method name="public Byte[] getTagOrder()">1</method>
			<method name="public java.util.Map getFilters()">1</method>
			<method name="public boolean getHandleSkewJoin()">1</method>
			<method name="public java.util.List getCondsList()">3</method>
			<method name="public java.util.Map getSkewKeysValuesTables()">1</method>
			<method name="public void setHandleSkewJoin(boolean handleSkewJoin)">1</method>
			<method name="public void setReversedExprs(java.util.Map reversedExprs)">1</method>
			<method name="public void setSmallKeysDirMap(java.util.Map smallKeysDirMap)">1</method>
			<method name="public void _init_(java.util.Map exprs, java.util.List outputColumnNames)">0</method>
			<method name="public void setExprs(java.util.Map exprs)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.JoinCondDesc[] getConds()">1</method>
			<method name="public String getNullSafeString()">4</method>
			<method name="public boolean[] getNullSafes()">1</method>
			<method name="public void setBigKeysDirMap(java.util.Map bigKeysDirMap)">1</method>
			<method name="public void _init_(java.util.Map exprs, java.util.List outputColumnNames, org.apache.hadoop.hive.ql.plan.JoinCondDesc[] conds)">0</method>
			<method name="public boolean isNoOuterJoin()">1</method>
			<method name="public boolean getNoOuterJoin()">1</method>
			<method name="public void _init_(java.util.Map exprs, java.util.List outputColumnNames, boolean noOuterJoin, org.apache.hadoop.hive.ql.plan.JoinCondDesc[] conds)">0</method>
			<method name="public java.util.Map getBigKeysDirMap()">1</method>
			<method name="public java.util.Map getReversedExprs()">1</method>
			<method name="public void setKeyTableDesc(org.apache.hadoop.hive.ql.plan.TableDesc keyTblDesc)">1</method>
			<method name="public java.util.Map getExprs()">1</method>
			<method name="public void _init_(java.util.Map exprs, java.util.List outputColumnNames, boolean noOuterJoin, org.apache.hadoop.hive.ql.plan.JoinCondDesc[] conds, java.util.Map filters)">0</method>
			<method name="public void setConds(org.apache.hadoop.hive.ql.plan.JoinCondDesc[] conds)">1</method>
			<method name="public void setFilters(java.util.Map filters)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.List getOutputColumnNames()">1</method>
			<method name="public void setNullSafes(boolean[] nullSafes)">1</method>
			<method name="public java.util.Map getFiltersStringMap()">9</method>
			<method name="public void setNoOuterJoin(boolean noOuterJoin)">1</method>
			<method name="public void setTagOrder(Byte[] tagOrder)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.TableDesc getKeyTableDesc()">1</method>
			<method name="public int getSkewKeyDefinition()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.JoinDesc clone)">0</method>
			<method name="public java.util.Map getSmallKeysDirMap()">1</method>
			<method name="public void setOutputColumnNames(java.util.List outputColumnNames)">1</method>
			<method name="public void setSkewKeysValuesTables(java.util.Map skewKeysValuesTables)">1</method>
			<method name="public void setSkewKeyDefinition(int skewKeyDefinition)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFLike$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>28</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$columnNameColonType_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.PrivilegeDesc</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>6</npm>
		<lcom3>0.8</lcom3>
		<loc>35</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.333333333333333</amc>
		<cc>
			<method name="public void setPrivilege(org.apache.hadoop.hive.ql.security.authorization.Privilege privilege)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.security.authorization.Privilege privilege, java.util.List columns)">0</method>
			<method name="public org.apache.hadoop.hive.ql.security.authorization.Privilege getPrivilege()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.List getColumns()">1</method>
			<method name="public void setColumns(java.util.List columns)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyBoolean</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>8</cbo>
		<rfc>12</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>6</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>136</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>44.333333333333336</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyBooleanObjectInspector oi)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">12</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.LazyBoolean copy)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNot</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>16</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>10</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>87</loc>
		<dam>0.3333333333333333</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.8</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFLocate</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>24</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>16</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>244</loc>
		<dam>0.6666666666666666</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>47.2</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>5</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>6</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>15</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.mapred.RecordWriter getRecordWriter(org.apache.hadoop.fs.FileSystem ignored, org.apache.hadoop.mapred.JobConf job, String name, org.apache.hadoop.util.Progressable progress)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.AlterIndexDesc</name>
		<wmc>14</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>15</rfc>
		<lcom>75</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>14</npm>
		<lcom3>0.9340659340659341</lcom3>
		<loc>72</loc>
		<dam>0.8571428571428571</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.642857142857143</amc>
		<cc>
			<method name="public void setSpec(java.util.Map partSpec)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setOp(org.apache.hadoop.hive.ql.plan.AlterIndexDesc$AlterIndexTypes op)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.AlterIndexDesc$AlterIndexTypes type)">0</method>
			<method name="public String getIndexName()">1</method>
			<method name="public void setDbName(String dbName)">1</method>
			<method name="public void setBaseTableName(String baseTable)">1</method>
			<method name="public java.util.Map getProps()">1</method>
			<method name="public String getDbName()">1</method>
			<method name="public void setIndexName(String indexName)">1</method>
			<method name="public String getBaseTableName()">1</method>
			<method name="public void setProps(java.util.Map props)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.AlterIndexDesc$AlterIndexTypes getOp()">1</method>
			<method name="public java.util.Map getSpec()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeFlagArgs</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.CollectOperator</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>20</rfc>
		<lcom>5</lcom>
		<ca>0</ca>
		<ce>8</ce>
		<npm>4</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>109</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.36</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.166666666666668</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void processOp(Object row, int tag)">1</method>
			<method name="public void retrieve(org.apache.hadoop.hive.serde2.objectinspector.InspectableObject result)">4</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.LocalMapJoinProcFactory$LocalMapJoinProcessor</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>26</cbo>
		<rfc>50</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>26</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>233</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.42857142857142855</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>76.66666666666667</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, Object[] nodeOutputs)">1</method>
			<method name="public void hasGroupBy(org.apache.hadoop.hive.ql.exec.Operator mapJoinOp, org.apache.hadoop.hive.ql.optimizer.physical.MapJoinResolver$LocalMapJoinProcCtx localMapJoinProcCtx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.NonSyncDataOutputBuffer</name>
		<wmc>9</wmc>
		<dit>4</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>17</rfc>
		<lcom>0</lcom>
		<ca>6</ca>
		<ce>1</ce>
		<npm>7</npm>
		<lcom3>0.125</lcom3>
		<loc>79</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.7941176470588235</mfa>
		<cam>0.35555555555555557</cam>
		<ic>1</ic>
		<cbm>9</cbm>
		<amc>7.666666666666667</amc>
		<cc>
			<method name="public byte[] getData()">1</method>
			<method name="public void write(java.io.DataInput in, int length)">1</method>
			<method name="public void write(int b)">1</method>
			<method name="private void incCount(int value)">2</method>
			<method name="public org.apache.hadoop.hive.ql.io.NonSyncDataOutputBuffer reset()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void write(byte[] b, int off, int len)">1</method>
			<method name="private void _init_(org.apache.hadoop.hive.common.io.NonSyncByteArrayOutputStream buffer)">0</method>
			<method name="public int getLength()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.OperatorFactory$OpTuple</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>12</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.0</amc>
		<cc>
			<method name="public void _init_(Class descClass, Class opClass)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TCompactProtocol</name>
		<wmc>63</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>23</cbo>
		<rfc>99</rfc>
		<lcom>1741</lcom>
		<ca>12</ca>
		<ce>11</ce>
		<npm>43</npm>
		<lcom3>0.9546370967741935</lcom3>
		<loc>1360</loc>
		<dam>0.8125</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.09392789373814042</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>20.333333333333332</amc>
		<cc>
			<method name="public void readFieldEnd()">1</method>
			<method name="public void writeI16(short i16)">1</method>
			<method name="private byte getTType(byte type)">1</method>
			<method name="protected void writeCollectionBegin(byte elemType, int size)">1</method>
			<method name="public void writeString(String str)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void _init_(org.apache.thrift.transport.TTransport transport)">0</method>
			<method name="public void writeStructEnd()">1</method>
			<method name="public boolean readBool()">1</method>
			<method name="public void writeFieldBegin(org.apache.thrift.protocol.TField field)">1</method>
			<method name="private int intToZigZag(int n)">1</method>
			<method name="public void writeBinary(java.nio.ByteBuffer bin)">1</method>
			<method name="private int readVarint32()">1</method>
			<method name="private void writeFieldBeginInternal(org.apache.thrift.protocol.TField field, byte typeOverride)">1</method>
			<method name="public void writeListEnd()">1</method>
			<method name="private void writeVarint32(int n)">1</method>
			<method name="public String readString()">1</method>
			<method name="public void writeMessageBegin(org.apache.thrift.protocol.TMessage message)">1</method>
			<method name="private long readVarint64()">1</method>
			<method name="private int zigzagToInt(int n)">1</method>
			<method name="private long zigzagToLong(long n)">1</method>
			<method name="private void writeVarint64(long n)">1</method>
			<method name="public org.apache.thrift.protocol.TField readFieldBegin()">1</method>
			<method name="public int readI32()">1</method>
			<method name="public void readMapEnd()">1</method>
			<method name="public void writeBool(boolean b)">1</method>
			<method name="private void writeBinary(byte[] buf, int offset, int length)">1</method>
			<method name="private long bytesToLong(byte[] bytes)">1</method>
			<method name="public void readSetEnd()">1</method>
			<method name="public void writeSetBegin(org.apache.thrift.protocol.TSet set)">1</method>
			<method name="public byte readByte()">1</method>
			<method name="public java.nio.ByteBuffer readBinary()">1</method>
			<method name="public void writeSetEnd()">1</method>
			<method name="public void writeDouble(double dub)">1</method>
			<method name="public void reset()">1</method>
			<method name="public void writeStructBegin(org.apache.thrift.protocol.TStruct struct)">1</method>
			<method name="private void writeByteDirect(int n)">1</method>
			<method name="public org.apache.thrift.protocol.TMap readMapBegin()">1</method>
			<method name="public void readStructEnd()">1</method>
			<method name="public org.apache.thrift.protocol.TStruct readStructBegin()">1</method>
			<method name="private boolean isBoolType(byte b)">3</method>
			<method name="public void writeFieldStop()">1</method>
			<method name="public void writeMapBegin(org.apache.thrift.protocol.TMap map)">1</method>
			<method name="public org.apache.thrift.protocol.TSet readSetBegin()">1</method>
			<method name="private long longToZigzag(long l)">1</method>
			<method name="public org.apache.thrift.protocol.TMessage readMessageBegin()">1</method>
			<method name="private byte getCompactType(byte ttype)">1</method>
			<method name="public void readListEnd()">1</method>
			<method name="private byte[] readBinary(int length)">1</method>
			<method name="public void writeMapEnd()">1</method>
			<method name="public void readMessageEnd()">1</method>
			<method name="public void writeListBegin(org.apache.thrift.protocol.TList list)">1</method>
			<method name="public void writeFieldEnd()">1</method>
			<method name="public long readI64()">1</method>
			<method name="public short readI16()">1</method>
			<method name="public void writeI64(long i64)">1</method>
			<method name="private void fixedLongToBytes(long n, byte[] buf, int off)">1</method>
			<method name="public org.apache.thrift.protocol.TList readListBegin()">1</method>
			<method name="public double readDouble()">1</method>
			<method name="public void writeMessageEnd()">1</method>
			<method name="public void writeByte(byte b)">1</method>
			<method name="public void writeI32(int i32)">1</method>
			<method name="private void writeByteDirect(byte b)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.async.TAsyncMethodCall</name>
		<wmc>22</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>62</rfc>
		<lcom>49</lcom>
		<ca>4</ca>
		<ce>12</ce>
		<npm>3</npm>
		<lcom3>0.8168498168498168</lcom3>
		<loc>392</loc>
		<dam>1.0</dam>
		<moa>5</moa>
		<mfa>0.0</mfa>
		<cam>0.16666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.227272727272727</amc>
		<cc>
			<method name="private void doWritingRequestSize()">1</method>
			<method name="protected void onError(Exception e)">1</method>
			<method name="protected abstract void write_args(org.apache.thrift.protocol.TProtocol)">1</method>
			<method name="public long getTimeoutTimestamp()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="protected org.apache.thrift.async.TAsyncMethodCall$State getState()">1</method>
			<method name="private void cleanUpAndFireCallback(java.nio.channels.SelectionKey key)">1</method>
			<method name="protected void prepareMethodCall()">1</method>
			<method name="protected boolean isFinished()">2</method>
			<method name="protected long getStartTime()">1</method>
			<method name="void registerForFirstWrite(java.nio.channels.SelectionKey key)">1</method>
			<method name="private void doReadingResponseBody(java.nio.channels.SelectionKey key)">1</method>
			<method name="private void doReadingResponseSize()">1</method>
			<method name="void start(java.nio.channels.Selector sel)">1</method>
			<method name="protected java.nio.ByteBuffer getFrameBuffer()">1</method>
			<method name="public org.apache.thrift.async.TAsyncClient getClient()">1</method>
			<method name="private void doWritingRequestBody(java.nio.channels.SelectionKey key)">1</method>
			<method name="protected void _init_(org.apache.thrift.async.TAsyncClient client, org.apache.thrift.protocol.TProtocolFactory protocolFactory, org.apache.thrift.transport.TNonblockingTransport transport, org.apache.thrift.async.AsyncMethodCallback callback, boolean isOneway)">0</method>
			<method name="protected void transition(java.nio.channels.SelectionKey key)">3</method>
			<method name="public boolean hasTimeout()">1</method>
			<method name="protected long getSequenceId()">1</method>
			<method name="private void doConnecting(java.nio.channels.SelectionKey key)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.pcr.PcrOpProcFactory$FilterPCR</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>24</cbo>
		<rfc>43</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>24</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>240</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>119.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.GenMRRedSink4</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>27</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>13</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>113</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>36.333333333333336</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx opProcCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$showGrants_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.history.HiveHistory$TaskInfo</name>
		<wmc>1</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>10</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.errors.ErrorHeuristic</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>3</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>3</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void processLogLine(String)">1</method>
			<method name="public abstract void init(String, org.apache.hadoop.mapred.JobConf)">1</method>
			<method name="public abstract org.apache.hadoop.hive.ql.exec.errors.ErrorAndSolution getErrorAndSolution()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.GenMRRedSink1</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>27</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>11</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>102</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>50.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx opProcCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.GenMRRedSink3</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>23</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>12</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>101</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>49.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx opProcCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.MapJoinProcessor$MapJoinWalkerCtx</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>11</rfc>
		<lcom>12</lcom>
		<ca>4</ca>
		<ce>3</ce>
		<npm>9</npm>
		<lcom3>0.75</lcom3>
		<loc>58</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.4166666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public void _init_(java.util.List listMapJoinsNoRed, org.apache.hadoop.hive.ql.parse.ParseContext pGraphContext)">0</method>
			<method name="public void setListRejectedMapJoins(java.util.List listRejectedMapJoins)">1</method>
			<method name="public void setpGraphContext(org.apache.hadoop.hive.ql.parse.ParseContext pGraphContext)">1</method>
			<method name="public java.util.List getListRejectedMapJoins()">1</method>
			<method name="public void setListMapJoins(java.util.List listMapJoinsNoRed)">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator getCurrMapJoinOp()">1</method>
			<method name="public java.util.List getListMapJoinsNoRed()">1</method>
			<method name="public void setCurrMapJoinOp(org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator currMapJoinOp)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext getpGraphContext()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.GenMRRedSink2</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>22</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>89</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>43.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx opProcCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFDegrees</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>10</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.75</lcom3>
		<loc>31</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.666666666666666</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable i)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>41</cbo>
		<rfc>28</rfc>
		<lcom>26</lcom>
		<ca>33</ca>
		<ce>8</ce>
		<npm>7</npm>
		<lcom3>0.9485294117647058</lcom3>
		<loc>249</loc>
		<dam>0.0</dam>
		<moa>12</moa>
		<mfa>0.0</mfa>
		<cam>0.2</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>24.77777777777778</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.serde2.typeinfo.TypeInfo getPrimitiveTypeInfoFromJavaPrimitive(Class clazz)">1</method>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.typeinfo.TypeInfo getMapTypeInfo(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo keyTypeInfo, org.apache.hadoop.hive.serde2.typeinfo.TypeInfo valueTypeInfo)">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.typeinfo.TypeInfo getPrimitiveTypeInfoFromPrimitiveWritable(Class clazz)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.typeinfo.TypeInfo getListTypeInfo(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo elementTypeInfo)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.typeinfo.TypeInfo getStructTypeInfo(java.util.List names, java.util.List typeInfos)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.typeinfo.TypeInfo getPrimitiveTypeInfo(String typeName)">3</method>
			<method name="public static org.apache.hadoop.hive.serde2.typeinfo.TypeInfo getUnionTypeInfo(java.util.List typeInfos)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixProperties_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager</name>
		<wmc>30</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>31</cbo>
		<rfc>111</rfc>
		<lcom>233</lcom>
		<ca>1</ca>
		<ce>31</ce>
		<npm>13</npm>
		<lcom3>0.7931034482758621</lcom3>
		<loc>1368</loc>
		<dam>0.8461538461538461</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.18719211822660098</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>44.166666666666664</amc>
		<cc>
			<method name="public void releaseLocks(java.util.List hiveLocks)">3</method>
			<method name="public java.util.List getLocks(boolean verifyTablePartition, boolean fetchData)">1</method>
			<method name="private java.util.List getObjectNames(org.apache.hadoop.hive.ql.lockmgr.HiveLockObject key)">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="private org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLock lockPrimitive(org.apache.hadoop.hive.ql.lockmgr.HiveLockObject key, org.apache.hadoop.hive.ql.lockmgr.HiveLockMode mode, boolean keepAlive, boolean parentCreated)">1</method>
			<method name="public void close()">1</method>
			<method name="private static org.apache.hadoop.hive.ql.lockmgr.HiveLockObject getLockObject(org.apache.hadoop.hive.conf.HiveConf conf, String path, org.apache.hadoop.hive.ql.lockmgr.HiveLockMode mode, org.apache.hadoop.hive.ql.lockmgr.HiveLockObject$HiveLockObjectData data, String parent, boolean verifyTablePartition)">1</method>
			<method name="private void checkRedundantNode(String node)">4</method>
			<method name="public java.util.List getLocks(org.apache.hadoop.hive.ql.lockmgr.HiveLockObject key, boolean verifyTablePartitions, boolean fetchData)">1</method>
			<method name="private static String getLastObjectName(String parent, org.apache.hadoop.hive.ql.lockmgr.HiveLockObject key)">1</method>
			<method name="public void refresh()">1</method>
			<method name="public org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLock lock(org.apache.hadoop.hive.ql.lockmgr.HiveLockObject key, org.apache.hadoop.hive.ql.lockmgr.HiveLockMode mode, boolean keepAlive)">1</method>
			<method name="private void removeAllRedundantNodes()">1</method>
			<method name="private void renewZookeeperInstance(int sessionTimeout, String quorumServers)">1</method>
			<method name="public java.util.List lock(java.util.List lockObjects, boolean keepAlive)">1</method>
			<method name="public void unlock(org.apache.hadoop.hive.ql.lockmgr.HiveLock hiveLock)">1</method>
			<method name="private static void unlockPrimitive(org.apache.hadoop.hive.conf.HiveConf conf, org.apache.zookeeper.ZooKeeper zkpClient, org.apache.hadoop.hive.ql.lockmgr.HiveLock hiveLock, String parent)">1</method>
			<method name="public void prepareRetry()">1</method>
			<method name="private void unlockWithRetry(org.apache.hadoop.hive.conf.HiveConf conf, org.apache.zookeeper.ZooKeeper zkpClient, org.apache.hadoop.hive.ql.lockmgr.HiveLock hiveLock, String parent)">1</method>
			<method name="private static org.apache.hadoop.hive.ql.lockmgr.HiveLockMode getLockMode(org.apache.hadoop.hive.conf.HiveConf conf, String path)">3</method>
			<method name="public void setContext(org.apache.hadoop.hive.ql.lockmgr.HiveLockManagerCtx ctx)">1</method>
			<method name="public void _init_()">0</method>
			<method name="private String createChild(String name, byte[] data, org.apache.zookeeper.CreateMode mode)">1</method>
			<method name="public volatile org.apache.hadoop.hive.ql.lockmgr.HiveLock lock(org.apache.hadoop.hive.ql.lockmgr.HiveLockObject x0, org.apache.hadoop.hive.ql.lockmgr.HiveLockMode x1, boolean x2)">1</method>
			<method name="public static void releaseAllLocks(org.apache.hadoop.hive.conf.HiveConf conf)">1</method>
			<method name="private org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLock lock(org.apache.hadoop.hive.ql.lockmgr.HiveLockObject key, org.apache.hadoop.hive.ql.lockmgr.HiveLockMode mode, boolean keepAlive, boolean parentCreated)">1</method>
			<method name="private String getLockName(String parent, org.apache.hadoop.hive.ql.lockmgr.HiveLockMode mode)">1</method>
			<method name="private static String getQuorumServers(org.apache.hadoop.hive.conf.HiveConf conf)">1</method>
			<method name="private static java.util.List getLocks(org.apache.hadoop.hive.conf.HiveConf conf, org.apache.zookeeper.ZooKeeper zkpClient, org.apache.hadoop.hive.ql.lockmgr.HiveLockObject key, String parent, boolean verifyTablePartition, boolean fetchData)">1</method>
			<method name="private int getSequenceNumber(String resPath, String path)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.PostExecute</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void run(org.apache.hadoop.hive.ql.session.SessionState, java.util.Set, java.util.Set, org.apache.hadoop.hive.ql.hooks.LineageInfo, org.apache.hadoop.security.UserGroupInformation)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$splitSample_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.Serializer</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>4</rfc>
		<lcom>6</lcom>
		<ca>5</ca>
		<ce>5</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Class getSerializedClass()">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.SerDeStats getSerDeStats()">1</method>
			<method name="public abstract org.apache.hadoop.io.Writable serialize(Object, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)">1</method>
			<method name="public abstract void initialize(org.apache.hadoop.conf.Configuration, java.util.Properties)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.BucketizedHiveInputSplit</name>
		<wmc>16</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>41</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>6</ce>
		<npm>15</npm>
		<lcom3>0.5555555555555555</lcom3>
		<loc>344</loc>
		<dam>0.6666666666666666</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.24444444444444444</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>20.3125</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.mapred.InputSplit[] inputSplits, String inputFormatClassName)">0</method>
			<method name="public long getStart()">4</method>
			<method name="public void setInputFormatClassName(String inputFormatClassName)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void write(java.io.DataOutput out)">1</method>
			<method name="public void readFields(java.io.DataInput in)">1</method>
			<method name="public long getLength(int idx)">2</method>
			<method name="public org.apache.hadoop.mapred.InputSplit getSplit(int idx)">4</method>
			<method name="public long getLength()">2</method>
			<method name="public String inputFormatClassName()">1</method>
			<method name="public String[] getLocations()">1</method>
			<method name="public String getInputFormatClassName()">1</method>
			<method name="public int getNumSplits()">1</method>
			<method name="public String toString()">3</method>
			<method name="public org.apache.hadoop.fs.Path getPath()">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.MapJoinFactory$MapJoin</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>24</cbo>
		<rfc>44</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>23</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>198</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>64.66666666666667</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$partitionSpec_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$3</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>56</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>54.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ConditionalResolverCommonJoin$ConditionalResolverCommonJoinCtx</name>
		<wmc>13</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>14</rfc>
		<lcom>66</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>13</npm>
		<lcom3>0.9404761904761906</lcom3>
		<loc>65</loc>
		<dam>0.7142857142857143</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.36538461538461536</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.4615384615384617</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.exec.Task getCommonJoinTask()">1</method>
			<method name="public void setAliasToTask(java.util.HashMap aliasToTask)">1</method>
			<method name="public String getHdfsTmpDir()">1</method>
			<method name="public java.util.HashMap getPathToAliases()">1</method>
			<method name="public void setPathToAliases(java.util.HashMap pathToAliases)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setLocalTmpDir(String localTmpDir)">1</method>
			<method name="public java.util.HashMap getAliasToTask()">1</method>
			<method name="public void setHdfsTmpDir(String hdfsTmpDir)">1</method>
			<method name="public void setCommonJoinTask(org.apache.hadoop.hive.ql.exec.Task commonJoinTask)">1</method>
			<method name="public void setAliasToKnownSize(java.util.HashMap aliasToKnownSize)">1</method>
			<method name="public String getLocalTmpDir()">1</method>
			<method name="public java.util.HashMap getAliasToKnownSize()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileBlockMergeRecordReader</name>
		<wmc>15</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>34</rfc>
		<lcom>67</lcom>
		<ca>1</ca>
		<ce>11</ce>
		<npm>13</npm>
		<lcom3>0.7738095238095237</lcom3>
		<loc>225</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.21904761904761905</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.6</amc>
		<cc>
			<method name="public long getStart()">1</method>
			<method name="public float getProgress()">1</method>
			<method name="public volatile boolean next(Object x0, Object x1)">1</method>
			<method name="public void close()">1</method>
			<method name="public org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileValueBufferWrapper createValue()">1</method>
			<method name="public org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileKeyBufferWrapper createKey()">1</method>
			<method name="public volatile Object createKey()">1</method>
			<method name="protected boolean nextBlock(org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileKeyBufferWrapper keyWrapper, org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileValueBufferWrapper valueWrapper)">1</method>
			<method name="protected void seek(long pos)">1</method>
			<method name="public volatile Object createValue()">1</method>
			<method name="public Class getKeyClass()">1</method>
			<method name="public long getPos()">1</method>
			<method name="public void _init_(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.mapred.FileSplit split)">0</method>
			<method name="public Class getValueClass()">1</method>
			<method name="public boolean next(org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileKeyBufferWrapper key, org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileValueBufferWrapper value)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$1</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>5</ce>
		<npm>1</npm>
		<lcom3>0.5</lcom3>
		<loc>20</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.0</amc>
		<cc>
			<method name="public transient Object dispatch(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, Object[] nodeOutputs)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.parse.SemanticAnalyzer, org.apache.hadoop.hive.ql.parse.ASTNodeOrigin)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$2</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>1</npm>
		<lcom3>0.5</lcom3>
		<loc>24</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.0</amc>
		<cc>
			<method name="public boolean accept(org.apache.hadoop.fs.Path file)">2</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.parse.SemanticAnalyzer, org.apache.hadoop.hive.ql.Context)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.history.HiveHistory</name>
		<wmc>19</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>21</cbo>
		<rfc>98</rfc>
		<lcom>89</lcom>
		<ca>6</ca>
		<ce>17</ce>
		<npm>15</npm>
		<lcom3>0.8962962962962963</lcom3>
		<loc>891</loc>
		<dam>0.8</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.22777777777777777</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>45.10526315789474</amc>
		<cc>
			<method name="public void finalize()">1</method>
			<method name="private static void parseLine(String line, org.apache.hadoop.hive.ql.history.HiveHistory$Listener l)">1</method>
			<method name="public void printRowCount(String queryId)">2</method>
			<method name="public void setIdToTableMap(java.util.Map map)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void setTaskProperty(String queryId, String taskId, org.apache.hadoop.hive.ql.history.HiveHistory$Keys propName, String propValue)">2</method>
			<method name="public void endQuery(String queryId)">2</method>
			<method name="public void startTask(String queryId, org.apache.hadoop.hive.ql.exec.Task task, String taskName)">2</method>
			<method name="String getRowCountTableName(String name)">3</method>
			<method name="void log(org.apache.hadoop.hive.ql.history.HiveHistory$RecordTypes rt, java.util.Map keyValMap)">4</method>
			<method name="public void progressTask(String queryId, org.apache.hadoop.hive.ql.exec.Task task)">2</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.session.SessionState ss)">0</method>
			<method name="public void startQuery(String cmd, String id)">2</method>
			<method name="public static void parseHiveHistory(String path, org.apache.hadoop.hive.ql.history.HiveHistory$Listener l)">1</method>
			<method name="public void logPlanProgress(org.apache.hadoop.hive.ql.QueryPlan plan)">1</method>
			<method name="public void endTask(String queryId, org.apache.hadoop.hive.ql.exec.Task task)">2</method>
			<method name="public String getHistFileName()">1</method>
			<method name="public void setQueryProperty(String queryId, org.apache.hadoop.hive.ql.history.HiveHistory$Keys propName, String propValue)">2</method>
			<method name="public void setTaskCounters(String queryId, String taskId, org.apache.hadoop.mapred.Counters ctrs)">7</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$viewPartition_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.JJTthrift_grammarState</name>
		<wmc>12</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>25</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>12</npm>
		<lcom3>0.43636363636363634</lcom3>
		<loc>247</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3958333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.166666666666668</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.dynamic_type.Node rootNode()">1</method>
			<method name="public void closeNodeScope(org.apache.hadoop.hive.serde2.dynamic_type.Node n, int num)">2</method>
			<method name="public void clearNodeScope(org.apache.hadoop.hive.serde2.dynamic_type.Node n)">2</method>
			<method name="public int nodeArity()">1</method>
			<method name="public void pushNode(org.apache.hadoop.hive.serde2.dynamic_type.Node n)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void openNodeScope(org.apache.hadoop.hive.serde2.dynamic_type.Node n)">1</method>
			<method name="public void closeNodeScope(org.apache.hadoop.hive.serde2.dynamic_type.Node n, boolean condition)">3</method>
			<method name="public org.apache.hadoop.hive.serde2.dynamic_type.Node popNode()">2</method>
			<method name="public void reset()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.dynamic_type.Node peekNode()">1</method>
			<method name="public boolean nodeCreated()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeByte</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>14</rfc>
		<lcom>21</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>7</npm>
		<lcom3>2.0</lcom3>
		<loc>50</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.38095238095238093</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.142857142857143</amc>
		<cc>
			<method name="public Object deserialize(Object reuse, org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public Byte deserialize(org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public void serialize(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public byte getType()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int i)">0</method>
			<method name="public String toString()">1</method>
			<method name="public void _init_(int i)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.cli.CommonCliOptions</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>33</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>7</ce>
		<npm>5</npm>
		<lcom3>0.5</lcom3>
		<loc>159</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>30.0</amc>
		<cc>
			<method name="public boolean isVerbose()">1</method>
			<method name="public void _init_(String cliname, boolean includeHiveConf)">0</method>
			<method name="public java.util.Properties addHiveconfToSystemProperties()">3</method>
			<method name="public void parse(String[] args)">2</method>
			<method name="public void printUsage()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.Graph</name>
		<wmc>47</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>24</cbo>
		<rfc>110</rfc>
		<lcom>555</lcom>
		<ca>3</ca>
		<ce>21</ce>
		<npm>44</npm>
		<lcom3>0.7663043478260869</lcom3>
		<loc>999</loc>
		<dam>0.875</dam>
		<moa>5</moa>
		<mfa>0.0</mfa>
		<cam>0.11645962732919254</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>20.085106382978722</amc>
		<cc>
			<method name="public void clear()">1</method>
			<method name="public void setNodeTypeIsSet(boolean value)">2</method>
			<method name="public int getRootsSize()">2</method>
			<method name="public java.util.List getRoots()">1</method>
			<method name="public java.util.List getAdjacencyList()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public volatile org.apache.thrift.TBase deepCopy()">1</method>
			<method name="public int compareTo(org.apache.hadoop.hive.ql.plan.api.Graph other)">11</method>
			<method name="public volatile Object getFieldValue(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="private void writeObject(java.io.ObjectOutputStream out)">1</method>
			<method name="public void setAdjacencyList(java.util.List adjacencyList)">1</method>
			<method name="public void read(org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public boolean isSet(org.apache.hadoop.hive.ql.plan.api.Graph$_Fields field)">3</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.NodeType getNodeType()">1</method>
			<method name="public int getAdjacencyListSize()">2</method>
			<method name="public void write(org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public volatile boolean isSet(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="public void setRootsIsSet(boolean value)">2</method>
			<method name="public Object getFieldValue(org.apache.hadoop.hive.ql.plan.api.Graph$_Fields field)">2</method>
			<method name="public String toString()">6</method>
			<method name="public boolean isSetRoots()">2</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.Graph$_Fields fieldForId(int fieldId)">1</method>
			<method name="public void validate()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.Iterator getRootsIterator()">2</method>
			<method name="public void unsetRoots()">1</method>
			<method name="public java.util.Iterator getAdjacencyListIterator()">2</method>
			<method name="public void addToAdjacencyList(org.apache.hadoop.hive.ql.plan.api.Adjacency elem)">2</method>
			<method name="public volatile void setFieldValue(org.apache.thrift.TFieldIdEnum x0, Object x1)">1</method>
			<method name="public void unsetAdjacencyList()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.api.Graph other)">0</method>
			<method name="public volatile int compareTo(Object x0)">1</method>
			<method name="public void setRoots(java.util.List roots)">1</method>
			<method name="public void setNodeType(org.apache.hadoop.hive.ql.plan.api.NodeType nodeType)">1</method>
			<method name="public int hashCode()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.api.NodeType nodeType, java.util.List roots, java.util.List adjacencyList)">0</method>
			<method name="private void readObject(java.io.ObjectInputStream in)">1</method>
			<method name="public boolean isSetAdjacencyList()">2</method>
			<method name="public void setFieldValue(org.apache.hadoop.hive.ql.plan.api.Graph$_Fields field, Object value)">5</method>
			<method name="public void addToRoots(String elem)">2</method>
			<method name="public void setAdjacencyListIsSet(boolean value)">2</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.Graph deepCopy()">1</method>
			<method name="public boolean equals(org.apache.hadoop.hive.ql.plan.api.Graph that)">17</method>
			<method name="public boolean equals(Object that)">3</method>
			<method name="public volatile org.apache.thrift.TFieldIdEnum fieldForId(int x0)">1</method>
			<method name="public void unsetNodeType()">1</method>
			<method name="public boolean isSetNodeType()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.MsckDesc</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>17</rfc>
		<lcom>21</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>10</npm>
		<lcom3>0.7777777777777778</lcom3>
		<loc>84</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public java.util.ArrayList getPartSpecs()">1</method>
			<method name="public void setRepairPartitions(boolean repairPartitions)">1</method>
			<method name="public String getResFile()">1</method>
			<method name="public String getTableName()">1</method>
			<method name="public void setResFile(String resFile)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setPartSpecs(java.util.ArrayList partSpecs)">1</method>
			<method name="public void setTableName(String tableName)">1</method>
			<method name="public boolean isRepairPartitions()">1</method>
			<method name="public void _init_(String tableName, java.util.List partSpecs, org.apache.hadoop.fs.Path resFile, boolean repairPartitions)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.InvalidTableException</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>9</rfc>
		<lcom>0</lcom>
		<ca>5</ca>
		<ce>1</ce>
		<npm>5</npm>
		<lcom3>0.0</lcom3>
		<loc>37</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.7333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.2</amc>
		<cc>
			<method name="public void _init_(String tableName)">0</method>
			<method name="public String getTableName()">1</method>
			<method name="public void _init_(String message, String tableName)">0</method>
			<method name="public void _init_(String message, Throwable cause, String tableName)">0</method>
			<method name="public void _init_(Throwable cause, String tableName)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndex$NewQueryGroupbySchemaProc</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>20</cbo>
		<rfc>47</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>20</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>232</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4444444444444444</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>76.33333333333333</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, Object[] nodeOutputs)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndex$1 x0)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters$StructConverter</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>19</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>132</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>40.666666666666664</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector inputOI, org.apache.hadoop.hive.serde2.objectinspector.SettableStructObjectInspector outputOI)">0</method>
			<method name="public Object convert(Object input)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPEqualOrLessThan</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>17</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>17</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>202</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>100.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeConstListContents</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.SkewJoinProcFactory$SkewJoinJoinProcessor</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>6</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>23</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCorrelation$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>70</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>68.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tableComment_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.Dimension</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>1</noc>
		<cbo>3</cbo>
		<rfc>16</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>7</npm>
		<lcom3>0.16666666666666666</lcom3>
		<loc>115</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.39285714285714285</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>15.142857142857142</amc>
		<cc>
			<method name="public String getDimensionId()">1</method>
			<method name="public Class getDimensionType()">1</method>
			<method name="public boolean equals(Object o)">6</method>
			<method name="public int hashCode()">3</method>
			<method name="public int hashCode(Object o)">1</method>
			<method name="public void _init_(Class t, String id)">0</method>
			<method name="public String toString()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.SerDe</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>22</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>20</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ppr.ExprPrunerInfo</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>1</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>14</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.3333333333333335</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void setTabAlias(String tabAlias)">1</method>
			<method name="public String getTabAlias()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$searchCondition_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$whenExpression_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.client.TUGIAssumingTransport$1</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>6</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>26</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.333333333333333</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.thrift.client.TUGIAssumingTransport)">0</method>
			<method name="public volatile Object run()">1</method>
			<method name="public Void run()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFBaseBitOP</name>
		<wmc>1</wmc>
		<dit>0</dit>
		<noc>4</noc>
		<cbo>9</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>5</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>28</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>23.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.thrift.WriteNullsProtocol</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>11</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract boolean lastPrimitiveWasNull()">1</method>
			<method name="public abstract void writeNull()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.UDAF</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>3</noc>
		<cbo>7</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>5</ca>
		<ce>2</ce>
		<npm>4</npm>
		<lcom3>0.0</lcom3>
		<loc>28</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.75</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void setResolver(org.apache.hadoop.hive.ql.exec.UDAFEvaluatorResolver rslv)">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.UDAFEvaluatorResolver getResolver()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.UDAFEvaluatorResolver rslv)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.EncodingUtils</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>6</rfc>
		<lcom>10</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>94</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>17.8</amc>
		<cc>
			<method name="public static final void encodeBigEndian(int integer, byte[] buf)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public static final int decodeBigEndian(byte[] buf)">1</method>
			<method name="public static final void encodeBigEndian(int integer, byte[] buf, int offset)">1</method>
			<method name="public static final int decodeBigEndian(byte[] buf, int offset)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFOPMod</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>20</rfc>
		<lcom>21</lcom>
		<ca>0</ca>
		<ce>7</ce>
		<npm>7</npm>
		<lcom3>2.0</lcom3>
		<loc>114</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2653061224489796</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.285714285714286</amc>
		<cc>
			<method name="public org.apache.hadoop.io.FloatWritable evaluate(org.apache.hadoop.io.FloatWritable a, org.apache.hadoop.io.FloatWritable b)">3</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.hive.serde2.io.ByteWritable a, org.apache.hadoop.hive.serde2.io.ByteWritable b)">3</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable a, org.apache.hadoop.hive.serde2.io.DoubleWritable b)">3</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.hive.serde2.io.ShortWritable a, org.apache.hadoop.hive.serde2.io.ShortWritable b)">3</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.LongWritable a, org.apache.hadoop.io.LongWritable b)">3</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.IntWritable a, org.apache.hadoop.io.IntWritable b)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.ppd.OpProcFactory$TableScanPPD</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>12</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>11</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>47</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>22.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeFieldRequiredness$RequirednessTypes</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9166666666666666</lcom3>
		<loc>56</loc>
		<dam>0.25</dam>
		<moa>4</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>12.0</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeFieldRequiredness$RequirednessTypes[] values()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeFieldRequiredness$RequirednessTypes valueOf(String name)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters$ListConverter</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>16</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>98</loc>
		<dam>0.0</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>45.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.ListObjectInspector inputOI, org.apache.hadoop.hive.serde2.objectinspector.SettableListObjectInspector outputOI)">0</method>
			<method name="public Object convert(Object input)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.DelegationTokenIdentifier</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>7</ca>
		<ce>2</ce>
		<npm>3</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>22</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.25</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.io.Text owner, org.apache.hadoop.io.Text renewer, org.apache.hadoop.io.Text realUser)">0</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.io.Text getKind()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFParameterInfo</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>4</rfc>
		<lcom>6</lcom>
		<ca>6</ca>
		<ce>2</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract boolean isAllColumns()">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] getParameters()">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] getParameterObjectInspectors()">1</method>
			<method name="public abstract boolean isDistinct()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$queryOperator_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.ppd.ExprWalkerInfo$ExprInfo</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>38</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(boolean isCandidate, String alias, org.apache.hadoop.hive.ql.plan.ExprNodeDesc replacedNode)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.LineageInfo$DataContainer</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>2</ce>
		<npm>5</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>39</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.2</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.metastore.api.Table tab, org.apache.hadoop.hive.metastore.api.Partition part)">0</method>
			<method name="public org.apache.hadoop.hive.metastore.api.Table getTable()">1</method>
			<method name="public org.apache.hadoop.hive.metastore.api.Partition getPartition()">1</method>
			<method name="public boolean isPartition()">2</method>
			<method name="public void _init_(org.apache.hadoop.hive.metastore.api.Table tab)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$selectTrfmClause_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.DDLSemanticAnalyzer$TablePartition</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>10</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>41</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.parse.ASTNode tblPart)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFRadians</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>10</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.75</lcom3>
		<loc>31</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.666666666666666</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable i)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.KeyWrapper</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>2</noc>
		<cbo>6</cbo>
		<rfc>7</rfc>
		<lcom>15</lcom>
		<ca>4</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.5</amc>
		<cc>
			<method name="abstract void setHashKey()">1</method>
			<method name="abstract void copyKey(org.apache.hadoop.hive.ql.exec.KeyWrapper)">1</method>
			<method name="abstract void getNewKey(Object, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)">1</method>
			<method name="public void _init_()">0</method>
			<method name="abstract org.apache.hadoop.hive.ql.exec.KeyWrapper copyKey()">1</method>
			<method name="abstract Object[] getKeyArray()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$columnNameColonTypeList_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$groupByClause_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.io.DoubleWritable</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>71</cbo>
		<rfc>18</rfc>
		<lcom>0</lcom>
		<ca>68</ca>
		<ce>3</ce>
		<npm>10</npm>
		<lcom3>0.1</lcom3>
		<loc>104</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.32</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>8.363636363636363</amc>
		<cc>
			<method name="public boolean equals(Object o)">3</method>
			<method name="public int hashCode()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void write(java.io.DataOutput out)">1</method>
			<method name="public String toString()">1</method>
			<method name="public void set(double value)">1</method>
			<method name="public void readFields(java.io.DataInput in)">1</method>
			<method name="public int compareTo(Object o)">3</method>
			<method name="public double get()">1</method>
			<method name="public void _init_(double value)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.io.ShortWritable$Comparator</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>20</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.0</amc>
		<cc>
			<method name="public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2)">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ExprNodeGenericFuncEvaluator$EagerExprObject</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>1</npm>
		<lcom3>0.5</lcom3>
		<loc>27</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.ql.exec.ExprNodeGenericFuncEvaluator, org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator eval)">0</method>
			<method name="void evaluate()">1</method>
			<method name="public Object get()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$createFunctionStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.LateralViewForwardOperator</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>6</rfc>
		<lcom>6</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>4</npm>
		<lcom3>1.3333333333333333</lcom3>
		<loc>20</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.75</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void processOp(Object row, int tag)">1</method>
			<method name="public String getName()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.PhysicalPlanResolver</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>6</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext resolve(org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.server.THsHaServer</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>27</rfc>
		<lcom>13</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>2</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>128</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>17.0</amc>
		<cc>
			<method name="protected static java.util.concurrent.ExecutorService createInvokerPool(org.apache.thrift.server.THsHaServer$Args options)">1</method>
			<method name="protected Runnable getRunnable(org.apache.thrift.server.TNonblockingServer$FrameBuffer frameBuffer)">1</method>
			<method name="protected void gracefullyShutdownInvokerPool()">2</method>
			<method name="protected boolean requestInvoke(org.apache.thrift.server.TNonblockingServer$FrameBuffer frameBuffer)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void serve()">3</method>
			<method name="public void _init_(org.apache.thrift.server.THsHaServer$Args args)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ShowTablesDesc</name>
		<wmc>12</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>14</rfc>
		<lcom>26</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>12</npm>
		<lcom3>0.893939393939394</lcom3>
		<loc>79</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.083333333333333</amc>
		<cc>
			<method name="public String getDbName()">1</method>
			<method name="public void setPattern(String pattern)">1</method>
			<method name="public String getResFile()">1</method>
			<method name="public String getSchema()">1</method>
			<method name="public String getTable()">1</method>
			<method name="public void setResFile(String resFile)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(org.apache.hadoop.fs.Path resFile, String dbName, String pattern)">0</method>
			<method name="public void _init_(org.apache.hadoop.fs.Path resFile)">0</method>
			<method name="public String getPattern()">1</method>
			<method name="public void setDbName(String dbName)">1</method>
			<method name="public void _init_(org.apache.hadoop.fs.Path resFile, String dbName)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFCos</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>24</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable a)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>16</noc>
		<cbo>50</cbo>
		<rfc>14</rfc>
		<lcom>47</lcom>
		<ca>46</ca>
		<ce>4</ce>
		<npm>10</npm>
		<lcom3>0.85</lcom3>
		<loc>75</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.36666666666666664</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.636363636363637</amc>
		<cc>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector init(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode m, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] parameters)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public abstract org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer getNewAggregationBuffer()">1</method>
			<method name="public abstract void merge(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer, Object)">1</method>
			<method name="public abstract void reset(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer)">1</method>
			<method name="public void aggregate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object[] parameters)">1</method>
			<method name="public abstract Object terminatePartial(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer)">1</method>
			<method name="public abstract Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer)">1</method>
			<method name="public abstract void iterate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer, Object[])">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.SortedMergeBucketMapJoinOptimizer$SortedMergeBucketMapjoinProc</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>31</cbo>
		<rfc>67</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>31</ce>
		<npm>3</npm>
		<lcom3>0.6</lcom3>
		<loc>477</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.2692307692307692</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>78.16666666666667</amc>
		<cc>
			<method name="private boolean checkSortColsAndJoinCols(java.util.List sortCols, java.util.List joinCols)">5</method>
			<method name="private org.apache.hadoop.hive.ql.exec.SMBMapJoinOperator convertToSMBJoin(org.apache.hadoop.hive.ql.exec.MapJoinOperator mapJoinOp, String[] srcs)">5</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.optimizer.SortedMergeBucketMapJoinOptimizer, org.apache.hadoop.hive.ql.parse.ParseContext pctx)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.optimizer.SortedMergeBucketMapJoinOptimizer)">0</method>
			<method name="private boolean isTableSorted(org.apache.hadoop.hive.ql.parse.ParseContext pctx, org.apache.hadoop.hive.ql.exec.MapJoinOperator op, org.apache.hadoop.hive.ql.parse.QBJoinTree joinTree, String alias, int pos)">1</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager$DummyWatcher</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>6</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void process(org.apache.zookeeper.WatchedEvent event)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.lineage.OpProcFactory$DefaultLineage</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>7</noc>
		<cbo>20</cbo>
		<rfc>19</rfc>
		<lcom>1</lcom>
		<ca>8</ca>
		<ce>13</ce>
		<npm>2</npm>
		<lcom3>0.75</lcom3>
		<loc>75</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>23.333333333333332</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory$ColumnPrunerMapJoinProc</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>7</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>9</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>23</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.CommonJoinResolver$CommonJoinTaskDispatcher</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>29</cbo>
		<rfc>85</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>29</ce>
		<npm>2</npm>
		<lcom3>0.75</lcom3>
		<loc>510</loc>
		<dam>0.5</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.34</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>100.6</amc>
		<cc>
			<method name="public transient Object dispatch(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, Object[] nodeOutputs)">1</method>
			<method name="private void replaceTaskWithConditionalTask(org.apache.hadoop.hive.ql.exec.Task currTask, org.apache.hadoop.hive.ql.exec.ConditionalTask cndTsk, org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext physicalContext)">5</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.optimizer.physical.CommonJoinResolver, org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext context)">0</method>
			<method name="private org.apache.hadoop.hive.ql.exec.ConditionalTask processCurrentTask(org.apache.hadoop.hive.ql.exec.MapRedTask currTask, org.apache.hadoop.hive.ql.exec.ConditionalTask conditionalTask, org.apache.hadoop.hive.ql.Context context)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.JoinOperator getJoinOp(org.apache.hadoop.hive.ql.exec.MapRedTask task)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeConstMapContents</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.BucketMapJoinOptimizer$BucketMapjoinOptProcCtx</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>0.5</lcom3>
		<loc>18</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public java.util.Set getListOfRejectedMapjoins()">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.optimizer.BucketMapJoinOptimizer)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.SettableListObjectInspector</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>3</rfc>
		<lcom>3</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>3</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8888888888888888</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Object resize(Object, int)">1</method>
			<method name="public abstract Object create(int)">1</method>
			<method name="public abstract Object set(Object, int, Object)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.lineage.OpProcFactory$SelectLineage</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>17</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>16</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>59</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>28.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$dropPartitionSpec_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$selectClause_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.json.Cookie</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>28</rfc>
		<lcom>10</lcom>
		<ca>2</ca>
		<ce>3</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>287</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>56.4</amc>
		<cc>
			<method name="public static org.json.JSONObject toJSONObject(String arg0)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public static String escape(String arg0)">7</method>
			<method name="public static String unescape(String arg0)">7</method>
			<method name="public static String toString(org.json.JSONObject arg0)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.thrift.test.IntString</name>
		<wmc>41</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>91</rfc>
		<lcom>522</lcom>
		<ca>1</ca>
		<ce>15</ce>
		<npm>38</npm>
		<lcom3>0.7977272727272726</lcom3>
		<loc>801</loc>
		<dam>0.9090909090909091</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.15227272727272728</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>18.26829268292683</amc>
		<cc>
			<method name="public void clear()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public volatile org.apache.thrift.TBase deepCopy()">1</method>
			<method name="public void setMyintIsSet(boolean value)">1</method>
			<method name="public volatile Object getFieldValue(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="private void writeObject(java.io.ObjectOutputStream out)">1</method>
			<method name="public void read(org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public void write(org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public boolean isSet(org.apache.hadoop.hive.serde2.thrift.test.IntString$_Fields field)">3</method>
			<method name="public volatile boolean isSet(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="public void setMyint(int myint)">1</method>
			<method name="public void setMyString(String myString)">1</method>
			<method name="public void unsetMyString()">1</method>
			<method name="public boolean isSetMyString()">2</method>
			<method name="public org.apache.hadoop.hive.serde2.thrift.test.IntString deepCopy()">1</method>
			<method name="public void setMyStringIsSet(boolean value)">2</method>
			<method name="public String toString()">4</method>
			<method name="public int getUnderscore_int()">1</method>
			<method name="public void validate()">1</method>
			<method name="public boolean isSetMyint()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.thrift.test.IntString other)">0</method>
			<method name="public boolean equals(org.apache.hadoop.hive.serde2.thrift.test.IntString that)">17</method>
			<method name="public void _init_()">0</method>
			<method name="public volatile void setFieldValue(org.apache.thrift.TFieldIdEnum x0, Object x1)">1</method>
			<method name="public int compareTo(org.apache.hadoop.hive.serde2.thrift.test.IntString other)">11</method>
			<method name="public boolean isSetUnderscore_int()">1</method>
			<method name="public Object getFieldValue(org.apache.hadoop.hive.serde2.thrift.test.IntString$_Fields field)">2</method>
			<method name="public volatile int compareTo(Object x0)">1</method>
			<method name="public void unsetUnderscore_int()">1</method>
			<method name="public int hashCode()">1</method>
			<method name="public String getMyString()">1</method>
			<method name="private void readObject(java.io.ObjectInputStream in)">1</method>
			<method name="public int getMyint()">1</method>
			<method name="public void setUnderscore_intIsSet(boolean value)">1</method>
			<method name="public void setFieldValue(org.apache.hadoop.hive.serde2.thrift.test.IntString$_Fields field, Object value)">5</method>
			<method name="public void setUnderscore_int(int underscore_int)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.thrift.test.IntString$_Fields fieldForId(int fieldId)">1</method>
			<method name="public boolean equals(Object that)">3</method>
			<method name="public volatile org.apache.thrift.TFieldIdEnum fieldForId(int x0)">1</method>
			<method name="public void _init_(int myint, String myString, int underscore_int)">0</method>
			<method name="public void unsetMyint()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.ppd.ExprWalkerProcFactory$ColumnExprProcessor</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>16</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>94</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>30.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.JoinOperator</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>33</cbo>
		<rfc>69</rfc>
		<lcom>12</lcom>
		<ca>11</ca>
		<ce>22</ce>
		<npm>6</npm>
		<lcom3>0.8333333333333333</lcom3>
		<loc>534</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.3194444444444444</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>58.0</amc>
		<cc>
			<method name="public void closeOp(boolean abort)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="private void mvFileToFinalPath(String specPath, org.apache.hadoop.conf.Configuration hconf, boolean success, org.apache.commons.logging.Log log)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void jobClose(org.apache.hadoop.conf.Configuration hconf, boolean success, org.apache.hadoop.hive.ql.exec.JobCloseFeedBack feedBack)">1</method>
			<method name="public void endGroup()">1</method>
			<method name="public void processOp(Object row, int tag)">1</method>
			<method name="private void moveUpFiles(String specPath, org.apache.hadoop.conf.Configuration hconf, org.apache.commons.logging.Log log)">1</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$type_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.HiveException</name>
		<wmc>4</wmc>
		<dit>3</dit>
		<noc>3</noc>
		<cbo>204</cbo>
		<rfc>8</rfc>
		<lcom>6</lcom>
		<ca>204</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>20</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>1.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(Throwable cause)">0</method>
			<method name="public void _init_(String message, Throwable cause)">0</method>
			<method name="public void _init_(String message)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$orderByClause_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.DoubleObjectInspector</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>15</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract double get(Object)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>2</noc>
		<cbo>36</cbo>
		<rfc>43</rfc>
		<lcom>22</lcom>
		<ca>20</ca>
		<ce>16</ce>
		<npm>3</npm>
		<lcom3>0.95</lcom3>
		<loc>315</loc>
		<dam>0.7</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.234375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>32.888888888888886</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator mjop)">0</method>
			<method name="protected boolean hasAnyNulls(Object[] key)">7</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="protected boolean hasAnyNulls(org.apache.hadoop.hive.ql.exec.persistence.AbstractMapJoinKey key)">1</method>
			<method name="protected void fatalErrorMessage(StringBuilder errMsg, long counterCode)">1</method>
			<method name="protected boolean hasAnyNulls(java.util.ArrayList key)">7</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$rowFormatDelimited_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser</name>
		<wmc>233</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>246</cbo>
		<rfc>729</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>245</ce>
		<npm>232</npm>
		<lcom3>0.9889024101315987</lcom3>
		<loc>91776</loc>
		<dam>6.246096189881324E-4</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.33620689655172414</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>386.0171673819743</amc>
		<cc>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tableName_return tableName()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceNotExpression_return precedenceNotExpression()">2</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceAndOperator_return precedenceAndOperator()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$limitClause_return limitClause()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterProtectMode_return alterProtectMode()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tableRowFormatLinesIdentifier_return tableRowFormatLinesIdentifier()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterTblPartitionStatementSuffix_return alterTblPartitionStatementSuffix()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$importStatement_return importStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$viewPartition_return viewPartition()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$columnNameColonType_return columnNameColonType()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$showStatement_return showStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tableRowFormat_return tableRowFormat()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$function_return function()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$ifNotExists_return ifNotExists()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$dbPropertiesList_return dbPropertiesList()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$expressions_return expressions()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$privilegeIncludeColObject_return privilegeIncludeColObject()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tableProperties_return tableProperties()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tableOrPartition_return tableOrPartition()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tablePartitionPrefix_return tablePartitionPrefix()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceUnaryPrefixExpression_return precedenceUnaryPrefixExpression()">2</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tablePropertiesList_return tablePropertiesList()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterTableStatementSuffix_return alterTableStatementSuffix()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$execStatement_return execStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$indexTblName_return indexTblName()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$sortByClause_return sortByClause()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$partTypeExpr_return partTypeExpr()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceStarExpression_return precedenceStarExpression()">2</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$createDatabaseStatement_return createDatabaseStatement()">1</method>
			<method name="public void setTreeAdaptor(org.antlr.runtime.tree.TreeAdaptor adaptor)">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$destination_return destination()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$selectClause_return selectClause()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$grantPrivileges_return grantPrivileges()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$dropIndexStatement_return dropIndexStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$columnNameList_return columnNameList()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$havingCondition_return havingCondition()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tableSource_return tableSource()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$orderByClause_return orderByClause()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$constant_return constant()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedencePlusOperator_return precedencePlusOperator()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$privilegeObject_return privilegeObject()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$partitionVal_return partitionVal()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$fromSource_return fromSource()">2</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$privilegeList_return privilegeList()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$queryOperator_return queryOperator()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$columnNameOrderList_return columnNameOrderList()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$selectExpression_return selectExpression()">3</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixAddPartitions_return alterStatementSuffixAddPartitions()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$rowFormatSerde_return rowFormatSerde()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$createRoleStatement_return createRoleStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedencePlusExpression_return precedencePlusExpression()">2</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceBitwiseXorExpression_return precedenceBitwiseXorExpression()">2</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$dropViewStatement_return dropViewStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$body_return body()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$colType_return colType()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$statement_return statement()">3</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$loadStatement_return loadStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tableRowFormatCollItemsIdentifier_return tableRowFormatCollItemsIdentifier()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$columnRefOrder_return columnRefOrder()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tableRowFormatMapKeysIdentifier_return tableRowFormatMapKeysIdentifier()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceOrOperator_return precedenceOrOperator()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$createTableStatement_return createTableStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$dropFunctionStatement_return dropFunctionStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$autoRebuild_return autoRebuild()">1</method>
			<method name="public org.antlr.runtime.tree.TreeAdaptor getTreeAdaptor()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$kwRole_return kwRole()">1</method>
			<method name="public String[] getTokenNames()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$selectStatement_return selectStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$columnNameCommentList_return columnNameCommentList()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$databaseComment_return databaseComment()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$nullCondition_return nullCondition()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$indexPropertiesList_return indexPropertiesList()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$orReplace_return orReplace()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$lockMode_return lockMode()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tableFileFormat_return tableFileFormat()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterTblPartitionStatement_return alterTblPartitionStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceStarOperator_return precedenceStarOperator()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixClusterbySortby_return alterStatementSuffixClusterbySortby()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$whereClause_return whereClause()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$trfmClause_return trfmClause()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$columnNameType_return columnNameType()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$indexPropertiesPrefixed_return indexPropertiesPrefixed()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixProperties_return alterStatementSuffixProperties()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$selectItem_return selectItem()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tableRowFormatFieldIdentifier_return tableRowFormatFieldIdentifier()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$lockStatement_return lockStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixUnArchive_return alterStatementSuffixUnArchive()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$havingClause_return havingClause()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$dropPartitionVal_return dropPartitionVal()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$revokeRole_return revokeRole()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$fromClause_return fromClause()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tableAllColumns_return tableAllColumns()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$privilegeType_return privilegeType()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixDropPartitions_return alterStatementSuffixDropPartitions()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$selectExpressionList_return selectExpressionList()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixFileFormat_return alterStatementSuffixFileFormat()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$regular_body_return regular_body()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$exportStatement_return exportStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixRename_return alterStatementSuffixRename()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$hintList_return hintList()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$dropDatabaseStatement_return dropDatabaseStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$switchDatabaseStatement_return switchDatabaseStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$insertClause_return insertClause()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$clusterByClause_return clusterByClause()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$expressionList_return expressionList()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceBitwiseXorOperator_return precedenceBitwiseXorOperator()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$structType_return structType()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$type_return type()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$groupByClause_return groupByClause()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterViewStatementSuffix_return alterViewStatementSuffix()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$recordReader_return recordReader()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tabTypeExpr_return tabTypeExpr()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$joinToken_return joinToken()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$fileFormat_return fileFormat()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$rowFormat_return rowFormat()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterDatabaseSuffixProperties_return alterDatabaseSuffixProperties()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$descFuncNames_return descFuncNames()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$rowFormatDelimited_return rowFormatDelimited()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$columnNameColonTypeList_return columnNameColonTypeList()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceNotOperator_return precedenceNotOperator()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tableOrColumn_return tableOrColumn()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$descStatement_return descStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$unionType_return unionType()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterViewSuffixProperties_return alterViewSuffixProperties()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tableBuckets_return tableBuckets()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$groupByExpression_return groupByExpression()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$dropPartitionSpec_return dropPartitionSpec()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tableBucketSample_return tableBucketSample()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$mapType_return mapType()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$columnNameTypeList_return columnNameTypeList()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$listType_return listType()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$caseExpression_return caseExpression()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$functionName_return functionName()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterIndexStatementSuffix_return alterIndexStatementSuffix()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$createFunctionStatement_return createFunctionStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$unlockStatement_return unlockStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixRenamePart_return alterStatementSuffixRenamePart()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixProtectMode_return alterStatementSuffixProtectMode()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$showStmtIdentifier_return showStmtIdentifier()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixArchive_return alterStatementSuffixArchive()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$indexComment_return indexComment()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceBitwiseOrExpression_return precedenceBitwiseOrExpression()">2</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$columnNameOrder_return columnNameOrder()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$primitiveType_return primitiveType()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceFieldExpression_return precedenceFieldExpression()">3</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$explainStatement_return explainStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$selectTrfmClause_return selectTrfmClause()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$privlegeDef_return privlegeDef()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$dropTableStatement_return dropTableStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixAddCol_return alterStatementSuffixAddCol()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$expression_return expression()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$atomExpression_return atomExpression()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixMergeFiles_return alterStatementSuffixMergeFiles()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$subQuerySource_return subQuerySource()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$withOption_return withOption()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixSerdeProperties_return alterStatementSuffixSerdeProperties()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$indexProperties_return indexProperties()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$joinSource_return joinSource()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$kwUser_return kwUser()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceAndExpression_return precedenceAndExpression()">2</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$ddlStatement_return ddlStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixTouch_return alterStatementSuffixTouch()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$dbProperties_return dbProperties()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceUnaryOperator_return precedenceUnaryOperator()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$queryStatement_return queryStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$uniqueJoinSource_return uniqueJoinSource()">2</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$dropPartitionOperator_return dropPartitionOperator()">1</method>
			<method name="public String getGrammarFileName()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterStatement_return alterStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$booleanValue_return booleanValue()">3</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixLocation_return alterStatementSuffixLocation()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceBitwiseOrOperator_return precedenceBitwiseOrOperator()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$dropRoleStatement_return dropRoleStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$keyValueProperty_return keyValueProperty()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$uniqueJoinExpr_return uniqueJoinExpr()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$principalSpecification_return principalSpecification()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$kwInner_return kwInner()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$ifExists_return ifExists()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$queryStatementExpression_return queryStatementExpression()">2</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$createViewStatement_return createViewStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tablePartition_return tablePartition()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$splitSample_return splitSample()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$hintName_return hintName()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$hintArgs_return hintArgs()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$colTypeList_return colTypeList()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$columnName_return columnName()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$dbLocation_return dbLocation()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$revokePrivileges_return revokePrivileges()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tableLocation_return tableLocation()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$selectList_return selectList()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$showRoleGrants_return showRoleGrants()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$grantRole_return grantRole()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$viewName_return viewName()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$metastoreCheck_return metastoreCheck()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$searchCondition_return searchCondition()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$hintArgName_return hintArgName()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$analyzeStatement_return analyzeStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$hintClause_return hintClause()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tableComment_return tableComment()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$columnNameComment_return columnNameComment()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$uniqueJoinToken_return uniqueJoinToken()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tablePropertiesPrefixed_return tablePropertiesPrefixed()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$sysFuncNames_return sysFuncNames()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterProtectModeMode_return alterProtectModeMode()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixRenameCol_return alterStatementSuffixRenameCol()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tableAlias_return tableAlias()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceEqualExpression_return precedenceEqualExpression()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$castExpression_return castExpression()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceAmpersandExpression_return precedenceAmpersandExpression()">2</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$principalName_return principalName()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$recordWriter_return recordWriter()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceUnarySuffixExpression_return precedenceUnarySuffixExpression()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$lateralView_return lateralView()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceEqualOperator_return precedenceEqualOperator()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceAmpersandOperator_return precedenceAmpersandOperator()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$partitionLocation_return partitionLocation()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceOrExpression_return precedenceOrExpression()">2</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$charSetStringLiteral_return charSetStringLiteral()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementChangeColPosition_return alterStatementChangeColPosition()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$restrictOrCascade_return restrictOrCascade()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$aliasList_return aliasList()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$distributeByClause_return distributeByClause()">1</method>
			<method name="public void _init_(org.antlr.runtime.TokenStream input)">0</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$precedenceEqualNegatableOperator_return precedenceEqualNegatableOperator()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$hintItem_return hintItem()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$tableSample_return tableSample()">3</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$createIndexStatement_return createIndexStatement()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$alterDatabaseStatementSuffix_return alterDatabaseStatementSuffix()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$stringLiteralSequence_return stringLiteralSequence()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$partitionSpec_return partitionSpec()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$showGrants_return showGrants()">1</method>
			<method name="public final org.apache.hadoop.hive.ql.parse.HiveParser$whenExpression_return whenExpression()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.JavaByteObjectInspector</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>9</rfc>
		<lcom>10</lcom>
		<ca>2</ca>
		<ce>5</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>30</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public Object set(Object o, byte value)">1</method>
			<method name="void _init_()">0</method>
			<method name="public Object getPrimitiveWritableObject(Object o)">2</method>
			<method name="public byte get(Object o)">1</method>
			<method name="public Object create(byte value)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPEqualOrGreaterThan</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>18</cbo>
		<rfc>17</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>17</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>202</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>100.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.columnar.ColumnarStructBase</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>2</noc>
		<cbo>15</cbo>
		<rfc>26</rfc>
		<lcom>1</lcom>
		<ca>7</ca>
		<ce>9</ce>
		<npm>5</npm>
		<lcom3>0.7222222222222223</lcom3>
		<loc>212</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.35714285714285715</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>28.857142857142858</amc>
		<cc>
			<method name="public long getRawDataSerializedSize()">2</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.columnar.BytesRefArrayWritable cols)">3</method>
			<method name="public java.util.ArrayList getFieldsAsList()">3</method>
			<method name="protected abstract int getLength(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector, org.apache.hadoop.hive.serde2.lazy.ByteArrayRef, int, int)">1</method>
			<method name="public Object getField(int fieldID)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, java.util.ArrayList notSkippedColumnIDs)">0</method>
			<method name="protected abstract org.apache.hadoop.hive.serde2.lazy.LazyObjectBase createLazyObjectBase(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ComparisonOpMethodResolver</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>21</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>211</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>68.66666666666667</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="public java.lang.reflect.Method getEvalMethod(java.util.List argTypeInfos)">1</method>
			<method name="public void _init_(Class udfClass)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.RCFile</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>14</rfc>
		<lcom>6</lcom>
		<ca>2</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>1.1666666666666667</lcom3>
		<loc>91</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.25</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.8</amc>
		<cc>
			<method name="static org.apache.commons.logging.Log access$900()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="static byte[] access$700()">1</method>
			<method name="public static transient org.apache.hadoop.io.SequenceFile$Metadata createMetadata(org.apache.hadoop.io.Text[] values)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.xml.UDFXPathBoolean</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>18</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.5</amc>
		<cc>
			<method name="public boolean evaluate(String xml, String path)">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.tools.LineageInfo</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>31</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>14</ce>
		<npm>6</npm>
		<lcom3>0.2</lcom3>
		<loc>194</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2619047619047619</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>31.0</amc>
		<cc>
			<method name="public java.util.TreeSet getOutputTableList()">1</method>
			<method name="public void getLineageInfo(String query)">1</method>
			<method name="public static void main(String[] args)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.TreeSet getInputTableList()">1</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.Hive</name>
		<wmc>89</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>83</cbo>
		<rfc>325</rfc>
		<lcom>3642</lcom>
		<ca>36</ca>
		<ce>51</ce>
		<npm>74</npm>
		<lcom3>0.8181818181818182</lcom3>
		<loc>3580</loc>
		<dam>0.8333333333333334</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.11621900826446281</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>39.157303370786515</amc>
		<cc>
			<method name="public static void closeCurrent()">1</method>
			<method name="public boolean grantPrivileges(org.apache.hadoop.hive.metastore.api.PrivilegeBag privileges)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public java.util.List getIndexes(String dbName, String tblName, short max)">1</method>
			<method name="private java.util.List getGroupNames()">3</method>
			<method name="public void alterDatabase(String dbName, org.apache.hadoop.hive.metastore.api.Database db)">1</method>
			<method name="private void _init_(org.apache.hadoop.hive.conf.HiveConf c)">0</method>
			<method name="private org.apache.hadoop.hive.metastore.IMetaStoreClient createMetaStoreClient()">1</method>
			<method name="public java.util.List showPrivilegeGrant(org.apache.hadoop.hive.metastore.api.HiveObjectType objectType, String principalName, org.apache.hadoop.hive.metastore.api.PrincipalType principalType, String dbName, String tableName, java.util.List partValues, String columnName)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.metadata.Hive get(org.apache.hadoop.hive.conf.HiveConf c, boolean needsRefresh)">1</method>
			<method name="public java.util.ArrayList loadDynamicPartitions(org.apache.hadoop.fs.Path loadPath, String tableName, java.util.Map partSpec, boolean replace, int numDP, boolean holdDDLTime)">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Partition getPartition(org.apache.hadoop.hive.ql.metadata.Table tbl, java.util.Map partSpec, boolean forceCreate, String partPath, boolean inheritTableSpecs)">1</method>
			<method name="public org.apache.hadoop.hive.metastore.api.Database getDatabase(String dbName)">1</method>
			<method name="private org.apache.hadoop.hive.metastore.IMetaStoreClient getMSC()">1</method>
			<method name="public void alterPartition(String tblName, org.apache.hadoop.hive.ql.metadata.Partition newPart)">1</method>
			<method name="public void createTable(String tableName, java.util.List columns, java.util.List partCols, Class fileInputFormat, Class fileOutputFormat)">1</method>
			<method name="public void alterIndex(String dbName, String baseTblName, String idxName, org.apache.hadoop.hive.metastore.api.Index newIdx)">1</method>
			<method name="public java.util.List getTablesForDb(String database, String tablePattern)">1</method>
			<method name="public java.util.List getPartitions(org.apache.hadoop.hive.ql.metadata.Table tbl, java.util.Map partialPartSpec, short limit)">1</method>
			<method name="protected static void replaceFiles(org.apache.hadoop.fs.Path srcf, org.apache.hadoop.fs.Path destf, org.apache.hadoop.fs.Path oldPath, org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="public org.apache.hadoop.hive.metastore.api.Index getIndex(String dbName, String baseTableName, String indexName)">1</method>
			<method name="public java.util.List getDatabasesByPattern(String databasePattern)">1</method>
			<method name="public org.apache.hadoop.hive.metastore.api.Index getIndex(String baseTableName, String indexName)">1</method>
			<method name="public void createTable(org.apache.hadoop.hive.ql.metadata.Table tbl, boolean ifNotExists)">1</method>
			<method name="public void loadTable(org.apache.hadoop.fs.Path loadPath, String tableName, boolean replace, boolean holdDDLTime)">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Table getTable(String tableName, boolean throwException)">1</method>
			<method name="public java.util.List getAllRoleNames()">1</method>
			<method name="public java.util.List getPartitions(org.apache.hadoop.hive.ql.metadata.Table tbl, java.util.Map partialPartSpec)">1</method>
			<method name="public void loadPartition(org.apache.hadoop.fs.Path loadPath, String tableName, java.util.Map partSpec, boolean replace, boolean holdDDLTime, boolean inheritTableSpecs)">1</method>
			<method name="public java.util.List getTablesByPattern(String dbName, String tablePattern)">1</method>
			<method name="public java.util.List listRoles(String userName, org.apache.hadoop.hive.metastore.api.PrincipalType principalType)">1</method>
			<method name="public java.util.List getPartitionsByNames(org.apache.hadoop.hive.ql.metadata.Table tbl, java.util.Map partialPartSpec)">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Partition createPartition(org.apache.hadoop.hive.ql.metadata.Table tbl, java.util.Map partSpec, org.apache.hadoop.fs.Path location, java.util.Map partParams, String inputFormat, String outputFormat, int numBuckets, java.util.List cols, String serializationLib, java.util.Map serdeParams, java.util.List bucketCols, java.util.List sortCols)">1</method>
			<method name="public void dropDatabase(String name, boolean deleteData, boolean ignoreUnknownDb, boolean cascade)">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Table getTable(String tableName)">1</method>
			<method name="private static java.util.List getPvals(java.util.List partCols, java.util.Map partSpec)">3</method>
			<method name="public void alterTable(String tblName, org.apache.hadoop.hive.ql.metadata.Table newTbl)">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Table getTable(String dbName, String tableName, boolean throwException)">1</method>
			<method name="public void createIndex(String tableName, String indexName, String indexHandlerClass, java.util.List indexedCols, String indexTblName, boolean deferredRebuild, String inputFormat, String outputFormat, String serde, String storageHandler, String location, java.util.Map idxProps, java.util.Map tblProps, java.util.Map serdeProps, String collItemDelim, String fieldDelim, String fieldEscape, String lineDelim, String mapKeyDelim, String indexComment)">1</method>
			<method name="public java.util.List getAllTables(String dbName)">1</method>
			<method name="public boolean databaseExists(String dbName)">1</method>
			<method name="private static void checkPaths(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.FileStatus[] srcs, org.apache.hadoop.fs.Path destf, boolean replace)">1</method>
			<method name="public java.util.List showRoleGrant(String principalName, org.apache.hadoop.hive.metastore.api.PrincipalType principalType)">1</method>
			<method name="public java.util.List getPartitionNames(String dbName, String tblName, java.util.Map partSpec, short max)">1</method>
			<method name="public java.util.List getPartitionsByNames(org.apache.hadoop.hive.ql.metadata.Table tbl, java.util.List partNames)">1</method>
			<method name="public boolean dropPartition(String tblName, java.util.List part_vals, boolean deleteData)">1</method>
			<method name="protected static void copyFiles(org.apache.hadoop.fs.Path srcf, org.apache.hadoop.fs.Path destf, org.apache.hadoop.fs.FileSystem fs)">1</method>
			<method name="public boolean revokePrivileges(org.apache.hadoop.hive.metastore.api.PrivilegeBag privileges)">1</method>
			<method name="public java.util.List getPartitionsByFilter(org.apache.hadoop.hive.ql.metadata.Table tbl, String filter)">1</method>
			<method name="public org.apache.hadoop.hive.metastore.api.Index getIndex(String qualifiedIndexName)">3</method>
			<method name="public static org.apache.hadoop.hive.ql.metadata.Hive get(org.apache.hadoop.hive.conf.HiveConf c)">1</method>
			<method name="public java.util.List getTablesByPattern(String tablePattern)">1</method>
			<method name="public boolean revokeRole(String roleName, String userName, org.apache.hadoop.hive.metastore.api.PrincipalType principalType)">1</method>
			<method name="public void createRole(String roleName, String ownerName)">1</method>
			<method name="public void dropDatabase(String name)">1</method>
			<method name="private String getUserName()">3</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Table getTable(String dbName, String tableName)">1</method>
			<method name="static org.apache.hadoop.hive.conf.HiveConf access$100(org.apache.hadoop.hive.ql.metadata.Hive x0)">1</method>
			<method name="public void createTable(String tableName, java.util.List columns, java.util.List partCols, Class fileInputFormat, Class fileOutputFormat, int bucketCount, java.util.List bucketCols)">1</method>
			<method name="public java.util.List getPartitionNames(String dbName, String tblName, short max)">1</method>
			<method name="public java.util.List getAllTables()">1</method>
			<method name="public java.util.List getPartitions(org.apache.hadoop.hive.ql.metadata.Table tbl)">1</method>
			<method name="public void dropDatabase(String name, boolean deleteData, boolean ignoreUnknownDb)">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Partition createPartition(org.apache.hadoop.hive.ql.metadata.Table tbl, java.util.Map partSpec)">1</method>
			<method name="public boolean dropPartition(String db_name, String tbl_name, java.util.List part_vals, boolean deleteData)">1</method>
			<method name="public void dropRole(String roleName)">1</method>
			<method name="public void setCurrentDatabase(String currentDatabase)">1</method>
			<method name="static org.apache.commons.logging.Log access$200()">1</method>
			<method name="private static String[] getQualifiedNames(String qualifiedName)">1</method>
			<method name="public org.apache.hadoop.hive.metastore.api.PrincipalPrivilegeSet get_privilege_set(org.apache.hadoop.hive.metastore.api.HiveObjectType objectType, String db_name, String table_name, java.util.List part_values, String column_name, String user_name, java.util.List group_names)">1</method>
			<method name="public java.util.List getPartitionNames(String tblName, short max)">1</method>
			<method name="public boolean dropIndex(String db_name, String tbl_name, String index_name, boolean deleteData)">1</method>
			<method name="public boolean grantRole(String roleName, String userName, org.apache.hadoop.hive.metastore.api.PrincipalType principalType, String grantor, org.apache.hadoop.hive.metastore.api.PrincipalType grantorType, boolean grantOption)">1</method>
			<method name="public void createDatabase(org.apache.hadoop.hive.metastore.api.Database db)">1</method>
			<method name="private void close()">2</method>
			<method name="public void dropTable(String tableName)">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Table newTable(String tableName)">3</method>
			<method name="public org.apache.hadoop.hive.conf.HiveConf getConf()">1</method>
			<method name="public void createTable(org.apache.hadoop.hive.ql.metadata.Table tbl)">1</method>
			<method name="public java.util.List getAllDatabases()">1</method>
			<method name="public String getCurrentDatabase()">2</method>
			<method name="public void dropTable(String dbName, String tableName)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.metadata.Hive get()">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Partition getPartition(org.apache.hadoop.hive.ql.metadata.Table tbl, java.util.Map partSpec, boolean forceCreate)">1</method>
			<method name="static void access$000(org.apache.hadoop.hive.ql.metadata.Hive x0)">1</method>
			<method name="public void renamePartition(org.apache.hadoop.hive.ql.metadata.Table tbl, java.util.Map oldPartSpec, org.apache.hadoop.hive.ql.metadata.Partition newPart)">1</method>
			<method name="public void dropTable(String dbName, String tableName, boolean deleteData, boolean ignoreUnknownTab)">1</method>
			<method name="public void createDatabase(org.apache.hadoop.hive.metastore.api.Database db, boolean ifNotExist)">1</method>
			<method name="public static java.util.List getFieldsFromDeserializer(String name, org.apache.hadoop.hive.serde2.Deserializer serde)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat$SymlinkTextInputSplit</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>9</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>5</npm>
		<lcom3>0.0</lcom3>
		<loc>56</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.36</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.0</amc>
		<cc>
			<method name="public org.apache.hadoop.mapred.FileSplit getTargetSplit()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void write(java.io.DataOutput out)">1</method>
			<method name="public void _init_(org.apache.hadoop.fs.Path symlinkPath, org.apache.hadoop.mapred.FileSplit split)">0</method>
			<method name="public void readFields(java.io.DataInput in)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.FileSinkOperator$FSPaths</name>
		<wmc>14</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>37</rfc>
		<lcom>43</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>12</npm>
		<lcom3>0.8021978021978022</lcom3>
		<loc>294</loc>
		<dam>0.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.2767857142857143</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.FileSinkOperator)">0</method>
			<method name="public org.apache.hadoop.fs.Path getFinalPath(String taskId)">1</method>
			<method name="public org.apache.hadoop.fs.Path getOutPath(String taskId, org.apache.hadoop.fs.Path tmp)">1</method>
			<method name="static void access$300(org.apache.hadoop.hive.ql.exec.FileSinkOperator$FSPaths x0, org.apache.hadoop.fs.FileSystem x1)">1</method>
			<method name="public org.apache.hadoop.fs.Path getTaskOutPath(String taskId)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.FileSinkOperator, org.apache.hadoop.fs.Path specPath)">0</method>
			<method name="public void appendTmpPath(String dp)">1</method>
			<method name="public org.apache.hadoop.fs.Path getOutPath(String taskId)">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter[] getOutWriters()">1</method>
			<method name="private void commit(org.apache.hadoop.fs.FileSystem fs)">1</method>
			<method name="public void abortWriters(org.apache.hadoop.fs.FileSystem fs, boolean abort, boolean delete)">1</method>
			<method name="public void setOutWriters(org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter[] out)">1</method>
			<method name="public void closeWriters(boolean abort)">1</method>
			<method name="public org.apache.hadoop.fs.Path getFinalPath(String taskId, org.apache.hadoop.fs.Path tmpPath, String extension)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.Operator</name>
		<wmc>60</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>21</cbo>
		<rfc>137</rfc>
		<lcom>1064</lcom>
		<ca>2</ca>
		<ce>19</ce>
		<npm>57</npm>
		<lcom3>0.8295114656031903</lcom3>
		<loc>1603</loc>
		<dam>0.9411764705882353</dam>
		<moa>8</moa>
		<mfa>0.0</mfa>
		<cam>0.11743341404358354</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>25.433333333333334</amc>
		<cc>
			<method name="public boolean isSetOperatorCounters()">2</method>
			<method name="public boolean isStarted()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void setDoneIsSet(boolean value)">1</method>
			<method name="public void unsetOperatorType()">1</method>
			<method name="public volatile boolean isSet(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="public void setOperatorTypeIsSet(boolean value)">2</method>
			<method name="public int getOperatorCountersSize()">2</method>
			<method name="public boolean equals(org.apache.hadoop.hive.ql.plan.api.Operator that)">32</method>
			<method name="public void setFieldValue(org.apache.hadoop.hive.ql.plan.api.Operator$_Fields field, Object value)">8</method>
			<method name="public void unsetStarted()">1</method>
			<method name="public Object getFieldValue(org.apache.hadoop.hive.ql.plan.api.Operator$_Fields field)">2</method>
			<method name="public boolean isSetOperatorId()">2</method>
			<method name="public boolean isSetStarted()">1</method>
			<method name="public void validate()">1</method>
			<method name="public boolean isDone()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void unsetOperatorCounters()">1</method>
			<method name="public void setStartedIsSet(boolean value)">1</method>
			<method name="public boolean isSetOperatorAttributes()">2</method>
			<method name="public java.util.Map getOperatorCounters()">1</method>
			<method name="public volatile void setFieldValue(org.apache.thrift.TFieldIdEnum x0, Object x1)">1</method>
			<method name="public int getOperatorAttributesSize()">2</method>
			<method name="public java.util.Map getOperatorAttributes()">1</method>
			<method name="public volatile int compareTo(Object x0)">1</method>
			<method name="public boolean isSet(org.apache.hadoop.hive.ql.plan.api.Operator$_Fields field)">3</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.Operator$_Fields fieldForId(int fieldId)">1</method>
			<method name="public void _init_(String operatorId, org.apache.hadoop.hive.ql.plan.api.OperatorType operatorType, java.util.Map operatorAttributes, java.util.Map operatorCounters, boolean done, boolean started)">0</method>
			<method name="public void putToOperatorAttributes(String key, String val)">2</method>
			<method name="public boolean equals(Object that)">3</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.api.Operator other)">0</method>
			<method name="public boolean isSetDone()">1</method>
			<method name="public void unsetOperatorAttributes()">1</method>
			<method name="public void clear()">1</method>
			<method name="public int compareTo(org.apache.hadoop.hive.ql.plan.api.Operator other)">20</method>
			<method name="public void setStarted(boolean started)">1</method>
			<method name="public void setDone(boolean done)">1</method>
			<method name="public volatile org.apache.thrift.TBase deepCopy()">1</method>
			<method name="public void setOperatorIdIsSet(boolean value)">2</method>
			<method name="public volatile Object getFieldValue(org.apache.thrift.TFieldIdEnum x0)">1</method>
			<method name="private void writeObject(java.io.ObjectOutputStream out)">1</method>
			<method name="public void read(org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public void write(org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public void putToOperatorCounters(String key, long val)">2</method>
			<method name="public String getOperatorId()">1</method>
			<method name="public void setOperatorCounters(java.util.Map operatorCounters)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getOperatorType()">1</method>
			<method name="public boolean isSetOperatorType()">2</method>
			<method name="public String toString()">10</method>
			<method name="public void setOperatorAttributesIsSet(boolean value)">2</method>
			<method name="public void setOperatorCountersIsSet(boolean value)">2</method>
			<method name="public void setOperatorType(org.apache.hadoop.hive.ql.plan.api.OperatorType operatorType)">1</method>
			<method name="public void setOperatorId(String operatorId)">1</method>
			<method name="public void unsetOperatorId()">1</method>
			<method name="public void unsetDone()">1</method>
			<method name="public int hashCode()">1</method>
			<method name="private void readObject(java.io.ObjectInputStream in)">1</method>
			<method name="public void setOperatorAttributes(java.util.Map operatorAttributes)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.Operator deepCopy()">1</method>
			<method name="public volatile org.apache.thrift.TFieldIdEnum fieldForId(int x0)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.MapJoinFactory</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>21</rfc>
		<lcom>26</lcom>
		<ca>5</ca>
		<ce>8</ce>
		<npm>6</npm>
		<lcom3>0.8571428571428571</lcom3>
		<loc>87</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.14285714285714285</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.75</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getTableScanMapJoin()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getMapJoin()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getReduceSinkMapJoin()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getUnionMapJoin()">1</method>
			<method name="public static int getPositionParent(org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator op, java.util.Stack stack)">6</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getMapJoinMapJoin()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.IndexSearchCondition</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>12</rfc>
		<lcom>15</lcom>
		<ca>2</ca>
		<ce>3</ce>
		<npm>10</npm>
		<lcom3>0.75</lcom3>
		<loc>61</loc>
		<dam>1.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.36</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.7</amc>
		<cc>
			<method name="public void setConstantDesc(org.apache.hadoop.hive.ql.plan.ExprNodeConstantDesc constantDesc)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ExprNodeDesc getComparisonExpr()">1</method>
			<method name="public void setColumnDesc(org.apache.hadoop.hive.ql.plan.ExprNodeColumnDesc columnDesc)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.ExprNodeColumnDesc columnDesc, String comparisonOp, org.apache.hadoop.hive.ql.plan.ExprNodeConstantDesc constantDesc, org.apache.hadoop.hive.ql.plan.ExprNodeDesc comparisonExpr)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ExprNodeColumnDesc getColumnDesc()">1</method>
			<method name="public void setComparisonOp(String comparisonOp)">1</method>
			<method name="public String getComparisonOp()">1</method>
			<method name="public String toString()">1</method>
			<method name="public void setComparisonExpr(org.apache.hadoop.hive.ql.plan.ExprNodeDesc comparisonExpr)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ExprNodeConstantDesc getConstantDesc()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tablePartition_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.index.IndexWhereTaskDispatcher$1</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>1</npm>
		<lcom3>1.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.ql.optimizer.physical.index.IndexWhereTaskDispatcher)">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFReverse</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>9</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>106</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>34.0</amc>
		<cc>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text s)">4</method>
			<method name="public void _init_()">0</method>
			<method name="private void reverse(byte[] arr, int first, int last)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.SimpleNode</name>
		<wmc>12</wmc>
		<dit>1</dit>
		<noc>32</noc>
		<cbo>36</cbo>
		<rfc>18</rfc>
		<lcom>50</lcom>
		<ca>34</ca>
		<ce>3</ce>
		<npm>12</npm>
		<lcom3>0.8181818181818182</lcom3>
		<loc>141</loc>
		<dam>1.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.35</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.416666666666666</amc>
		<cc>
			<method name="public void dump(String prefix)">4</method>
			<method name="public org.apache.hadoop.hive.serde2.dynamic_type.Node jjtGetChild(int i)">1</method>
			<method name="public int jjtGetNumChildren()">2</method>
			<method name="public String toString(String prefix)">1</method>
			<method name="public void jjtAddChild(org.apache.hadoop.hive.serde2.dynamic_type.Node n, int i)">3</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int i)">0</method>
			<method name="public String toString()">1</method>
			<method name="public void jjtClose()">1</method>
			<method name="public void jjtOpen()">1</method>
			<method name="public void jjtSetParent(org.apache.hadoop.hive.serde2.dynamic_type.Node n)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.dynamic_type.Node jjtGetParent()">1</method>
			<method name="public void _init_(int i)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$createTableStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.objectinspector.LazySimpleStructObjectInspector</name>
		<wmc>17</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>35</rfc>
		<lcom>98</lcom>
		<ca>3</ca>
		<ce>10</ce>
		<npm>12</npm>
		<lcom3>0.765625</lcom3>
		<loc>263</loc>
		<dam>0.125</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.296875</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.0</amc>
		<cc>
			<method name="protected void init(java.util.List fields, byte separator, org.apache.hadoop.io.Text nullSequence)">2</method>
			<method name="public org.apache.hadoop.io.Text getNullSequence()">1</method>
			<method name="public Object getStructFieldData(Object data, org.apache.hadoop.hive.serde2.objectinspector.StructField fieldRef)">5</method>
			<method name="public boolean getLastColumnTakesRest()">1</method>
			<method name="protected void _init_(java.util.List structFieldNames, java.util.List structFieldObjectInspectors, byte separator, org.apache.hadoop.io.Text nullSequence, boolean lastColumnTakesRest, boolean escaped, byte escapeChar)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public final org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
			<method name="public java.util.List getStructFieldsDataAsList(Object data)">2</method>
			<method name="public java.util.List getAllStructFieldRefs()">1</method>
			<method name="public boolean isEscaped()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.StructField getStructFieldRef(String fieldName)">1</method>
			<method name="public void _init_(java.util.List structFieldNames, java.util.List structFieldObjectInspectors, java.util.List structFieldComments, byte separator, org.apache.hadoop.io.Text nullSequence, boolean lastColumnTakesRest, boolean escaped, byte escapeChar)">0</method>
			<method name="public byte getSeparator()">1</method>
			<method name="protected void init(java.util.List structFieldNames, java.util.List structFieldObjectInspectors, java.util.List structFieldComments, byte separator, org.apache.hadoop.io.Text nullSequence, boolean lastColumnTakesRest, boolean escaped, byte escapeChar)">8</method>
			<method name="protected void _init_(java.util.List fields, byte separator, org.apache.hadoop.io.Text nullSequence)">0</method>
			<method name="public String getTypeName()">1</method>
			<method name="public byte getEscapeChar()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPNotEqual$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>56</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>54.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.ColumnSet</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>5</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>17</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.333333333333333</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(java.util.ArrayList col)">0</method>
			<method name="public String toString()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.server.TThreadPoolServer$WorkerProcess</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>12</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>11</ce>
		<npm>1</npm>
		<lcom3>0.0</lcom3>
		<loc>95</loc>
		<dam>0.5</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>30.0</amc>
		<cc>
			<method name="public void run()">3</method>
			<method name="void _init_(org.apache.thrift.server.TThreadPoolServer x0, org.apache.thrift.transport.TTransport x1, org.apache.thrift.server.TThreadPoolServer$1 x2)">0</method>
			<method name="private void _init_(org.apache.thrift.server.TThreadPoolServer, org.apache.thrift.transport.TTransport client)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeStart</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.AggregationDesc</name>
		<wmc>13</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>21</rfc>
		<lcom>34</lcom>
		<ca>7</ca>
		<ce>3</ce>
		<npm>13</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>130</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.2948717948717949</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.538461538461538</amc>
		<cc>
			<method name="public boolean getDistinct()">1</method>
			<method name="public void setGenericUDAFEvaluator(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator genericUDAFEvaluator)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.ArrayList getParameters()">1</method>
			<method name="public void setMode(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode mode)">1</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getGenericUDAFEvaluator()">1</method>
			<method name="public void setGenericUDAFName(String genericUDAFName)">1</method>
			<method name="public String getExprString()">4</method>
			<method name="public void setParameters(java.util.ArrayList parameters)">1</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode getMode()">1</method>
			<method name="public void setDistinct(boolean distinct)">1</method>
			<method name="public void _init_(String genericUDAFName, org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator genericUDAFEvaluator, java.util.ArrayList parameters, boolean distinct, org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode mode)">0</method>
			<method name="public String getGenericUDAFName()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.index.IndexWhereProcCtx</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>7</rfc>
		<lcom>2</lcom>
		<ca>2</ca>
		<ce>5</ce>
		<npm>3</npm>
		<lcom3>0.7777777777777777</lcom3>
		<loc>27</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.exec.Task getCurrentTask()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.Task task, org.apache.hadoop.hive.ql.parse.ParseContext parseCtx)">0</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext getParseContext()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.TypeCheckProcFactory$StrExprProcessor</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>21</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>14</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>83</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>40.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ExtractOperator</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>11</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>3</npm>
		<lcom3>1.0</lcom3>
		<loc>40</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.5</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void processOp(Object row, int tag)">1</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryShort</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>14</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>1</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>53</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.0</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableShortObjectInspector oi)">0</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryShort copy)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.security.authorization.DefaultHiveAuthorizationProvider$BitSetChecker</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>0.0</lcom3>
		<loc>61</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>28.5</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.security.authorization.DefaultHiveAuthorizationProvider$BitSetChecker getBitSetChecker(org.apache.hadoop.hive.ql.security.authorization.Privilege[] inputRequiredPriv, org.apache.hadoop.hive.ql.security.authorization.Privilege[] outputRequiredPriv)">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.JavaVoidObjectInspector</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>8</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public Object getPrimitiveWritableObject(Object o)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ArchiveUtils$PartSpecInfo</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>27</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>3</npm>
		<lcom3>0.0</lcom3>
		<loc>127</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>30.25</amc>
		<cc>
			<method name="public org.apache.hadoop.fs.Path createPath(org.apache.hadoop.hive.ql.metadata.Table tbl)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.ArchiveUtils$PartSpecInfo create(org.apache.hadoop.hive.ql.metadata.Table tbl, java.util.Map partSpec)">1</method>
			<method name="public String getName()">1</method>
			<method name="private void _init_(java.util.List fields, java.util.List values)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFRTrim</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>25</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.0</amc>
		<cc>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text s)">2</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFField</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>22</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>13</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>173</loc>
		<dam>0.6666666666666666</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>33.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.HiveIndexHandler</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>5</rfc>
		<lcom>10</lcom>
		<ca>6</ca>
		<ce>9</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3090909090909091</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void generateIndexQuery(java.util.List, org.apache.hadoop.hive.ql.plan.ExprNodeDesc, org.apache.hadoop.hive.ql.parse.ParseContext, org.apache.hadoop.hive.ql.index.HiveIndexQueryContext)">1</method>
			<method name="public abstract void analyzeIndexDefinition(org.apache.hadoop.hive.metastore.api.Table, org.apache.hadoop.hive.metastore.api.Index, org.apache.hadoop.hive.metastore.api.Table)">1</method>
			<method name="public abstract boolean usesIndexTable()">1</method>
			<method name="public abstract boolean checkQuerySize(long, org.apache.hadoop.hive.conf.HiveConf)">1</method>
			<method name="public abstract java.util.List generateIndexBuildTaskList(org.apache.hadoop.hive.ql.metadata.Table, org.apache.hadoop.hive.metastore.api.Index, java.util.List, java.util.List, org.apache.hadoop.hive.ql.metadata.Table, java.util.Set, java.util.Set)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TFileTransport$chunkState</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>9</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>8</npm>
		<lcom3>0.5714285714285714</lcom3>
		<loc>69</loc>
		<dam>0.6666666666666666</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4583333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.25</amc>
		<cc>
			<method name="public long getOffset()">1</method>
			<method name="public int getRemaining()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public int getChunkNum()">1</method>
			<method name="public int getChunkSize()">1</method>
			<method name="public void seek(long offset)">1</method>
			<method name="public void skip(int size)">1</method>
			<method name="public void _init_(int chunk_size)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.persistence.HashMapWrapper</name>
		<wmc>30</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>67</rfc>
		<lcom>241</lcom>
		<ca>3</ca>
		<ce>5</ce>
		<npm>30</npm>
		<lcom3>0.9071618037135278</lcom3>
		<loc>287</loc>
		<dam>0.9230769230769231</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.125</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.133333333333333</amc>
		<cc>
			<method name="public void clear()">1</method>
			<method name="public int getKeySize()">1</method>
			<method name="public void setMHash(java.util.HashMap hash)">1</method>
			<method name="public void close()">1</method>
			<method name="public void _init_(int threshold)">0</method>
			<method name="public long flushMemoryCacheToPersistent(java.io.File file)">1</method>
			<method name="public int size()">1</method>
			<method name="public static java.lang.management.MemoryMXBean getMemoryMXBean()">1</method>
			<method name="public java.text.NumberFormat getNum()">1</method>
			<method name="public java.io.File getDumpFile()">1</method>
			<method name="public void initilizePersistentHash(String fileName)">1</method>
			<method name="public long getCurrentMemory()">1</method>
			<method name="public static void setMemoryMXBean(java.lang.management.MemoryMXBean memoryMXBean)">1</method>
			<method name="public java.util.HashMap getMHash()">1</method>
			<method name="public void setNum(java.text.NumberFormat num)">1</method>
			<method name="public org.apache.hadoop.hive.ql.session.SessionState$LogHelper getConsole()">1</method>
			<method name="public void setDumpFile(java.io.File dumpFile)">1</method>
			<method name="public java.util.Set keySet()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setLOG(org.apache.commons.logging.Log log)">1</method>
			<method name="public void setMaxMemory(long maxMemory)">1</method>
			<method name="public Object get(Object key)">1</method>
			<method name="public void _init_(int threshold, float loadFactor, float memoryUsage)">0</method>
			<method name="public boolean put(Object key, Object value)">1</method>
			<method name="public long getMaxMemory()">1</method>
			<method name="public void remove(Object key)">1</method>
			<method name="public void setConsole(org.apache.hadoop.hive.ql.session.SessionState$LogHelper console)">1</method>
			<method name="public static int getTHRESHOLD()">1</method>
			<method name="public boolean isAbort(long numRows, org.apache.hadoop.hive.ql.session.SessionState$LogHelper console)">2</method>
			<method name="public void setCurrentMemory(long currentMemory)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFWhen</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>20</rfc>
		<lcom>6</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>311</loc>
		<dam>0.6666666666666666</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>60.6</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.UDTFCollector</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>17</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.UDTFOperator op)">0</method>
			<method name="public void collect(Object input)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.SemanticAnalyzerFactory</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>23</rfc>
		<lcom>4</lcom>
		<ca>3</ca>
		<ce>15</ce>
		<npm>1</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>546</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>135.0</amc>
		<cc>
			<method name="private static void setSessionCommandType(org.apache.hadoop.hive.ql.plan.HiveOperation commandType)">2</method>
			<method name="private void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer get(org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.hive.ql.parse.ASTNode tree)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TSeekableFile</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>5</rfc>
		<lcom>10</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract long length()">1</method>
			<method name="public abstract void seek(long)">1</method>
			<method name="public abstract java.io.InputStream getInputStream()">1</method>
			<method name="public abstract java.io.OutputStream getOutputStream()">1</method>
			<method name="public abstract void close()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.ParseUtils</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>8</rfc>
		<lcom>3</lcom>
		<ca>3</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>28</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.333333333333334</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.parse.ASTNode findRootNonNullToken(org.apache.hadoop.hive.ql.parse.ASTNode tree)">3</method>
			<method name="public static boolean isJoinToken(org.apache.hadoop.hive.ql.parse.ASTNode node)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.AbstractPrimitiveObjectInspector</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>3</noc>
		<cbo>7</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>4</ce>
		<npm>5</npm>
		<lcom3>0.2</lcom3>
		<loc>31</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector$PrimitiveCategory getPrimitiveCategory()">1</method>
			<method name="public Class getJavaPrimitiveClass()">1</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils$PrimitiveTypeEntry typeEntry)">0</method>
			<method name="public String getTypeName()">1</method>
			<method name="public Class getPrimitiveWritableClass()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeDouble</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>15</rfc>
		<lcom>28</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>8</npm>
		<lcom3>2.0</lcom3>
		<loc>54</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.75</amc>
		<cc>
			<method name="public Object deserialize(Object reuse, org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public void serialize(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public Double getRealTypeInstance()">1</method>
			<method name="public byte getType()">1</method>
			<method name="public Class getRealType()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int i)">0</method>
			<method name="public String toString()">1</method>
			<method name="public void _init_(int i)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.MapredLocalTask</name>
		<wmc>18</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>44</cbo>
		<rfc>165</rfc>
		<lcom>91</lcom>
		<ca>2</ca>
		<ce>43</ce>
		<npm>12</npm>
		<lcom3>0.9090909090909092</lcom3>
		<loc>1156</loc>
		<dam>0.45454545454545453</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.1711229946524064</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>62.611111111111114</amc>
		<cc>
			<method name="public int execute(org.apache.hadoop.hive.ql.DriverContext driverContext)">14</method>
			<method name="private void initializeOperators(java.util.Map fetchOpJobConfMap)">1</method>
			<method name="public java.util.Collection getTopOperators()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public int executeFromChildJVM(org.apache.hadoop.hive.ql.DriverContext driverContext)">6</method>
			<method name="static void _clinit_()">0</method>
			<method name="public String getName()">1</method>
			<method name="public static String now()">1</method>
			<method name="private void startForward(boolean inputFileChangeSenstive, String bigTableBucket)">1</method>
			<method name="private void generateDummyHashTable(String alias, String bigBucketFileName)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.StageType getType()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.MapredLocalWork plan, org.apache.hadoop.mapred.JobConf job, boolean isSilent)">0</method>
			<method name="public boolean requireLock()">1</method>
			<method name="public boolean isMapRedLocalTask()">1</method>
			<method name="public void initialize(org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.hive.ql.QueryPlan queryPlan, org.apache.hadoop.hive.ql.DriverContext driverContext)">1</method>
			<method name="public void localizeMRTmpFilesImpl(org.apache.hadoop.hive.ql.Context ctx)">1</method>
			<method name="private void setUpFetchOpContext(org.apache.hadoop.hive.ql.exec.FetchOperator fetchOp, String alias, String currentInputFile)">1</method>
			<method name="private String getFileName(String path)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammarTreeConstants</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>241</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>192.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ReflectionStructObjectInspector$MyField</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>9</rfc>
		<lcom>2</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>5</npm>
		<lcom3>0.625</lcom3>
		<loc>30</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.6</amc>
		<cc>
			<method name="public String getFieldComment()">1</method>
			<method name="public String getFieldName()">1</method>
			<method name="public void _init_(java.lang.reflect.Field field, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector fieldObjectInspector)">0</method>
			<method name="public String toString()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getFieldObjectInspector()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDTFParseUrlTuple$PARTNAME</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9696969696969697</lcom3>
		<loc>133</loc>
		<dam>0.09090909090909091</dam>
		<moa>11</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>29.5</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.udf.generic.GenericUDTFParseUrlTuple$PARTNAME valueOf(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.udf.generic.GenericUDTFParseUrlTuple$PARTNAME[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceOrOperator_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$revokePrivileges_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$partitionLocation_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$withOption_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.security.authorization.Privilege$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>70</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>68.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HiveInputFormat</name>
		<wmc>12</wmc>
		<dit>1</dit>
		<noc>3</noc>
		<cbo>32</cbo>
		<rfc>83</rfc>
		<lcom>32</lcom>
		<ca>5</ca>
		<ce>27</ce>
		<npm>6</npm>
		<lcom3>0.6545454545454545</lcom3>
		<loc>633</loc>
		<dam>0.4</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.24793388429752067</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>51.333333333333336</amc>
		<cc>
			<method name="protected void pushProjectionsAndFilters(org.apache.hadoop.mapred.JobConf jobConf, Class inputFormatClass, String splitPath, String splitPathWithNoSchema, boolean nonNative)">11</method>
			<method name="public static org.apache.hadoop.mapred.InputFormat getInputFormatFromCache(Class inputFormatClass, org.apache.hadoop.mapred.JobConf job)">1</method>
			<method name="protected static org.apache.hadoop.hive.ql.plan.PartitionDesc getPartitionDescFromPath(java.util.Map pathToPartitionInfo, org.apache.hadoop.fs.Path dir)">1</method>
			<method name="public void configure(org.apache.hadoop.mapred.JobConf job)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="protected void pushFilters(org.apache.hadoop.mapred.JobConf jobConf, org.apache.hadoop.hive.ql.exec.TableScanOperator tableScan)">4</method>
			<method name="protected void pushProjectionsAndFilters(org.apache.hadoop.mapred.JobConf jobConf, Class inputFormatClass, String splitPath, String splitPathWithNoSchema)">1</method>
			<method name="protected void init(org.apache.hadoop.mapred.JobConf job)">1</method>
			<method name="public void validateInput(org.apache.hadoop.mapred.JobConf job)">1</method>
			<method name="public org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit split, org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.mapred.Reporter reporter)">1</method>
			<method name="public org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf job, int numSplits)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>26</rfc>
		<lcom>7</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>4</npm>
		<lcom3>0.5833333333333334</lcom3>
		<loc>162</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>21.857142857142858</amc>
		<cc>
			<method name="public boolean handleRecordReaderNextException(Exception e)">1</method>
			<method name="protected void setHandlerChain(java.util.List handlerChain)">1</method>
			<method name="public static org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain getHiveIOExceptionHandlerChain(org.apache.hadoop.mapred.JobConf conf)">7</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.mapred.RecordReader handleRecordReaderCreationException(Exception e)">1</method>
			<method name="protected java.util.List getHandlerChain()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.server.TNonblockingServer$Args</name>
		<wmc>1</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_(org.apache.thrift.transport.TNonblockingServerTransport transport)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.io.ByteWritable$Comparator</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>18</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.0</amc>
		<cc>
			<method name="public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2)">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.BucketizedHiveRecordReader</name>
		<wmc>12</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>26</rfc>
		<lcom>20</lcom>
		<ca>1</ca>
		<ce>12</ce>
		<npm>10</npm>
		<lcom3>0.6727272727272727</lcom3>
		<loc>197</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.21875</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.0</amc>
		<cc>
			<method name="public volatile Object createKey()">1</method>
			<method name="protected boolean initNextRecordReader()">1</method>
			<method name="public org.apache.hadoop.io.Writable createValue()">1</method>
			<method name="public volatile boolean doNext(Object x0, Object x1)">1</method>
			<method name="public float getProgress()">1</method>
			<method name="public boolean doNext(org.apache.hadoop.io.WritableComparable key, org.apache.hadoop.io.Writable value)">1</method>
			<method name="public volatile Object createValue()">1</method>
			<method name="public long getPos()">1</method>
			<method name="public org.apache.hadoop.io.WritableComparable createKey()">1</method>
			<method name="public void _init_(org.apache.hadoop.mapred.InputFormat inputFormat, org.apache.hadoop.hive.ql.io.BucketizedHiveInputSplit bucketizedSplit, org.apache.hadoop.mapred.JobConf jobConf, org.apache.hadoop.mapred.Reporter reporter)">0</method>
			<method name="public void doClose()">1</method>
			<method name="private boolean doNextWithExceptionHandler(org.apache.hadoop.io.WritableComparable key, org.apache.hadoop.io.Writable value)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Task</name>
		<wmc>60</wmc>
		<dit>1</dit>
		<noc>12</noc>
		<cbo>82</cbo>
		<rfc>85</rfc>
		<lcom>1656</lcom>
		<ca>67</ca>
		<ce>18</ce>
		<npm>53</npm>
		<lcom3>0.9761652542372882</lcom3>
		<loc>618</loc>
		<dam>0.78125</dam>
		<moa>7</moa>
		<mfa>0.0</mfa>
		<cam>0.10290556900726393</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.766666666666667</amc>
		<cc>
			<method name="public void setQueued()">1</method>
			<method name="public boolean getInitialized()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void removeFromChildrenTasks()">4</method>
			<method name="public java.util.List getChildren()">1</method>
			<method name="public void setRetryCmdWhenFail(boolean retryCmdWhenFail)">1</method>
			<method name="public java.util.List getParentTasks()">1</method>
			<method name="public java.io.Serializable getWork()">1</method>
			<method name="protected void receiveFeed(org.apache.hadoop.hive.ql.exec.Task$FeedType feedType, Object feedValue)">1</method>
			<method name="public void setTaskTag(int taskTag)">1</method>
			<method name="protected abstract int execute(org.apache.hadoop.hive.ql.DriverContext)">1</method>
			<method name="public boolean hasReduce()">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.Task getBackupTask()">1</method>
			<method name="public boolean getQueued()">1</method>
			<method name="public boolean isRunnable()">3</method>
			<method name="public java.util.List getResultSchema()">1</method>
			<method name="public String getId()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setFeedSubscribers(java.util.List s)">1</method>
			<method name="protected void pushFeed(org.apache.hadoop.hive.ql.exec.Task$FeedType feedType, Object feedValue)">3</method>
			<method name="public java.util.List getDependentTasks()">1</method>
			<method name="protected abstract void localizeMRTmpFilesImpl(org.apache.hadoop.hive.ql.Context)">1</method>
			<method name="public void setId(String id)">1</method>
			<method name="public boolean isMapRedLocalTask()">1</method>
			<method name="public void setLocalMode(boolean isLocalMode)">1</method>
			<method name="private boolean ancestorOrSelf(org.apache.hadoop.hive.ql.exec.Task desc)">4</method>
			<method name="public String getJobID()">1</method>
			<method name="public void setWork(java.io.Serializable work)">1</method>
			<method name="public void setStarted()">1</method>
			<method name="public void setBackupTask(org.apache.hadoop.hive.ql.exec.Task backupTask)">1</method>
			<method name="public final void localizeMRTmpFiles(org.apache.hadoop.hive.ql.Context ctx)">3</method>
			<method name="public org.apache.hadoop.hive.ql.QueryPlan getQueryPlan()">1</method>
			<method name="public void setDone()">1</method>
			<method name="public java.util.HashMap getCounters()">1</method>
			<method name="public boolean requireLock()">1</method>
			<method name="public void initialize(org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.hive.ql.QueryPlan queryPlan, org.apache.hadoop.hive.ql.DriverContext driverContext)">1</method>
			<method name="public boolean ifRetryCmdWhenFail()">1</method>
			<method name="public java.util.List getBackupChildrenTasks()">1</method>
			<method name="public java.util.List getFeedSubscribers()">1</method>
			<method name="public void removeDependentTask(org.apache.hadoop.hive.ql.exec.Task dependent)">5</method>
			<method name="protected void cloneConf()">2</method>
			<method name="public boolean fetch(java.util.ArrayList res)">1</method>
			<method name="public java.util.Collection getTopOperators()">1</method>
			<method name="public boolean isLocalMode()">1</method>
			<method name="public int getTaskTag()">1</method>
			<method name="public abstract org.apache.hadoop.hive.ql.plan.api.StageType getType()">1</method>
			<method name="public boolean isMapRedTask()">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.Task getAndInitBackupTask()">4</method>
			<method name="public int executeTask()">3</method>
			<method name="public java.util.List getChildTasks()">1</method>
			<method name="public void setParentTasks(java.util.List parentTasks)">1</method>
			<method name="public void setBackupChildrenTasks(java.util.List backupChildrenTasks)">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.Operator getReducer()">1</method>
			<method name="public void setInitialized()">1</method>
			<method name="public void subscribeFeed(org.apache.hadoop.hive.ql.exec.Task publisher)">4</method>
			<method name="public void setQueryPlan(org.apache.hadoop.hive.ql.QueryPlan queryPlan)">1</method>
			<method name="public boolean addDependentTask(org.apache.hadoop.hive.ql.exec.Task dependent)">5</method>
			<method name="public boolean done()">1</method>
			<method name="public boolean started()">1</method>
			<method name="public void setChildTasks(java.util.List childTasks)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFNamedStruct</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>18</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>11</ce>
		<npm>4</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>154</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>37.25</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.CommonJoinOperator$IntermediateObject</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>6</npm>
		<lcom3>0.3</lcom3>
		<loc>50</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public java.util.ArrayList[] getObjs()">1</method>
			<method name="public void _init_(java.util.ArrayList[] objs, int curSize)">0</method>
			<method name="public int getCurSize()">1</method>
			<method name="public void popObj()">1</method>
			<method name="public Object topObj()">1</method>
			<method name="public void pushObj(java.util.ArrayList newObj)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.TBaseHelper$1</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$selectExpression_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.GroupByOperator$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>70</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>68.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.conf.HiveConf$ConfVars</name>
		<wmc>9</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>85</cbo>
		<rfc>21</rfc>
		<lcom>4</lcom>
		<ca>84</ca>
		<ce>1</ce>
		<npm>3</npm>
		<lcom3>0.9829963235294118</lcom3>
		<loc>3642</loc>
		<dam>0.003676470588235294</dam>
		<moa>265</moa>
		<mfa>0.8125</mfa>
		<cam>0.4166666666666667</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>373.44444444444446</amc>
		<cc>
			<method name="private void _init_(String, int, String varname, String defaultVal)">0</method>
			<method name="private void _init_(String, int, String varname, boolean defaultBoolVal)">0</method>
			<method name="public static org.apache.hadoop.hive.conf.HiveConf$ConfVars valueOf(String name)">1</method>
			<method name="private void _init_(String, int, String varname, long defaultLongVal)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int, String varname, float defaultFloatVal)">0</method>
			<method name="private void _init_(String, int, String varname, int defaultIntVal)">0</method>
			<method name="public static org.apache.hadoop.hive.conf.HiveConf$ConfVars[] values()">1</method>
			<method name="public String toString()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFMonth</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>13</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>0.16666666666666674</lcom3>
		<loc>73</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>22.333333333333332</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable t)">2</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.Text dateString)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ArchiveUtils</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>51</rfc>
		<lcom>26</lcom>
		<ca>4</ca>
		<ce>9</ce>
		<npm>7</npm>
		<lcom3>0.8571428571428571</lcom3>
		<loc>284</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.17857142857142858</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>34.25</amc>
		<cc>
			<method name="public static boolean isArchived(org.apache.hadoop.hive.ql.metadata.Partition p)">2</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static String addSlash(String s)">2</method>
			<method name="public static int getArchivingLevel(org.apache.hadoop.hive.ql.metadata.Partition p)">1</method>
			<method name="public static String conflictingArchiveNameOrNull(org.apache.hadoop.hive.ql.metadata.Hive db, org.apache.hadoop.hive.ql.metadata.Table tbl, java.util.LinkedHashMap partSpec)">1</method>
			<method name="public static String getPartialName(org.apache.hadoop.hive.ql.metadata.Partition p, int level)">1</method>
			<method name="public static java.net.URI addSlash(java.net.URI u)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ConditionalResolverCommonJoin</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>41</rfc>
		<lcom>3</lcom>
		<ca>3</ca>
		<ce>10</ce>
		<npm>2</npm>
		<lcom3>1.5</lcom3>
		<loc>243</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>79.66666666666667</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="private String resolveMapJoinTask(java.util.HashMap pathToAliases, java.util.HashMap aliasToTask, java.util.HashMap aliasToKnownSize, String hdfsTmpDir, String localTmpDir, org.apache.hadoop.hive.conf.HiveConf conf)">10</method>
			<method name="public java.util.List getTasks(org.apache.hadoop.hive.conf.HiveConf conf, Object objCtx)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.SerDeException</name>
		<wmc>4</wmc>
		<dit>3</dit>
		<noc>0</noc>
		<cbo>54</cbo>
		<rfc>8</rfc>
		<lcom>6</lcom>
		<ca>54</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>1.3333333333333333</lcom3>
		<loc>21</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>1.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(Throwable cause)">0</method>
			<method name="public void _init_(String message, Throwable cause)">0</method>
			<method name="public void _init_(String message)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryPrimitive</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>11</noc>
		<cbo>16</cbo>
		<rfc>9</rfc>
		<lcom>3</lcom>
		<ca>13</ca>
		<ce>3</ce>
		<npm>4</npm>
		<lcom3>0.4</lcom3>
		<loc>35</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4444444444444444</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.666666666666667</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryPrimitive copy)">0</method>
			<method name="public int hashCode()">2</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">0</method>
			<method name="public org.apache.hadoop.io.Writable getWritableObject()">1</method>
			<method name="public String toString()">1</method>
			<method name="public Object getObject()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.LocalMapJoinProcFactory$MapJoinFollowedByGroupByProcessor</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>11</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>34</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.MetadataOnlyOptimizer$WalkerCtx</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>12</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>3</ce>
		<npm>5</npm>
		<lcom3>0.25</lcom3>
		<loc>54</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.42857142857142855</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.428571428571429</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public void convertNotMetadataOnly()">1</method>
			<method name="public void convertMetadataOnly()">1</method>
			<method name="public java.util.HashSet getMetadataOnlyTableScans()">1</method>
			<method name="public java.util.HashSet getMayBeMetadataOnlyTableScans()">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.optimizer.physical.MetadataOnlyOptimizer$1 x0)">0</method>
			<method name="public void setMayBeMetadataOnly(org.apache.hadoop.hive.ql.exec.TableScanOperator op)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.SerDeStats</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>13</ca>
		<ce>0</ce>
		<npm>3</npm>
		<lcom3>0.0</lcom3>
		<loc>17</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.333333333333333</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public long getRawDataSize()">1</method>
			<method name="public void setRawDataSize(long uSize)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixTouch_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ExplainWork</name>
		<wmc>12</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>14</rfc>
		<lcom>36</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>12</npm>
		<lcom3>0.8636363636363636</lcom3>
		<loc>77</loc>
		<dam>0.6666666666666666</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.916666666666667</amc>
		<cc>
			<method name="public void setExtended(boolean extended)">1</method>
			<method name="public java.util.ArrayList getRootTasks()">1</method>
			<method name="public void setRootTasks(java.util.ArrayList rootTasks)">1</method>
			<method name="public String getResFile()">1</method>
			<method name="public void setResFile(String resFile)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public boolean getExtended()">1</method>
			<method name="public String getAstStringTree()">1</method>
			<method name="public void _init_(String resFile, java.util.List rootTasks, String astStringTree, boolean extended, boolean formatted)">0</method>
			<method name="public void setAstStringTree(String astStringTree)">1</method>
			<method name="public boolean isFormatted()">1</method>
			<method name="public void setFormatted(boolean formatted)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lib.TaskGraphWalker$TaskGraphWalkerContext</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>23</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.5</amc>
		<cc>
			<method name="public void addToDispatchList(org.apache.hadoop.hive.ql.lib.Node dispatchedObj)">2</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.lib.TaskGraphWalker, java.util.HashMap reMap)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.Context</name>
		<wmc>46</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>55</cbo>
		<rfc>115</rfc>
		<lcom>825</lcom>
		<ca>39</ca>
		<ce>16</ce>
		<npm>39</npm>
		<lcom3>0.9119658119658121</lcom3>
		<loc>1009</loc>
		<dam>0.8461538461538461</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.12777777777777777</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>20.369565217391305</amc>
		<cc>
			<method name="public void clear()">1</method>
			<method name="public void setHiveLockMgr(org.apache.hadoop.hive.ql.lockmgr.HiveLockManager hiveLockMgr)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public java.util.List getHiveLocks()">1</method>
			<method name="public void setCmd(String cmd)">1</method>
			<method name="public boolean isMRTmpFileURI(String uriStr)">3</method>
			<method name="private String getScratchDir(String scheme, String authority, boolean mkdir, String scratchDir)">3</method>
			<method name="public void setHiveLocks(java.util.List hiveLocks)">1</method>
			<method name="public java.util.Map getPathToCS()">1</method>
			<method name="public String getLocalTmpFileURI()">1</method>
			<method name="public org.apache.hadoop.conf.Configuration getConf()">1</method>
			<method name="public String getMRScratchDir()">4</method>
			<method name="public String getCmd()">1</method>
			<method name="public int getTryCount()">1</method>
			<method name="public org.apache.hadoop.fs.ContentSummary getCS(String path)">1</method>
			<method name="public boolean isLocalOnlyExecutionMode()">1</method>
			<method name="public void localizePaths(java.util.List paths)">2</method>
			<method name="private static boolean strEquals(String str1, String str2)">1</method>
			<method name="public String getExternalTmpFileURI(java.net.URI extURI)">1</method>
			<method name="public org.apache.hadoop.fs.Path getResDir()">1</method>
			<method name="public void setResDir(org.apache.hadoop.fs.Path resDir)">1</method>
			<method name="public void localizeKeys(java.util.Map map)">2</method>
			<method name="private void removeScratchDir()">2</method>
			<method name="private String getExternalScratchDir(java.net.URI extURI)">2</method>
			<method name="private String nextPathId()">1</method>
			<method name="public String getMRTmpFileURI()">1</method>
			<method name="public void addCS(String path, org.apache.hadoop.fs.ContentSummary cs)">1</method>
			<method name="public String getLocalScratchDir(boolean mkdir)">1</method>
			<method name="public void restoreOriginalTracker()">2</method>
			<method name="public void setTokenRewriteStream(org.antlr.runtime.TokenRewriteStream tokenRewriteStream)">3</method>
			<method name="public void setExplain(boolean value)">1</method>
			<method name="public void setNeedLockMgr(boolean needLockMgr)">1</method>
			<method name="public static String generateExecutionId()">1</method>
			<method name="public org.apache.hadoop.hive.ql.lockmgr.HiveLockManager getHiveLockMgr()">2</method>
			<method name="public void _init_(org.apache.hadoop.conf.Configuration conf, String executionId)">0</method>
			<method name="public java.io.DataInput getStream()">10</method>
			<method name="private java.io.DataInput getNextStream()">1</method>
			<method name="public void setOriginalTracker(String originalTracker)">1</method>
			<method name="public org.antlr.runtime.TokenRewriteStream getTokenRewriteStream()">1</method>
			<method name="public void setResFile(org.apache.hadoop.fs.Path resFile)">1</method>
			<method name="public String localizeMRTmpFileURI(String originalURI)">3</method>
			<method name="public void setTryCount(int tryCount)">1</method>
			<method name="public boolean isNeedLockMgr()">1</method>
			<method name="public org.apache.hadoop.fs.Path getResFile()">1</method>
			<method name="public boolean getExplain()">1</method>
			<method name="public void _init_(org.apache.hadoop.conf.Configuration conf)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeStructBase</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>2</noc>
		<cbo>11</cbo>
		<rfc>18</rfc>
		<lcom>22</lcom>
		<ca>3</ca>
		<ce>8</ce>
		<npm>8</npm>
		<lcom3>0.7142857142857143</lcom3>
		<loc>59</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.25</amc>
		<cc>
			<method name="public Object deserialize(Object reuse, org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public void initialize()">1</method>
			<method name="public void serialize(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeFieldList getFieldList()">1</method>
			<method name="public Class getRealType()">1</method>
			<method name="public boolean isPrimitive()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int i)">0</method>
			<method name="public void _init_(int i)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.security.authorization.HiveAuthorizationProvider</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>8</rfc>
		<lcom>28</lcom>
		<ca>6</ca>
		<ce>9</ce>
		<npm>8</npm>
		<lcom3>2.0</lcom3>
		<loc>8</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.328125</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void authorize(org.apache.hadoop.hive.ql.metadata.Partition, org.apache.hadoop.hive.ql.security.authorization.Privilege[], org.apache.hadoop.hive.ql.security.authorization.Privilege[])">1</method>
			<method name="public abstract void authorize(org.apache.hadoop.hive.metastore.api.Database, org.apache.hadoop.hive.ql.security.authorization.Privilege[], org.apache.hadoop.hive.ql.security.authorization.Privilege[])">1</method>
			<method name="public abstract org.apache.hadoop.hive.ql.security.HiveAuthenticationProvider getAuthenticator()">1</method>
			<method name="public abstract void authorize(org.apache.hadoop.hive.ql.metadata.Table, org.apache.hadoop.hive.ql.security.authorization.Privilege[], org.apache.hadoop.hive.ql.security.authorization.Privilege[])">1</method>
			<method name="public abstract void authorize(org.apache.hadoop.hive.ql.security.authorization.Privilege[], org.apache.hadoop.hive.ql.security.authorization.Privilege[])">1</method>
			<method name="public abstract void init(org.apache.hadoop.conf.Configuration)">1</method>
			<method name="public abstract void setAuthenticator(org.apache.hadoop.hive.ql.security.HiveAuthenticationProvider)">1</method>
			<method name="public abstract void authorize(org.apache.hadoop.hive.ql.metadata.Table, org.apache.hadoop.hive.ql.metadata.Partition, java.util.List, org.apache.hadoop.hive.ql.security.authorization.Privilege[], org.apache.hadoop.hive.ql.security.authorization.Privilege[])">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.columnar.BytesRefWritable$1</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.5</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public org.apache.hadoop.io.Writable newInstance()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.lineage.OpProcFactory$UnionLineage</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>19</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>14</ce>
		<npm>2</npm>
		<lcom3>0.75</lcom3>
		<loc>79</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>24.666666666666668</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.Hive$1</name>
		<wmc>3</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>7</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>18</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.8461538461538461</mfa>
		<cam>1.0</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public synchronized void remove()">2</method>
			<method name="protected synchronized Object initialValue()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$columnNameOrder_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.Hive$2</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>16</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>12</ce>
		<npm>1</npm>
		<lcom3>0.0</lcom3>
		<loc>48</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>22.5</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.metastore.HiveMetaHook getHook(org.apache.hadoop.hive.metastore.api.Table tbl)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.metadata.Hive)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ShowPartitionsDesc</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>12</rfc>
		<lcom>27</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>10</npm>
		<lcom3>0.9444444444444444</lcom3>
		<loc>57</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.1</amc>
		<cc>
			<method name="public String getResFile()">1</method>
			<method name="public String getSchema()">1</method>
			<method name="public String getTable()">1</method>
			<method name="public void setResFile(String resFile)">1</method>
			<method name="public String getTabName()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setPartSpec(java.util.Map partSpec)">1</method>
			<method name="public java.util.Map getPartSpec()">1</method>
			<method name="public void setTabName(String tabName)">1</method>
			<method name="public void _init_(String tabName, org.apache.hadoop.fs.Path resFile, java.util.Map partSpec)">0</method>
		</cc>
	</class>
	<class>
		<name>org.json.JSONException</name>
		<wmc>3</wmc>
		<dit>3</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>5</rfc>
		<lcom>1</lcom>
		<ca>16</ca>
		<ce>0</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>19</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.9545454545454546</mfa>
		<cam>0.5555555555555556</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public void _init_(String arg0)">0</method>
			<method name="public void _init_(Throwable arg0)">0</method>
			<method name="public Throwable getCause()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ListObjectInspector</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>27</cbo>
		<rfc>4</rfc>
		<lcom>6</lcom>
		<ca>26</ca>
		<ce>1</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract int getListLength(Object)">1</method>
			<method name="public abstract Object getListElement(Object, int)">1</method>
			<method name="public abstract java.util.List getList(Object)">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getListElementObjectInspector()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.SplitSample</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>6</npm>
		<lcom3>0.7333333333333333</lcom3>
		<loc>41</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.333333333333333</amc>
		<cc>
			<method name="public void _init_(double percent, int seedNum)">0</method>
			<method name="public void setPercent(double percent)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setSeedNum(int seedNum)">1</method>
			<method name="public int getSeedNum()">1</method>
			<method name="public double getPercent()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.Task$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>63</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>61.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ScriptOperator$ErrorStreamProcessor</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>16</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>131</loc>
		<dam>0.75</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>41.333333333333336</amc>
		<cc>
			<method name="public void close()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.ScriptOperator, int maxBytes)">0</method>
			<method name="public void processLine(org.apache.hadoop.io.Writable line)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFHistogramNumeric</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>15</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>12</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>130</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>42.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] parameters)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.UnionStructObjectInspector$MyField</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>8</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>4</npm>
		<lcom3>0.5</lcom3>
		<loc>27</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.25</amc>
		<cc>
			<method name="public String getFieldComment()">1</method>
			<method name="public String getFieldName()">1</method>
			<method name="public void _init_(int structID, org.apache.hadoop.hive.serde2.objectinspector.StructField structField)">0</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getFieldObjectInspector()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.classification.InterfaceAudience$Public</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$grantRole_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryFactory</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>42</cbo>
		<rfc>34</rfc>
		<lcom>6</lcom>
		<ca>6</ca>
		<ce>39</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>154</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.25</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>37.5</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryPrimitive createLazyBinaryPrimitiveClass(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector oi)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createColumnarStructInspector(java.util.List columnNames, java.util.List columnTypes)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryObject createLazyBinaryObject(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$createDatabaseStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.TextRecordWriter</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>11</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>4</npm>
		<lcom3>0.3333333333333333</lcom3>
		<loc>35</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.5</amc>
		<cc>
			<method name="public void initialize(java.io.OutputStream out, org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="public void write(org.apache.hadoop.io.Writable row)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void close()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryNonPrimitive</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>3</noc>
		<cbo>7</cbo>
		<rfc>8</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>0.3333333333333333</lcom3>
		<loc>56</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.25</amc>
		<cc>
			<method name="public int hashCode()">1</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">3</method>
			<method name="public Object getObject()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$hintArgName_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.CommonJoinResolver</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>8</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>6</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>31</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext resolve(org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext pctx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>28</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.errors.TaskLogProcessor</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>43</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>10</ce>
		<npm>4</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>360</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>88.0</amc>
		<cc>
			<method name="public void addTaskAttemptLogUrl(String url)">1</method>
			<method name="public void _init_(org.apache.hadoop.mapred.JobConf conf)">0</method>
			<method name="public java.util.List getStackTraces()">9</method>
			<method name="public java.util.List getErrors()">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.TException</name>
		<wmc>4</wmc>
		<dit>3</dit>
		<noc>3</noc>
		<cbo>70</cbo>
		<rfc>8</rfc>
		<lcom>6</lcom>
		<ca>70</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>1.3333333333333333</lcom3>
		<loc>21</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>1.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(Throwable cause)">0</method>
			<method name="public void _init_(String message, Throwable cause)">0</method>
			<method name="public void _init_(String message)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.bitmap.BitmapObjectInput</name>
		<wmc>25</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>35</rfc>
		<lcom>288</lcom>
		<ca>3</ca>
		<ce>4</ce>
		<npm>25</npm>
		<lcom3>0.875</lcom3>
		<loc>171</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.28</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.76</amc>
		<cc>
			<method name="public void readFromList(java.util.List l)">1</method>
			<method name="public char readChar()">1</method>
			<method name="public int readUnsignedShort()">1</method>
			<method name="public short readShort()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public long readLong()">1</method>
			<method name="public int readUnsignedByte()">1</method>
			<method name="public int available()">1</method>
			<method name="public void close()">1</method>
			<method name="public String readLine()">1</method>
			<method name="public int readInt()">1</method>
			<method name="public void readFully(byte[] arg0)">1</method>
			<method name="public int read(byte[] arg0, int arg1, int arg2)">1</method>
			<method name="public void readFully(byte[] arg0, int arg1, int arg2)">1</method>
			<method name="public Object readObject()">1</method>
			<method name="public boolean readBoolean()">1</method>
			<method name="public double readDouble()">1</method>
			<method name="public void _init_(java.util.List l)">0</method>
			<method name="public String readUTF()">1</method>
			<method name="public int read(byte[] arg0)">1</method>
			<method name="public float readFloat()">1</method>
			<method name="public int read()">1</method>
			<method name="public long skip(long arg0)">1</method>
			<method name="public byte readByte()">1</method>
			<method name="public int skipBytes(int n)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ForwardOperator</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>5</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>1.5</lcom3>
		<loc>17</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.333333333333333</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void processOp(Object row, int tag)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndexCtx$1</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>1</npm>
		<lcom3>1.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndexCtx)">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TNonblockingServerSocket</name>
		<wmc>11</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>35</rfc>
		<lcom>37</lcom>
		<ca>0</ca>
		<ce>6</ce>
		<npm>8</npm>
		<lcom3>0.55</lcom3>
		<loc>178</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.818181818181818</amc>
		<cc>
			<method name="public void _init_(int port)">0</method>
			<method name="public void registerSelector(java.nio.channels.Selector selector)">1</method>
			<method name="public void interrupt()">1</method>
			<method name="protected org.apache.thrift.transport.TNonblockingSocket acceptImpl()">1</method>
			<method name="public void _init_(java.net.InetSocketAddress bindAddr, int clientTimeout)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void _init_(java.net.InetSocketAddress bindAddr)">0</method>
			<method name="public void _init_(int port, int clientTimeout)">0</method>
			<method name="public void close()">2</method>
			<method name="public void listen()">1</method>
			<method name="protected volatile org.apache.thrift.transport.TTransport acceptImpl()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFOPNegative</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>20</rfc>
		<lcom>21</lcom>
		<ca>0</ca>
		<ce>7</ce>
		<npm>7</npm>
		<lcom3>2.0</lcom3>
		<loc>90</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2653061224489796</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.857142857142858</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ShortWritable evaluate(org.apache.hadoop.hive.serde2.io.ShortWritable a)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable a)">2</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.LongWritable a)">2</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.IntWritable a)">2</method>
			<method name="public org.apache.hadoop.io.FloatWritable evaluate(org.apache.hadoop.io.FloatWritable a)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.ByteWritable evaluate(org.apache.hadoop.hive.serde2.io.ByteWritable a)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.ServerUtils</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>15</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>7</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>58</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.0</amc>
		<cc>
			<method name="public static void cleanUpScratchDir(org.apache.hadoop.hive.conf.HiveConf hiveConf)">2</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.ppd.PredicatePushDown</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>23</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>12</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>121</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>59.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext transform(org.apache.hadoop.hive.ql.parse.ParseContext pctx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFFromUnixTime</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>18</rfc>
		<lcom>7</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>5</npm>
		<lcom3>0.35</lcom3>
		<loc>104</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.666666666666666</amc>
		<cc>
			<method name="private org.apache.hadoop.io.Text eval(long unixtime, org.apache.hadoop.io.Text format)">2</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.IntWritable unixtime, org.apache.hadoop.io.Text format)">3</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.IntWritable unixtime)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.LongWritable unixtime)">2</method>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.LongWritable unixtime, org.apache.hadoop.io.Text format)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableIntObjectInspector</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>15</cbo>
		<rfc>11</rfc>
		<lcom>15</lcom>
		<ca>10</ca>
		<ce>5</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>45</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.5</amc>
		<cc>
			<method name="public Object create(int value)">1</method>
			<method name="public int get(Object o)">1</method>
			<method name="void _init_()">0</method>
			<method name="public Object set(Object o, int value)">1</method>
			<method name="public Object getPrimitiveJavaObject(Object o)">2</method>
			<method name="public Object copyObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCollectSet</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>13</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>53</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.333333333333332</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] parameters)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazydio.LazyDioShort</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>12</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>3</npm>
		<lcom3>1.0</lcom3>
		<loc>83</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyShortObjectInspector oi)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazydio.LazyDioShort copy)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ScriptOperator$Counter</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.888888888888889</lcom3>
		<loc>45</loc>
		<dam>0.3333333333333333</dam>
		<moa>3</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>9.5</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.ScriptOperator$Counter[] values()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.ScriptOperator$Counter valueOf(String name)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.TApplicationException</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>27</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>5</ce>
		<npm>7</npm>
		<lcom3>1.0</lcom3>
		<loc>163</loc>
		<dam>0.38461538461538464</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.42857142857142855</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>17.75</amc>
		<cc>
			<method name="public void _init_(int type)">0</method>
			<method name="public void _init_(int type, String message)">0</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.thrift.TApplicationException read(org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public int getType()">1</method>
			<method name="public void _init_(String message)">0</method>
			<method name="public void write(org.apache.thrift.protocol.TProtocol oprot)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCorrelation$GenericUDAFCorrelationEvaluator$StdAgg</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>10</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TServerSocket</name>
		<wmc>13</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>33</rfc>
		<lcom>44</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>10</npm>
		<lcom3>0.47222222222222227</lcom3>
		<loc>173</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4166666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.076923076923077</amc>
		<cc>
			<method name="public void _init_(int port)">0</method>
			<method name="public void _init_(java.net.ServerSocket serverSocket, int clientTimeout)">0</method>
			<method name="public void interrupt()">1</method>
			<method name="public void _init_(java.net.InetSocketAddress bindAddr, int clientTimeout)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void _init_(int port, int clientTimeout)">0</method>
			<method name="public void close()">2</method>
			<method name="public void listen()">1</method>
			<method name="public void _init_(java.net.ServerSocket serverSocket)">0</method>
			<method name="protected org.apache.thrift.transport.TSocket acceptImpl()">1</method>
			<method name="public void _init_(java.net.InetSocketAddress bindAddr)">0</method>
			<method name="protected volatile org.apache.thrift.transport.TTransport acceptImpl()">1</method>
			<method name="public java.net.ServerSocket getServerSocket()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.JavaDoubleObjectInspector</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>9</rfc>
		<lcom>10</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>30</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public double get(Object o)">1</method>
			<method name="void _init_()">0</method>
			<method name="public Object set(Object o, double value)">1</method>
			<method name="public Object getPrimitiveWritableObject(Object o)">2</method>
			<method name="public Object create(double value)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$expressions_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.HadoopJobExecHelper$ExecDriverTaskHandle</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>30</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.6</amc>
		<cc>
			<method name="public void setRunningJob(org.apache.hadoop.mapred.RunningJob job)">1</method>
			<method name="public org.apache.hadoop.mapred.Counters getCounters()">1</method>
			<method name="public void _init_(org.apache.hadoop.mapred.JobClient jc, org.apache.hadoop.mapred.RunningJob rj)">0</method>
			<method name="org.apache.hadoop.mapred.JobClient getJobClient()">1</method>
			<method name="org.apache.hadoop.mapred.RunningJob getRunningJob()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>21</cbo>
		<rfc>41</rfc>
		<lcom>6</lcom>
		<ca>1</ca>
		<ce>21</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>217</loc>
		<dam>0.6666666666666666</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>41.8</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.io.Writable serialize(Object obj, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector objInspector)">1</method>
			<method name="public void initialize(org.apache.hadoop.conf.Configuration conf, java.util.Properties tbl)">1</method>
			<method name="public String toString()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ppr.PartExprEvalUtils</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>29</rfc>
		<lcom>8</lcom>
		<ca>2</ca>
		<ce>12</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>184</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.32142857142857145</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>35.6</amc>
		<cc>
			<method name="public static synchronized Object evalExprWithPart(org.apache.hadoop.hive.ql.plan.ExprNodeDesc expr, java.util.LinkedHashMap partSpec, org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector rowObjectInspector)">1</method>
			<method name="public static synchronized Object evaluateExprOnPart(java.util.Map pair, Object[] rowWithPart)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static synchronized java.util.Map prepareExpr(org.apache.hadoop.hive.ql.plan.ExprNodeDesc expr, java.util.List partNames, org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector rowObjectInspector)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.ExecuteWithHookContext</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void run(org.apache.hadoop.hive.ql.hooks.HookContext)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tableName_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lockmgr.HiveLockObject$HiveLockObjectData</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>15</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>0</ce>
		<npm>9</npm>
		<lcom3>0.65</lcom3>
		<loc>107</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.333333333333334</amc>
		<cc>
			<method name="public String getQueryStr()">1</method>
			<method name="public String getLockMode()">1</method>
			<method name="public void _init_(String data)">0</method>
			<method name="public void setClientIp(String clientIp)">1</method>
			<method name="public void _init_(String queryId, String lockTime, String lockMode, String queryStr)">0</method>
			<method name="public String getLockTime()">1</method>
			<method name="public String getQueryId()">1</method>
			<method name="public String toString()">1</method>
			<method name="public String getClientIp()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.MetadataOnlyOptimizer</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>12</rfc>
		<lcom>4</lcom>
		<ca>2</ca>
		<ce>9</ce>
		<npm>2</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>41</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.0</amc>
		<cc>
			<method name="static org.apache.commons.logging.Log access$000()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext resolve(org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext pctx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.AlterTableDesc</name>
		<wmc>57</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>61</rfc>
		<lcom>1358</lcom>
		<ca>3</ca>
		<ce>5</ce>
		<npm>57</npm>
		<lcom3>0.9561011904761905</lcom3>
		<loc>397</loc>
		<dam>0.08333333333333333</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.18908382066276802</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.543859649122807</amc>
		<cc>
			<method name="public void setNumberBuckets(int numberBuckets)">1</method>
			<method name="public java.util.ArrayList getSortColumns()">1</method>
			<method name="public String getNewColType()">1</method>
			<method name="public void setStorageHandler(String storageHandler)">1</method>
			<method name="public String getNewColComment()">1</method>
			<method name="public java.util.HashMap getProps()">1</method>
			<method name="public String getAfterCol()">1</method>
			<method name="public boolean isProtectModeEnable()">1</method>
			<method name="public void setNewLocation(String newLocation)">1</method>
			<method name="public void setProps(java.util.HashMap props)">1</method>
			<method name="public String getAlterTableTypeString()">2</method>
			<method name="public void setNewColComment(String newComment)">1</method>
			<method name="public void _init_(String oldName, String newName, boolean expectView)">0</method>
			<method name="public void setBucketColumns(java.util.ArrayList bucketColumns)">1</method>
			<method name="public String getOldColName()">1</method>
			<method name="public void setOp(org.apache.hadoop.hive.ql.plan.AlterTableDesc$AlterTableTypes op)">1</method>
			<method name="public String getInputFormat()">1</method>
			<method name="public String getNewLocation()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public String getOldName()">1</method>
			<method name="public void setFirst(boolean first)">1</method>
			<method name="public String getNewColName()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.AlterTableDesc$AlterTableTypes alterType, boolean expectView)">0</method>
			<method name="public void setOutputFormat(String outputFormat)">1</method>
			<method name="public void setExpectView(boolean expectView)">1</method>
			<method name="public void setPartSpec(java.util.HashMap partSpec)">1</method>
			<method name="public java.util.ArrayList getBucketColumns()">1</method>
			<method name="public java.util.HashMap getPartSpec()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.AlterTableDesc$ProtectModeType getProtectModeType()">1</method>
			<method name="public String getSerdeName()">1</method>
			<method name="public void _init_(String name, String inputFormat, String outputFormat, String serdeName, String storageHandler, java.util.HashMap partSpec)">0</method>
			<method name="public void setNewName(String newName)">1</method>
			<method name="public String getStorageHandler()">1</method>
			<method name="public void setInputFormat(String inputFormat)">1</method>
			<method name="public void setNewColName(String newColName)">1</method>
			<method name="public void setProtectModeType(org.apache.hadoop.hive.ql.plan.AlterTableDesc$ProtectModeType protectModeType)">1</method>
			<method name="public void setAfterCol(String afterCol)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.AlterTableDesc$AlterTableTypes getOp()">1</method>
			<method name="public int getNumberBuckets()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.AlterTableDesc$AlterTableTypes alterType)">0</method>
			<method name="public void setOldColName(String oldColName)">1</method>
			<method name="public void setNewColType(String newType)">1</method>
			<method name="public void _init_(String tableName, int numBuckets, java.util.List bucketCols, java.util.List sortCols)">0</method>
			<method name="public void setSortColumns(java.util.ArrayList sortColumns)">1</method>
			<method name="public java.util.ArrayList getNewCols()">1</method>
			<method name="public void setNewCols(java.util.ArrayList newCols)">1</method>
			<method name="public boolean getExpectView()">1</method>
			<method name="public void setSerdeName(String serdeName)">1</method>
			<method name="public String getNewName()">1</method>
			<method name="public void _init_(String tableName, String newLocation, java.util.HashMap partSpec)">0</method>
			<method name="public java.util.List getNewColsString()">1</method>
			<method name="public void _init_(String tblName, String oldColName, String newColName, String newType, String newComment, boolean first, String afterCol)">0</method>
			<method name="public void _init_(String name, java.util.List newCols, org.apache.hadoop.hive.ql.plan.AlterTableDesc$AlterTableTypes alterType)">0</method>
			<method name="public String getOutputFormat()">1</method>
			<method name="public void setProtectModeEnable(boolean protectModeEnable)">1</method>
			<method name="public boolean getFirst()">1</method>
			<method name="public void setOldName(String oldName)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.lockmgr.HiveLockObj</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>8</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>6</npm>
		<lcom3>0.5</lcom3>
		<loc>35</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void setObj(org.apache.hadoop.hive.ql.lockmgr.HiveLockObject obj)">1</method>
			<method name="public void setMode(org.apache.hadoop.hive.ql.lockmgr.HiveLockMode mode)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.lockmgr.HiveLockObject obj, org.apache.hadoop.hive.ql.lockmgr.HiveLockMode mode)">0</method>
			<method name="public org.apache.hadoop.hive.ql.lockmgr.HiveLockMode getMode()">1</method>
			<method name="public String getName()">1</method>
			<method name="public org.apache.hadoop.hive.ql.lockmgr.HiveLockObject getObj()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFTan</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>10</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.75</lcom3>
		<loc>31</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.666666666666666</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable a)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypedef</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>17</rfc>
		<lcom>28</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>7</npm>
		<lcom3>1.1428571428571428</lcom3>
		<loc>82</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.125</amc>
		<cc>
			<method name="public Object deserialize(Object reuse, org.apache.thrift.protocol.TProtocol iprot)">1</method>
			<method name="public void serialize(Object o, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, org.apache.thrift.protocol.TProtocol oprot)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeBase getMyType()">1</method>
			<method name="public byte getType()">1</method>
			<method name="private org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeSimpleNode getDefinitionType()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int i)">0</method>
			<method name="public String toString()">1</method>
			<method name="public void _init_(int i)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ReduceSinkDeDuplication$ReduceSinkDeduplicateProcFactory$DefaultProc</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>7</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.5</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$showStmtIdentifier_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.index.RewriteQueryUsingAggregateIndex$1</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$regular_body_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server$3</name>
		<wmc>3</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.8461538461538461</mfa>
		<cam>1.0</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>2.6666666666666665</amc>
		<cc>
			<method name="protected volatile Object initialValue()">1</method>
			<method name="void _init_()">0</method>
			<method name="protected synchronized org.apache.hadoop.security.UserGroupInformation$AuthenticationMethod initialValue()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server$1</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>24</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.333333333333333</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server, String)">0</method>
			<method name="public volatile Object run()">1</method>
			<method name="public String run()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.RCFile$ValueBuffer$LazyDecompressionCallbackImpl</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>17</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>8</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>123</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>59.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.io.RCFile$ValueBuffer, int index, int colIndex)">0</method>
			<method name="public byte[] decompress()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.Transform</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>17</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>15</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract org.apache.hadoop.hive.ql.parse.ParseContext transform(org.apache.hadoop.hive.ql.parse.ParseContext)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFToLong</name>
		<wmc>11</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>24</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>12</ce>
		<npm>11</npm>
		<lcom3>0.2</lcom3>
		<loc>138</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.17355371900826447</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.454545454545455</amc>
		<cc>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.IntWritable i)">2</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.BooleanWritable i)">3</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable i)">2</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.Text i)">2</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.FloatWritable i)">2</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.LongWritable i)">1</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.hive.serde2.io.ShortWritable i)">2</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.NullWritable i)">1</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.hive.serde2.io.ByteWritable i)">2</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable i)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge20S$Server$2</name>
		<wmc>3</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>3</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.8461538461538461</mfa>
		<cam>1.0</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>2.6666666666666665</amc>
		<cc>
			<method name="protected volatile Object initialValue()">1</method>
			<method name="void _init_()">0</method>
			<method name="protected synchronized java.net.InetAddress initialValue()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyShortObjectInspector</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>9</rfc>
		<lcom>6</lcom>
		<ca>4</ca>
		<ce>7</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>33</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.875</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.25</amc>
		<cc>
			<method name="public short get(Object o)">1</method>
			<method name="void _init_()">0</method>
			<method name="public Object getPrimitiveJavaObject(Object o)">2</method>
			<method name="public Object copyObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPEqual</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>18</cbo>
		<rfc>16</rfc>
		<lcom>1</lcom>
		<ca>3</ca>
		<ce>15</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>180</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>89.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TFramedTransport</name>
		<wmc>15</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>39</rfc>
		<lcom>7</lcom>
		<ca>4</ca>
		<ce>4</ce>
		<npm>14</npm>
		<lcom3>0.7261904761904763</lcom3>
		<loc>301</loc>
		<dam>1.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.666666666666668</amc>
		<cc>
			<method name="public int getBufferPosition()">1</method>
			<method name="public void consumeBuffer(int len)">1</method>
			<method name="public void write(byte[] buf, int off, int len)">1</method>
			<method name="public void _init_(org.apache.thrift.transport.TTransport transport)">0</method>
			<method name="public static final int decodeFrameSize(byte[] buf)">1</method>
			<method name="public void close()">1</method>
			<method name="public int read(byte[] buf, int off, int len)">1</method>
			<method name="public static final void encodeFrameSize(int frameSize, byte[] buf)">1</method>
			<method name="public byte[] getBuffer()">1</method>
			<method name="public boolean isOpen()">1</method>
			<method name="public void open()">1</method>
			<method name="public void flush()">1</method>
			<method name="public int getBytesRemainingInBuffer()">1</method>
			<method name="private void readFrame()">1</method>
			<method name="public void _init_(org.apache.thrift.transport.TTransport transport, int maxLength)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryObject</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>2</noc>
		<cbo>10</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>8</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public abstract int hashCode()">1</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.DescFunctionDesc</name>
		<wmc>11</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>13</rfc>
		<lcom>27</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>11</npm>
		<lcom3>0.9166666666666666</lcom3>
		<loc>68</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4090909090909091</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.636363636363637</amc>
		<cc>
			<method name="public String getResFile()">1</method>
			<method name="public String getSchema()">1</method>
			<method name="public String getTable()">1</method>
			<method name="public void setResFile(String resFile)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(org.apache.hadoop.fs.Path resFile)">0</method>
			<method name="public boolean isExtended()">1</method>
			<method name="public void setName(String name)">1</method>
			<method name="public void setExtended(boolean isExtended)">1</method>
			<method name="public String getName()">1</method>
			<method name="public void _init_(org.apache.hadoop.fs.Path resFile, String name, boolean isExtended)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterStatementSuffixAddCol_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.HiveIndex</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>11</rfc>
		<lcom>6</lcom>
		<ca>3</ca>
		<ce>3</ce>
		<npm>3</npm>
		<lcom3>1.0</lcom3>
		<loc>70</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.index.HiveIndex$IndexType getIndexType(String name)">3</method>
			<method name="public static org.apache.hadoop.hive.ql.index.HiveIndex$IndexType getIndexTypeByClassName(String className)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.CreateIndexDesc</name>
		<wmc>43</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>44</rfc>
		<lcom>777</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>43</npm>
		<lcom3>0.9546485260770975</lcom3>
		<loc>276</loc>
		<dam>0.047619047619047616</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3116279069767442</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.930232558139535</amc>
		<cc>
			<method name="public String getMapKeyDelim()">1</method>
			<method name="public void _init_(String tableName, String indexName, java.util.List indexedCols, String indexTableName, boolean deferredRebuild, String inputFormat, String outputFormat, String storageHandler, String typeName, String location, java.util.Map idxProps, java.util.Map tblProps, String serde, java.util.Map serdeProps, String collItemDelim, String fieldDelim, String fieldEscape, String lineDelim, String mapKeyDelim, String indexComment)">0</method>
			<method name="public String getIndexComment()">1</method>
			<method name="public boolean getDeferredRebuild()">1</method>
			<method name="public void setIdxProps(java.util.Map idxProps)">1</method>
			<method name="public String getStorageHandler()">1</method>
			<method name="public void setIndexTypeHandlerClass(String indexTypeHandlerClass)">1</method>
			<method name="public void setSerdeProps(java.util.Map serdeProps)">1</method>
			<method name="public void setStorageHandler(String storageHandler)">1</method>
			<method name="public String getIndexName()">1</method>
			<method name="public void setInputFormat(String inputFormat)">1</method>
			<method name="public void setSerde(String serde)">1</method>
			<method name="public void setCollItemDelim(String collItemDelim)">1</method>
			<method name="public void setFieldDelim(String fieldDelim)">1</method>
			<method name="public void setIndexName(String indexName)">1</method>
			<method name="public String getTableName()">1</method>
			<method name="public void setIndexTableName(String indexTableName)">1</method>
			<method name="public void setLocation(String location)">1</method>
			<method name="public void setTableName(String tableName)">1</method>
			<method name="public java.util.Map getIdxProps()">1</method>
			<method name="public void setMapKeyDelim(String mapKeyDelim)">1</method>
			<method name="public String getCollItemDelim()">1</method>
			<method name="public java.util.Map getSerdeProps()">1</method>
			<method name="public java.util.List getIndexedCols()">1</method>
			<method name="public String getInputFormat()">1</method>
			<method name="public String getLocation()">1</method>
			<method name="public void setIndexedCols(java.util.List indexedCols)">1</method>
			<method name="public String getLineDelim()">1</method>
			<method name="public String getFieldEscape()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setDeferredRebuild(boolean deferredRebuild)">1</method>
			<method name="public boolean isDeferredRebuild()">1</method>
			<method name="public void setFieldEscape(String fieldEscape)">1</method>
			<method name="public void setOutputFormat(String outputFormat)">1</method>
			<method name="public void setIndexComment(String indexComment)">1</method>
			<method name="public String getSerde()">1</method>
			<method name="public String getIndexTypeHandlerClass()">1</method>
			<method name="public void setTblProps(java.util.Map tblProps)">1</method>
			<method name="public java.util.Map getTblProps()">1</method>
			<method name="public String getOutputFormat()">1</method>
			<method name="public String getFieldDelim()">1</method>
			<method name="public void setLineDelim(String lineDelim)">1</method>
			<method name="public String getIndexTableName()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.errors.ScriptErrorHeuristic</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>26</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>99</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>31.333333333333332</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.exec.errors.ErrorAndSolution getErrorAndSolution()">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFToUtcTimestamp</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>8</rfc>
		<lcom>6</lcom>
		<ca>0</ca>
		<ce>1</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>46</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="protected boolean invert()">1</method>
			<method name="public String getDisplayString(String[] children)">2</method>
			<method name="public String getName()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory$ColumnPrunerDefaultProc</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>6</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>6</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>20</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx ctx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.RCFile$Reader$SelectedColumn</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>12</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.io.RCFile$1 x0)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.classification.InterfaceAudience$LimitedPrivate</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract String[] value()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Jetty20SShims</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>5</rfc>
		<lcom>3</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>22</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.7777777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.333333333333333</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public volatile org.apache.hadoop.hive.shims.JettyShims$Server startServer(String x0, int x1)">1</method>
			<method name="public org.apache.hadoop.hive.shims.Jetty20SShims$Server startServer(String listen, int port)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.Operator$_Fields</name>
		<wmc>9</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>24</rfc>
		<lcom>26</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>0.775</lcom3>
		<loc>185</loc>
		<dam>0.4</dam>
		<moa>7</moa>
		<mfa>0.65</mfa>
		<cam>0.3125</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>18.444444444444443</amc>
		<cc>
			<method name="private void _init_(String, int, short thriftId, String fieldName)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Operator$_Fields findByThriftId(int fieldId)">2</method>
			<method name="public String getFieldName()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Operator$_Fields findByName(String name)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Operator$_Fields[] values()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Operator$_Fields valueOf(String name)">1</method>
			<method name="public short getThriftFieldId()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Operator$_Fields findByThriftIdOrThrow(int fieldId)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveSemanticAnalyzerHook</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void postAnalyze(org.apache.hadoop.hive.ql.parse.HiveSemanticAnalyzerHookContext, java.util.List)">1</method>
			<method name="public abstract org.apache.hadoop.hive.ql.parse.ASTNode preAnalyze(org.apache.hadoop.hive.ql.parse.HiveSemanticAnalyzerHookContext, org.apache.hadoop.hive.ql.parse.ASTNode)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.CreateViewDesc</name>
		<wmc>24</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>26</rfc>
		<lcom>218</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>24</npm>
		<lcom3>0.9288537549407114</lcom3>
		<loc>140</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.31666666666666665</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.375</amc>
		<cc>
			<method name="public void _init_(String viewName, java.util.List schema, String comment, java.util.Map tblProps, java.util.List partColNames, boolean ifNotExists, boolean orReplace)">0</method>
			<method name="public void setViewName(String viewName)">1</method>
			<method name="public void setPartColNames(java.util.List partColNames)">1</method>
			<method name="public String getViewExpandedText()">1</method>
			<method name="public void setViewExpandedText(String expandedText)">1</method>
			<method name="public void setOrReplace(boolean orReplace)">1</method>
			<method name="public void setComment(String comment)">1</method>
			<method name="public String getComment()">1</method>
			<method name="public java.util.List getPartColNames()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setSchema(java.util.List schema)">1</method>
			<method name="public void setPartCols(java.util.List partCols)">1</method>
			<method name="public java.util.List getSchema()">1</method>
			<method name="public void setViewOriginalText(String originalText)">1</method>
			<method name="public java.util.List getPartColsString()">1</method>
			<method name="public void setIfNotExists(boolean ifNotExists)">1</method>
			<method name="public java.util.List getPartCols()">1</method>
			<method name="public boolean getOrReplace()">1</method>
			<method name="public java.util.List getSchemaString()">1</method>
			<method name="public boolean getIfNotExists()">1</method>
			<method name="public String getViewName()">1</method>
			<method name="public java.util.Map getTblProps()">1</method>
			<method name="public void setTblProps(java.util.Map tblProps)">1</method>
			<method name="public String getViewOriginalText()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.FunctionRegistry</name>
		<wmc>50</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>74</cbo>
		<rfc>158</rfc>
		<lcom>1067</lcom>
		<ca>29</ca>
		<ce>49</ce>
		<npm>40</npm>
		<lcom3>0.7959183673469388</lcom3>
		<loc>2122</loc>
		<dam>0.25</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.10841836734693877</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>41.36</amc>
		<cc>
			<method name="public static void registerTemporaryGenericUDAF(String functionName, org.apache.hadoop.hive.ql.udf.generic.GenericUDAFResolver genericUDAFResolver)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.udf.generic.GenericUDAFResolver getGenericUDAFResolver(String functionName)">3</method>
			<method name="static void registerGenericUDAF(String functionName, org.apache.hadoop.hive.ql.udf.generic.GenericUDAFResolver genericUDAFResolver)">1</method>
			<method name="static void registerNumericType(String typeName, int level)">1</method>
			<method name="public static boolean isOpOr(org.apache.hadoop.hive.ql.plan.ExprNodeDesc desc)">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.typeinfo.TypeInfo getCommonClassForComparison(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo a, org.apache.hadoop.hive.serde2.typeinfo.TypeInfo b)">3</method>
			<method name="public static boolean isDeterministic(org.apache.hadoop.hive.ql.udf.generic.GenericUDF genericUDF)">7</method>
			<method name="public static void registerGenericUDF(boolean isNative, String functionName, Class genericUDFClass)">2</method>
			<method name="public static boolean isOpAndOrNot(org.apache.hadoop.hive.ql.plan.ExprNodeDesc desc)">4</method>
			<method name="public static org.apache.hadoop.hive.ql.udf.generic.GenericUDF getGenericUDFForAnd()">1</method>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.FunctionInfo getFunctionInfo(String functionName)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.udf.generic.GenericUDF getGenericUDFForIndex()">1</method>
			<method name="public static void registerUDF(String functionName, Class UDFClass, boolean isOperator, String displayName)">1</method>
			<method name="public static void registerTemporaryGenericUDF(String functionName, Class genericUDFClass)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.udf.generic.GenericUDTF cloneGenericUDTF(org.apache.hadoop.hive.ql.udf.generic.GenericUDTF genericUDTF)">2</method>
			<method name="public static java.lang.reflect.Method getMethodInternal(Class udfClass, String methodName, boolean exact, java.util.List argumentClasses)">1</method>
			<method name="public static void registerGenericUDAF(boolean isNative, String functionName, org.apache.hadoop.hive.ql.udf.generic.GenericUDAFResolver genericUDAFResolver)">1</method>
			<method name="public static void registerGenericUDTF(boolean isNative, String functionName, Class genericUDTFClass)">2</method>
			<method name="public static void registerTemporaryGenericUDTF(String functionName, Class genericUDTFClass)">1</method>
			<method name="public static transient Object invoke(java.lang.reflect.Method m, Object thisObject, Object[] arguments)">1</method>
			<method name="private static Class getUDFClassFromExprDesc(org.apache.hadoop.hive.ql.plan.ExprNodeDesc desc)">3</method>
			<method name="public static org.apache.hadoop.hive.ql.udf.generic.GenericUDF cloneGenericUDF(org.apache.hadoop.hive.ql.udf.generic.GenericUDF genericUDF)">3</method>
			<method name="public static void registerTemporaryUDAF(String functionName, Class udafClass)">1</method>
			<method name="public static boolean isOpAnd(org.apache.hadoop.hive.ql.plan.ExprNodeDesc desc)">2</method>
			<method name="static void registerUDF(String functionName, Class UDFClass, boolean isOperator)">1</method>
			<method name="public static int matchCost(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo argumentPassed, org.apache.hadoop.hive.serde2.typeinfo.TypeInfo argumentAccepted, boolean exact)">12</method>
			<method name="public static void registerUDF(boolean isNative, String functionName, Class UDFClass, boolean isOperator, String displayName)">2</method>
			<method name="public static boolean isOpNot(org.apache.hadoop.hive.ql.plan.ExprNodeDesc desc)">2</method>
			<method name="public static void registerUDF(boolean isNative, String functionName, Class UDFClass, boolean isOperator)">1</method>
			<method name="public static org.apache.hadoop.hive.serde2.typeinfo.TypeInfo getCommonClassForUnionAll(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo a, org.apache.hadoop.hive.serde2.typeinfo.TypeInfo b)">5</method>
			<method name="static void registerGenericUDF(String functionName, Class genericUDFClass)">1</method>
			<method name="static void registerUDAF(String functionName, Class udafClass)">1</method>
			<method name="public static boolean implicitConvertable(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo from, org.apache.hadoop.hive.serde2.typeinfo.TypeInfo to)">10</method>
			<method name="public static void registerUDAF(boolean isNative, String functionName, Class udafClass)">1</method>
			<method name="public static boolean isStateful(org.apache.hadoop.hive.ql.udf.generic.GenericUDF genericUDF)">6</method>
			<method name="public static org.apache.hadoop.hive.serde2.typeinfo.TypeInfo getCommonClass(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo a, org.apache.hadoop.hive.serde2.typeinfo.TypeInfo b)">5</method>
			<method name="public static boolean registerTemporaryFunction(String functionName, Class udfClass)">6</method>
			<method name="public static boolean isOpPositive(org.apache.hadoop.hive.ql.plan.ExprNodeDesc desc)">2</method>
			<method name="public static java.util.Set getFunctionSynonyms(String funcName)">4</method>
			<method name="public static org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getGenericUDAFEvaluator(String name, java.util.List argumentOIs, boolean isDistinct, boolean isAllColumns)">1</method>
			<method name="public static void registerTemporaryUDF(String functionName, Class UDFClass, boolean isOperator)">1</method>
			<method name="static void registerGenericUDTF(String functionName, Class genericUDTFClass)">1</method>
			<method name="public static java.util.Set getFunctionNames()">1</method>
			<method name="public static void registerFunctionsFromPluginJar(java.net.URL jarLocation, ClassLoader classLoader)">1</method>
			<method name="private static Class getGenericUDFClassFromExprDesc(org.apache.hadoop.hive.ql.plan.ExprNodeDesc desc)">2</method>
			<method name="public static void unregisterTemporaryUDF(String functionName)">1</method>
			<method name="public static java.util.Set getFunctionNames(String funcPatternStr)">2</method>
			<method name="public static java.lang.reflect.Method getMethodInternal(Class udfClass, java.util.List mlist, boolean exact, java.util.List argumentsPassed)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCovarianceSample$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>70</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>68.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.session.SessionState$ResourceType</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>10</rfc>
		<lcom>4</lcom>
		<ca>10</ca>
		<ce>5</ce>
		<npm>2</npm>
		<lcom3>0.8666666666666667</lcom3>
		<loc>69</loc>
		<dam>0.2</dam>
		<moa>5</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4166666666666667</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>15.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int, org.apache.hadoop.hive.ql.session.SessionState$ResourceHook hook)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.session.SessionState$ResourceType valueOf(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.session.SessionState$ResourceType[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde.test.InnerStruct$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>14</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$colTypeList_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Utilities$StreamStatus</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.888888888888889</lcom3>
		<loc>45</loc>
		<dam>0.3333333333333333</dam>
		<moa>3</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>9.5</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.exec.Utilities$StreamStatus valueOf(String name)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.Utilities$StreamStatus[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFWeekOfYear</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>15</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>0.16666666666666674</lcom3>
		<loc>77</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>23.666666666666668</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable t)">2</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.Text dateString)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ShowGrantDesc</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>11</rfc>
		<lcom>21</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>10</npm>
		<lcom3>0.7777777777777778</lcom3>
		<loc>60</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.36</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.6</amc>
		<cc>
			<method name="public String getResFile()">1</method>
			<method name="public void setHiveObj(org.apache.hadoop.hive.ql.plan.PrivilegeObjectDesc subjectObj)">1</method>
			<method name="public void setResFile(String resFile)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.List getColumns()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.PrincipalDesc getPrincipalDesc()">1</method>
			<method name="public void setPrincipalDesc(org.apache.hadoop.hive.ql.plan.PrincipalDesc principalDesc)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.PrivilegeObjectDesc getHiveObj()">1</method>
			<method name="public void _init_(String resFile, org.apache.hadoop.hive.ql.plan.PrincipalDesc principalDesc, org.apache.hadoop.hive.ql.plan.PrivilegeObjectDesc subjectObj, java.util.List columns)">0</method>
			<method name="public void setColumns(java.util.List columns)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFSum$GenericUDAFSumLong</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>24</rfc>
		<lcom>24</lcom>
		<ca>1</ca>
		<ce>14</ce>
		<npm>8</npm>
		<lcom3>0.78125</lcom3>
		<loc>153</loc>
		<dam>0.75</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.3541666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.555555555555555</amc>
		<cc>
			<method name="public void iterate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object[] parameters)">1</method>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector init(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode m, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] parameters)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer getNewAggregationBuffer()">1</method>
			<method name="public void merge(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object partial)">1</method>
			<method name="public Object terminatePartial(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void reset(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.AbstractPrimitiveWritableObjectInspector</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>11</noc>
		<cbo>19</cbo>
		<rfc>4</rfc>
		<lcom>3</lcom>
		<ca>17</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.6666666666666665</amc>
		<cc>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils$PrimitiveTypeEntry typeEntry)">0</method>
			<method name="public Object getPrimitiveWritableObject(Object o)">1</method>
			<method name="public boolean preferWritable()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$createViewStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.ParseException</name>
		<wmc>5</wmc>
		<dit>3</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>18</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>4</npm>
		<lcom3>0.55</lcom3>
		<loc>371</loc>
		<dam>0.4</dam>
		<moa>1</moa>
		<mfa>0.9130434782608695</mfa>
		<cam>0.4</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>72.2</amc>
		<cc>
			<method name="protected String add_escapes(String str)">14</method>
			<method name="public void _init_()">0</method>
			<method name="public String getMessage()">10</method>
			<method name="public void _init_(String message)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.Token currentTokenVal, int[][] expectedTokenSequencesVal, String[] tokenImageVal)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFRegExpReplace</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>15</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>101</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>47.0</amc>
		<cc>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text s, org.apache.hadoop.io.Text regex, org.apache.hadoop.io.Text replacement)">8</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.SerDeStatsStruct</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract long getRawDataSerializedSize()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.ByteStream</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFPercentileApprox$GenericUDAFPercentileApproxEvaluator</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>2</noc>
		<cbo>14</cbo>
		<rfc>40</rfc>
		<lcom>20</lcom>
		<ca>2</ca>
		<ce>12</ce>
		<npm>6</npm>
		<lcom3>0.8571428571428571</lcom3>
		<loc>307</loc>
		<dam>0.8</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>36.75</amc>
		<cc>
			<method name="public void iterate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object[] parameters)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer getNewAggregationBuffer()">1</method>
			<method name="public void reset(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="protected double[] getQuantileArray(org.apache.hadoop.hive.serde2.objectinspector.ConstantObjectInspector quantileOI)">1</method>
			<method name="public Object terminatePartial(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void merge(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object partial)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TSSLTransportFactory</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>42</rfc>
		<lcom>55</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>8</npm>
		<lcom3>2.0</lcom3>
		<loc>270</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2840909090909091</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>23.545454545454547</amc>
		<cc>
			<method name="private static org.apache.thrift.transport.TSocket createClient(javax.net.ssl.SSLSocketFactory factory, String host, int port, int timeout)">1</method>
			<method name="public static org.apache.thrift.transport.TSocket getClientSocket(String host, int port, int timeout)">1</method>
			<method name="public void _init_()">0</method>
			<method name="private static javax.net.ssl.SSLContext createSSLContext(org.apache.thrift.transport.TSSLTransportFactory$TSSLTransportParameters params)">1</method>
			<method name="public static org.apache.thrift.transport.TSocket getClientSocket(String host, int port, int timeout, org.apache.thrift.transport.TSSLTransportFactory$TSSLTransportParameters params)">1</method>
			<method name="private static org.apache.thrift.transport.TServerSocket createServer(javax.net.ssl.SSLServerSocketFactory factory, int port, int timeout, boolean clientAuth, java.net.InetAddress ifAddress, org.apache.thrift.transport.TSSLTransportFactory$TSSLTransportParameters params)">1</method>
			<method name="public static org.apache.thrift.transport.TServerSocket getServerSocket(int port, int clientTimeout, java.net.InetAddress ifAddress, org.apache.thrift.transport.TSSLTransportFactory$TSSLTransportParameters params)">1</method>
			<method name="public static org.apache.thrift.transport.TSocket getClientSocket(String host, int port)">1</method>
			<method name="public static org.apache.thrift.transport.TServerSocket getServerSocket(int port, int clientTimeout)">1</method>
			<method name="public static org.apache.thrift.transport.TServerSocket getServerSocket(int port, int clientTimeout, boolean clientAuth, java.net.InetAddress ifAddress)">1</method>
			<method name="public static org.apache.thrift.transport.TServerSocket getServerSocket(int port)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HiveInputFormat$HiveInputSplit</name>
		<wmc>13</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>9</cbo>
		<rfc>34</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>6</ce>
		<npm>13</npm>
		<lcom3>0.611111111111111</lcom3>
		<loc>168</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.23076923076923078</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.692307692307692</amc>
		<cc>
			<method name="public long getLength()">1</method>
			<method name="public org.apache.hadoop.conf.Configuration getConf()">1</method>
			<method name="public long getStart()">2</method>
			<method name="public void _init_()">0</method>
			<method name="public void setConf(org.apache.hadoop.conf.Configuration conf)">1</method>
			<method name="public void write(java.io.DataOutput out)">1</method>
			<method name="public String inputFormatClassName()">1</method>
			<method name="public String[] getLocations()">1</method>
			<method name="public void _init_(org.apache.hadoop.mapred.InputSplit inputSplit, String inputFormatClassName)">0</method>
			<method name="public String toString()">1</method>
			<method name="public void readFields(java.io.DataInput in)">1</method>
			<method name="public org.apache.hadoop.mapred.InputSplit getInputSplit()">1</method>
			<method name="public org.apache.hadoop.fs.Path getPath()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.TUGIContainingTransport$Factory</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>10</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>5</ce>
		<npm>3</npm>
		<lcom3>0.3333333333333333</lcom3>
		<loc>33</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.thrift.TUGIContainingTransport getTransport(org.apache.thrift.transport.TTransport trans)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public volatile org.apache.thrift.transport.TTransport getTransport(org.apache.thrift.transport.TTransport x0)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.AbstractIndexHandler</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>1</noc>
		<cbo>9</cbo>
		<rfc>13</rfc>
		<lcom>6</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>43</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3125</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.75</amc>
		<cc>
			<method name="public void generateIndexQuery(org.apache.hadoop.hive.metastore.api.Index index, org.apache.hadoop.hive.ql.plan.ExprNodeDesc predicate, org.apache.hadoop.hive.ql.parse.ParseContext pctx, org.apache.hadoop.hive.ql.index.HiveIndexQueryContext queryContext)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public static String getColumnNames(java.util.List fieldSchemas)">3</method>
			<method name="public boolean checkQuerySize(long inputSize, org.apache.hadoop.hive.conf.HiveConf conf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.meta_data.StructMetaData</name>
		<wmc>1</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>7</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public void _init_(byte type, Class sClass)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.commons.lang.StringUtils</name>
		<wmc>161</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>35</cbo>
		<rfc>232</rfc>
		<lcom>12880</lcom>
		<ca>30</ca>
		<ce>6</ce>
		<npm>153</npm>
		<lcom3>1.00625</lcom3>
		<loc>4545</loc>
		<dam>0.3333333333333333</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.14658385093167703</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>27.211180124223603</amc>
		<cc>
			<method name="public static String defaultString(String str)">2</method>
			<method name="public static String abbreviate(String str, int offset, int maxWidth)">9</method>
			<method name="public static String uncapitalise(String str)">1</method>
			<method name="public static boolean isAlpha(String str)">4</method>
			<method name="public static String difference(String str1, String str2)">4</method>
			<method name="public static String[] stripAll(String[] strs, String stripChars)">4</method>
			<method name="private static String[] splitWorker(String str, String separatorChars, int max, boolean preserveAllTokens)">22</method>
			<method name="public static String leftPad(String str, int size, char padChar)">4</method>
			<method name="public static boolean isBlank(String str)">5</method>
			<method name="public static String leftPad(String str, int size)">1</method>
			<method name="public static String join(java.util.Iterator iterator, char separator)">6</method>
			<method name="public static int indexOfAny(String str, String searchChars)">3</method>
			<method name="public static boolean isNotBlank(String str)">2</method>
			<method name="public static String chompLast(String str)">1</method>
			<method name="public static int lastIndexOf(String str, char searchChar)">2</method>
			<method name="public static String stripToEmpty(String str)">2</method>
			<method name="public static String substringAfter(String str, String separator)">4</method>
			<method name="public static String overlay(String str, String overlay, int start, int end)">8</method>
			<method name="public static boolean containsAny(String str, char[] searchChars)">8</method>
			<method name="public static String rightPad(String str, int size)">1</method>
			<method name="public static String[] splitByWholeSeparatorPreserveAllTokens(String str, String separator)">1</method>
			<method name="public static String center(String str, int size)">1</method>
			<method name="public static String[] splitByWholeSeparatorPreserveAllTokens(String str, String separator, int max)">1</method>
			<method name="public static String prechomp(String str, String sep)">2</method>
			<method name="public static String[] stripAll(String[] strs)">1</method>
			<method name="public static String replaceOnce(String text, String searchString, String replacement)">1</method>
			<method name="public static int length(String str)">2</method>
			<method name="public static String remove(String str, char remove)">5</method>
			<method name="public static boolean endsWithIgnoreCase(String str, String suffix)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public static String removeStart(String str, String remove)">4</method>
			<method name="public static boolean startsWithIgnoreCase(String str, String prefix)">1</method>
			<method name="public static int indexOfAny(String str, char[] searchChars)">6</method>
			<method name="public static String removeStartIgnoreCase(String str, String remove)">4</method>
			<method name="public static String defaultString(String str, String defaultStr)">2</method>
			<method name="private static boolean endsWith(String str, String suffix, boolean ignoreCase)">6</method>
			<method name="public static String lowerCase(String str)">2</method>
			<method name="public static String getCommonPrefix(String[] strs)">6</method>
			<method name="public static String reverseDelimitedString(String str, String separatorChars)">3</method>
			<method name="public static String concatenate(Object[] array)">1</method>
			<method name="public static String replace(String text, String searchString, String replacement)">1</method>
			<method name="public static String[] splitByCharacterTypeCamelCase(String str)">1</method>
			<method name="public static String substringBefore(String str, String separator)">5</method>
			<method name="public static int getLevenshteinDistance(String s, String t)">10</method>
			<method name="private static String[] splitWorker(String str, char separatorChar, boolean preserveAllTokens)">10</method>
			<method name="public static String reverse(String str)">2</method>
			<method name="public static boolean containsAny(String str, String searchChars)">2</method>
			<method name="public static String[] split(String str, char separatorChar)">1</method>
			<method name="public static int lastIndexOf(String str, String searchStr, int startPos)">3</method>
			<method name="public static String join(Object[] array)">1</method>
			<method name="public static boolean isNumeric(String str)">4</method>
			<method name="public static String left(String str, int len)">4</method>
			<method name="public static boolean isNotEmpty(String str)">2</method>
			<method name="public static int indexOfAnyBut(String str, String searchChars)">5</method>
			<method name="public static String join(Object[] array, char separator, int startIndex, int endIndex)">7</method>
			<method name="public static String chopNewline(String str)">4</method>
			<method name="public static boolean containsNone(String str, char[] invalidChars)">6</method>
			<method name="public static String center(String str, int size, String padStr)">5</method>
			<method name="public static boolean isNumericSpace(String str)">5</method>
			<method name="public static String substringAfterLast(String str, String separator)">5</method>
			<method name="public static String join(Object[] array, char separator)">2</method>
			<method name="public static String deleteWhitespace(String str)">5</method>
			<method name="public static String replaceChars(String str, char searchChar, char replaceChar)">2</method>
			<method name="public static String defaultIfEmpty(String str, String defaultStr)">2</method>
			<method name="public static String leftPad(String str, int size, String padStr)">9</method>
			<method name="public static String repeat(String str, int repeat)">13</method>
			<method name="public static boolean containsNone(String str, String invalidChars)">3</method>
			<method name="public static boolean isWhitespace(String str)">4</method>
			<method name="public static String abbreviate(String str, int maxWidth)">1</method>
			<method name="public static String join(java.util.Collection collection, char separator)">2</method>
			<method name="public static String[] splitPreserveAllTokens(String str, char separatorChar)">1</method>
			<method name="public static String stripStart(String str, String stripChars)">9</method>
			<method name="public static boolean contains(String str, String searchStr)">4</method>
			<method name="public static String getNestedString(String str, String tag)">1</method>
			<method name="public static String reverseDelimited(String str, char separatorChar)">2</method>
			<method name="public static String substring(String str, int start, int end)">8</method>
			<method name="public static boolean isAlphanumeric(String str)">4</method>
			<method name="public static String chomp(String str)">8</method>
			<method name="public static String upperCase(String str)">2</method>
			<method name="private static String[] splitByCharacterType(String str, boolean camelCase)">8</method>
			<method name="public static String join(Object[] array, String separator)">2</method>
			<method name="public static String stripToNull(String str)">3</method>
			<method name="public static String remove(String str, String remove)">3</method>
			<method name="public static String[] splitPreserveAllTokens(String str, String separatorChars)">1</method>
			<method name="public static String[] splitByWholeSeparator(String str, String separator)">1</method>
			<method name="public static int lastIndexOfAny(String str, String[] searchStrs)">6</method>
			<method name="public static String replaceChars(String str, String searchChars, String replaceChars)">8</method>
			<method name="public static String mid(String str, int pos, int len)">6</method>
			<method name="public static int indexOf(String str, char searchChar)">2</method>
			<method name="public static String deleteSpaces(String str)">2</method>
			<method name="public static String substring(String str, int start)">5</method>
			<method name="public static String[] split(String str)">1</method>
			<method name="public static String join(java.util.Collection collection, String separator)">2</method>
			<method name="public static int indexOfAny(String str, String[] searchStrs)">8</method>
			<method name="public static int ordinalIndexOf(String str, String searchStr, int ordinal)">7</method>
			<method name="public static String getNestedString(String str, String open, String close)">1</method>
			<method name="public static String[] substringsBetween(String str, String open, String close)">9</method>
			<method name="public static String strip(String str, String stripChars)">2</method>
			<method name="public static int indexOfDifference(String[] strs)">15</method>
			<method name="public static String rightPad(String str, int size, char padChar)">4</method>
			<method name="public static String capitalize(String str)">3</method>
			<method name="public static String[] splitByCharacterType(String str)">1</method>
			<method name="public static String[] splitPreserveAllTokens(String str)">1</method>
			<method name="public static String removeEndIgnoreCase(String str, String remove)">4</method>
			<method name="public static int indexOf(String str, String searchStr)">3</method>
			<method name="public static String substringBetween(String str, String open, String close)">6</method>
			<method name="public static String strip(String str)">1</method>
			<method name="public static String center(String str, int size, char padChar)">4</method>
			<method name="public static String getChomp(String str, String sep)">3</method>
			<method name="public static String capitalise(String str)">1</method>
			<method name="public static int indexOf(String str, String searchStr, int startPos)">5</method>
			<method name="public static String removeEnd(String str, String remove)">4</method>
			<method name="public static boolean contains(String str, char searchChar)">3</method>
			<method name="public static String overlayString(String text, String overlay, int start, int end)">1</method>
			<method name="public static String swapCase(String str)">7</method>
			<method name="private static String replaceEach(String text, String[] searchList, String[] replacementList, boolean repeat, int timeToLive)">31</method>
			<method name="public static String stripEnd(String str, String stripChars)">9</method>
			<method name="public static String[] splitByWholeSeparator(String str, String separator, int max)">1</method>
			<method name="public static String[] splitPreserveAllTokens(String str, String separatorChars, int max)">1</method>
			<method name="public static int indexOfDifference(String str1, String str2)">9</method>
			<method name="public static int lastIndexOf(String str, String searchStr)">3</method>
			<method name="public static String trimToEmpty(String str)">2</method>
			<method name="public static String uncapitalize(String str)">3</method>
			<method name="public static String trim(String str)">2</method>
			<method name="private static String[] splitByWholeSeparatorWorker(String str, String separator, int max, boolean preserveAllTokens)">11</method>
			<method name="public static boolean containsOnly(String str, char[] valid)">6</method>
			<method name="private static String padding(int repeat, char padChar)">1</method>
			<method name="public static boolean containsIgnoreCase(String str, String searchStr)">3</method>
			<method name="public static String capitaliseAllWords(String str)">1</method>
			<method name="public static String[] split(String str, String separatorChars, int max)">1</method>
			<method name="public static String substringBeforeLast(String str, String separator)">4</method>
			<method name="public static String join(java.util.Iterator iterator, String separator)">7</method>
			<method name="public static int indexOf(String str, char searchChar, int startPos)">2</method>
			<method name="public static String chomp(String str, String separator)">4</method>
			<method name="public static boolean isAlphaSpace(String str)">5</method>
			<method name="public static int countMatches(String str, String sub)">4</method>
			<method name="public static String escape(String str)">1</method>
			<method name="public static String substringBetween(String str, String tag)">1</method>
			<method name="private static boolean startsWith(String str, String prefix, boolean ignoreCase)">6</method>
			<method name="public static String rightPad(String str, int size, String padStr)">9</method>
			<method name="public static String trimToNull(String str)">2</method>
			<method name="public static boolean isEmpty(String str)">3</method>
			<method name="public static String[] split(String str, String separatorChars)">1</method>
			<method name="public static String join(Object[] array, String separator, int startIndex, int endIndex)">8</method>
			<method name="public static String right(String str, int len)">4</method>
			<method name="public static boolean endsWith(String str, String suffix)">1</method>
			<method name="public static boolean equals(String str1, String str2)">3</method>
			<method name="public static int indexOfAnyBut(String str, char[] searchChars)">6</method>
			<method name="public static String replace(String text, String searchString, String replacement, int max)">11</method>
			<method name="public static boolean containsOnly(String str, String validChars)">3</method>
			<method name="public static String chompLast(String str, String sep)">3</method>
			<method name="public static String chop(String str)">5</method>
			<method name="public static int lastIndexOf(String str, char searchChar, int startPos)">2</method>
			<method name="public static String clean(String str)">2</method>
			<method name="public static String replaceEachRepeatedly(String text, String[] searchList, String[] replacementList)">2</method>
			<method name="public static String getPrechomp(String str, String sep)">2</method>
			<method name="public static boolean isAsciiPrintable(String str)">4</method>
			<method name="public static boolean startsWith(String str, String prefix)">1</method>
			<method name="public static boolean equalsIgnoreCase(String str1, String str2)">3</method>
			<method name="public static String replaceEach(String text, String[] searchList, String[] replacementList)">1</method>
			<method name="public static boolean isAlphanumericSpace(String str)">5</method>
		</cc>
	</class>
	<class>
		<name>javaewah.IntIterator</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract boolean hasNext()">1</method>
			<method name="public abstract int next()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.ppd.ExprWalkerProcFactory</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>27</cbo>
		<rfc>49</rfc>
		<lcom>34</lcom>
		<ca>2</ca>
		<ce>25</ce>
		<npm>5</npm>
		<lcom3>0.875</lcom3>
		<loc>259</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.17857142857142858</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>27.555555555555557</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.ppd.ExprWalkerInfo extractPushdownPreds(org.apache.hadoop.hive.ql.ppd.OpWalkerInfo opContext, org.apache.hadoop.hive.ql.exec.Operator op, org.apache.hadoop.hive.ql.plan.ExprNodeDesc pred)">1</method>
			<method name="private static org.apache.hadoop.hive.ql.lib.NodeProcessor getFieldProcessor()">1</method>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getGenericFuncProcessor()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.ppd.ExprWalkerInfo extractPushdownPreds(org.apache.hadoop.hive.ql.ppd.OpWalkerInfo opContext, org.apache.hadoop.hive.ql.exec.Operator op, java.util.List preds)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getColumnProcessor()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private static void extractFinalCandidates(org.apache.hadoop.hive.ql.plan.ExprNodeDesc expr, org.apache.hadoop.hive.ql.ppd.ExprWalkerInfo ctx, org.apache.hadoop.hive.conf.HiveConf conf)">8</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getDefaultExprProcessor()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.DynamicPartitionCtx</name>
		<wmc>27</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>44</rfc>
		<lcom>225</lcom>
		<ca>12</ca>
		<ce>3</ce>
		<npm>26</npm>
		<lcom3>0.8964497041420117</lcom3>
		<loc>291</loc>
		<dam>0.9230769230769231</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.23626373626373626</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.296296296296296</amc>
		<cc>
			<method name="public int getNumBuckets()">1</method>
			<method name="public void setSPPath(String sp)">1</method>
			<method name="public void setSPColNames(java.util.List sp)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void setPartSpec(java.util.Map ps)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Table tbl, java.util.Map partSpec, String defaultPartName, int maxParts)">0</method>
			<method name="public int getNumDPCols()">1</method>
			<method name="public void setNumBuckets(int bk)">1</method>
			<method name="public int getNumSPCols()">1</method>
			<method name="public String getDefaultPartitionName()">1</method>
			<method name="public void setInputToDPCols(java.util.Map map)">1</method>
			<method name="public void setDefaultPartitionName(String pname)">1</method>
			<method name="public void setNumDPCols(int dp)">1</method>
			<method name="public String getRootPath()">1</method>
			<method name="public void mapInputToDP(java.util.List fs)">5</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.List getSPColNames()">1</method>
			<method name="public int getMaxPartitionsPerNode()">1</method>
			<method name="public String getSPPath()">1</method>
			<method name="public void setRootPath(String root)">1</method>
			<method name="public void setMaxPartitionsPerNode(int maxParts)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.DynamicPartitionCtx dp)">0</method>
			<method name="public java.util.List getDPColNames()">1</method>
			<method name="public java.util.Map getPartSpec()">1</method>
			<method name="public void setDPColNames(java.util.List dp)">1</method>
			<method name="public java.util.Map getInputToDPCols()">1</method>
			<method name="public void setNumSPCols(int sp)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.MapEqualComparer</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract int compare(Object, org.apache.hadoop.hive.serde2.objectinspector.MapObjectInspector, Object, org.apache.hadoop.hive.serde2.objectinspector.MapObjectInspector)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ReduceSinkDeDuplication$ReduceSinkDeduplicateProcFactory$ReducerReducerProc</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>28</cbo>
		<rfc>72</rfc>
		<lcom>36</lcom>
		<ca>1</ca>
		<ce>27</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>739</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.29292929292929293</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>81.11111111111111</amc>
		<cc>
			<method name="private java.util.HashMap getPartitionAndKeyColumnMapping(org.apache.hadoop.hive.ql.exec.ReduceSinkOperator reduceSink)">5</method>
			<method name="void _init_()">0</method>
			<method name="private boolean compareExprNodes(java.util.HashMap childColumnMapping, java.util.HashMap parentColumnMapping, java.util.ArrayList childColExprs, java.util.ArrayList parentColExprs)">11</method>
			<method name="private boolean backTrackColumnNames(java.util.HashMap columnMapping, org.apache.hadoop.hive.ql.exec.ReduceSinkOperator reduceSink, org.apache.hadoop.hive.ql.exec.Operator stopBacktrackFlagOp, org.apache.hadoop.hive.ql.parse.ParseContext pGraphContext)">6</method>
			<method name="private boolean compareReduceSink(org.apache.hadoop.hive.ql.exec.ReduceSinkOperator childReduceSink, org.apache.hadoop.hive.ql.exec.ReduceSinkOperator parentRS, java.util.HashMap childColumnMapping, java.util.HashMap parentColumnMapping)">14</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator putOpInsertMap(org.apache.hadoop.hive.ql.exec.Operator op, org.apache.hadoop.hive.ql.parse.RowResolver rr, org.apache.hadoop.hive.ql.parse.ParseContext pGraphContext)">1</method>
			<method name="private void replaceReduceSinkWithSelectOperator(org.apache.hadoop.hive.ql.exec.ReduceSinkOperator childReduceSink, org.apache.hadoop.hive.ql.parse.ParseContext pGraphContext)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.ReduceSinkOperator findSingleParentReduceSink(org.apache.hadoop.hive.ql.exec.ReduceSinkOperator childReduceSink, org.apache.hadoop.hive.ql.parse.ParseContext pGraphContext)">13</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$booleanValue_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$recordWriter_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$alterTableStatementSuffix_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$indexComment_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyLong</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>13</cbo>
		<rfc>25</rfc>
		<lcom>22</lcom>
		<ca>8</ca>
		<ce>7</ce>
		<npm>7</npm>
		<lcom3>2.0</lcom3>
		<loc>281</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.25</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>34.125</amc>
		<cc>
			<method name="public static long parseLong(byte[] bytes, int start, int length)">1</method>
			<method name="public static void writeUTF8(java.io.OutputStream out, long i)">1</method>
			<method name="private static long parse(byte[] bytes, int start, int length, int offset, int radix, boolean negative)">7</method>
			<method name="public static long parseLong(byte[] bytes, int start, int length, int radix)">9</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
			<method name="public static void writeUTF8NoException(java.io.OutputStream out, long i)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.LazyLong copy)">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyLongObjectInspector oi)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.unionproc.UnionProcFactory$MapUnion</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>11</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>43</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>20.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFAverage$GenericUDAFAverageEvaluator$AverageAgg</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>6</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TMessageType</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>8</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.DefaultBucketMatcher</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>21</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>5</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>89</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.2</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void setBucketFileNameMapping(java.util.LinkedHashMap bucketFileNameMapping)">1</method>
			<method name="public void setAliasBucketFileNameMapping(java.util.LinkedHashMap aliasBucketFileNameMapping)">1</method>
			<method name="public java.util.List getAliasBucketFiles(String refTableInputFile, String refTableAlias, String alias)">3</method>
			<method name="public java.util.LinkedHashMap getBucketFileNameMapping()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.MoveTask</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>36</cbo>
		<rfc>105</rfc>
		<lcom>28</lcom>
		<ca>1</ca>
		<ce>35</ce>
		<npm>5</npm>
		<lcom3>0.9375</lcom3>
		<loc>806</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2916666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>88.33333333333333</amc>
		<cc>
			<method name="public int execute(org.apache.hadoop.hive.ql.DriverContext driverContext)">27</method>
			<method name="private org.apache.hadoop.fs.Path createTargetPath(org.apache.hadoop.fs.Path targetPath, org.apache.hadoop.fs.FileSystem fs)">1</method>
			<method name="public boolean isLocal()">4</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="protected void localizeMRTmpFilesImpl(org.apache.hadoop.hive.ql.Context ctx)">1</method>
			<method name="public String getName()">1</method>
			<method name="private void moveFile(org.apache.hadoop.fs.Path sourcePath, org.apache.hadoop.fs.Path targetPath, boolean isDfsDir)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.StageType getType()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.Graph$_Fields</name>
		<wmc>9</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>24</rfc>
		<lcom>26</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>0.7857142857142857</lcom3>
		<loc>140</loc>
		<dam>0.5714285714285714</dam>
		<moa>4</moa>
		<mfa>0.65</mfa>
		<cam>0.3125</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>13.777777777777779</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Graph$_Fields findByThriftId(int fieldId)">2</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Graph$_Fields valueOf(String name)">1</method>
			<method name="private void _init_(String, int, short thriftId, String fieldName)">0</method>
			<method name="public String getFieldName()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Graph$_Fields[] values()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Graph$_Fields findByThriftIdOrThrow(int fieldId)">2</method>
			<method name="public short getThriftFieldId()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Graph$_Fields findByName(String name)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tablePropertiesList_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFStd$GenericUDAFStdEvaluator</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>6</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>38</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.0</amc>
		<cc>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.HiveIndex$IndexType</name>
		<wmc>6</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>9</rfc>
		<lcom>9</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>4</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>78</loc>
		<dam>0.5</dam>
		<moa>4</moa>
		<mfa>0.7647058823529411</mfa>
		<cam>0.4</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>11.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.index.HiveIndex$IndexType valueOf(String name)">1</method>
			<method name="private void _init_(String, int, String indexType, String className)">0</method>
			<method name="public String getName()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.index.HiveIndex$IndexType[] values()">1</method>
			<method name="public String getHandlerClsName()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$ifNotExists_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$hintName_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFRegExp</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>22</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>5</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>100</loc>
		<dam>0.8</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>30.666666666666668</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.io.BooleanWritable evaluate(org.apache.hadoop.io.Text s, org.apache.hadoop.io.Text regex)">7</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils$TypeInfoParser$Token</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>8</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>1.1666666666666667</lcom3>
		<loc>27</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils$1 x0)">0</method>
			<method name="public String toString()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyFloatObjectInspector</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>9</rfc>
		<lcom>6</lcom>
		<ca>4</ca>
		<ce>7</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>33</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.875</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.25</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public float get(Object o)">1</method>
			<method name="public Object getPrimitiveJavaObject(Object o)">2</method>
			<method name="public Object copyObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.CrossMapEqualComparer</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>13</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>100</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>49.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public int compare(Object o1, org.apache.hadoop.hive.serde2.objectinspector.MapObjectInspector moi1, Object o2, org.apache.hadoop.hive.serde2.objectinspector.MapObjectInspector moi2)">6</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFVarianceSample$GenericUDAFVarianceSampleEvaluator</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>5</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>5</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>39</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.5</amc>
		<cc>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tableRowFormatCollItemsIdentifier_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFBetween</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>24</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>12</ce>
		<npm>4</npm>
		<lcom3>0.5</lcom3>
		<loc>215</loc>
		<dam>0.5</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>51.75</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.pcr.PcrExprProcFactory$FieldExprProcessor</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>7</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>71</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>22.333333333333332</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$insertClause_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.TServiceClient</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>21</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>4</npm>
		<lcom3>0.5333333333333333</lcom3>
		<loc>99</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.0</amc>
		<cc>
			<method name="public void _init_(org.apache.thrift.protocol.TProtocol prot)">0</method>
			<method name="protected void sendBase(String methodName, org.apache.thrift.TBase args)">1</method>
			<method name="public void _init_(org.apache.thrift.protocol.TProtocol iprot, org.apache.thrift.protocol.TProtocol oprot)">0</method>
			<method name="protected void receiveBase(org.apache.thrift.TBase result, String methodName)">1</method>
			<method name="public org.apache.thrift.protocol.TProtocol getInputProtocol()">1</method>
			<method name="public org.apache.thrift.protocol.TProtocol getOutputProtocol()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$columnNameOrderList_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCovariance$GenericUDAFCovarianceEvaluator$StdAgg</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>8</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.security.token.delegation.HiveDelegationTokenSupport</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>20</rfc>
		<lcom>6</lcom>
		<ca>2</ca>
		<ce>3</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>75</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.25</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>17.75</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public static byte[] encodeDelegationTokenInformation(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$DelegationTokenInformation token)">1</method>
			<method name="public static void rollMasterKey(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager mgr)">1</method>
			<method name="public static org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$DelegationTokenInformation decodeDelegationTokenInformation(byte[] tokenBytes)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.GenMapRedUtils</name>
		<wmc>22</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>64</cbo>
		<rfc>216</rfc>
		<lcom>141</lcom>
		<ca>13</ca>
		<ce>51</ce>
		<npm>17</npm>
		<lcom3>0.5952380952380952</lcom3>
		<loc>2450</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.19607843137254902</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>110.27272727272727</amc>
		<cc>
			<method name="private static org.apache.hadoop.hive.ql.exec.Operator putOpInsertMap(org.apache.hadoop.hive.ql.exec.Operator op, org.apache.hadoop.hive.ql.parse.RowResolver rr, org.apache.hadoop.hive.ql.parse.ParseContext parseCtx)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.MapredWork getMapRedWork(org.apache.hadoop.hive.ql.parse.ParseContext parseCtx)">1</method>
			<method name="private static void setupBucketMapJoinInfo(org.apache.hadoop.hive.ql.plan.MapredWork plan, org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator currMapJoinOp, boolean createLocalPlan)">11</method>
			<method name="public static void initUnionPlan(org.apache.hadoop.hive.ql.exec.ReduceSinkOperator op, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext opProcCtx, org.apache.hadoop.hive.ql.exec.Task unionTask)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static void splitTasks(org.apache.hadoop.hive.ql.exec.Operator op, org.apache.hadoop.hive.ql.exec.Task parentTask, org.apache.hadoop.hive.ql.exec.Task childTask, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext opProcCtx, boolean setReducer, boolean local, int posn)">1</method>
			<method name="public static void setTaskPlan(String alias_id, org.apache.hadoop.hive.ql.exec.Operator topOp, org.apache.hadoop.hive.ql.plan.MapredWork plan, boolean local, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext opProcCtx, org.apache.hadoop.hive.ql.parse.PrunedPartitionList pList)">1</method>
			<method name="public static void setKeyAndValueDesc(org.apache.hadoop.hive.ql.plan.MapredWork plan, org.apache.hadoop.hive.ql.exec.Operator topOp)">6</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.MapredWork getMapRedWorkFromConf(org.apache.hadoop.hive.conf.HiveConf conf)">1</method>
			<method name="public static void joinPlan(org.apache.hadoop.hive.ql.exec.Operator op, org.apache.hadoop.hive.ql.exec.Task oldTask, org.apache.hadoop.hive.ql.exec.Task task, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext opProcCtx, int pos, boolean split, boolean readMapJoinData, boolean readUnionData, boolean createLocalWork)">1</method>
			<method name="public static void initUnionPlan(org.apache.hadoop.hive.ql.optimizer.GenMRProcContext opProcCtx, org.apache.hadoop.hive.ql.exec.Task currTask, boolean local)">1</method>
			<method name="public static void joinUnionPlan(org.apache.hadoop.hive.ql.optimizer.GenMRProcContext opProcCtx, org.apache.hadoop.hive.ql.exec.Task currentUnionTask, org.apache.hadoop.hive.ql.exec.Task existingTask, boolean local)">1</method>
			<method name="public static void joinPlan(org.apache.hadoop.hive.ql.exec.Operator op, org.apache.hadoop.hive.ql.exec.Task oldTask, org.apache.hadoop.hive.ql.exec.Task task, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext opProcCtx, int pos, boolean split, boolean readMapJoinData, boolean readUnionData)">1</method>
			<method name="public static void initMapJoinPlan(org.apache.hadoop.hive.ql.exec.Operator op, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext opProcCtx, boolean readInputMapJoin, boolean readInputUnion, boolean setReducer, int pos, boolean createLocalPlan)">1</method>
			<method name="private void _init_()">0</method>
			<method name="public static void initPlan(org.apache.hadoop.hive.ql.exec.ReduceSinkOperator op, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext opProcCtx)">1</method>
			<method name="private static void setUnionPlan(org.apache.hadoop.hive.ql.optimizer.GenMRProcContext opProcCtx, boolean local, org.apache.hadoop.hive.ql.plan.MapredWork plan, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext$GenMRUnionCtx uCtx, boolean mergeTask)">1</method>
			<method name="public static void mergeMapJoinUnion(org.apache.hadoop.hive.ql.exec.UnionOperator union, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext ctx, int pos)">1</method>
			<method name="public static void setTaskPlan(String path, String alias, org.apache.hadoop.hive.ql.exec.Operator topOp, org.apache.hadoop.hive.ql.plan.MapredWork plan, boolean local, org.apache.hadoop.hive.ql.plan.TableDesc tt_desc)">1</method>
			<method name="public static void initMapJoinPlan(org.apache.hadoop.hive.ql.exec.Operator op, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext ctx, boolean readInputMapJoin, boolean readInputUnion, boolean setReducer, int pos)">1</method>
			<method name="public static void setTaskPlan(String alias_id, org.apache.hadoop.hive.ql.exec.Operator topOp, org.apache.hadoop.hive.ql.plan.MapredWork plan, boolean local, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext opProcCtx)">1</method>
			<method name="public static void splitPlan(org.apache.hadoop.hive.ql.exec.ReduceSinkOperator op, org.apache.hadoop.hive.ql.optimizer.GenMRProcContext opProcCtx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableLongObjectInspector</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>18</cbo>
		<rfc>11</rfc>
		<lcom>15</lcom>
		<ca>13</ca>
		<ce>5</ce>
		<npm>5</npm>
		<lcom3>2.0</lcom3>
		<loc>45</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.5</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public Object set(Object o, long value)">1</method>
			<method name="public Object create(long value)">1</method>
			<method name="public long get(Object o)">1</method>
			<method name="public Object getPrimitiveJavaObject(Object o)">2</method>
			<method name="public Object copyObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.QB</name>
		<wmc>32</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>60</rfc>
		<lcom>354</lcom>
		<ca>7</ca>
		<ce>7</ce>
		<npm>31</npm>
		<lcom3>0.9204301075268817</lcom3>
		<loc>388</loc>
		<dam>0.9333333333333333</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.21658986175115208</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.65625</amc>
		<cc>
			<method name="public void setIsQuery(boolean isQuery)">1</method>
			<method name="public void countSelDi()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void print(String msg)">2</method>
			<method name="public void rewriteViewToSubq(String alias, String viewName, org.apache.hadoop.hive.ql.parse.QBExpr qbexpr)">3</method>
			<method name="public boolean exists(String alias)">3</method>
			<method name="public org.apache.hadoop.hive.ql.parse.QBParseInfo getParseInfo()">1</method>
			<method name="public void setQbJoinTree(org.apache.hadoop.hive.ql.parse.QBJoinTree qbjoin)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.QBMetaData getMetaData()">1</method>
			<method name="public java.util.List getAliases()">1</method>
			<method name="public int getNumGbys()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.QBJoinTree getQbJoinTree()">1</method>
			<method name="public void addAlias(String alias)">2</method>
			<method name="public void setTableDesc(org.apache.hadoop.hive.ql.plan.CreateTableDesc desc)">1</method>
			<method name="public void _init_(String outer_id, String alias, boolean isSubQ)">0</method>
			<method name="public void setSubqAlias(String alias, org.apache.hadoop.hive.ql.parse.QBExpr qbexpr)">1</method>
			<method name="public String getId()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.Set getTabAliases()">1</method>
			<method name="public boolean getIsQuery()">1</method>
			<method name="public int getNumJoins()">1</method>
			<method name="public void setTabAlias(String alias, String tabName)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.CreateTableDesc getTableDesc()">1</method>
			<method name="public java.util.Set getSubqAliases()">1</method>
			<method name="public boolean isCTAS()">2</method>
			<method name="public String getTabNameForAlias(String alias)">1</method>
			<method name="public boolean isSelectStarQuery()">5</method>
			<method name="public void countSel()">1</method>
			<method name="public void setQBParseInfo(org.apache.hadoop.hive.ql.parse.QBParseInfo qbp)">1</method>
			<method name="public int getNumSels()">1</method>
			<method name="public int getNumSelDi()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.QBExpr getSubqForAlias(String alias)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.processors.SetProcessor</name>
		<wmc>12</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>69</rfc>
		<lcom>64</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>4</npm>
		<lcom3>1.0454545454545454</lcom3>
		<loc>815</loc>
		<dam>0.16666666666666666</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4090909090909091</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>66.41666666666667</amc>
		<cc>
			<method name="private java.util.SortedMap propertiesToSortedMap(java.util.Properties p)">2</method>
			<method name="private org.apache.hadoop.hive.metastore.api.Schema getSchema()">1</method>
			<method name="private org.apache.hadoop.hive.ql.processors.CommandProcessorResponse getVariable(String varname)">10</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void dumpOption(String s)">3</method>
			<method name="private java.util.SortedMap mapToSortedMap(java.util.Map data)">1</method>
			<method name="private void dumpOptions(java.util.Properties p)">7</method>
			<method name="public org.apache.hadoop.hive.ql.processors.CommandProcessorResponse run(String command)">6</method>
			<method name="private org.apache.hadoop.hive.ql.processors.CommandProcessorResponse setVariable(String varname, String varvalue)">5</method>
			<method name="public static boolean getBoolean(String value)">5</method>
			<method name="public void init()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.typeinfo.StructTypeInfo</name>
		<wmc>11</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>29</rfc>
		<lcom>7</lcom>
		<ca>8</ca>
		<ce>2</ce>
		<npm>10</npm>
		<lcom3>0.6333333333333333</lcom3>
		<loc>204</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2909090909090909</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>17.272727272727273</amc>
		<cc>
			<method name="void _init_(java.util.List names, java.util.List typeInfos)">0</method>
			<method name="public int hashCode()">1</method>
			<method name="public java.util.ArrayList getAllStructFieldTypeInfos()">1</method>
			<method name="public java.util.ArrayList getAllStructFieldNames()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setAllStructFieldTypeInfos(java.util.ArrayList allStructFieldTypeInfos)">1</method>
			<method name="public void setAllStructFieldNames(java.util.ArrayList allStructFieldNames)">1</method>
			<method name="public String getTypeName()">3</method>
			<method name="public boolean equals(Object other)">8</method>
			<method name="public org.apache.hadoop.hive.serde2.typeinfo.TypeInfo getStructFieldTypeInfo(String field)">3</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeDefinitionType</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.RCFile$Reader</name>
		<wmc>35</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>34</cbo>
		<rfc>121</rfc>
		<lcom>339</lcom>
		<ca>4</ca>
		<ce>30</ce>
		<npm>25</npm>
		<lcom3>0.7622549019607843</lcom3>
		<loc>1608</loc>
		<dam>0.8333333333333334</dam>
		<moa>9</moa>
		<mfa>0.0</mfa>
		<cam>0.14805194805194805</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>43.91428571428571</amc>
		<cc>
			<method name="private int nextKeyValueTolerateCorruptions()">1</method>
			<method name="public int getCurrentBlockLength()">1</method>
			<method name="public synchronized void getCurrentRow(org.apache.hadoop.hive.serde2.columnar.BytesRefArrayWritable ret)">1</method>
			<method name="public org.apache.hadoop.io.compress.CompressionCodec getCompressionCodec()">1</method>
			<method name="public void _init_(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path file, org.apache.hadoop.conf.Configuration conf)">0</method>
			<method name="private void handleChecksumException(org.apache.hadoop.fs.ChecksumException e)">1</method>
			<method name="public void close()">2</method>
			<method name="private org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer createKeyBuffer()">1</method>
			<method name="protected org.apache.hadoop.fs.FSDataInputStream openFile(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path file, int bufferSize, long length)">1</method>
			<method name="public int getCurrentKeyLength()">1</method>
			<method name="public synchronized void resetBuffer()">1</method>
			<method name="public boolean nextBlock()">1</method>
			<method name="public boolean syncSeen()">1</method>
			<method name="public org.apache.hadoop.io.Text getMetadataValueOf(org.apache.hadoop.io.Text key)">1</method>
			<method name="protected int nextKeyBuffer()">1</method>
			<method name="public org.apache.hadoop.hive.ql.io.RCFile$KeyBuffer getCurrentKeyBufferObj()">1</method>
			<method name="public synchronized void seek(long position)">1</method>
			<method name="private void colAdvanceRow(int selCol, org.apache.hadoop.hive.ql.io.RCFile$Reader$SelectedColumn col)">1</method>
			<method name="public boolean isCompressedRCFile()">1</method>
			<method name="public String toString()">1</method>
			<method name="private void seekToNextKeyBuffer()">1</method>
			<method name="public int getCurrentCompressedKeyLen()">1</method>
			<method name="public long lastSeenSyncPos()">1</method>
			<method name="public org.apache.hadoop.io.SequenceFile$Metadata getMetadata()">1</method>
			<method name="protected void currentValueBuffer()">1</method>
			<method name="private void init()">1</method>
			<method name="public synchronized void sync(long position)">1</method>
			<method name="private synchronized int readRecordLength()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.columnar.BytesRefArrayWritable getColumn(int columnID, org.apache.hadoop.hive.serde2.columnar.BytesRefArrayWritable rest)">1</method>
			<method name="public synchronized boolean nextColumnsBatch()">1</method>
			<method name="public synchronized long getPosition()">1</method>
			<method name="public void _init_(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path file, int bufferSize, org.apache.hadoop.conf.Configuration conf, long start, long length)">0</method>
			<method name="public synchronized boolean next(org.apache.hadoop.io.LongWritable readRows)">1</method>
			<method name="public org.apache.hadoop.hive.ql.io.RCFile$ValueBuffer getCurrentValueBufferObj()">1</method>
			<method name="public boolean hasRecordsInBuffer()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.ZooKeeperTokenStore$1</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>4</ce>
		<npm>1</npm>
		<lcom3>0.0</lcom3>
		<loc>43</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.5</amc>
		<cc>
			<method name="public void process(org.apache.zookeeper.WatchedEvent event)">4</method>
			<method name="void _init_(java.util.concurrent.CountDownLatch, org.apache.zookeeper.Watcher[])">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ThriftStructObjectInspector</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.5</amc>
		<cc>
			<method name="public boolean shouldIgnoreField(String name)">1</method>
			<method name="void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.ZooKeeperTokenStore$2</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>14</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$joinToken_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFToDate</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>18</rfc>
		<lcom>36</lcom>
		<ca>0</ca>
		<ce>1</ce>
		<npm>9</npm>
		<lcom3>2.0</lcom3>
		<loc>84</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.20987654320987653</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.333333333333334</amc>
		<cc>
			<method name="public java.sql.Date evaluate(String i)">2</method>
			<method name="public java.sql.Date evaluate(Float i)">2</method>
			<method name="public void _init_()">0</method>
			<method name="public java.sql.Date evaluate(Void i)">1</method>
			<method name="public java.sql.Date evaluate(Long i)">2</method>
			<method name="public java.sql.Date evaluate(Integer i)">2</method>
			<method name="public java.sql.Date evaluate(Double i)">2</method>
			<method name="public java.sql.Date evaluate(Byte i)">2</method>
			<method name="public java.sql.Date evaluate(Short i)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.columnar.BytesRefArrayWritable$1</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.5</amc>
		<cc>
			<method name="void _init_()">0</method>
			<method name="public org.apache.hadoop.io.Writable newInstance()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFUnixTimeStamp</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>18</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>5</npm>
		<lcom3>0.41666666666666663</lcom3>
		<loc>105</loc>
		<dam>0.3333333333333333</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5333333333333333</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.4</amc>
		<cc>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable i)">2</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.Text dateText)">2</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.Text dateText, org.apache.hadoop.io.Text patternText)">3</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.ByteObjectInspector</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>20</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>19</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract byte get(Object)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.QueryPlan$_Fields</name>
		<wmc>9</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>24</rfc>
		<lcom>26</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>0.7857142857142857</lcom3>
		<loc>140</loc>
		<dam>0.5714285714285714</dam>
		<moa>4</moa>
		<mfa>0.65</mfa>
		<cam>0.3125</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>13.777777777777779</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.QueryPlan$_Fields findByThriftId(int fieldId)">2</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.QueryPlan$_Fields valueOf(String name)">1</method>
			<method name="private void _init_(String, int, short thriftId, String fieldName)">0</method>
			<method name="public String getFieldName()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.QueryPlan$_Fields findByName(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.QueryPlan$_Fields findByThriftIdOrThrow(int fieldId)">2</method>
			<method name="public short getThriftFieldId()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.QueryPlan$_Fields[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>117</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>114.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFContextNGrams$GenericUDAFContextNGramEvaluator$NGramAggBuf</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>6</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$tableOrColumn_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.GenMRProcContext$GenMRMapJoinCtx</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>11</rfc>
		<lcom>3</lcom>
		<ca>6</ca>
		<ce>3</ce>
		<npm>10</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>72</loc>
		<dam>0.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.36</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.8</amc>
		<cc>
			<method name="public void setOldMapJoin(org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator oldMapJoin)">1</method>
			<method name="public void setTTDesc(org.apache.hadoop.hive.ql.plan.TableDesc tt_desc)">1</method>
			<method name="public void _init_(String taskTmpDir, org.apache.hadoop.hive.ql.plan.TableDesc tt_desc, org.apache.hadoop.hive.ql.exec.Operator rootMapJoinOp, org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator oldMapJoin)">0</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.TableDesc getTTDesc()">1</method>
			<method name="public String getTaskTmpDir()">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.Operator getRootMapJoinOp()">1</method>
			<method name="public void setRootMapJoinOp(org.apache.hadoop.hive.ql.exec.Operator rootMapJoinOp)">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.AbstractMapJoinOperator getOldMapJoin()">1</method>
			<method name="public void setTaskTmpDir(String taskTmpDir)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.MoveWork</name>
		<wmc>17</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>18</rfc>
		<lcom>102</lcom>
		<ca>7</ca>
		<ce>3</ce>
		<npm>17</npm>
		<lcom3>0.9166666666666666</lcom3>
		<loc>101</loc>
		<dam>0.8888888888888888</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.24369747899159663</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.411764705882353</amc>
		<cc>
			<method name="public void setDPSpecPaths(java.util.ArrayList dpsp)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs)">0</method>
			<method name="public void setCheckFileFormat(boolean checkFileFormat)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.LoadFileDesc getLoadFileWork()">1</method>
			<method name="public java.util.ArrayList getDPSpecPaths()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.LoadMultiFilesDesc getLoadMultiFilesWork()">1</method>
			<method name="public void setLoadFileWork(org.apache.hadoop.hive.ql.plan.LoadFileDesc loadFileWork)">1</method>
			<method name="public void setMultiFilesDesc(org.apache.hadoop.hive.ql.plan.LoadMultiFilesDesc lmfd)">1</method>
			<method name="public boolean getCheckFileFormat()">1</method>
			<method name="public java.util.HashSet getOutputs()">1</method>
			<method name="public void setInputs(java.util.HashSet inputs)">1</method>
			<method name="public void _init_(java.util.HashSet inputs, java.util.HashSet outputs, org.apache.hadoop.hive.ql.plan.LoadTableDesc loadTableWork, org.apache.hadoop.hive.ql.plan.LoadFileDesc loadFileWork, boolean checkFileFormat)">0</method>
			<method name="public void setLoadTableWork(org.apache.hadoop.hive.ql.plan.LoadTableDesc loadTableWork)">1</method>
			<method name="public void setOutputs(java.util.HashSet outputs)">1</method>
			<method name="public java.util.HashSet getInputs()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.LoadTableDesc getLoadTableWork()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.objectinspector.LazyUnionObjectInspector</name>
		<wmc>14</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>22</rfc>
		<lcom>73</lcom>
		<ca>3</ca>
		<ce>7</ce>
		<npm>9</npm>
		<lcom3>0.7948717948717949</lcom3>
		<loc>119</loc>
		<dam>0.16666666666666666</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.3717948717948718</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.071428571428571</amc>
		<cc>
			<method name="public byte getTag(Object data)">2</method>
			<method name="protected void init(java.util.List ois, byte separator, org.apache.hadoop.io.Text nullSequence)">1</method>
			<method name="public org.apache.hadoop.io.Text getNullSequence()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public final org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
			<method name="protected void init(java.util.List ois, byte separator, org.apache.hadoop.io.Text nullSequence, boolean escaped, byte escapeChar)">1</method>
			<method name="protected void _init_(java.util.List ois, byte separator, org.apache.hadoop.io.Text nullSequence, boolean escaped, byte escapeChar)">0</method>
			<method name="public Object getField(Object data)">2</method>
			<method name="public boolean isEscaped()">1</method>
			<method name="public java.util.List getObjectInspectors()">1</method>
			<method name="protected void _init_(java.util.List ois, byte separator, org.apache.hadoop.io.Text nullSequence)">0</method>
			<method name="public byte getSeparator()">1</method>
			<method name="public String getTypeName()">1</method>
			<method name="public byte getEscapeChar()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFPrintf</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>23</cbo>
		<rfc>44</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>23</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>366</loc>
		<dam>0.6666666666666666</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>71.6</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.AlterTableSimpleDesc</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>12</rfc>
		<lcom>21</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>10</npm>
		<lcom3>0.7777777777777778</lcom3>
		<loc>69</loc>
		<dam>0.75</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.34</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.5</amc>
		<cc>
			<method name="public void setType(org.apache.hadoop.hive.ql.plan.AlterTableDesc$AlterTableTypes type)">1</method>
			<method name="public String getDbName()">1</method>
			<method name="public String getTableName()">1</method>
			<method name="public void setPartSpec(java.util.LinkedHashMap partSpec)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.LinkedHashMap getPartSpec()">1</method>
			<method name="public void setTableName(String tableName)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.AlterTableDesc$AlterTableTypes getType()">1</method>
			<method name="public void _init_(String dbName, String tableName, java.util.Map partSpec, org.apache.hadoop.hive.ql.plan.AlterTableDesc$AlterTableTypes type)">0</method>
			<method name="public void setDbName(String dbName)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde.test.ThriftTestObj$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>28</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.RoleDDLDesc$RoleOperation</name>
		<wmc>7</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>10</rfc>
		<lcom>13</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>4</npm>
		<lcom3>0.8666666666666667</lcom3>
		<loc>77</loc>
		<dam>0.4</dam>
		<moa>4</moa>
		<mfa>0.7647058823529411</mfa>
		<cam>0.5</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>9.285714285714286</amc>
		<cc>
			<method name="public String getOperationName()">1</method>
			<method name="private void _init_(String, int, String operationName)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public String toString()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.RoleDDLDesc$RoleOperation[] values()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.RoleDDLDesc$RoleOperation valueOf(String name)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeEnumDef</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ReduceSinkOperator</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>43</cbo>
		<rfc>72</rfc>
		<lcom>9</lcom>
		<ca>17</ca>
		<ce>26</ce>
		<npm>4</npm>
		<lcom3>0.890909090909091</lcom3>
		<loc>750</loc>
		<dam>0.2727272727272727</dam>
		<moa>10</moa>
		<mfa>0.0</mfa>
		<cam>0.2857142857142857</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>120.33333333333333</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void processOp(Object row, int tag)">1</method>
			<method name="protected static org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector initEvaluatorsAndReturnStruct(org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator[] evals, java.util.List distinctColIndices, java.util.List outputColNames, int length, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector rowInspector)">1</method>
			<method name="public String getName()">1</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.server.TServer$Args</name>
		<wmc>1</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_(org.apache.thrift.transport.TServerTransport transport)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFTrim</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>25</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.0</amc>
		<cc>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text s)">2</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.TaskFactory</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>21</cbo>
		<rfc>35</rfc>
		<lcom>20</lcom>
		<ca>17</ca>
		<ce>4</ce>
		<npm>6</npm>
		<lcom3>0.42857142857142855</lcom3>
		<loc>275</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2619047619047619</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>33.125</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.Task get(Class workClass, org.apache.hadoop.hive.conf.HiveConf conf)">2</method>
			<method name="public static transient void makeChild(org.apache.hadoop.hive.ql.exec.Task ret, org.apache.hadoop.hive.ql.exec.Task[] tasklist)">3</method>
			<method name="public static transient org.apache.hadoop.hive.ql.exec.Task getAndMakeChild(java.io.Serializable work, org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.hive.ql.exec.Task[] tasklist)">2</method>
			<method name="public static transient org.apache.hadoop.hive.ql.exec.Task get(java.io.Serializable work, org.apache.hadoop.hive.conf.HiveConf conf, org.apache.hadoop.hive.ql.exec.Task[] tasklist)">3</method>
			<method name="public static void resetId()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static int getAndIncrementId()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.MapJoinFactory$MapJoinMapJoin</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>15</cbo>
		<rfc>30</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>15</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>134</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>43.333333333333336</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.JoinUtil</name>
		<wmc>14</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>32</cbo>
		<rfc>69</rfc>
		<lcom>91</lcom>
		<ca>7</ca>
		<ce>25</ce>
		<npm>13</npm>
		<lcom3>2.0</lcom3>
		<loc>713</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.24404761904761904</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>49.92857142857143</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.plan.TableDesc getSpillTableDesc(Byte alias, java.util.Map spillTableDesc, org.apache.hadoop.hive.ql.plan.JoinDesc conf, boolean noOuterJoin)">3</method>
			<method name="public static java.util.ArrayList computeKeys(Object row, java.util.List keyFields, java.util.List keyFieldsOI)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.persistence.RowContainer getRowContainer(org.apache.hadoop.conf.Configuration hconf, java.util.List structFieldObjectInspectors, Byte alias, int containerSize, java.util.Map spillTableDesc, org.apache.hadoop.hive.ql.plan.JoinDesc conf, boolean noOuterJoin)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public static Object[] computeMapJoinValues(Object row, java.util.List valueFields, java.util.List valueFieldsOI, java.util.List filters, java.util.List filtersOI, boolean noOuterJoin)">1</method>
			<method name="public static java.util.ArrayList computeValues(Object row, java.util.List valueFields, java.util.List valueFieldsOI, java.util.List filters, java.util.List filtersOI, boolean noOuterJoin)">1</method>
			<method name="public static java.util.HashMap getStandardObjectInspectors(java.util.Map aliasToObjectInspectors, int posBigTableAlias)">4</method>
			<method name="public static java.util.Map getSpillTableDesc(java.util.Map spillTableDesc, org.apache.hadoop.hive.ql.plan.JoinDesc conf, boolean noOuterJoin)">2</method>
			<method name="public static java.util.Map initSpillTables(org.apache.hadoop.hive.ql.plan.JoinDesc conf, boolean noOuterJoin)">5</method>
			<method name="protected static Boolean isFiltered(Object row, java.util.List filters, java.util.List ois)">1</method>
			<method name="public static org.apache.hadoop.hive.serde2.SerDe getSpillSerDe(byte alias, java.util.Map spillTableDesc, org.apache.hadoop.hive.ql.plan.JoinDesc conf, boolean noOuterJoin)">2</method>
			<method name="public static int populateJoinKeyValue(java.util.Map outMap, java.util.Map inputMap, Byte[] order, int posBigTableAlias)">4</method>
			<method name="public static java.util.HashMap getObjectInspectorsFromEvaluators(java.util.Map exprEntries, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] inputObjInspector, int posBigTableAlias)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.exec.persistence.AbstractMapJoinKey computeMapJoinKeys(Object row, java.util.List keyFields, java.util.List keyFieldsOI)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$limitClause_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFPercentileApprox$GenericUDAFMultiplePercentileApproxEvaluator</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>16</cbo>
		<rfc>18</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>15</ce>
		<npm>3</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>115</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>27.5</amc>
		<cc>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector init(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode m, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] parameters)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFRand</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>10</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>3</npm>
		<lcom3>0.25</lcom3>
		<loc>49</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.666666666666666</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.io.LongWritable seed)">2</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFAverage$GenericUDAFAverageEvaluator</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>22</cbo>
		<rfc>34</rfc>
		<lcom>22</lcom>
		<ca>1</ca>
		<ce>22</ce>
		<npm>8</npm>
		<lcom3>0.8625</lcom3>
		<loc>330</loc>
		<dam>0.0</dam>
		<moa>7</moa>
		<mfa>0.0</mfa>
		<cam>0.3541666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>34.55555555555556</amc>
		<cc>
			<method name="public void iterate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object[] parameters)">1</method>
			<method name="public Object terminate(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector init(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode m, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] parameters)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer getNewAggregationBuffer()">1</method>
			<method name="public void merge(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg, Object partial)">1</method>
			<method name="public Object terminatePartial(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
			<method name="public void reset(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$AggregationBuffer agg)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFMapValues</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>24</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>11</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>120</loc>
		<dam>0.6666666666666666</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>22.4</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.json.JSONObject$Null</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>6</rfc>
		<lcom>10</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>24</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.8</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="void _init_(org.json.JSONObject$1 arg0)">0</method>
			<method name="public String toString()">1</method>
			<method name="public boolean equals(Object arg0)">3</method>
			<method name="protected final Object clone()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.UnparseTranslator$CopyTranslation</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>10</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.parse.UnparseTranslator$1 x0)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.StatsTask$TableStatistics</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>23</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>3</ce>
		<npm>7</npm>
		<lcom3>0.5</lcom3>
		<loc>132</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.42857142857142855</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>17.571428571428573</amc>
		<cc>
			<method name="public void setNumPartitions(int np)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.StatsTask)">0</method>
			<method name="public int getNumPartitions()">1</method>
			<method name="public String toString()">1</method>
			<method name="public void updateStats(org.apache.hadoop.hive.ql.exec.StatsTask$PartitionStatistics oldStats, org.apache.hadoop.hive.ql.exec.StatsTask$PartitionStatistics newStats)">1</method>
			<method name="public void deletePartitionStats(org.apache.hadoop.hive.ql.exec.StatsTask$PartitionStatistics oldStats)">2</method>
			<method name="public void addPartitionStats(org.apache.hadoop.hive.ql.exec.StatsTask$PartitionStatistics newStats)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFAsin</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>24</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable a)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFRpad</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>8</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>95</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>46.0</amc>
		<cc>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text s, org.apache.hadoop.io.IntWritable n, org.apache.hadoop.io.Text pad)">10</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.FunctionWork</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>8</rfc>
		<lcom>9</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>0.8333333333333334</lcom3>
		<loc>39</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.5238095238095238</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.142857142857143</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.plan.DropFunctionDesc getDropFunctionDesc()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.CreateFunctionDesc createFunctionDesc)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.CreateFunctionDesc getCreateFunctionDesc()">1</method>
			<method name="public void setDropFunctionDesc(org.apache.hadoop.hive.ql.plan.DropFunctionDesc dropFunctionDesc)">1</method>
			<method name="public void setCreateFunctionDesc(org.apache.hadoop.hive.ql.plan.CreateFunctionDesc createFunctionDesc)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.DropFunctionDesc dropFunctionDesc)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableConstantIntObjectInspector</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>16</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public volatile Object getWritableConstantValue()">1</method>
			<method name="public org.apache.hadoop.io.IntWritable getWritableConstantValue()">1</method>
			<method name="void _init_(org.apache.hadoop.io.IntWritable value)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.ErrorMsg</name>
		<wmc>18</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>27</cbo>
		<rfc>48</rfc>
		<lcom>135</lcom>
		<ca>21</ca>
		<ce>6</ce>
		<npm>12</npm>
		<lcom3>0.9930283224400872</lcom3>
		<loc>1914</loc>
		<dam>0.05185185185185185</dam>
		<moa>129</moa>
		<mfa>0.4642857142857143</mfa>
		<cam>0.24369747899159663</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>97.83333333333333</amc>
		<cc>
			<method name="public static void renderOrigin(StringBuilder sb, org.apache.hadoop.hive.ql.parse.ASTNodeOrigin origin)">2</method>
			<method name="public static org.apache.hadoop.hive.ql.parse.ErrorMsg valueOf(String name)">1</method>
			<method name="private static void renderPosition(StringBuilder sb, org.apache.hadoop.hive.ql.parse.ASTNode tree)">1</method>
			<method name="public String getMsg(org.apache.hadoop.hive.ql.parse.ASTNode tree, String reason)">1</method>
			<method name="public String getSQLState()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static String findSQLState(String mesg)">9</method>
			<method name="private void _init_(String, int, String mesg)">0</method>
			<method name="public String getMsg()">1</method>
			<method name="public String getMsg(org.antlr.runtime.tree.Tree tree)">1</method>
			<method name="public static String getText(org.apache.hadoop.hive.ql.parse.ASTNode tree)">2</method>
			<method name="private static int getCharPositionInLine(org.apache.hadoop.hive.ql.parse.ASTNode tree)">2</method>
			<method name="public String getMsg(org.antlr.runtime.tree.Tree tree, String reason)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.parse.ErrorMsg[] values()">1</method>
			<method name="private static int getLine(org.apache.hadoop.hive.ql.parse.ASTNode tree)">2</method>
			<method name="private void _init_(String, int, String mesg, String sqlState)">0</method>
			<method name="public String getMsg(String reason)">1</method>
			<method name="public String getMsg(org.apache.hadoop.hive.ql.parse.ASTNode tree)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ExprNodeFieldEvaluator</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>22</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>11</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>135</loc>
		<dam>0.25</dam>
		<moa>7</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>41.333333333333336</amc>
		<cc>
			<method name="public Object evaluate(Object row)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector rowInspector)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.ExprNodeFieldDesc desc)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Description</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>3</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>3</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract String name()">1</method>
			<method name="public abstract String extended()">1</method>
			<method name="public abstract String value()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils$ObjectInspectorCopyOption</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>20</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>19</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9166666666666666</lcom3>
		<loc>56</loc>
		<dam>0.25</dam>
		<moa>4</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>12.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils$ObjectInspectorCopyOption[] values()">1</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils$ObjectInspectorCopyOption valueOf(String name)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.ReduceSinkDeDuplication$ReduceSinkDeduplicateProcCtx</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>9</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>4</ce>
		<npm>5</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>45</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.4</amc>
		<cc>
			<method name="public boolean contains(org.apache.hadoop.hive.ql.exec.ReduceSinkOperator rsOp)">1</method>
			<method name="public void addRejectedReduceSinkOperator(org.apache.hadoop.hive.ql.exec.ReduceSinkOperator rsOp)">2</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext getPctx()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.optimizer.ReduceSinkDeDuplication, org.apache.hadoop.hive.ql.parse.ParseContext pctx)">0</method>
			<method name="public void setPctx(org.apache.hadoop.hive.ql.parse.ParseContext pctx)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.AlterDatabaseDesc</name>
		<wmc>13</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>14</rfc>
		<lcom>48</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>13</npm>
		<lcom3>0.8055555555555555</lcom3>
		<loc>82</loc>
		<dam>0.16666666666666666</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4230769230769231</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.846153846153846</amc>
		<cc>
			<method name="public void setDatabaseProperties(java.util.Map dbProps)">1</method>
			<method name="public void _init_(String databaseName, String comment, String locationUri, boolean ifNotExists)">0</method>
			<method name="public void setComment(String comment)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public String getComment()">1</method>
			<method name="public String getDatabaseName()">1</method>
			<method name="public void _init_(String databaseName, boolean ifNotExists)">0</method>
			<method name="public void setIfNotExists(boolean ifNotExists)">1</method>
			<method name="public void setDatabaseName(String databaseName)">1</method>
			<method name="public boolean getIfNotExists()">1</method>
			<method name="public java.util.Map getDatabaseProperties()">1</method>
			<method name="public String getLocationUri()">1</method>
			<method name="public void setLocationUri(String locationUri)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$tableSpec$SpecType</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9166666666666666</lcom3>
		<loc>56</loc>
		<dam>0.25</dam>
		<moa>4</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>12.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$tableSpec$SpecType valueOf(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer$tableSpec$SpecType[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.VariableSubstitution</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>31</rfc>
		<lcom>0</lcom>
		<ca>5</ca>
		<ce>5</ce>
		<npm>2</npm>
		<lcom3>0.5555555555555555</lcom3>
		<loc>193</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.7777777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>46.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public String substitute(org.apache.hadoop.hive.conf.HiveConf conf, String expr)">6</method>
			<method name="private String getSubstitute(org.apache.hadoop.hive.conf.HiveConf conf, String var)">7</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.StatsTask</name>
		<wmc>14</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>35</cbo>
		<rfc>105</rfc>
		<lcom>59</lcom>
		<ca>3</ca>
		<ce>34</ce>
		<npm>5</npm>
		<lcom3>0.8653846153846154</lcom3>
		<loc>1025</loc>
		<dam>0.875</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.14743589743589744</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>71.64285714285714</amc>
		<cc>
			<method name="public int execute(org.apache.hadoop.hive.ql.DriverContext driverContext)">8</method>
			<method name="static java.util.List access$000()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static void cleanUp(String jobID, org.apache.hadoop.conf.Configuration config)">2</method>
			<method name="protected void localizeMRTmpFilesImpl(org.apache.hadoop.hive.ql.Context ctx)">1</method>
			<method name="private int aggregateStats()">25</method>
			<method name="public String getName()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.StageType getType()">1</method>
			<method name="static java.util.Map access$100()">1</method>
			<method name="protected void receiveFeed(org.apache.hadoop.hive.ql.exec.Task$FeedType feedType, Object feedValue)">4</method>
			<method name="private void updateStats(java.util.List statsList, org.apache.hadoop.hive.ql.exec.StatsTask$PartitionStatistics stats, org.apache.hadoop.hive.ql.stats.StatsAggregator statsAggregator, java.util.Map parameters, String aggKey, boolean atomic)">1</method>
			<method name="private java.util.List getPartitionsList()">1</method>
			<method name="private boolean existStats(java.util.Map parameters)">6</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyPrimitive</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>10</noc>
		<cbo>21</cbo>
		<rfc>19</rfc>
		<lcom>0</lcom>
		<ca>14</ca>
		<ce>7</ce>
		<npm>5</npm>
		<lcom3>0.6190476190476192</lcom3>
		<loc>103</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2857142857142857</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.5</amc>
		<cc>
			<method name="public void logExceptionMessage(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length, String dataType)">1</method>
			<method name="public int hashCode()">2</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.lazy.LazyPrimitive copy)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.io.Writable getWritableObject()">2</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">0</method>
			<method name="public String toString()">2</method>
			<method name="public Object getObject()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDTFStack</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>25</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>10</ce>
		<npm>5</npm>
		<lcom3>0.5</lcom3>
		<loc>311</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>60.2</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void close()">1</method>
			<method name="public String toString()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] args)">1</method>
			<method name="public void process(Object[] args)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.HashTableSinkOperator</name>
		<wmc>11</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>39</cbo>
		<rfc>104</rfc>
		<lcom>15</lcom>
		<ca>2</ca>
		<ce>37</ce>
		<npm>6</npm>
		<lcom3>0.896875</lcom3>
		<loc>872</loc>
		<dam>0.84375</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.22857142857142856</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>75.36363636363636</amc>
		<cc>
			<method name="private void setValueMetaData(int tag)">1</method>
			<method name="protected static java.util.HashMap getStandardObjectInspectors(java.util.Map aliasToObjectInspectors)">3</method>
			<method name="public void closeOp(boolean abort)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void processOp(Object row, int tag)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.MapJoinOperator mjop)">0</method>
			<method name="public String getName()">1</method>
			<method name="private void setKeyMetaData()">1</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.AuthorizationException</name>
		<wmc>4</wmc>
		<dit>4</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>8</rfc>
		<lcom>6</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>4</npm>
		<lcom3>1.3333333333333333</lcom3>
		<loc>21</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>1.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(Throwable cause)">0</method>
			<method name="public void _init_(String message, Throwable cause)">0</method>
			<method name="public void _init_(String message)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TNonblockingServerTransport</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>7</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>6</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>1.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public abstract void registerSelector(java.nio.channels.Selector)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.ppd.OpProcFactory$ScriptPPD</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>14</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>14</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>48</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>23.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.TBaseProcessor</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>18</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>8</ce>
		<npm>1</npm>
		<lcom3>0.0</lcom3>
		<loc>76</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>36.0</amc>
		<cc>
			<method name="protected void _init_(Object iface, java.util.Map processFunctionMap)">0</method>
			<method name="public boolean process(org.apache.thrift.protocol.TProtocol in, org.apache.thrift.protocol.TProtocol out)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFOPGreaterThan$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>56</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>54.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDAFPercentile$PercentileLongArrayEvaluator</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>34</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>6</ce>
		<npm>6</npm>
		<lcom3>0.5</lcom3>
		<loc>249</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>40.166666666666664</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.udf.UDAFPercentile$State terminatePartial()">1</method>
			<method name="public boolean merge(org.apache.hadoop.hive.ql.udf.UDAFPercentile$State other)">6</method>
			<method name="public void _init_()">0</method>
			<method name="public boolean iterate(org.apache.hadoop.io.LongWritable o, java.util.List percentiles)">7</method>
			<method name="public void init()">2</method>
			<method name="public java.util.List terminate()">7</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.GroupByDesc$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>56</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>54.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.io.ShortWritable</name>
		<wmc>11</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>34</cbo>
		<rfc>18</rfc>
		<lcom>0</lcom>
		<ca>31</ca>
		<ce>3</ce>
		<npm>10</npm>
		<lcom3>0.1</lcom3>
		<loc>83</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.32</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>6.454545454545454</amc>
		<cc>
			<method name="public short get()">1</method>
			<method name="public boolean equals(Object o)">4</method>
			<method name="public int hashCode()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void _init_(short s)">0</method>
			<method name="public void write(java.io.DataOutput out)">1</method>
			<method name="public void set(short value)">1</method>
			<method name="public String toString()">1</method>
			<method name="public void readFields(java.io.DataInput in)">1</method>
			<method name="public int compareTo(Object o)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.Deserializer</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>29</cbo>
		<rfc>4</rfc>
		<lcom>6</lcom>
		<ca>24</ca>
		<ce>5</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>4</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Object deserialize(org.apache.hadoop.io.Writable)">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.SerDeStats getSerDeStats()">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getObjectInspector()">1</method>
			<method name="public abstract void initialize(org.apache.hadoop.conf.Configuration, java.util.Properties)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyIntObjectInspector</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>9</rfc>
		<lcom>6</lcom>
		<ca>4</ca>
		<ce>7</ce>
		<npm>3</npm>
		<lcom3>2.0</lcom3>
		<loc>33</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.875</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.25</amc>
		<cc>
			<method name="public int get(Object o)">1</method>
			<method name="void _init_()">0</method>
			<method name="public Object getPrimitiveJavaObject(Object o)">2</method>
			<method name="public Object copyObject(Object o)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorConverter$BinaryConverter</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>8</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>6</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>37</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector inputOI, org.apache.hadoop.hive.serde2.objectinspector.primitive.SettableBinaryObjectInspector outputOI)">0</method>
			<method name="public Object convert(Object input)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.pcr.PcrExprProcFactory</name>
		<wmc>14</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>28</cbo>
		<rfc>48</rfc>
		<lcom>91</lcom>
		<ca>2</ca>
		<ce>27</ce>
		<npm>6</npm>
		<lcom3>2.0</lcom3>
		<loc>353</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.12698412698412698</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>24.214285714285715</amc>
		<cc>
			<method name="static Boolean opNot(Boolean op)">3</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getGenericFuncProcessor()">1</method>
			<method name="private void _init_()">0</method>
			<method name="static Object ifResultsAgree(Object[] resultVector)">5</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getColumnProcessor()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getFieldProcessor()">1</method>
			<method name="static Boolean opAnd(Boolean op1, Boolean op2)">5</method>
			<method name="public static org.apache.hadoop.hive.ql.lib.NodeProcessor getDefaultExprProcessor()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc getOutExpr(org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc funcExpr, Object[] nodeOutputs)">3</method>
			<method name="static Boolean opOr(Boolean op1, Boolean op2)">5</method>
			<method name="static org.apache.hadoop.hive.ql.optimizer.pcr.PcrExprProcFactory$NodeInfoWrapper getResultWrapFromResults(Boolean[] results, org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc fd, Object[] nodeOutputs)">3</method>
			<method name="static Object evalExprWithPart(org.apache.hadoop.hive.ql.plan.ExprNodeDesc expr, org.apache.hadoop.hive.ql.metadata.Partition p)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.pcr.PcrExprProcFactory$NodeInfoWrapper walkExprTree(String tabAlias, java.util.ArrayList parts, org.apache.hadoop.hive.ql.plan.ExprNodeDesc pred)">1</method>
			<method name="static Boolean ifResultsAgree(Boolean[] resultVector)">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.index.compact.HiveCompactIndexInputFormat</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>1</npm>
		<lcom3>1.0</lcom3>
		<loc>12</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.MapJoinResolver$LocalMapJoinTaskDispatcher</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>29</cbo>
		<rfc>78</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>29</ce>
		<npm>4</npm>
		<lcom3>0.5</lcom3>
		<loc>392</loc>
		<dam>0.5</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.2777777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>64.0</amc>
		<cc>
			<method name="public transient Object dispatch(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, Object[] nodeOutputs)">1</method>
			<method name="private org.apache.hadoop.hive.ql.optimizer.physical.MapJoinResolver$LocalMapJoinProcCtx adjustLocalTask(org.apache.hadoop.hive.ql.exec.MapredLocalTask task)">1</method>
			<method name="public org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext getPhysicalContext()">1</method>
			<method name="public void setPhysicalContext(org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext physicalContext)">1</method>
			<method name="private void processCurrentTask(org.apache.hadoop.hive.ql.exec.Task currTask, org.apache.hadoop.hive.ql.exec.ConditionalTask conditionalTask)">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.optimizer.physical.MapJoinResolver, org.apache.hadoop.hive.ql.optimizer.physical.PhysicalContext context)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.MetadataOnlyOptimizer$1</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.pcr.PcrExprProcFactory$WalkState</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>7</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9523809523809524</lcom3>
		<loc>89</loc>
		<dam>0.14285714285714285</dam>
		<moa>7</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>19.5</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.pcr.PcrExprProcFactory$WalkState valueOf(String name)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.optimizer.pcr.PcrExprProcFactory$WalkState[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeDefinition</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.RevokeDesc</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>9</rfc>
		<lcom>10</lcom>
		<ca>3</ca>
		<ce>2</ce>
		<npm>8</npm>
		<lcom3>0.8214285714285714</lcom3>
		<loc>48</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5416666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public java.util.List getPrivileges()">1</method>
			<method name="public void setPrivilegeSubjectDesc(org.apache.hadoop.hive.ql.plan.PrivilegeObjectDesc privilegeSubjectDesc)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public java.util.List getPrincipals()">1</method>
			<method name="public void _init_(java.util.List privileges, java.util.List principals, org.apache.hadoop.hive.ql.plan.PrivilegeObjectDesc privilegeSubjectDesc)">0</method>
			<method name="public org.apache.hadoop.hive.ql.plan.PrivilegeObjectDesc getPrivilegeSubjectDesc()">1</method>
			<method name="public void setPrincipals(java.util.List principals)">1</method>
			<method name="public void setPrivileges(java.util.List privileges)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.processors.CommandProcessorResponse</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>8</rfc>
		<lcom>13</lcom>
		<ca>6</ca>
		<ce>1</ce>
		<npm>7</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>51</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4642857142857143</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.714285714285714</amc>
		<cc>
			<method name="public String getErrorMessage()">1</method>
			<method name="public void _init_(int responseCode, String errorMessage, String SQLState, org.apache.hadoop.hive.metastore.api.Schema schema)">0</method>
			<method name="public org.apache.hadoop.hive.metastore.api.Schema getSchema()">1</method>
			<method name="public String getSQLState()">1</method>
			<method name="public void _init_(int responseCode, String errorMessage, String SQLState)">0</method>
			<method name="public int getResponseCode()">1</method>
			<method name="public void _init_(int responseCode)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.protocol.TMap</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>14</ca>
		<ce>0</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>23</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.0</amc>
		<cc>
			<method name="public void _init_(byte k, byte v, int s)">0</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.AdjacencyType</name>
		<wmc>6</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>9</rfc>
		<lcom>9</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>64</loc>
		<dam>0.5</dam>
		<moa>3</moa>
		<mfa>0.7647058823529411</mfa>
		<cam>0.4</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>9.0</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.AdjacencyType valueOf(String name)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.AdjacencyType findByValue(int value)">4</method>
			<method name="public int getValue()">1</method>
			<method name="private void _init_(String, int, int value)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.AdjacencyType[] values()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.LineageInfo$TableAliasInfo</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>6</rfc>
		<lcom>6</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>5</npm>
		<lcom3>0.9166666666666667</lcom3>
		<loc>25</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.4</amc>
		<cc>
			<method name="public void setAlias(String alias)">1</method>
			<method name="public String getAlias()">1</method>
			<method name="public void setTable(org.apache.hadoop.hive.metastore.api.Table table)">1</method>
			<method name="public org.apache.hadoop.hive.metastore.api.Table getTable()">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.common.LogUtils</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>12</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>31</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public static String initHiveLog4j()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.ImportSemanticAnalyzer$1OrderComparator</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>5</rfc>
		<lcom>3</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>29</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.666666666666666</amc>
		<cc>
			<method name="public volatile int compare(Object x0, Object x1)">1</method>
			<method name="void _init_()">0</method>
			<method name="public int compare(org.apache.hadoop.hive.metastore.api.Order o1, org.apache.hadoop.hive.metastore.api.Order o2)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.PlanUtils$ExpressionTypes</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.888888888888889</lcom3>
		<loc>45</loc>
		<dam>0.3333333333333333</dam>
		<moa>3</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>9.5</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.plan.PlanUtils$ExpressionTypes[] values()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.PlanUtils$ExpressionTypes valueOf(String name)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.server.TNonblockingServer</name>
		<wmc>17</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>11</cbo>
		<rfc>32</rfc>
		<lcom>68</lcom>
		<ca>3</ca>
		<ce>10</ce>
		<npm>4</npm>
		<lcom3>0.7875</lcom3>
		<loc>151</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.2375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.588235294117647</amc>
		<cc>
			<method name="static java.util.concurrent.atomic.AtomicLong access$300(org.apache.thrift.server.TNonblockingServer x0)">1</method>
			<method name="protected boolean requestInvoke(org.apache.thrift.server.TNonblockingServer$FrameBuffer frameBuffer)">1</method>
			<method name="static boolean access$000(org.apache.thrift.server.TNonblockingServer x0)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public boolean isStopped()">1</method>
			<method name="public void _init_(org.apache.thrift.server.TNonblockingServer$AbstractNonblockingServerArgs args)">0</method>
			<method name="static org.slf4j.Logger access$100()">1</method>
			<method name="protected void joinSelector()">1</method>
			<method name="protected void requestSelectInterestChange(org.apache.thrift.server.TNonblockingServer$FrameBuffer frameBuffer)">1</method>
			<method name="protected boolean startListening()">1</method>
			<method name="public void stop()">2</method>
			<method name="static org.apache.thrift.server.TNonblockingServer$SelectThread access$400(org.apache.thrift.server.TNonblockingServer x0)">1</method>
			<method name="public void serve()">3</method>
			<method name="protected void stopListening()">1</method>
			<method name="protected boolean startSelectorThread()">1</method>
			<method name="static boolean access$002(org.apache.thrift.server.TNonblockingServer x0, boolean x1)">1</method>
			<method name="static long access$200(org.apache.thrift.server.TNonblockingServer x0)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFSin</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>7</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>24</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.serde2.io.DoubleWritable evaluate(org.apache.hadoop.hive.serde2.io.DoubleWritable a)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.package-info</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.LoadFileDesc</name>
		<wmc>12</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>20</rfc>
		<lcom>40</lcom>
		<ca>10</ca>
		<ce>2</ce>
		<npm>12</npm>
		<lcom3>0.8181818181818182</lcom3>
		<loc>110</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.666666666666667</amc>
		<cc>
			<method name="public void setColumns(String columns)">1</method>
			<method name="public String getDestinationCreateTable()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.plan.CreateTableDesc createTableDesc, String sourceDir, String targetDir, boolean isDfsDir, String columns, String columnTypes)">0</method>
			<method name="public void _init_()">0</method>
			<method name="public void setColumnTypes(String columnTypes)">1</method>
			<method name="public boolean getIsDfsDir()">1</method>
			<method name="public String getColumns()">1</method>
			<method name="public void setIsDfsDir(boolean isDfsDir)">1</method>
			<method name="public void _init_(String sourceDir, String targetDir, boolean isDfsDir, String columns, String columnTypes)">0</method>
			<method name="public void setTargetDir(String targetDir)">1</method>
			<method name="public String getColumnTypes()">1</method>
			<method name="public String getTargetDir()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFJson</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>38</rfc>
		<lcom>5</lcom>
		<ca>0</ca>
		<ce>6</ce>
		<npm>2</npm>
		<lcom3>0.6666666666666667</lcom3>
		<loc>411</loc>
		<dam>0.2222222222222222</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>66.0</amc>
		<cc>
			<method name="private Object extract_json_withindex(Object json, java.util.ArrayList indexList)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.io.Text evaluate(String jsonString, String pathString)">9</method>
			<method name="private Object extract_json_withkey(Object json, String path)">1</method>
			<method name="private Object extract(Object json, String path)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.physical.MetadataOnlyOptimizer$TableScanProcessor</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>9</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>37</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>17.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.persistence.MapJoinObjectKey</name>
		<wmc>9</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>27</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>9</npm>
		<lcom3>0.125</lcom3>
		<loc>225</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2777777777777778</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>23.88888888888889</amc>
		<cc>
			<method name="public void readExternal(java.io.ObjectInput in)">1</method>
			<method name="public void _init_(Object[] obj)">0</method>
			<method name="public boolean equals(Object o)">11</method>
			<method name="public Object[] getObj()">1</method>
			<method name="public int hashCode()">4</method>
			<method name="public void _init_()">0</method>
			<method name="public void setObj(Object[] obj)">1</method>
			<method name="public void writeExternal(java.io.ObjectOutput out)">1</method>
			<method name="public boolean hasAnyNulls(boolean[] nullsafes)">7</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.RowSchema</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>32</cbo>
		<rfc>14</rfc>
		<lcom>0</lcom>
		<ca>31</ca>
		<ce>1</ce>
		<npm>5</npm>
		<lcom3>0.75</lcom3>
		<loc>52</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.7</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>9.0</amc>
		<cc>
			<method name="public java.util.ArrayList getSignature()">1</method>
			<method name="public void setSignature(java.util.ArrayList signature)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(java.util.ArrayList signature)">0</method>
			<method name="public String toString()">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$queryStatement_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.UpdateInputAccessTimeHook</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>0</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ExprNodeEvaluator</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>5</noc>
		<cbo>24</cbo>
		<rfc>5</rfc>
		<lcom>6</lcom>
		<ca>22</ca>
		<ce>2</ce>
		<npm>4</npm>
		<lcom3>2.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>1.25</amc>
		<cc>
			<method name="public boolean isDeterministic()">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public abstract Object evaluate(Object)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.objectinspector.LazyBinaryStructObjectInspector</name>
		<wmc>6</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>15</rfc>
		<lcom>13</lcom>
		<ca>4</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.8</lcom3>
		<loc>70</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.55</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.5</amc>
		<cc>
			<method name="protected void _init_(java.util.List structFieldNames, java.util.List structFieldObjectInspectors)">0</method>
			<method name="protected void _init_(java.util.List structFieldNames, java.util.List structFieldObjectInspectors, java.util.List structFieldComments)">0</method>
			<method name="public Object getStructFieldData(Object data, org.apache.hadoop.hive.serde2.objectinspector.StructField fieldRef)">5</method>
			<method name="static void _clinit_()">0</method>
			<method name="public java.util.List getStructFieldsDataAsList(Object data)">2</method>
			<method name="protected void _init_(java.util.List fields)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDAFPercentile$State</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>6</rfc>
		<lcom>6</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>0.75</lcom3>
		<loc>26</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.35</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.8</amc>
		<cc>
			<method name="static java.util.Map access$000(org.apache.hadoop.hive.ql.udf.UDAFPercentile$State x0)">1</method>
			<method name="static java.util.Map access$002(org.apache.hadoop.hive.ql.udf.UDAFPercentile$State x0, java.util.Map x1)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static java.util.List access$102(org.apache.hadoop.hive.ql.udf.UDAFPercentile$State x0, java.util.List x1)">1</method>
			<method name="static java.util.List access$100(org.apache.hadoop.hive.ql.udf.UDAFPercentile$State x0)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.MapJoinProcessor$MapJoinDefault</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>5</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>7</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>16</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammarConstants</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>343</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>288.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.Stage$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>56</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>54.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFParseUrl</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>21</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>1</ce>
		<npm>3</npm>
		<lcom3>0.25</lcom3>
		<loc>165</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>52.666666666666664</amc>
		<cc>
			<method name="public String evaluate(String urlStr, String partToExtract)">13</method>
			<method name="public void _init_()">0</method>
			<method name="public String evaluate(String urlStr, String partToExtract, String key)">5</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.Stage$_Fields</name>
		<wmc>9</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>24</rfc>
		<lcom>26</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>7</npm>
		<lcom3>0.7727272727272727</lcom3>
		<loc>200</loc>
		<dam>0.36363636363636365</dam>
		<moa>8</moa>
		<mfa>0.65</mfa>
		<cam>0.3125</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>20.0</amc>
		<cc>
			<method name="private void _init_(String, int, short thriftId, String fieldName)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Stage$_Fields findByName(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Stage$_Fields findByThriftId(int fieldId)">2</method>
			<method name="public String getFieldName()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Stage$_Fields[] values()">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Stage$_Fields valueOf(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.api.Stage$_Fields findByThriftIdOrThrow(int fieldId)">2</method>
			<method name="public short getThriftFieldId()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryTimestamp</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>11</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>1</npm>
		<lcom3>1.0</lcom3>
		<loc>38</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.25</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableTimestampObjectInspector oi)">0</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.lazybinary.LazyBinaryTimestamp copy)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.client.TUGIAssumingTransport</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>8</rfc>
		<lcom>1</lcom>
		<ca>2</ca>
		<ce>5</ce>
		<npm>2</npm>
		<lcom3>0.5</lcom3>
		<loc>49</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4166666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.0</amc>
		<cc>
			<method name="public void open()">1</method>
			<method name="public void _init_(org.apache.thrift.transport.TTransport wrapped, org.apache.hadoop.security.UserGroupInformation ugi)">0</method>
			<method name="static org.apache.thrift.transport.TTransport access$000(org.apache.hadoop.hive.thrift.client.TUGIAssumingTransport x0)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.FullMapEqualComparer$MapKeyComparator</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>0.0</lcom3>
		<loc>17</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public int compare(Object o1, Object o2)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFPrintf$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>77</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>75.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.columnar.LazyDecompressionCallback</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract byte[] decompress()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.TableScanOperator</name>
		<wmc>14</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>48</cbo>
		<rfc>69</rfc>
		<lcom>55</lcom>
		<ca>28</ca>
		<ce>20</ce>
		<npm>10</npm>
		<lcom3>0.8538461538461538</lcom3>
		<loc>523</loc>
		<dam>0.8</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.21978021978021978</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>35.642857142857146</amc>
		<cc>
			<method name="public void closeOp(boolean abort)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.api.OperatorType getType()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void processOp(Object row, int tag)">1</method>
			<method name="private void publishStats()">5</method>
			<method name="public String getName()">1</method>
			<method name="public void setNeededColumnIDs(java.util.ArrayList orign_columns)">1</method>
			<method name="protected void initializeOp(org.apache.hadoop.conf.Configuration hconf)">1</method>
			<method name="private void gatherStats(Object row)">17</method>
			<method name="public java.util.ArrayList getNeededColumnIDs()">1</method>
			<method name="public void cleanUpInputFileChangedOp()">1</method>
			<method name="public void setTableDesc(org.apache.hadoop.hive.ql.plan.TableDesc tableDesc)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.TableDesc getTableDesc()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFLength</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>10</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>5</ce>
		<npm>3</npm>
		<lcom3>0.0</lcom3>
		<loc>54</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.666666666666668</amc>
		<cc>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.BytesWritable bw)">2</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.Text s)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.xml.UDFXPathShort</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>18</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public short evaluate(String xml, String path)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.ppd.ExprWalkerInfo</name>
		<wmc>20</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>22</cbo>
		<rfc>38</rfc>
		<lcom>68</lcom>
		<ca>14</ca>
		<ce>8</ce>
		<npm>19</npm>
		<lcom3>0.8157894736842105</lcom3>
		<loc>403</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.2046783625730994</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.75</amc>
		<cc>
			<method name="public void addConvertedNode(org.apache.hadoop.hive.ql.plan.ExprNodeDesc oldNode, org.apache.hadoop.hive.ql.plan.ExprNodeDesc newNode)">2</method>
			<method name="public boolean isDeterministic()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public boolean isCandidate(org.apache.hadoop.hive.ql.plan.ExprNodeDesc expr)">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.Operator op, org.apache.hadoop.hive.ql.parse.RowResolver toRR)">0</method>
			<method name="public void merge(org.apache.hadoop.hive.ql.ppd.ExprWalkerInfo ewi)">6</method>
			<method name="public org.apache.hadoop.hive.ql.exec.Operator getOp()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.RowResolver getToRR()">1</method>
			<method name="public void setIsCandidate(org.apache.hadoop.hive.ql.plan.ExprNodeDesc expr, boolean b)">2</method>
			<method name="public String getAlias(org.apache.hadoop.hive.ql.plan.ExprNodeDesc expr)">2</method>
			<method name="public void addAlias(org.apache.hadoop.hive.ql.plan.ExprNodeDesc expr, String alias)">3</method>
			<method name="public void setDeterministic(boolean b)">1</method>
			<method name="public java.util.Map getNewToOldExprMap()">1</method>
			<method name="public void addNonFinalCandidate(org.apache.hadoop.hive.ql.plan.ExprNodeDesc expr)">2</method>
			<method name="public void addFinalCandidate(org.apache.hadoop.hive.ql.plan.ExprNodeDesc expr)">2</method>
			<method name="public java.util.Map getNonFinalCandidates()">1</method>
			<method name="public void addPushDowns(String alias, java.util.List pushDowns)">2</method>
			<method name="public java.util.Map getFinalCandidates()">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ExprNodeDesc getConvertedNode(org.apache.hadoop.hive.ql.lib.Node nd)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFSentences</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>13</cbo>
		<rfc>35</rfc>
		<lcom>2</lcom>
		<ca>0</ca>
		<ce>13</ce>
		<npm>4</npm>
		<lcom3>0.625</lcom3>
		<loc>305</loc>
		<dam>0.5</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>59.6</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">6</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceNotExpression_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.pcr.PcrOpWalkerCtx</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>4</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>2</ce>
		<npm>3</npm>
		<lcom3>0.5</lcom3>
		<loc>20</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.ql.parse.ParseContext parseContext, java.util.List opToRemove)">0</method>
			<method name="public java.util.List getOpToRemove()">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext getParseContext()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TTransport</name>
		<wmc>14</wmc>
		<dit>1</dit>
		<noc>12</noc>
		<cbo>81</cbo>
		<rfc>20</rfc>
		<lcom>91</lcom>
		<ca>80</ca>
		<ce>1</ce>
		<npm>14</npm>
		<lcom3>2.0</lcom3>
		<loc>79</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5238095238095238</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.642857142857143</amc>
		<cc>
			<method name="public int getBufferPosition()">1</method>
			<method name="public void consumeBuffer(int len)">1</method>
			<method name="public abstract void write(byte[], int, int)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public boolean peek()">1</method>
			<method name="public abstract int read(byte[], int, int)">1</method>
			<method name="public abstract void close()">1</method>
			<method name="public void write(byte[] buf)">1</method>
			<method name="public byte[] getBuffer()">1</method>
			<method name="public abstract boolean isOpen()">1</method>
			<method name="public void flush()">1</method>
			<method name="public abstract void open()">1</method>
			<method name="public int getBytesRemainingInBuffer()">1</method>
			<method name="public int readAll(byte[] buf, int off, int len)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.Jetty20SShims$1</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.JobDebugger$TaskLogGrabber</name>
		<wmc>4</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>33</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>1</npm>
		<lcom3>0.3333333333333333</lcom3>
		<loc>199</loc>
		<dam>0.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>48.25</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.ql.exec.JobDebugger)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void run()">1</method>
			<method name="private void getTaskLogs()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFYear</name>
		<wmc>3</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>13</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>0.16666666666666674</lcom3>
		<loc>69</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5555555555555556</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>21.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.hive.serde2.io.TimestampWritable t)">2</method>
			<method name="public org.apache.hadoop.io.IntWritable evaluate(org.apache.hadoop.io.Text dateString)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>5</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>110</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>107.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFOPLongDivide</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>6</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>28</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.LongWritable a, org.apache.hadoop.io.LongWritable b)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyPrimitiveObjectInspectorFactory$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>84</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>82.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>1</noc>
		<cbo>7</cbo>
		<rfc>9</rfc>
		<lcom>28</lcom>
		<ca>3</ca>
		<ce>4</ce>
		<npm>8</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.40625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.375</amc>
		<cc>
			<method name="public abstract void startDelegationTokenSecretManager(org.apache.hadoop.conf.Configuration)">1</method>
			<method name="public abstract org.apache.thrift.transport.TTransportFactory createTransportFactory()">1</method>
			<method name="public abstract java.net.InetAddress getRemoteAddress()">1</method>
			<method name="public abstract org.apache.thrift.TProcessor wrapProcessor(org.apache.thrift.TProcessor)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public abstract long renewDelegationToken(String)">1</method>
			<method name="public abstract void cancelDelegationToken(String)">1</method>
			<method name="public abstract String getDelegationToken(String, String)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.api.Graph$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>28</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>26.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.GroupByDesc$Mode</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>6</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9583333333333334</lcom3>
		<loc>100</loc>
		<dam>0.125</dam>
		<moa>8</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>22.0</amc>
		<cc>
			<method name="public static org.apache.hadoop.hive.ql.plan.GroupByDesc$Mode[] values()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="private void _init_(String, int)">0</method>
			<method name="public static org.apache.hadoop.hive.ql.plan.GroupByDesc$Mode valueOf(String name)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Operator$OperatorFunc</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract void func(org.apache.hadoop.hive.ql.exec.Operator)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFMax$GenericUDAFMaxEvaluator$MaxAgg</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.RCFile$Writer$ColumnBuffer</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>11</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>3</npm>
		<lcom3>0.35</lcom3>
		<loc>112</loc>
		<dam>0.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.4</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>20.4</amc>
		<cc>
			<method name="public void clear()">1</method>
			<method name="public void flushGroup()">1</method>
			<method name="private void startNewGroup(int currentLen)">1</method>
			<method name="public void append(org.apache.hadoop.hive.serde2.columnar.BytesRefWritable data)">1</method>
			<method name="void _init_(org.apache.hadoop.hive.ql.io.RCFile$Writer)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFConcatWS$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>21</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TFastFramedTransport$Factory</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>6</rfc>
		<lcom>4</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>4</npm>
		<lcom3>0.0</lcom3>
		<loc>34</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public void _init_(int initialCapacity)">0</method>
			<method name="public void _init_()">0</method>
			<method name="public void _init_(int initialCapacity, int maxLength)">0</method>
			<method name="public org.apache.thrift.transport.TTransport getTransport(org.apache.thrift.transport.TTransport trans)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.SettableByteObjectInspector</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>5</cbo>
		<rfc>2</rfc>
		<lcom>1</lcom>
		<ca>4</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>2</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract Object set(Object, byte)">1</method>
			<method name="public abstract Object create(byte)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.HiveBinaryOutputFormat</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>6</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>19</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5714285714285714</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.5</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf jc, org.apache.hadoop.fs.Path outPath, Class valueClass, boolean isCompressed, java.util.Properties tableProperties, org.apache.hadoop.util.Progressable progress)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.ArchiveWork</name>
		<wmc>3</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>1</ce>
		<npm>3</npm>
		<lcom3>1.3</lcom3>
		<loc>18</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.3333333333333335</amc>
		<cc>
			<method name="public void setType(org.apache.hadoop.hive.ql.plan.ArchiveWork$ArchiveActionType type)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ArchiveWork$ArchiveActionType getType()">1</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.ExecMapper</name>
		<wmc>10</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>22</cbo>
		<rfc>70</rfc>
		<lcom>3</lcom>
		<ca>3</ca>
		<ce>20</ce>
		<npm>8</npm>
		<lcom3>0.7857142857142857</lcom3>
		<loc>455</loc>
		<dam>0.8571428571428571</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.2222222222222222</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>43.1</amc>
		<cc>
			<method name="public static boolean getDone()">1</method>
			<method name="public boolean isAbort()">1</method>
			<method name="private long getNextCntr(long cntr)">2</method>
			<method name="public void configure(org.apache.hadoop.mapred.JobConf job)">3</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void map(Object key, Object value, org.apache.hadoop.mapred.OutputCollector output, org.apache.hadoop.mapred.Reporter reporter)">1</method>
			<method name="public static void setDone(boolean done)">1</method>
			<method name="public void close()">9</method>
			<method name="public void setAbort(boolean abort)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.TDeserializer</name>
		<wmc>17</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>51</rfc>
		<lcom>94</lcom>
		<ca>1</ca>
		<ce>11</ce>
		<npm>15</npm>
		<lcom3>0.0</lcom3>
		<loc>503</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.45588235294117646</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>28.470588235294116</amc>
		<cc>
			<method name="private transient Object partialDeserializeField(byte ttype, byte[] bytes, org.apache.thrift.TFieldIdEnum fieldIdPathFirst, org.apache.thrift.TFieldIdEnum[] fieldIdPathRest)">1</method>
			<method name="public transient Double partialDeserializeDouble(byte[] bytes, org.apache.thrift.TFieldIdEnum fieldIdPathFirst, org.apache.thrift.TFieldIdEnum[] fieldIdPathRest)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void deserialize(org.apache.thrift.TBase base, byte[] bytes)">1</method>
			<method name="public transient Byte partialDeserializeByte(byte[] bytes, org.apache.thrift.TFieldIdEnum fieldIdPathFirst, org.apache.thrift.TFieldIdEnum[] fieldIdPathRest)">1</method>
			<method name="public transient void partialDeserialize(org.apache.thrift.TBase tb, byte[] bytes, org.apache.thrift.TFieldIdEnum fieldIdPathFirst, org.apache.thrift.TFieldIdEnum[] fieldIdPathRest)">1</method>
			<method name="public transient Integer partialDeserializeI32(byte[] bytes, org.apache.thrift.TFieldIdEnum fieldIdPathFirst, org.apache.thrift.TFieldIdEnum[] fieldIdPathRest)">1</method>
			<method name="public void _init_(org.apache.thrift.protocol.TProtocolFactory protocolFactory)">0</method>
			<method name="public transient Long partialDeserializeI64(byte[] bytes, org.apache.thrift.TFieldIdEnum fieldIdPathFirst, org.apache.thrift.TFieldIdEnum[] fieldIdPathRest)">1</method>
			<method name="public transient Boolean partialDeserializeBool(byte[] bytes, org.apache.thrift.TFieldIdEnum fieldIdPathFirst, org.apache.thrift.TFieldIdEnum[] fieldIdPathRest)">1</method>
			<method name="public transient Short partialDeserializeI16(byte[] bytes, org.apache.thrift.TFieldIdEnum fieldIdPathFirst, org.apache.thrift.TFieldIdEnum[] fieldIdPathRest)">1</method>
			<method name="public void fromString(org.apache.thrift.TBase base, String data)">1</method>
			<method name="public transient Short partialDeserializeSetFieldIdInUnion(byte[] bytes, org.apache.thrift.TFieldIdEnum fieldIdPathFirst, org.apache.thrift.TFieldIdEnum[] fieldIdPathRest)">1</method>
			<method name="public transient java.nio.ByteBuffer partialDeserializeByteArray(byte[] bytes, org.apache.thrift.TFieldIdEnum fieldIdPathFirst, org.apache.thrift.TFieldIdEnum[] fieldIdPathRest)">1</method>
			<method name="public transient String partialDeserializeString(byte[] bytes, org.apache.thrift.TFieldIdEnum fieldIdPathFirst, org.apache.thrift.TFieldIdEnum[] fieldIdPathRest)">1</method>
			<method name="public void deserialize(org.apache.thrift.TBase base, String data, String charset)">1</method>
			<method name="private transient org.apache.thrift.protocol.TField locateField(byte[] bytes, org.apache.thrift.TFieldIdEnum fieldIdPathFirst, org.apache.thrift.TFieldIdEnum[] fieldIdPathRest)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.UDFArgumentLengthException</name>
		<wmc>1</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>32</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>31</ca>
		<ce>1</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>5</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void _init_(String message)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.Stat</name>
		<wmc>7</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>18</rfc>
		<lcom>0</lcom>
		<ca>3</ca>
		<ce>1</ce>
		<npm>7</npm>
		<lcom3>0.5</lcom3>
		<loc>89</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4642857142857143</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>11.428571428571429</amc>
		<cc>
			<method name="public void clear()">1</method>
			<method name="public void addToStat(String statType, long amount)">2</method>
			<method name="public void _init_()">0</method>
			<method name="public int getBookkeepingInfo(String statType)">2</method>
			<method name="public void setBookkeepingInfo(String statType, int info)">1</method>
			<method name="public long getStat(String statType)">2</method>
			<method name="public java.util.Collection getStoredStats()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeInclude</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>11</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.8333333333333334</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.5</amc>
		<cc>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int id)">0</method>
			<method name="public void _init_(int id)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.objectinspector.primitive.VoidObjectInspector</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>5</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>javaewah.EWAHCompressedBitmap$2</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>10</rfc>
		<lcom>4</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>4</npm>
		<lcom3>0.625</lcom3>
		<loc>37</loc>
		<dam>0.5</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.0</amc>
		<cc>
			<method name="void _init_(javaewah.EWAHCompressedBitmap)">0</method>
			<method name="public Integer next()">1</method>
			<method name="public boolean hasNext()">1</method>
			<method name="public void remove()">1</method>
			<method name="public volatile Object next()">1</method>
		</cc>
	</class>
	<class>
		<name>javaewah.EWAHCompressedBitmap$1</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>4</cbo>
		<rfc>15</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>4</ce>
		<npm>2</npm>
		<lcom3>0.575</lcom3>
		<loc>227</loc>
		<dam>0.0</dam>
		<moa>3</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>35.5</amc>
		<cc>
			<method name="public int next()">2</method>
			<method name="private boolean loadNextRLE()">2</method>
			<method name="public boolean hasNext()">3</method>
			<method name="private void add(int val)">2</method>
			<method name="void _init_(javaewah.EWAHCompressedBitmap, javaewah.EWAHIterator)">0</method>
			<method name="private void loadBuffer()">6</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.ASTNode</name>
		<wmc>8</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>43</cbo>
		<rfc>25</rfc>
		<lcom>26</lcom>
		<ca>39</ca>
		<ce>5</ce>
		<npm>8</npm>
		<lcom3>1.0</lcom3>
		<loc>110</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4166666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.5</amc>
		<cc>
			<method name="public void setOrigin(org.apache.hadoop.hive.ql.parse.ASTNodeOrigin origin)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ASTNodeOrigin getOrigin()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public volatile java.util.List getChildren()">1</method>
			<method name="public java.util.ArrayList getChildren()">3</method>
			<method name="public String dump()">4</method>
			<method name="public String getName()">1</method>
			<method name="public void _init_(org.antlr.runtime.Token t)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.SamplePruner$AddPathReturnStatus</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>2</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>16</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>12.0</amc>
		<cc>
			<method name="public void _init_(boolean hasFile, boolean allFile, long sizeLeft)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyFactory</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>57</cbo>
		<rfc>63</rfc>
		<lcom>36</lcom>
		<ca>7</ca>
		<ce>54</ce>
		<npm>8</npm>
		<lcom3>2.0</lcom3>
		<loc>447</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.26666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>48.666666666666664</amc>
		<cc>
			<method name="private void _init_()">0</method>
			<method name="public static org.apache.hadoop.hive.serde2.lazy.LazyPrimitive createLazyPrimitiveClass(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector oi)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.lazy.LazyObject createLazyObject(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createColumnarStructInspector(java.util.List columnNames, java.util.List columnTypes, byte[] separators, org.apache.hadoop.io.Text nullSequence, boolean escaped, byte escapeChar)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createLazyStructInspector(java.util.List columnNames, java.util.List typeInfos, byte[] separators, org.apache.hadoop.io.Text nullSequence, boolean lastColumnTakesRest, boolean escaped, byte escapeChar)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createLazyObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo typeInfo, byte[] separator, int separatorIndex, org.apache.hadoop.io.Text nullSequence, boolean escaped, byte escapeChar)">4</method>
			<method name="public static org.apache.hadoop.hive.serde2.lazy.LazyPrimitive createLazyPrimitiveBinaryClass(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector poi)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.lazy.LazyPrimitive createLazyPrimitiveClass(org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector poi, boolean typeBinary)">2</method>
			<method name="public static org.apache.hadoop.hive.serde2.lazy.LazyObject createLazyObject(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector oi, boolean typeBinary)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil</name>
		<wmc>5</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>13</rfc>
		<lcom>8</lcom>
		<ca>6</ca>
		<ce>3</ce>
		<npm>3</npm>
		<lcom3>0.25</lcom3>
		<loc>60</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.8</amc>
		<cc>
			<method name="private static org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain get(org.apache.hadoop.mapred.JobConf job)">2</method>
			<method name="public static org.apache.hadoop.mapred.RecordReader handleRecordReaderCreationException(Exception e, org.apache.hadoop.mapred.JobConf job)">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static boolean handleRecordReaderNextException(Exception e, org.apache.hadoop.mapred.JobConf job)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.metadata.Partition</name>
		<wmc>44</wmc>
		<dit>1</dit>
		<noc>1</noc>
		<cbo>71</cbo>
		<rfc>143</rfc>
		<lcom>212</lcom>
		<ca>44</ca>
		<ce>29</ce>
		<npm>42</npm>
		<lcom3>0.7840531561461794</lcom3>
		<loc>1015</loc>
		<dam>1.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.1331923890063425</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>21.90909090909091</amc>
		<cc>
			<method name="public int getLastAccessTime()">1</method>
			<method name="public void setTable(org.apache.hadoop.hive.ql.metadata.Table table)">1</method>
			<method name="public final Class getOutputFormatClass()">1</method>
			<method name="public java.util.LinkedHashMap getSpec()">1</method>
			<method name="public org.apache.hadoop.hive.metastore.ProtectMode getProtectMode()">3</method>
			<method name="static void _clinit_()">0</method>
			<method name="public org.apache.hadoop.fs.Path getBucketPath(int bucketNum)">4</method>
			<method name="public org.apache.hadoop.hive.metastore.api.Partition getTPartition()">1</method>
			<method name="public String getName()">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.Deserializer getDeserializer(java.util.Properties props)">2</method>
			<method name="public void setLastAccessTime(int lastAccessTime)">1</method>
			<method name="public java.util.List getSortCols()">1</method>
			<method name="public java.util.List getCols()">1</method>
			<method name="public org.apache.hadoop.hive.ql.metadata.Table getTable()">1</method>
			<method name="public void setOutputFormatClass(Class outputFormatClass)">1</method>
			<method name="public void setTPartition(org.apache.hadoop.hive.metastore.api.Partition partition)">1</method>
			<method name="public void setLocation(String location)">1</method>
			<method name="public org.apache.hadoop.fs.Path[] getPath(org.apache.hadoop.hive.ql.metadata.Sample s)">1</method>
			<method name="public boolean canDrop()">5</method>
			<method name="private void initialize(org.apache.hadoop.hive.ql.metadata.Table table, org.apache.hadoop.hive.metastore.api.Partition tPartition)">1</method>
			<method name="public void setProtectMode(org.apache.hadoop.hive.metastore.ProtectMode protectMode)">1</method>
			<method name="public final Class getInputFormatClass()">1</method>
			<method name="public String toString()">1</method>
			<method name="public boolean canWrite()">3</method>
			<method name="public String getLocation()">2</method>
			<method name="public java.util.Map getParameters()">1</method>
			<method name="public org.apache.hadoop.fs.Path[] getPath()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public String getCompleteName()">1</method>
			<method name="public boolean isOffline()">2</method>
			<method name="public int getBucketCount()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Table tbl)">0</method>
			<method name="public org.apache.hadoop.fs.Path getPartitionPath()">2</method>
			<method name="public java.util.List getBucketCols()">1</method>
			<method name="public java.util.List getSortColNames()">1</method>
			<method name="public void setInputFormatClass(Class inputFormatClass)">1</method>
			<method name="public java.util.Properties getSchemaFromTableSchema(java.util.Properties tblSchema)">1</method>
			<method name="public final org.apache.hadoop.hive.serde2.Deserializer getDeserializer()">2</method>
			<method name="public java.util.List getValues()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Table tbl, org.apache.hadoop.hive.metastore.api.Partition tp)">0</method>
			<method name="public java.util.Properties getSchema()">1</method>
			<method name="public final java.net.URI getDataLocation()">2</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.metadata.Table tbl, java.util.Map partSpec, org.apache.hadoop.fs.Path location)">0</method>
			<method name="public void setValues(java.util.Map partSpec)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.objectinspector.LazyMapObjectInspector</name>
		<wmc>14</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>9</cbo>
		<rfc>24</rfc>
		<lcom>71</lcom>
		<ca>3</ca>
		<ce>7</ce>
		<npm>12</npm>
		<lcom3>0.9134615384615384</lcom3>
		<loc>118</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.2564102564102564</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>6.857142857142857</amc>
		<cc>
			<method name="public int getMapSize(Object data)">2</method>
			<method name="public org.apache.hadoop.io.Text getNullSequence()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public final org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
			<method name="public byte getKeyValueSeparator()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getMapValueObjectInspector()">1</method>
			<method name="public boolean isEscaped()">1</method>
			<method name="public Object getMapValueElement(Object data, Object key)">2</method>
			<method name="public byte getItemSeparator()">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getMapKeyObjectInspector()">1</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector mapKeyObjectInspector, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector mapValueObjectInspector, byte itemSeparator, byte keyValueSeparator, org.apache.hadoop.io.Text nullSequence, boolean escaped, byte escapeChar)">0</method>
			<method name="public java.util.Map getMap(Object data)">2</method>
			<method name="public String getTypeName()">1</method>
			<method name="public byte getEscapeChar()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyMap</name>
		<wmc>11</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>40</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>12</ce>
		<npm>4</npm>
		<lcom3>0.5222222222222223</lcom3>
		<loc>572</loc>
		<dam>0.1111111111111111</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.2727272727272727</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>50.18181818181818</amc>
		<cc>
			<method name="private org.apache.hadoop.hive.serde2.lazy.LazyPrimitive uncheckedGetKey(int index)">6</method>
			<method name="private org.apache.hadoop.hive.serde2.lazy.LazyObject uncheckedGetValue(int index)">6</method>
			<method name="public Object getMapValueElement(Object key)">7</method>
			<method name="protected void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.LazyMapObjectInspector oi)">0</method>
			<method name="protected void enlargeArrays()">2</method>
			<method name="public int getMapSize()">2</method>
			<method name="public java.util.Map getMap()">8</method>
			<method name="protected void setParsed(boolean parsed)">1</method>
			<method name="private void parse()">14</method>
			<method name="protected boolean getParsed()">1</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TSSLTransportFactory$TSSLTransportParameters</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>1</cbo>
		<rfc>9</rfc>
		<lcom>14</lcom>
		<ca>1</ca>
		<ce>0</ce>
		<npm>8</npm>
		<lcom3>0.6263736263736265</lcom3>
		<loc>150</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>16.125</amc>
		<cc>
			<method name="public void setTrustStore(String trustStore, String trustPass)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public void setTrustStore(String trustStore, String trustPass, String trustManagerType, String trustStoreType)">3</method>
			<method name="public void _init_(String protocol, String[] cipherSuites, boolean clientAuth)">0</method>
			<method name="public void _init_(String protocol, String[] cipherSuites)">0</method>
			<method name="public void setKeyStore(String keyStore, String keyPass, String keyManagerType, String keyStoreType)">3</method>
			<method name="public void requireClientAuth(boolean clientAuth)">1</method>
			<method name="public void setKeyStore(String keyStore, String keyPass)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.DefaultHivePartitioner</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>4</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>12</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>5.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public int getBucket(Object key, Object value, int numBuckets)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$precedenceUnarySuffixExpression_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFCovarianceSample</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>12</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>124</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.75</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>61.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getEvaluator(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo[] parameters)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.meta_data.FieldValueMetaData</name>
		<wmc>8</wmc>
		<dit>1</dit>
		<noc>5</noc>
		<cbo>17</cbo>
		<rfc>9</rfc>
		<lcom>4</lcom>
		<ca>17</ca>
		<ce>0</ce>
		<npm>8</npm>
		<lcom3>0.5357142857142857</lcom3>
		<loc>80</loc>
		<dam>0.75</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.40625</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>8.5</amc>
		<cc>
			<method name="public boolean isBinary()">1</method>
			<method name="public boolean isContainer()">4</method>
			<method name="public boolean isTypedef()">1</method>
			<method name="public void _init_(byte type)">0</method>
			<method name="public void _init_(byte type, boolean binary)">0</method>
			<method name="public void _init_(byte type, String typedefName)">0</method>
			<method name="public boolean isStruct()">2</method>
			<method name="public String getTypedefName()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.io.HiveIOExceptionNextHandleResult</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>7</rfc>
		<lcom>3</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>6</npm>
		<lcom3>0.6</lcom3>
		<loc>32</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.0</amc>
		<cc>
			<method name="public void clear()">1</method>
			<method name="public boolean getHandleResult()">1</method>
			<method name="public void _init_()">0</method>
			<method name="public boolean getHandled()">1</method>
			<method name="public void setHandled(boolean handled)">1</method>
			<method name="public void setHandleResult(boolean handleResult)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFHash</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>11</cbo>
		<rfc>13</rfc>
		<lcom>2</lcom>
		<ca>1</ca>
		<ce>10</ce>
		<npm>4</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>63</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>14.25</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.persistence.MapJoinDoubleKeys</name>
		<wmc>11</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>30</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>11</npm>
		<lcom3>0.3</lcom3>
		<loc>230</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.32727272727272727</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>19.727272727272727</amc>
		<cc>
			<method name="public Object getObj1()">1</method>
			<method name="public void setObj1(Object obj1)">1</method>
			<method name="public void readExternal(java.io.ObjectInput in)">1</method>
			<method name="public Object getObj2()">1</method>
			<method name="public boolean equals(Object o)">12</method>
			<method name="public void setObj2(Object obj2)">1</method>
			<method name="public int hashCode()">3</method>
			<method name="public void _init_()">0</method>
			<method name="public void writeExternal(java.io.ObjectOutput out)">1</method>
			<method name="public void _init_(Object obj1, Object obj2)">0</method>
			<method name="public boolean hasAnyNulls(boolean[] nullsafes)">7</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.transport.TIOStreamTransport</name>
		<wmc>11</wmc>
		<dit>0</dit>
		<noc>1</noc>
		<cbo>21</cbo>
		<rfc>23</rfc>
		<lcom>1</lcom>
		<ca>17</ca>
		<ce>4</ce>
		<npm>9</npm>
		<lcom3>0.6</lcom3>
		<loc>179</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.36</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>15.0</amc>
		<cc>
			<method name="public boolean isOpen()">1</method>
			<method name="public void _init_(java.io.InputStream is, java.io.OutputStream os)">0</method>
			<method name="public void _init_(java.io.InputStream is)">0</method>
			<method name="public void open()">1</method>
			<method name="public void write(byte[] buf, int off, int len)">1</method>
			<method name="protected void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void flush()">1</method>
			<method name="public void close()">3</method>
			<method name="public void _init_(java.io.OutputStream os)">0</method>
			<method name="public int read(byte[] buf, int off, int len)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader</name>
		<wmc>10</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>42</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>9</ce>
		<npm>7</npm>
		<lcom3>0.7692307692307693</lcom3>
		<loc>318</loc>
		<dam>0.8461538461538461</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2962962962962963</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>29.5</amc>
		<cc>
			<method name="private boolean doNextWithExceptionHandler(Object key, Object value)">1</method>
			<method name="public Object createValue()">1</method>
			<method name="protected boolean initNextRecordReader(Object key)">1</method>
			<method name="public float getProgress()">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object createKey()">1</method>
			<method name="public long getPos()">1</method>
			<method name="public void close()">1</method>
			<method name="public void _init_(org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.mapred.lib.CombineFileSplit split, org.apache.hadoop.mapred.Reporter reporter, Class rrClass)">0</method>
			<method name="public boolean next(Object key, Object value)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.TProcessor</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>1</rfc>
		<lcom>0</lcom>
		<ca>12</ca>
		<ce>2</ce>
		<npm>1</npm>
		<lcom3>2.0</lcom3>
		<loc>1</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
			<method name="public abstract boolean process(org.apache.thrift.protocol.TProtocol, org.apache.thrift.protocol.TProtocol)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$kwInner_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat</name>
		<wmc>7</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>22</cbo>
		<rfc>44</rfc>
		<lcom>21</lcom>
		<ca>1</ca>
		<ce>21</ce>
		<npm>6</npm>
		<lcom3>2.0</lcom3>
		<loc>349</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2857142857142857</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>48.857142857142854</amc>
		<cc>
			<method name="public void configure(org.apache.hadoop.mapred.JobConf job)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public org.apache.hadoop.fs.ContentSummary getContentSummary(org.apache.hadoop.fs.Path p, org.apache.hadoop.mapred.JobConf job)">1</method>
			<method name="private static void getTargetPathsFromSymlinksDirs(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.fs.Path[] symlinksDirs, java.util.List targetPaths, java.util.List symlinkPaths)">1</method>
			<method name="public void validateInput(org.apache.hadoop.mapred.JobConf job)">1</method>
			<method name="public org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit split, org.apache.hadoop.mapred.JobConf job, org.apache.hadoop.mapred.Reporter reporter)">1</method>
			<method name="public org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf job, int numSplits)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.thrift.TokenStoreDelegationTokenSecretManager</name>
		<wmc>24</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>19</cbo>
		<rfc>94</rfc>
		<lcom>158</lcom>
		<ca>3</ca>
		<ce>17</ce>
		<npm>11</npm>
		<lcom3>0.7913043478260869</lcom3>
		<loc>591</loc>
		<dam>1.0</dam>
		<moa>1</moa>
		<mfa>0.0</mfa>
		<cam>0.1541501976284585</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>23.416666666666668</amc>
		<cc>
			<method name="static long access$000(org.apache.hadoop.hive.thrift.TokenStoreDelegationTokenSecretManager x0)">1</method>
			<method name="public static String encodeWritable(org.apache.hadoop.io.Writable key)">1</method>
			<method name="public static void decodeWritable(org.apache.hadoop.io.Writable w, String idStr)">1</method>
			<method name="protected volatile byte[] createPassword(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier x0)">1</method>
			<method name="static void _clinit_()">0</method>
			<method name="static boolean access$200(org.apache.hadoop.hive.thrift.TokenStoreDelegationTokenSecretManager x0)">1</method>
			<method name="protected byte[] createPassword(org.apache.hadoop.hive.thrift.DelegationTokenIdentifier id)">2</method>
			<method name="static org.slf4j.Logger access$100()">1</method>
			<method name="public long renewToken(org.apache.hadoop.security.token.Token token, String renewer)">1</method>
			<method name="protected void rollMasterKeyExt()">1</method>
			<method name="protected org.apache.hadoop.hive.thrift.DelegationTokenIdentifier getTokenIdentifier(org.apache.hadoop.security.token.Token token)">1</method>
			<method name="public synchronized void stopThreads()">3</method>
			<method name="public volatile byte[] retrievePassword(org.apache.hadoop.security.token.TokenIdentifier x0)">1</method>
			<method name="public volatile org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier cancelToken(org.apache.hadoop.security.token.Token x0, String x1)">1</method>
			<method name="public void _init_(long delegationKeyUpdateInterval, long delegationTokenMaxLifetime, long delegationTokenRenewInterval, long delegationTokenRemoverScanInterval, org.apache.hadoop.hive.thrift.DelegationTokenStore sharedStore)">0</method>
			<method name="public org.apache.hadoop.hive.thrift.DelegationTokenIdentifier cancelToken(org.apache.hadoop.security.token.Token token, String canceller)">1</method>
			<method name="protected void logUpdateMasterKey(org.apache.hadoop.security.token.delegation.DelegationKey key)">1</method>
			<method name="public synchronized void startThreads()">1</method>
			<method name="static long access$300(org.apache.hadoop.hive.thrift.TokenStoreDelegationTokenSecretManager x0)">1</method>
			<method name="protected volatile byte[] createPassword(org.apache.hadoop.security.token.TokenIdentifier x0)">1</method>
			<method name="protected java.util.Map reloadKeys()">2</method>
			<method name="public volatile byte[] retrievePassword(org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier x0)">1</method>
			<method name="protected void removeExpiredTokens()">3</method>
			<method name="public byte[] retrievePassword(org.apache.hadoop.hive.thrift.DelegationTokenIdentifier identifier)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.hooks.Entity$Type</name>
		<wmc>4</wmc>
		<dit>2</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>7</rfc>
		<lcom>4</lcom>
		<ca>6</ca>
		<ce>1</ce>
		<npm>2</npm>
		<lcom3>0.9444444444444443</lcom3>
		<loc>78</loc>
		<dam>0.16666666666666666</dam>
		<moa>6</moa>
		<mfa>0.8666666666666667</mfa>
		<cam>0.4444444444444444</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>17.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
			<method name="public static org.apache.hadoop.hive.ql.hooks.Entity$Type valueOf(String name)">1</method>
			<method name="public static org.apache.hadoop.hive.ql.hooks.Entity$Type[] values()">1</method>
			<method name="private void _init_(String, int)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDFIndex</name>
		<wmc>5</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>12</cbo>
		<rfc>26</rfc>
		<lcom>2</lcom>
		<ca>0</ca>
		<ce>12</ce>
		<npm>4</npm>
		<lcom3>0.75</lcom3>
		<loc>246</loc>
		<dam>0.8333333333333334</dam>
		<moa>4</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>47.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public Object evaluate(org.apache.hadoop.hive.ql.udf.generic.GenericUDF$DeferredObject[] arguments)">1</method>
			<method name="public org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector initialize(org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] arguments)">1</method>
			<method name="public String getDisplayString(String[] children)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.ppd.ExprWalkerProcFactory$DefaultExprProcessor</name>
		<wmc>2</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>5</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>6</ce>
		<npm>2</npm>
		<lcom3>2.0</lcom3>
		<loc>16</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>7.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public transient Object process(org.apache.hadoop.hive.ql.lib.Node nd, java.util.Stack stack, org.apache.hadoop.hive.ql.lib.NodeProcessorCtx procCtx, Object[] nodeOutputs)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.exec.KeyWrapperFactory$ListKeyWrapper</name>
		<wmc>12</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>8</cbo>
		<rfc>17</rfc>
		<lcom>6</lcom>
		<ca>1</ca>
		<ce>8</ce>
		<npm>8</npm>
		<lcom3>0.5227272727272727</lcom3>
		<loc>174</loc>
		<dam>0.0</dam>
		<moa>2</moa>
		<mfa>0.0</mfa>
		<cam>0.24166666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>13.166666666666666</amc>
		<cc>
			<method name="public org.apache.hadoop.hive.ql.exec.KeyWrapper copyKey()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.ql.exec.KeyWrapperFactory, boolean isCopy)">0</method>
			<method name="public Object[] getKeyArray()">1</method>
			<method name="public int hashCode()">1</method>
			<method name="private void deepCopyElements(Object[] keys, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] keyObjectInspectors, Object[] result, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils$ObjectInspectorCopyOption copyOption)">2</method>
			<method name="public void setHashKey()">1</method>
			<method name="private void _init_(org.apache.hadoop.hive.ql.exec.KeyWrapperFactory, int hashcode, Object[] copiedKeys, boolean isCopy)">0</method>
			<method name="private Object[] deepCopyElements(Object[] keys, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] keyObjectInspectors, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils$ObjectInspectorCopyOption copyOption)">1</method>
			<method name="public void getNewKey(Object row, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector rowInspector)">1</method>
			<method name="public boolean equals(Object obj)">1</method>
			<method name="private void setEqualComparer(boolean copy)">2</method>
			<method name="public void copyKey(org.apache.hadoop.hive.ql.exec.KeyWrapper oldWrapper)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.SemanticAnalyzer</name>
		<wmc>144</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>189</cbo>
		<rfc>931</rfc>
		<lcom>7034</lcom>
		<ca>8</ca>
		<ce>186</ce>
		<npm>17</npm>
		<lcom3>0.9345654345654345</lcom3>
		<loc>20878</loc>
		<dam>0.8571428571428571</dam>
		<moa>7</moa>
		<mfa>0.0</mfa>
		<cam>0.08033429984649497</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>143.79166666666666</amc>
		<cc>
			<method name="protected void reset()">1</method>
			<method name="private void genJoinOperatorTypeCheck(org.apache.hadoop.hive.ql.exec.Operator left, org.apache.hadoop.hive.ql.exec.Operator[] right)">1</method>
			<method name="private String getScriptProgName(String cmd)">2</method>
			<method name="static void _clinit_()">0</method>
			<method name="public static String generateErrorMessage(org.apache.hadoop.hive.ql.parse.ASTNode ast, String message)">1</method>
			<method name="private void doPhase1GetColumnAliasesFromSelect(org.apache.hadoop.hive.ql.parse.ASTNode selectExpr, org.apache.hadoop.hive.ql.parse.QBParseInfo qbp)">4</method>
			<method name="public void _init_(org.apache.hadoop.hive.conf.HiveConf conf)">0</method>
			<method name="private static int getPositionFromInternalName(String internalName)">1</method>
			<method name="private java.util.ArrayList getReduceKeysForReduceSink(java.util.List grpByExprs, String dest, org.apache.hadoop.hive.ql.parse.RowResolver reduceSinkInputRowResolver, org.apache.hadoop.hive.ql.parse.RowResolver reduceSinkOutputRowResolver, java.util.List outputKeyColumnNames, java.util.Map colExprMap)">1</method>
			<method name="private java.util.ArrayList getSortCols(String dest, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.metadata.Table tab, org.apache.hadoop.hive.ql.plan.TableDesc table_desc, org.apache.hadoop.hive.ql.exec.Operator input, boolean convert)">1</method>
			<method name="private boolean optimizeMapAggrGroupBy(String dest, org.apache.hadoop.hive.ql.parse.QB qb)">4</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genMapGroupByForSemijoin(org.apache.hadoop.hive.ql.parse.QB qb, java.util.ArrayList fields, org.apache.hadoop.hive.ql.exec.Operator inputOperatorInfo, org.apache.hadoop.hive.ql.plan.GroupByDesc$Mode mode)">1</method>
			<method name="private java.util.List getMapSideJoinTables(org.apache.hadoop.hive.ql.parse.QB qb)">5</method>
			<method name="private java.util.List getColumnExprsFromASTNode(org.apache.hadoop.hive.ql.parse.ASTNode node, org.apache.hadoop.hive.ql.parse.RowResolver inputRR)">1</method>
			<method name="private void mergeJoins(org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.parse.QBJoinTree parent, org.apache.hadoop.hive.ql.parse.QBJoinTree node, org.apache.hadoop.hive.ql.parse.QBJoinTree target, int pos)">22</method>
			<method name="private void mergeJoinTree(org.apache.hadoop.hive.ql.parse.QB qb)">5</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genSelectPlan(org.apache.hadoop.hive.ql.parse.ASTNode selExprList, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator input)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genHavingPlan(String dest, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator input)">1</method>
			<method name="static org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator getGenericUDAFEvaluator(String aggName, java.util.ArrayList aggParameters, org.apache.hadoop.hive.ql.parse.ASTNode aggTree, boolean isDistinct, boolean isAllColumns)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genReduceSinkPlan(String dest, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator input, int numReducers)">1</method>
			<method name="private java.util.List validateColumnNameUniqueness(java.util.List fieldSchemas)">1</method>
			<method name="private String processLateralView(org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.parse.ASTNode lateralView)">4</method>
			<method name="private static int getNumberOfReducers(org.apache.hadoop.hive.ql.plan.MapredWork mrwork, org.apache.hadoop.hive.conf.HiveConf conf)">3</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genLimitPlan(String dest, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator input, int limit)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genGroupByPlanMapGroupByOperator(org.apache.hadoop.hive.ql.parse.QB qb, String dest, org.apache.hadoop.hive.ql.exec.Operator inputOperatorInfo, org.apache.hadoop.hive.ql.plan.GroupByDesc$Mode mode, java.util.Map genericUDAFEvaluators)">1</method>
			<method name="private java.util.List doPhase1GetDistinctFuncExprs(java.util.HashMap aggregationTrees)">1</method>
			<method name="private void getReduceValuesForReduceSinkNoMapAgg(org.apache.hadoop.hive.ql.parse.QBParseInfo parseInfo, String dest, org.apache.hadoop.hive.ql.parse.RowResolver reduceSinkInputRowResolver, org.apache.hadoop.hive.ql.parse.RowResolver reduceSinkOutputRowResolver, java.util.List outputValueColumnNames, java.util.ArrayList reduceValues)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genGroupByPlanReduceSinkOperator2MR(org.apache.hadoop.hive.ql.parse.QBParseInfo parseInfo, String dest, org.apache.hadoop.hive.ql.exec.Operator groupByOperatorInfo, int numPartitionFields, int numReducers)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genJoinPlan(org.apache.hadoop.hive.ql.parse.QB qb, java.util.HashMap map)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genPostGroupByBodyPlan(org.apache.hadoop.hive.ql.exec.Operator curr, String dest, org.apache.hadoop.hive.ql.parse.QB qb)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genGroupByPlanMapAggr1MR(String dest, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator inputOperatorInfo)">1</method>
			<method name="private Integer checkQbpForGlobalLimit(org.apache.hadoop.hive.ql.parse.QB localQb)">19</method>
			<method name="void genLateralViewPlans(java.util.HashMap aliasToOpInfo, org.apache.hadoop.hive.ql.parse.QB qb)">1</method>
			<method name="private boolean isPresent(String[] list, String elem)">3</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genPlan(org.apache.hadoop.hive.ql.parse.QBExpr qbexpr)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genBodyPlan(org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator input)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genGroupByPlan2MRMultiGroupBy(String dest, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator input)">1</method>
			<method name="public void analyzeInternal(org.apache.hadoop.hive.ql.parse.ASTNode ast)">1</method>
			<method name="private boolean isJoinToken(org.apache.hadoop.hive.ql.parse.ASTNode node)">7</method>
			<method name="private org.apache.hadoop.hive.ql.plan.TableDesc getTableDescFromSerDe(org.apache.hadoop.hive.ql.parse.ASTNode child, String cols, String colTypes, boolean defaultCols)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genJoinOperatorChildren(org.apache.hadoop.hive.ql.parse.QBJoinTree join, org.apache.hadoop.hive.ql.exec.Operator left, org.apache.hadoop.hive.ql.exec.Operator[] right, java.util.HashSet omitOpts)">1</method>
			<method name="private java.util.List convertRowSchemaToViewSchema(org.apache.hadoop.hive.ql.parse.RowResolver rr)">3</method>
			<method name="private java.util.ArrayList getParitionColsFromBucketCols(String dest, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.metadata.Table tab, org.apache.hadoop.hive.ql.plan.TableDesc table_desc, org.apache.hadoop.hive.ql.exec.Operator input, boolean convert)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genUnionPlan(String unionalias, String leftalias, org.apache.hadoop.hive.ql.exec.Operator leftOp, String rightalias, org.apache.hadoop.hive.ql.exec.Operator rightOp)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genGroupByPlanGroupByOperator1(org.apache.hadoop.hive.ql.parse.QBParseInfo parseInfo, String dest, org.apache.hadoop.hive.ql.exec.Operator reduceSinkOperatorInfo, org.apache.hadoop.hive.ql.plan.GroupByDesc$Mode mode, java.util.Map genericUDAFEvaluators, boolean distPartAgg)">1</method>
			<method name="private void doPhase1GetAllAggregations(org.apache.hadoop.hive.ql.parse.ASTNode expressionTree, java.util.HashMap aggregations)">10</method>
			<method name="private org.apache.hadoop.hive.ql.parse.QBJoinTree genJoinTree(org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.parse.ASTNode joinParseTree)">1</method>
			<method name="static java.util.List getGroupByForClause(org.apache.hadoop.hive.ql.parse.QBParseInfo parseInfo, String dest)">9</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ExprNodeDesc genExprNodeDesc(org.apache.hadoop.hive.ql.parse.ASTNode expr, org.apache.hadoop.hive.ql.parse.RowResolver input)">1</method>
			<method name="private int findMergePos(org.apache.hadoop.hive.ql.parse.QBJoinTree node, org.apache.hadoop.hive.ql.parse.QBJoinTree target)">9</method>
			<method name="private void parseJoinCondPopulateAlias(org.apache.hadoop.hive.ql.parse.QBJoinTree joinTree, org.apache.hadoop.hive.ql.parse.ASTNode condn, java.util.ArrayList leftAliases, java.util.ArrayList rightAliases, java.util.ArrayList fields)">1</method>
			<method name="private void generateCountersTask(org.apache.hadoop.hive.ql.exec.Task task)">8</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genScriptPlan(org.apache.hadoop.hive.ql.parse.ASTNode trfm, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator input)">1</method>
			<method name="private void generateCountersOperator(org.apache.hadoop.hive.ql.exec.Operator op)">3</method>
			<method name="private java.util.List getCommonDistinctExprs(org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator input)">9</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genUDTFPlan(org.apache.hadoop.hive.ql.udf.generic.GenericUDTF genericUDTF, String outputTableAlias, java.util.ArrayList colAliases, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator input)">1</method>
			<method name="static org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$GenericUDAFInfo getGenericUDAFInfo(org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator evaluator, org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode emode, java.util.ArrayList aggParameters)">1</method>
			<method name="private java.util.LinkedHashMap doPhase1GetAggregationsFromSelect(org.apache.hadoop.hive.ql.parse.ASTNode selExpr)">2</method>
			<method name="private org.apache.hadoop.hive.ql.parse.QBJoinTree genUniqueJoinTree(org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.parse.ASTNode joinParseTree)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genSelectPlan(String dest, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator input)">1</method>
			<method name="private void breakTaskTree(org.apache.hadoop.hive.ql.exec.Task task)">6</method>
			<method name="public org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$Phase1Ctx initPhase1Ctx()">1</method>
			<method name="private void saveViewDefinition()">1</method>
			<method name="private void validateCreateTable(org.apache.hadoop.hive.ql.plan.CreateTableDesc crtTblDesc)">1</method>
			<method name="private void getMetaData(org.apache.hadoop.hive.ql.parse.QBExpr qbexpr)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genFilterPlan(String dest, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator input)">1</method>
			<method name="private void getLeafTasks(org.apache.hadoop.hive.ql.exec.Task task, java.util.HashSet leaves)">3</method>
			<method name="private void decideExecMode(java.util.List rootTasks, org.apache.hadoop.hive.ql.Context ctx, org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$GlobalLimitCtx globalLimitCtx)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genGroupByPlan1MRMultiReduceGB(java.util.List dests, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator input)">1</method>
			<method name="private org.apache.hadoop.hive.ql.parse.ASTNode analyzeCreateTable(org.apache.hadoop.hive.ql.parse.ASTNode ast, org.apache.hadoop.hive.ql.parse.QB qb)">1</method>
			<method name="private String processTable(org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.parse.ASTNode tabref)">1</method>
			<method name="public void doPhase1QBExpr(org.apache.hadoop.hive.ql.parse.ASTNode ast, org.apache.hadoop.hive.ql.parse.QBExpr qbexpr, String id, String alias)">1</method>
			<method name="private void setKeyDescTaskTree(org.apache.hadoop.hive.ql.exec.Task task)">6</method>
			<method name="private void validate(org.apache.hadoop.hive.ql.exec.Task task, boolean reworkMapredWork)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genLimitMapRedPlan(String dest, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator input, int limit, boolean extraMRStep)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator insertSelectForSemijoin(java.util.ArrayList fields, org.apache.hadoop.hive.ql.exec.Operator input)">1</method>
			<method name="private void getLeafTasks(java.util.List rootTasks, java.util.HashSet leaves)">2</method>
			<method name="private static boolean isRegex(String pattern)">4</method>
			<method name="private int getReducersBucketing(int totalFiles, int maxReducers)">2</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genReduceSinkPlanForSortingBucketing(org.apache.hadoop.hive.ql.metadata.Table tab, org.apache.hadoop.hive.ql.exec.Operator input, java.util.ArrayList sortCols, java.util.ArrayList partitionCols, int numReducers)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genGroupByPlanMapAggr2MR(String dest, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator inputOperatorInfo)">1</method>
			<method name="private void populateAliases(java.util.ArrayList leftAliases, java.util.ArrayList rightAliases, org.apache.hadoop.hive.ql.parse.ASTNode condn, org.apache.hadoop.hive.ql.parse.QBJoinTree joinTree, java.util.ArrayList leftSrc)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genGroupByPlan1MR(String dest, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator input)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genCommonGroupByPlanReduceSinkOperator(org.apache.hadoop.hive.ql.parse.QB qb, java.util.List dests, org.apache.hadoop.hive.ql.exec.Operator inputOperatorInfo)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genJoinReduceSinkChild(org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.parse.QBJoinTree joinTree, org.apache.hadoop.hive.ql.exec.Operator child, String srcName, int pos)">1</method>
			<method name="private void replaceViewReferenceWithDefinition(org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.metadata.Table tab, String tab_name, String alias)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genConversionOps(String dest, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator input)">3</method>
			<method name="private java.util.Map addDefaultProperties(java.util.Map tblProp)">7</method>
			<method name="public java.util.List getResultSchema()">1</method>
			<method name="static java.util.ArrayList getWritableObjectInspector(java.util.ArrayList exprs)">2</method>
			<method name="public void validate()">1</method>
			<method name="private void failIfColAliasExists(java.util.Set nameSet, String name)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genFileSinkPlan(String dest, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator input)">1</method>
			<method name="public org.apache.hadoop.hive.ql.plan.ExprNodeDesc genExprNodeDesc(org.apache.hadoop.hive.ql.parse.ASTNode expr, org.apache.hadoop.hive.ql.parse.RowResolver input, org.apache.hadoop.hive.ql.parse.TypeCheckCtx tcCtx)">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.Operator putOpInsertMap(org.apache.hadoop.hive.ql.exec.Operator op, org.apache.hadoop.hive.ql.parse.RowResolver rr)">1</method>
			<method name="private static org.apache.hadoop.hive.ql.udf.generic.GenericUDAFEvaluator$Mode groupByDescModeToUDAFMode(org.apache.hadoop.hive.ql.plan.GroupByDesc$Mode mode, boolean isDistinct)">4</method>
			<method name="public static String getColumnInternalName(int pos)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genGroupByPlanGroupByOperator(org.apache.hadoop.hive.ql.parse.QBParseInfo parseInfo, String dest, org.apache.hadoop.hive.ql.exec.Operator reduceSinkOperatorInfo, org.apache.hadoop.hive.ql.plan.GroupByDesc$Mode mode, java.util.Map genericUDAFEvaluators)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator insertSelectAllPlanForGroupBy(org.apache.hadoop.hive.ql.exec.Operator input)">1</method>
			<method name="private String fetchFilesNotInLocalFilesystem(String cmd)">3</method>
			<method name="private void parseStreamTables(org.apache.hadoop.hive.ql.parse.QBJoinTree joinTree, org.apache.hadoop.hive.ql.parse.QB qb)">3</method>
			<method name="private void setupStats(org.apache.hadoop.hive.ql.plan.TableScanDesc tsDesc, org.apache.hadoop.hive.ql.parse.QBParseInfo qbp, org.apache.hadoop.hive.ql.metadata.Table tab, String alias, org.apache.hadoop.hive.ql.parse.RowResolver rwsch)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genTablePlan(String alias, org.apache.hadoop.hive.ql.parse.QB qb)">1</method>
			<method name="public org.apache.hadoop.hive.ql.parse.ParseContext getParseContext()">1</method>
			<method name="private String getAliasId(String alias, org.apache.hadoop.hive.ql.parse.QB qb)">2</method>
			<method name="private java.util.List getDistinctColIndicesForReduceSink(org.apache.hadoop.hive.ql.parse.QBParseInfo parseInfo, String dest, java.util.ArrayList reduceKeys, org.apache.hadoop.hive.ql.parse.RowResolver reduceSinkInputRowResolver, org.apache.hadoop.hive.ql.parse.RowResolver reduceSinkOutputRowResolver, java.util.List outputKeyColumnNames)">1</method>
			<method name="static java.util.ArrayList getUDAFEvaluators(java.util.ArrayList aggs)">2</method>
			<method name="private org.apache.hadoop.hive.ql.plan.ExprNodeDesc genSamplePredicate(org.apache.hadoop.hive.ql.parse.TableSample ts, java.util.List bucketCols, boolean useBucketCols, String alias, org.apache.hadoop.hive.ql.parse.RowResolver rwsch, org.apache.hadoop.hive.ql.parse.QBMetaData qbm, org.apache.hadoop.hive.ql.plan.ExprNodeDesc planExpr)">1</method>
			<method name="private Class getRecordReader(org.apache.hadoop.hive.ql.parse.ASTNode node)">1</method>
			<method name="public void getMetaData(org.apache.hadoop.hive.ql.parse.QB qb)">1</method>
			<method name="private org.apache.hadoop.hive.ql.parse.ASTNode analyzeCreateView(org.apache.hadoop.hive.ql.parse.ASTNode ast, org.apache.hadoop.hive.ql.parse.QB qb)">1</method>
			<method name="private void processJoin(org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.parse.ASTNode join)">1</method>
			<method name="private Integer genColListRegex(String colRegex, String tabAlias, org.apache.hadoop.hive.ql.parse.ASTNode sel, java.util.ArrayList col_list, org.apache.hadoop.hive.ql.parse.RowResolver input, Integer pos, org.apache.hadoop.hive.ql.parse.RowResolver output, java.util.List aliases)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genGroupByPlan2MR(String dest, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator input)">1</method>
			<method name="private java.util.ArrayList genConvertCol(String dest, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.metadata.Table tab, org.apache.hadoop.hive.ql.plan.TableDesc table_desc, org.apache.hadoop.hive.ql.exec.Operator input, java.util.List posns, boolean convert)">1</method>
			<method name="private java.util.List getDistinctExprs(org.apache.hadoop.hive.ql.parse.QBParseInfo qbp, String dest, org.apache.hadoop.hive.ql.parse.RowResolver inputRR)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genGroupByPlanReduceSinkOperator(org.apache.hadoop.hive.ql.parse.QB qb, String dest, org.apache.hadoop.hive.ql.exec.Operator inputOperatorInfo, int numPartitionFields, int numReducers, boolean mapAggrDone)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genJoinOperator(org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.parse.QBJoinTree joinTree, java.util.HashMap map)">1</method>
			<method name="public org.apache.hadoop.hive.ql.exec.Operator genPlan(org.apache.hadoop.hive.ql.parse.QB qb)">1</method>
			<method name="private static String[] getColAlias(org.apache.hadoop.hive.ql.parse.ASTNode selExpr, String defaultName, org.apache.hadoop.hive.ql.parse.RowResolver inputRR, boolean includeFuncName, int colNum)">11</method>
			<method name="private boolean checkHoldDDLTime(org.apache.hadoop.hive.ql.parse.QB qb)">4</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genBucketingSortingDest(String dest, org.apache.hadoop.hive.ql.exec.Operator input, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.plan.TableDesc table_desc, org.apache.hadoop.hive.ql.metadata.Table dest_tab, org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$SortBucketRSCtx ctx)">1</method>
			<method name="private java.util.List getCommonGroupByDestGroups(org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator input)">1</method>
			<method name="private void genMapRedTasks(org.apache.hadoop.hive.ql.parse.QB qb)">1</method>
			<method name="private boolean distinctExprsExists(org.apache.hadoop.hive.ql.parse.QB qb)">2</method>
			<method name="private Class getDefaultRecordReader()">1</method>
			<method name="private String processSubQuery(org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.parse.ASTNode subq)">1</method>
			<method name="private void parseJoinCondition(org.apache.hadoop.hive.ql.parse.QBJoinTree joinTree, org.apache.hadoop.hive.ql.parse.ASTNode joinCond, java.util.ArrayList leftSrc)">1</method>
			<method name="private void LVmergeRowResolvers(org.apache.hadoop.hive.ql.parse.RowResolver source, org.apache.hadoop.hive.ql.parse.RowResolver dest, java.util.ArrayList outputInternalColNames)">2</method>
			<method name="static java.util.ArrayList getTypeInfo(java.util.ArrayList exprs)">2</method>
			<method name="private Class getRecordWriter(org.apache.hadoop.hive.ql.parse.ASTNode node)">1</method>
			<method name="private void breakOperatorTree(org.apache.hadoop.hive.ql.exec.Operator topOp)">4</method>
			<method name="public org.apache.hadoop.hive.ql.parse.RowResolver getRowResolver(org.apache.hadoop.hive.ql.exec.Operator opt)">1</method>
			<method name="private boolean mergeJoinNodes(org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.parse.QBJoinTree parent, org.apache.hadoop.hive.ql.parse.QBJoinTree node, org.apache.hadoop.hive.ql.parse.QBJoinTree target)">3</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genFilterPlan(org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.parse.ASTNode condn, org.apache.hadoop.hive.ql.exec.Operator input)">1</method>
			<method name="public void init(org.apache.hadoop.hive.ql.parse.ParseContext pctx)">1</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator genGroupByPlanGroupByOperator2MR(org.apache.hadoop.hive.ql.parse.QBParseInfo parseInfo, String dest, org.apache.hadoop.hive.ql.exec.Operator reduceSinkOperatorInfo2, org.apache.hadoop.hive.ql.plan.GroupByDesc$Mode mode, java.util.Map genericUDAFEvaluators)">1</method>
			<method name="public boolean doPhase1(org.apache.hadoop.hive.ql.parse.ASTNode ast, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.parse.SemanticAnalyzer$Phase1Ctx ctx_1)">1</method>
			<method name="private void pushJoinFilters(org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.parse.QBJoinTree joinTree, java.util.HashMap map)">1</method>
			<method name="org.apache.hadoop.hive.ql.exec.Operator genConversionSelectOperator(String dest, org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator input, org.apache.hadoop.hive.ql.plan.TableDesc table_desc, org.apache.hadoop.hive.ql.plan.DynamicPartitionCtx dpCtx)">1</method>
			<method name="private boolean matchExprLists(java.util.List list1, java.util.List list2)">3</method>
			<method name="private org.apache.hadoop.hive.ql.exec.Operator createCommonReduceSink(org.apache.hadoop.hive.ql.parse.QB qb, org.apache.hadoop.hive.ql.exec.Operator input)">1</method>
			<method name="static org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector[] getStandardObjectInspector(java.util.ArrayList exprs)">2</method>
			<method name="private String getScriptArgs(String cmd)">2</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.typeinfo.TypeInfo</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>5</noc>
		<cbo>83</cbo>
		<rfc>7</rfc>
		<lcom>15</lcom>
		<ca>82</ca>
		<ce>1</ce>
		<npm>5</npm>
		<lcom3>1.2</lcom3>
		<loc>13</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.5833333333333334</cam>
		<ic>1</ic>
		<cbm>1</cbm>
		<amc>1.0</amc>
		<cc>
			<method name="public abstract String getTypeName()">1</method>
			<method name="protected void _init_()">0</method>
			<method name="public abstract boolean equals(Object)">1</method>
			<method name="public abstract int hashCode()">1</method>
			<method name="public String toString()">1</method>
			<method name="public abstract org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector$Category getCategory()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.lazy.LazyBinary</name>
		<wmc>4</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>10</cbo>
		<rfc>18</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>9</ce>
		<npm>2</npm>
		<lcom3>0.6666666666666666</lcom3>
		<loc>78</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4666666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>18.25</amc>
		<cc>
			<method name="void _init_(org.apache.hadoop.hive.serde2.lazy.objectinspector.primitive.LazyBinaryObjectInspector oi)">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.lazy.LazyBinary other)">0</method>
			<method name="public void init(org.apache.hadoop.hive.serde2.lazy.ByteArrayRef bytes, int start, int length)">3</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.UnparseTranslator</name>
		<wmc>9</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>14</cbo>
		<rfc>44</rfc>
		<lcom>0</lcom>
		<ca>4</ca>
		<ce>10</ce>
		<npm>1</npm>
		<lcom3>0.53125</lcom3>
		<loc>369</loc>
		<dam>0.75</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.4375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>39.55555555555556</amc>
		<cc>
			<method name="void addIdentifierTranslation(org.apache.hadoop.hive.ql.parse.ASTNode identifier)">4</method>
			<method name="void addTableNameTranslation(org.apache.hadoop.hive.ql.parse.ASTNode tableName)">8</method>
			<method name="boolean isEnabled()">1</method>
			<method name="public void _init_()">0</method>
			<method name="static void _clinit_()">0</method>
			<method name="void enable()">1</method>
			<method name="void addCopyTranslation(org.apache.hadoop.hive.ql.parse.ASTNode targetNode, org.apache.hadoop.hive.ql.parse.ASTNode sourceNode)">3</method>
			<method name="void addTranslation(org.apache.hadoop.hive.ql.parse.ASTNode node, String replacementText)">21</method>
			<method name="void applyTranslations(org.antlr.runtime.TokenRewriteStream tokenRewriteStream)">4</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.optimizer.unionproc.UnionProcContext$UnionParseContext</name>
		<wmc>12</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>7</cbo>
		<rfc>13</rfc>
		<lcom>30</lcom>
		<ca>7</ca>
		<ce>0</ce>
		<npm>12</npm>
		<lcom3>0.8181818181818182</lcom3>
		<loc>145</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6388888888888888</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>10.583333333333334</amc>
		<cc>
			<method name="public boolean getMapOnlySubq(int pos)">1</method>
			<method name="public int getNumInputs()">1</method>
			<method name="public void setMapOnlySubq(int pos, boolean mapOnlySubq)">1</method>
			<method name="public void setRootTask(int pos, boolean rootTask)">1</method>
			<method name="public boolean allMapOnlySubQ()">4</method>
			<method name="public void setMapJoinSubq(int pos, boolean mapJoinSubq)">2</method>
			<method name="public boolean getMapJoinQuery()">1</method>
			<method name="public void setNumInputs(int numInputs)">1</method>
			<method name="public boolean allMapOnlySubQSet()">4</method>
			<method name="public boolean getMapJoinSubq(int pos)">1</method>
			<method name="public boolean getRootTask(int pos)">1</method>
			<method name="public void _init_(int numInputs)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.parse.HiveParser$viewName_return</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>3</rfc>
		<lcom>1</lcom>
		<ca>1</ca>
		<ce>2</ce>
		<npm>2</npm>
		<lcom3>1.0</lcom3>
		<loc>9</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>1.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>3.0</amc>
		<cc>
			<method name="public void _init_()">0</method>
			<method name="public Object getTree()">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.history.HiveHistoryViewer</name>
		<wmc>6</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>21</rfc>
		<lcom>1</lcom>
		<ca>0</ca>
		<ce>6</ce>
		<npm>5</npm>
		<lcom3>0.7</lcom3>
		<loc>173</loc>
		<dam>0.5</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.375</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>27.166666666666668</amc>
		<cc>
			<method name="public java.util.Map getTaskInfoMap()">1</method>
			<method name="public String getSessionId()">1</method>
			<method name="public void _init_(String path)">0</method>
			<method name="public java.util.Map getJobInfoMap()">1</method>
			<method name="void init()">1</method>
			<method name="public void handle(org.apache.hadoop.hive.ql.history.HiveHistory$RecordTypes recType, java.util.Map values)">9</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.plan.DescTableDesc</name>
		<wmc>15</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>6</cbo>
		<rfc>17</rfc>
		<lcom>69</lcom>
		<ca>4</ca>
		<ce>2</ce>
		<npm>15</npm>
		<lcom3>0.9285714285714286</lcom3>
		<loc>88</loc>
		<dam>0.375</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.30666666666666664</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>4.333333333333333</amc>
		<cc>
			<method name="public void setPartSpecs(java.util.HashMap partSpec)">1</method>
			<method name="public java.util.HashMap getPartSpec()">1</method>
			<method name="public String getResFile()">1</method>
			<method name="public void _init_(org.apache.hadoop.fs.Path resFile, String tableName, java.util.HashMap partSpec)">0</method>
			<method name="public String getTable()">1</method>
			<method name="public void setResFile(String resFile)">1</method>
			<method name="public void _init_()">0</method>
			<method name="public boolean isFormatted()">1</method>
			<method name="public static String getSchema()">1</method>
			<method name="public void setExt(boolean isExt)">1</method>
			<method name="public String getTableName()">1</method>
			<method name="public boolean isExt()">1</method>
			<method name="public void setTableName(String tableName)">1</method>
			<method name="public void setPartSpec(java.util.HashMap partSpec)">1</method>
			<method name="public void setFormatted(boolean isFormat)">1</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDeTypeBase</name>
		<wmc>12</wmc>
		<dit>0</dit>
		<noc>12</noc>
		<cbo>21</cbo>
		<rfc>16</rfc>
		<lcom>66</lcom>
		<ca>15</ca>
		<ce>6</ce>
		<npm>12</npm>
		<lcom3>1.0909090909090908</lcom3>
		<loc>43</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.2916666666666667</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>2.5</amc>
		<cc>
			<method name="public void initialize()">1</method>
			<method name="public abstract Object deserialize(Object, org.apache.thrift.protocol.TProtocol)">1</method>
			<method name="public boolean isList()">1</method>
			<method name="public byte getType()">1</method>
			<method name="public Class getRealType()">1</method>
			<method name="public boolean isPrimitive()">1</method>
			<method name="public void _init_(org.apache.hadoop.hive.serde2.dynamic_type.thrift_grammar p, int i)">0</method>
			<method name="public String toString()">1</method>
			<method name="public abstract void serialize(Object, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector, org.apache.thrift.protocol.TProtocol)">1</method>
			<method name="public boolean isMap()">1</method>
			<method name="public Object get(Object obj)">1</method>
			<method name="public void _init_(int i)">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.UDFLpad</name>
		<wmc>2</wmc>
		<dit>0</dit>
		<noc>0</noc>
		<cbo>3</cbo>
		<rfc>9</rfc>
		<lcom>0</lcom>
		<ca>0</ca>
		<ce>3</ce>
		<npm>2</npm>
		<lcom3>0.0</lcom3>
		<loc>108</loc>
		<dam>1.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.6666666666666666</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>52.5</amc>
		<cc>
			<method name="public org.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text s, org.apache.hadoop.io.IntWritable n, org.apache.hadoop.io.Text pad)">10</method>
			<method name="public void _init_()">0</method>
		</cc>
	</class>
	<class>
		<name>org.apache.thrift.async.TAsyncClientManager$1</name>
		<wmc>0</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>0</rfc>
		<lcom>0</lcom>
		<ca>2</ca>
		<ce>0</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>0</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>0.0</amc>
		<cc>
		</cc>
	</class>
	<class>
		<name>org.apache.hadoop.hive.ql.udf.generic.GenericUDAFSum$1</name>
		<wmc>1</wmc>
		<dit>1</dit>
		<noc>0</noc>
		<cbo>2</cbo>
		<rfc>3</rfc>
		<lcom>0</lcom>
		<ca>1</ca>
		<ce>1</ce>
		<npm>0</npm>
		<lcom3>2.0</lcom3>
		<loc>70</loc>
		<dam>0.0</dam>
		<moa>0</moa>
		<mfa>0.0</mfa>
		<cam>0.0</cam>
		<ic>0</ic>
		<cbm>0</cbm>
		<amc>68.0</amc>
		<cc>
			<method name="static void _clinit_()">0</method>
		</cc>
	</class>
</classes>